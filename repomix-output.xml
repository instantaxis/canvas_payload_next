This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.
The content has been processed where line numbers have been added.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*.ts, **/*.tsx, **/*.js, **/*.jsx, **/*.json, **/*.md, **/*.yml, **/*.yaml, **/*.env.example, **/*.config.*, **/*.mjs, **/*.mts
- Files matching these patterns are excluded: node_modules/**, .git/**, dist/**, build/**, .next/**, coverage/**, *.log, *.lock, pnpm-lock.yaml, yarn.lock, package-lock.json, .env, .env.local, .env.production, **/.DS_Store, **/Thumbs.db, **/*.min.js, **/*.min.css, **/payload-types.ts, **/*.d.ts, repomix-output.*
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Line numbers have been added to the beginning of each line
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<user_provided_header>
Canvas Payload v3 Restaurant Management System - Complete Codebase
</user_provided_header>

<directory_structure>
.clinerules/
  cline_rules.md
  dev_workflow.md
  self_improve.md
  taskmaster.md
.cursor/
  mcp.json
.gemini/
  settings.json
.github/
  instructions/
    dev_workflow.md
    self_improve.md
    taskmaster.md
    vscode_rules.md
.roo/
  rules/
    dev_workflow.md
    roo_rules.md
    self_improve.md
    taskmaster.md
  mcp.json
.taskmaster/
  reports/
    task-complexity-report.json
  tasks/
    tasks.json
  config.json
  state.json
.trae/
  rules/
    dev_workflow.md
    self_improve.md
    taskmaster.md
    trae_rules.md
.windsurf/
  rules/
    dev_workflow.md
    self_improve.md
    taskmaster.md
    windsurf_rules.md
  mcp.json
llm_context/
  forms/
    complex_forms.md
    README.md
  llm_agent_insights/
    code_documentation_standards.md
    README.md
  mcp_tools/
    context7_advanced.md
    README.md
    repomix_automation.md
  payload3/
    best_practices.md
    data_models.md
    README.md
    user_documentation.md
  responses/
    prompt_template.md
    setup_verification.md
    typescript_error_resolution_v2.md
    typescript_errors.md
  state_management/
    README.md
  tanstack/
    README.md
  ui_patterns/
    README.md
  README.md
  repomix_integration.md
open_tasks/
  api-and-data-fetching/
    01_audit_existing_data_fetching_patterns.md
    02_implement_ssr_hydration.md
    03_optimize_pagination_strategies.md
    04_enhance_caching_strategies.md
    05_implement_optimistic_updates.md
    06_secure_authentication_aware_queries.md
    07_refactor_table_data_fetching.md
    08_establish_monitoring_and_metrics.md
  ci-cd-and-deployment/
    01_dockerfile_security_audit.md
    02_analyze_ci_cd_pipeline.md
    03_implement_secret_management.md
    04_setup_environment_configuration.md
    05_integrate_monitoring.md
    06_document_and_validate_workflows.md
  database-and-schema/
    01_export_payload_and_supabase_schemas.md
    02_analyze_and_document_schema_differences.md
    03_generate_migration_scripts.md
    04_apply_and_validate_migrations.md
    05_document_and_version_control_schema_changes.md
  documentation-and-guidelines/
    01_implement_automated_typescript_enforcement.md
    02_enforce_code_documentation_standards.md
  forms-and-validation/
    01_audit_and_catalog_form_implementations.md
    02_review_and_validate_form_composition.md
    03_assess_dynamic_fields_and_file_uploads.md
    04_review_accessibility_and_ux.md
    05_update_subtasks_and_documentation.md
  logging-and-monitoring/
    01_research_supabase_logging_options.md
    02_define_logging_schema.md
  security-and-authentication/
    01_implement_jwt_revocation.md
    02_enhance_password_and_cookie_security.md
    03_apply_rate_limiting_and_input_validation.md
    04_refactor_middleware_and_centralize_access_control.md
    05_accessibility_testing_and_docker_hardening.md
payload-backend/
  .next/
    server/
      static/
        webpack/
          761622449e9f097a.edge-runtime-webpack.hot-update.json
      app-paths-manifest.json
      interception-route-rewrite-manifest.js
      middleware-manifest.json
      pages-manifest.json
      server-reference-manifest.js
      server-reference-manifest.json
    types/
      package.json
prompts/
  architectural_review.md
  git_update.md
  open_hands_agent.md
scripts/
  merge-tasks.js
src/
  access/
    index.ts
    rbac.ts
  app/
    (frontend)/
      components/
        forms/
          ArrayField.tsx
          DynamicForm.test.tsx
          DynamicForm.tsx
          FieldRegistry.test.tsx
          FieldRegistry.tsx
          FormWrapper.tsx
          InputField.tsx
          LoginForm.tsx
          PasswordResetForm.tsx
          PasswordResetRequestForm.tsx
          SelectField.tsx
          TabbedField.tsx
        ErrorBoundary.tsx
        LoadingSpinner.tsx
        PermissionGate.tsx
      context/
        AuthContext.tsx
      hooks/
        useAuth.ts
        useAuthQuery.ts
        useCollectionSchema.ts
        useCrudMutation.ts
        useFormState.ts
        useFormSubmission.ts
      lib/
        HydrationProvider.tsx
        queryClient.ts
        QueryClientProviderWrapper.tsx
        queryFactories.ts
      register/
        page.tsx
      actions.ts
      layout.tsx
      page.tsx
    (payload)/
      admin/
        [[...segments]]/
          not-found.tsx
          page.tsx
        importMap.js
      api/
        auth/
          login/
            route.ts
          logout/
            route.ts
          password-reset/
            route.ts
          password-reset-request/
            route.ts
          refresh-token/
            route.ts
        graphql/
          route.ts
        graphql-playground/
          route.ts
        media/
          upload/
            route.ts
        users/
          me/
            route.ts
        v1/
          [...slug]/
            route.ts
      layout.tsx
    api/
      users/
        login/
          route.ts
      v1/
        my-route/
          route.ts
  collections/
    Contacts.ts
    DietaryRestrictions.ts
    DrinkMenuItems.ts
    DrinkSubcategories.ts
    EmployeeRatings.ts
    Features.ts
    HotspotLogins.ts
    Incidents.ts
    Jobs.ts
    Locations.ts
    ManagerReports.ts
    Media.ts
    Messages.ts
    MessageTypes.ts
    QrFeedback.ts
    Questions.ts
    ReviewKeywords.ts
    Reviews.ts
    ServerReports.ts
    ShiftTypes.ts
    Upgrades.ts
    UpgradeTypes.ts
    Users.ts
  components/
    ui/
      button.tsx
      form.tsx
      input.tsx
      label.tsx
      select.tsx
      toaster.tsx
      use-toast.ts
  lib/
    constants.ts
    payloadClient.ts
    utils.ts
  middleware/
    authentication.ts
    cors.ts
    csrfProtection.ts
    rateLimiting.ts
    securityHeaders.ts
  migrations/
    20250702_042115_initial_schema.json
    20250702_042115_initial_schema.ts
    index.ts
  schemas/
    loginSchema.ts
    registerSchema.ts
  types/
    auth.ts
    restaurant.ts
  utils/
    index.ts
  middleware.ts
  payload.config.ts
tests/
  e2e/
    frontend.e2e.spec.ts
  int/
    api.int.spec.ts
    DynamicForm.int.spec.tsx
    DynamicFormBuilder.int.spec.tsx
.env.example
.prettierrc.json
AGENTS.md
CLAUDE.md
docker-compose.yml
eslint.config.mjs
next.config.mjs
package.json
playwright.config.ts
repomix.config.json
tasks-updated.json
tsconfig.json
vitest.config.mts
vitest.setup.ts
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="open_tasks/database-and-schema/01_export_payload_and_supabase_schemas.md">
 1: # Task: Export Payload and Supabase Schemas
 2: 
 3: ## Overview
 4: This task involves extracting the current schema definitions from both Payload CMS and Supabase. This is the first step in identifying and resolving any discrepancies between the two schemas.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses Payload CMS for its data models and Supabase as its underlying database.
10: 
11: ### Relevant Libraries & Tools
12: - **Payload CMS**: For exporting the schema as JSON.
13: - **Supabase CLI**: For dumping the database schema.
14: 
15: ### Best Practices
16: - **Schema-Only Dump**: When exporting the Supabase schema, use the `--schema-only` flag to avoid exporting any data.
17: - **Filtering**: Filter the Supabase schema dump to include only the relevant schemas (e.g., `public`).
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 32.1
22: **Title**: Export Payload and Supabase Schemas
23: **Description**: Extract the current schema definitions from both Payload CMS and Supabase. For Payload, use the `dump` command to export the schema as JSON, referencing collections, fields, and relationships as defined in `llm_context/payload3/data_models.md`. For Supabase, use `pg_dump --schema-only` via the Supabase CLI, filtering to relevant schemas.
24: **Dependencies**: []
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Payload Schema Export**: The Payload CMS schema is successfully exported as a JSON file.
29: 2.  **Supabase Schema Export**: The Supabase database schema is successfully exported as a SQL file.
30: 3.  **Testing**:
31:     - The exported Payload schema is reviewed to ensure that it accurately reflects the collections and fields defined in the codebase.
32:     - The exported Supabase schema is reviewed to ensure that it accurately reflects the current state of the database.
33: 
34: ## Progress Report
35: [Agent will fill this section]
36: 
37: ### Completed Tasks:
38: - Task ID [X]: [Status] - [Brief description of what was done]
39: 
40: ### Issues Encountered:
41: - [Document any problems or blockers]
42: 
43: ### Files Modified/Created:
44: - [List all files changed]
45: 
46: ### Ready for Commit: [Yes/No]
47: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/database-and-schema/02_analyze_and_document_schema_differences.md">
 1: # Task: Analyze and Document Schema Differences
 2: 
 3: ## Overview
 4: This task involves performing a structural and constraint-based comparison between the exported Payload and Supabase schemas. The goal is to generate a delta report identifying all discrepancies.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses Payload CMS for its data models and Supabase as its underlying database.
10: 
11: ### Relevant Libraries & Tools
12: - **Schema comparison tools**: (e.g., `diff`, `pgdiff`) can be used to automate the comparison process.
13: 
14: ### Best Practices
15: - **Structural Comparison**: Compare tables, columns, and data types.
16: - **Constraint Comparison**: Compare primary keys, foreign keys, indexes, and other constraints.
17: - **Detailed Reporting**: The delta report should be detailed enough to be used as a basis for generating migration scripts.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 32.2
22: **Title**: Analyze and Document Schema Differences
23: **Description**: Perform a structural and constraint-based comparison between the exported Payload and Supabase schemas. Generate a delta report identifying missing tables, field type mismatches (e.g., `richText` vs `TEXT`), relationship inconsistencies, and constraint differences.
24: **Dependencies**: [32.1]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Schema Comparison**: A thorough comparison of the two schemas is performed.
29: 2.  **Delta Report**: A delta report is generated that clearly documents all differences between the two schemas.
30: 3.  **Testing**:
31:     - The delta report is reviewed for accuracy and completeness.
32:     - The report is used to manually verify a subset of the identified differences.
33: 
34: ## Progress Report
35: [Agent will fill this section]
36: 
37: ### Completed Tasks:
38: - Task ID [X]: [Status] - [Brief description of what was done]
39: 
40: ### Issues Encountered:
41: - [Document any problems or blockers]
42: 
43: ### Files Modified/Created:
44: - [List all files changed]
45: 
46: ### Ready for Commit: [Yes/No]
47: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/database-and-schema/03_generate_migration_scripts.md">
 1: # Task: Generate Migration Scripts for Supabase
 2: 
 3: ## Overview
 4: This task involves creating SQL migration scripts to synchronize the Supabase database schema with the Payload CMS data model. These scripts will be based on the differences documented in the delta report from the previous task.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses Payload CMS for its data models and Supabase as its underlying database.
10: 
11: ### Relevant Libraries & Tools
12: - **SQL**: For writing the migration scripts.
13: - **Supabase CLI**: For applying the migrations.
14: 
15: ### Best Practices
16: - **Idempotent Scripts**: Write migration scripts that are idempotent, meaning they can be run multiple times without causing errors.
17: - **Transactional Migrations**: Wrap migrations in a transaction to ensure that they are applied atomically.
18: - **Reversible Migrations**: For each migration, create a corresponding "down" migration that can be used to revert the changes.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 32.3
23: **Title**: Generate Migration Scripts for Supabase
24: **Description**: Based on the documented differences, create SQL migration scripts to synchronize Supabase's schema with Payload's data model. Scripts should handle table/column creation, type conversions, and constraint synchronization.
25: **Dependencies**: [32.2]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Migration Scripts**: SQL migration scripts are created to address all the differences identified in the delta report.
30: 2.  **Down Migrations**: For each migration script, a corresponding "down" migration is created.
31: 3.  **Testing**:
32:     - The migration scripts are reviewed for correctness and completeness.
33:     - The scripts are tested on a development database to ensure that they work as expected.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/database-and-schema/04_apply_and_validate_migrations.md">
 1: # Task: Apply and Validate Migrations on Supabase
 2: 
 3: ## Overview
 4: This task involves applying the generated migration scripts to the Supabase database and validating that the resulting schema is correct.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses Payload CMS for its data models and Supabase as its underlying database.
10: 
11: ### Relevant Libraries & Tools
12: - **Supabase CLI**: For applying the migrations.
13: - **Payload CMS**: For validating the schema.
14: 
15: ### Best Practices
16: - **Pre-Execution Checks**: Before applying migrations, use `supabase migration lint` to check for any potential issues.
17: - **Atomic Migrations**: Apply migrations atomically to ensure that the database is not left in an inconsistent state.
18: - **Schema Validation**: After applying migrations, use Payload's `validate` command to ensure that the database schema is in sync with the Payload collections.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 32.4
23: **Title**: Apply and Validate Migrations on Supabase
24: **Description**: Run pre-execution checks on the migration scripts using `supabase migration lint`, then apply the migrations atomically with `supabase migration up`. Validate the resulting schema using Payload's `validate` command and test relationship queries.
25: **Dependencies**: [32.3]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Pre-Execution Checks**: The `supabase migration lint` command is run on the migration scripts, and all reported issues are addressed.
30: 2.  **Migration Application**: The migrations are successfully applied to the Supabase database.
31: 3.  **Schema Validation**: The `payload validate` command is run, and it reports no issues.
32: 4.  **Relationship Testing**: All relationship queries are tested to ensure that they are working correctly.
33: 
34: ## Progress Report
35: [Agent will fill this section]
36: 
37: ### Completed Tasks:
38: - Task ID [X]: [Status] - [Brief description of what was done]
39: 
40: ### Issues Encountered:
41: - [Document any problems or blockers]
42: 
43: ### Files Modified/Created:
44: - [List all files changed]
45: 
46: ### Ready for Commit: [Yes/No]
47: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/database-and-schema/05_document_and_version_control_schema_changes.md">
 1: # Task: Document and Version-Control Schema Changes
 2: 
 3: ## Overview
 4: This task involves committing the updated `schema.sql`, Payload configs, and migration scripts to the project's Git repository. This will ensure that all schema changes are version-controlled and can be easily tracked and reverted if necessary.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses Git for version control.
10: 
11: ### Relevant Libraries & Tools
12: - **Git**: For version control.
13: 
14: ### Best Practices
15: - **Clear Commit Messages**: Write clear and descriptive commit messages that explain the purpose of the schema changes.
16: - **Atomic Commits**: Each commit should represent a single, logical change to the schema.
17: - **Reverse Migrations**: For each migration, include a corresponding "down" migration that can be used to revert the changes.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 32.5
22: **Title**: Document and Version-Control Schema Changes
23: **Description**: Commit the updated `schema.sql`, Payload configs, and migration scripts to the project's Git repository. Include a clear commit message and store reverse migration scripts for rollback capability.
24: **Dependencies**: [32.4]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Git Commit**: All schema-related changes are committed to the Git repository with a clear and descriptive commit message.
29: 2.  **Rollback Capability**: For each migration, a corresponding "down" migration is created and committed.
30: 3.  **Testing**:
31:     - The Git history is reviewed to ensure that all schema changes are correctly version-controlled.
32:     - A "down" migration is tested on a development database to verify that it correctly reverts the schema changes.
33: 
34: ## Progress Report
35: [Agent will fill this section]
36: 
37: ### Completed Tasks:
38: - Task ID [X]: [Status] - [Brief description of what was done]
39: 
40: ### Issues Encountered:
41: - [Document any problems or blockers]
42: 
43: ### Files Modified/Created:
44: - [List all files changed]
45: 
46: ### Ready for Commit: [Yes/No]
47: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/logging-and-monitoring/01_research_supabase_logging_options.md">
 1: # Task: Research Supabase Logging Options
 2: 
 3: ## Overview
 4: This task involves investigating Supabase's native logging capabilities and evaluating Log Drains for exporting logs to external systems. This research will inform the design of a centralized logging solution.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses Supabase for its database and other backend services.
10: 
11: ### Relevant Libraries & Tools
12: - **Supabase**: The backend-as-a-service provider.
13: - **Datadog, Sentry, or similar**: (Potential) external logging systems.
14: 
15: ### Best Practices
16: - **Centralized Logging**: Consolidate logs from all services into a single, searchable location.
17: - **Structured Logging**: Use a structured logging format (e.g., JSON) to make logs easier to parse and analyze.
18: - **Log Levels**: Use different log levels (e.g., `info`, `warn`, `error`) to categorize logs and filter them effectively.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 25.1
23: **Title**: Research Supabase Logging Options
24: **Description**: Investigate Supabase's native logging capabilities (Logs Explorer) for auth, database, storage, and realtime logs. Evaluate Log Drains for exporting logs to external systems such as Datadog, including compliance and integration with custom HTTP endpoints.
25: **Dependencies**: []
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Supabase Logging Capabilities Documented**: A document is created that details Supabase's native logging capabilities, including the types of logs available and how to access them.
30: 2.  **Log Drain Evaluation**: A report is generated that evaluates the feasibility of using Supabase Log Drains to export logs to an external system. The report should include a comparison of different external logging systems.
31: 3.  **Recommendations**: A set of recommendations is provided for the best approach to implementing a centralized logging solution.
32: 
33: ## Progress Report
34: [Agent will fill this section]
35: 
36: ### Completed Tasks:
37: - Task ID [X]: [Status] - [Brief description of what was done]
38: 
39: ### Issues Encountered:
40: - [Document any problems or blockers]
41: 
42: ### Files Modified/Created:
43: - [List all files changed]
44: 
45: ### Ready for Commit: [Yes/No]
46: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/logging-and-monitoring/02_define_logging_schema.md">
 1: # Task: Define Logging Schema
 2: 
 3: ## Overview
 4: This task involves designing a standardized log entry schema to be used across all services. This will ensure that logs are consistent and easy to parse, and that they include all necessary information for debugging and auditing purposes.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a centralized logging solution.
10: 
11: ### Relevant Libraries & Tools
12: - **JSON**: The recommended format for structured logging.
13: 
14: ### Best Practices
15: - **Standardized Schema**: Use a standardized schema for all log entries to ensure consistency.
16: - **User Context**: Include user context (e.g., user ID, IP address) in all relevant log entries.
17: - **Payload Diffs**: For mutation logs, include a diff of the data before and after the change.
18: - **Compliance**: Ensure that the logging schema meets all relevant audit and compliance requirements.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 25.2
23: **Title**: Define Logging Schema
24: **Description**: Design a standardized log entry schema to be used across all services, ensuring inclusion of user context, payload diffs for mutations, and compliance with audit requirements.
25: **Dependencies**: [25.1]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Logging Schema Definition**: A document is created that defines the standardized logging schema.
30: 2.  **Schema Review**: The schema is reviewed to ensure that it meets all requirements.
31: 3.  **Testing**:
32:     - The schema is used to create a sample log entry, which is then reviewed for correctness and completeness.
33: 
34: ## Progress Report
35: [Agent will fill this section]
36: 
37: ### Completed Tasks:
38: - Task ID [X]: [Status] - [Brief description of what was done]
39: 
40: ### Issues Encountered:
41: - [Document any problems or blockers]
42: 
43: ### Files Modified/Created:
44: - [List all files changed]
45: 
46: ### Ready for Commit: [Yes/No]
47: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="src/app/api/users/login/route.ts">
1: import { NextRequest, NextResponse } from 'next/server'
</file>

<file path="src/lib/constants.ts">
1: export const AUTH_COOKIE_NAME = 'auth_token'
2: export const TOKEN_EXPIRATION = 60 * 60 * 24 * 7 // 7 days in seconds
</file>

<file path="src/lib/payloadClient.ts">
 1: import { getPayload } from 'payload'
 2: import config from '@payload-config'
 3: 
 4: let cachedPayload: any = null
 5: 
 6: /**
 7:  * Get a cached Payload client instance
 8:  * This ensures we don't create multiple instances in serverless environments
 9:  */
10: export const getPayloadClient = () => {
11:   if (cachedPayload) {
12:     return cachedPayload
13:   }
14: 
15:   cachedPayload = getPayload({ config })
16:   return cachedPayload
17: }
18: 
19: /**
20:  * Initialize Payload client (useful for server startup)
21:  */
22: export const initPayload = async () => {
23:   if (!cachedPayload) {
24:     cachedPayload = await getPayload({ config })
25:   }
26:   return cachedPayload
27: }
28: 
29: export default getPayloadClient
</file>

<file path=".clinerules/dev_workflow.md">
  1: ---
  2: description: Guide for using Taskmaster to manage task-driven development workflows
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Development Workflow
  8: 
  9: This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.
 10: 
 11: - **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
 12: - **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.
 13: 
 14: ## The Basic Loop
 15: The fundamental development cycle you will facilitate is:
 16: 1.  **`list`**: Show the user what needs to be done.
 17: 2.  **`next`**: Help the user decide what to work on.
 18: 3.  **`show <id>`**: Provide details for a specific task.
 19: 4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
 20: 5.  **Implement**: The user writes the code and tests.
 21: 6.  **`update-subtask`**: Log progress and findings on behalf of the user.
 22: 7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
 23: 8.  **Repeat**.
 24: 
 25: All your standard command executions should operate on the user's current task context, which defaults to `master`.
 26: 
 27: ---
 28: 
 29: ## Standard Development Workflow Process
 30: 
 31: ### Simple Workflow (Default Starting Point)
 32: 
 33: For new projects or when users are getting started, operate within the `master` tag context:
 34: 
 35: -   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
 36: -   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules cline,windsurf`) or manage them later with `task-master rules add/remove` commands  
 37: -   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
 38: -   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
 39: -   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
 40: -   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
 41: -   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
 42: -   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
 43: -   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
 44: -   Implement code following task details, dependencies, and project standards
 45: -   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
 46: -   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)
 47: 
 48: ---
 49: 
 50: ## Leveling Up: Agent-Led Multi-Context Workflows
 51: 
 52: While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.
 53: 
 54: **Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.
 55: 
 56: ### When to Introduce Tags: Your Decision Patterns
 57: 
 58: Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.
 59: 
 60: #### Pattern 1: Simple Git Feature Branching
 61: This is the most common and direct use case for tags.
 62: 
 63: - **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
 64: - **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
 65: - **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
 66: - **Tool to Use**: `task-master add-tag --from-branch`
 67: 
 68: #### Pattern 2: Team Collaboration
 69: - **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
 70: - **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
 71: - **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
 72: - **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`
 73: 
 74: #### Pattern 3: Experiments or Risky Refactors
 75: - **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
 76: - **Your Action**: Propose creating a sandboxed tag for the experimental work.
 77: - **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
 78: - **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`
 79: 
 80: #### Pattern 4: Large Feature Initiatives (PRD-Driven)
 81: This is a more structured approach for significant new features or epics.
 82: 
 83: - **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
 84: - **Your Action**: Propose a comprehensive, PRD-driven workflow.
 85: - **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
 86: - **Your Implementation Flow**:
 87:     1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
 88:     2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
 89:     3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
 90:     4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.
 91: 
 92: #### Pattern 5: Version-Based Development
 93: Tailor your approach based on the project maturity indicated by tag names.
 94: 
 95: - **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
 96:   - **Your Approach**: Focus on speed and functionality over perfection
 97:   - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
 98:   - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
 99:   - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
100:   - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*
101: 
102: - **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
103:   - **Your Approach**: Emphasize robustness, testing, and maintainability
104:   - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
105:   - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
106:   - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
107:   - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*
108: 
109: ### Advanced Workflow (Tag-Based & PRD-Driven)
110: 
111: **When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
112: - User mentions teammates or collaboration needs
113: - Project has grown to 15+ tasks with mixed priorities
114: - User creates feature branches or mentions major initiatives
115: - User initializes Taskmaster on an existing, complex codebase
116: - User describes large features that would benefit from dedicated planning
117: 
118: **Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.
119: 
120: #### Master List Strategy (High-Value Focus)
121: Once you transition to tag-based workflows, the `master` tag should ideally contain only:
122: - **High-level deliverables** that provide significant business value
123: - **Major milestones** and epic-level features
124: - **Critical infrastructure** work that affects the entire project
125: - **Release-blocking** items
126: 
127: **What NOT to put in master**:
128: - Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
129: - Refactoring work (create dedicated tags like `refactor-auth`)
130: - Experimental features (use `experiment-*` tags)
131: - Team member-specific tasks (use person-specific tags)
132: 
133: #### PRD-Driven Feature Development
134: 
135: **For New Major Features**:
136: 1. **Identify the Initiative**: When user describes a significant feature
137: 2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
138: 3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
139: 4. **Parse & Prepare**: 
140:    - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
141:    - `analyze_project_complexity --tag=feature-[name] --research`
142:    - `expand_all --tag=feature-[name] --research`
143: 5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag
144: 
145: **For Existing Codebase Analysis**:
146: When users initialize Taskmaster on existing projects:
147: 1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
148: 2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
149: 3. **Strategic PRD Creation**: Co-author PRDs that include:
150:    - Current state analysis (based on your codebase research)
151:    - Proposed improvements or new features
152:    - Implementation strategy considering existing code
153: 4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
154: 5. **Master List Curation**: Keep only the most valuable initiatives in master
155: 
156: The parse-prd's `--append` flag enables the user to parse multple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.
157: 
158: ### Workflow Transition Examples
159: 
160: **Example 1: Simple → Team-Based**
161: ```
162: User: "Alice is going to help with the API work"
163: Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
164: Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
165: ```
166: 
167: **Example 2: Simple → PRD-Driven**
168: ```
169: User: "I want to add a complete user dashboard with analytics, user management, and reporting"
170: Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
171: Actions: 
172: 1. add_tag feature-dashboard --description="User dashboard with analytics and management"
173: 2. Collaborate on PRD creation
174: 3. parse_prd dashboard-prd.txt --tag=feature-dashboard
175: 4. Add high-level "User Dashboard" task to master
176: ```
177: 
178: **Example 3: Existing Project → Strategic Planning**
179: ```
180: User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
181: Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
182: Actions:
183: 1. research "Current React app architecture and improvement opportunities" --tree --files=src/
184: 2. Collaborate on improvement PRD based on findings
185: 3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
186: 4. Keep only major improvement initiatives in master
187: ```
188: 
189: ---
190: 
191: ## Primary Interaction: MCP Server vs. CLI
192: 
193: Taskmaster offers two primary ways to interact:
194: 
195: 1.  **MCP Server (Recommended for Integrated Tools)**:
196:     - For AI agents and integrated development environments (like Cline), interacting via the **MCP server is the preferred method**.
197:     - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
198:     - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
199:     - Refer to @`mcp.md` for details on the MCP architecture and available tools.
200:     - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
201:     - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
202:     - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.
203: 
204: 2.  **`task-master` CLI (For Users & Fallback)**:
205:     - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
206:     - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
207:     - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
208:     - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
209:     - Refer to @`taskmaster.md` for a detailed command reference.
210:     - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.
211: 
212: ## How the Tag System Works (For Your Reference)
213: 
214: - **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
215: - **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
216: - **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
217: - **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
218: - **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.
219: 
220: ---
221: 
222: ## Task Complexity Analysis
223: 
224: -   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
225: -   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
226: -   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
227: -   Use analysis results to determine appropriate subtask allocation
228: -   Note that reports are automatically used by the `expand_task` tool/command
229: 
230: ## Task Breakdown Process
231: 
232: -   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
233: -   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
234: -   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
235: -   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
236: -   Use `--prompt="<context>"` to provide additional context when needed.
237: -   Review and adjust generated subtasks as necessary.
238: -   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
239: -   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.
240: 
241: ## Implementation Drift Handling
242: 
243: -   When implementation differs significantly from planned approach
244: -   When future tasks need modification due to current implementation choices
245: -   When new dependencies or requirements emerge
246: -   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
247: -   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.
248: 
249: ## Task Status Management
250: 
251: -   Use 'pending' for tasks ready to be worked on
252: -   Use 'done' for completed and verified tasks
253: -   Use 'deferred' for postponed tasks
254: -   Add custom status values as needed for project-specific workflows
255: 
256: ## Task Structure Fields
257: 
258: - **id**: Unique identifier for the task (Example: `1`, `1.1`)
259: - **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
260: - **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
261: - **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
262: - **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
263:     - Dependencies are displayed with status indicators (✅ for completed, ⏱️ for pending)
264:     - This helps quickly identify which prerequisite tasks are blocking work
265: - **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
266: - **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`) 
267: - **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`) 
268: - **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`) 
269: - Refer to task structure details (previously linked to `tasks.md`).
270: 
271: ## Configuration Management (Updated)
272: 
273: Taskmaster configuration is managed through two main mechanisms:
274: 
275: 1.  **`.taskmaster/config.json` File (Primary):**
276:     *   Located in the project root directory.
277:     *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
278:     *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
279:     *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
280:     *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
281:     *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.
282: 
283: 2.  **Environment Variables (`.env` / `mcp.json`):**
284:     *   Used **only** for sensitive API keys and specific endpoint URLs.
285:     *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
286:     *   For MCP/Cline integration, configure these keys in the `env` section of `.cline/mcp.json`.
287:     *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).
288: 
289: 3.  **`.taskmaster/state.json` File (Tagged System State):**
290:     *   Tracks current tag context and migration status.
291:     *   Automatically created during tagged system migration.
292:     *   Contains: `currentTag`, `lastSwitched`, `migrationNoticeShown`.
293: 
294: **Important:** Non-API key settings (like model selections, `MAX_TOKENS`, `TASKMASTER_LOG_LEVEL`) are **no longer configured via environment variables**. Use the `task-master models` command (or `--setup` for interactive configuration) or the `models` MCP tool.
295: **If AI commands FAIL in MCP** verify that the API key for the selected provider is present in the `env` section of `.cline/mcp.json`.
296: **If AI commands FAIL in CLI** verify that the API key for the selected provider is present in the `.env` file in the root of the project.
297: 
298: ## Rules Management
299: 
300: Taskmaster supports multiple AI coding assistant rule sets that can be configured during project initialization or managed afterward:
301: 
302: - **Available Profiles**: Claude Code, Cline, Codex, Cline, Roo Code, Trae, Windsurf (claude, cline, codex, cline, roo, trae, windsurf)
303: - **During Initialization**: Use `task-master init --rules cline,windsurf` to specify which rule sets to include
304: - **After Initialization**: Use `task-master rules add <profiles>` or `task-master rules remove <profiles>` to manage rule sets
305: - **Interactive Setup**: Use `task-master rules setup` to launch an interactive prompt for selecting rule profiles
306: - **Default Behavior**: If no `--rules` flag is specified during initialization, all available rule profiles are included
307: - **Rule Structure**: Each profile creates its own directory (e.g., `.cline/rules`, `.roo/rules`) with appropriate configuration files
308: 
309: ## Determining the Next Task
310: 
311: - Run `next_task` / `task-master next` to show the next task to work on.
312: - The command identifies tasks with all dependencies satisfied
313: - Tasks are prioritized by priority level, dependency count, and ID
314: - The command shows comprehensive task information including:
315:     - Basic task details and description
316:     - Implementation details
317:     - Subtasks (if they exist)
318:     - Contextual suggested actions
319: - Recommended before starting any new development work
320: - Respects your project's dependency structure
321: - Ensures tasks are completed in the appropriate sequence
322: - Provides ready-to-use commands for common task actions
323: 
324: ## Viewing Specific Task Details
325: 
326: - Run `get_task` / `task-master show <id>` to view a specific task.
327: - Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
328: - Displays comprehensive information similar to the next command, but for a specific task
329: - For parent tasks, shows all subtasks and their current status
330: - For subtasks, shows parent task information and relationship
331: - Provides contextual suggested actions appropriate for the specific task
332: - Useful for examining task details before implementation or checking status
333: 
334: ## Managing Task Dependencies
335: 
336: - Use `add_dependency` / `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency.
337: - Use `remove_dependency` / `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency.
338: - The system prevents circular dependencies and duplicate dependency entries
339: - Dependencies are checked for existence before being added or removed
340: - Task files are automatically regenerated after dependency changes
341: - Dependencies are visualized with status indicators in task listings and files
342: 
343: ## Task Reorganization
344: 
345: - Use `move_task` / `task-master move --from=<id> --to=<id>` to move tasks or subtasks within the hierarchy
346: - This command supports several use cases:
347:   - Moving a standalone task to become a subtask (e.g., `--from=5 --to=7`)
348:   - Moving a subtask to become a standalone task (e.g., `--from=5.2 --to=7`) 
349:   - Moving a subtask to a different parent (e.g., `--from=5.2 --to=7.3`)
350:   - Reordering subtasks within the same parent (e.g., `--from=5.2 --to=5.4`)
351:   - Moving a task to a new, non-existent ID position (e.g., `--from=5 --to=25`)
352:   - Moving multiple tasks at once using comma-separated IDs (e.g., `--from=10,11,12 --to=16,17,18`)
353: - The system includes validation to prevent data loss:
354:   - Allows moving to non-existent IDs by creating placeholder tasks
355:   - Prevents moving to existing task IDs that have content (to avoid overwriting)
356:   - Validates source tasks exist before attempting to move them
357: - The system maintains proper parent-child relationships and dependency integrity
358: - Task files are automatically regenerated after the move operation
359: - This provides greater flexibility in organizing and refining your task structure as project understanding evolves
360: - This is especially useful when dealing with potential merge conflicts arising from teams creating tasks on separate branches. Solve these conflicts very easily by moving your tasks and keeping theirs.
361: 
362: ## Iterative Subtask Implementation
363: 
364: Once a task has been broken down into subtasks using `expand_task` or similar methods, follow this iterative process for implementation:
365: 
366: 1.  **Understand the Goal (Preparation):**
367:     *   Use `get_task` / `task-master show <subtaskId>` (see @`taskmaster.md`) to thoroughly understand the specific goals and requirements of the subtask.
368: 
369: 2.  **Initial Exploration & Planning (Iteration 1):**
370:     *   This is the first attempt at creating a concrete implementation plan.
371:     *   Explore the codebase to identify the precise files, functions, and even specific lines of code that will need modification.
372:     *   Determine the intended code changes (diffs) and their locations.
373:     *   Gather *all* relevant details from this exploration phase.
374: 
375: 3.  **Log the Plan:**
376:     *   Run `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<detailed plan>'`.
377:     *   Provide the *complete and detailed* findings from the exploration phase in the prompt. Include file paths, line numbers, proposed diffs, reasoning, and any potential challenges identified. Do not omit details. The goal is to create a rich, timestamped log within the subtask's `details`.
378: 
379: 4.  **Verify the Plan:**
380:     *   Run `get_task` / `task-master show <subtaskId>` again to confirm that the detailed implementation plan has been successfully appended to the subtask's details.
381: 
382: 5.  **Begin Implementation:**
383:     *   Set the subtask status using `set_task_status` / `task-master set-status --id=<subtaskId> --status=in-progress`.
384:     *   Start coding based on the logged plan.
385: 
386: 6.  **Refine and Log Progress (Iteration 2+):**
387:     *   As implementation progresses, you will encounter challenges, discover nuances, or confirm successful approaches.
388:     *   **Before appending new information**: Briefly review the *existing* details logged in the subtask (using `get_task` or recalling from context) to ensure the update adds fresh insights and avoids redundancy.
389:     *   **Regularly** use `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<update details>\n- What worked...\n- What didn't work...'` to append new findings.
390:     *   **Crucially, log:**
391:         *   What worked ("fundamental truths" discovered).
392:         *   What didn't work and why (to avoid repeating mistakes).
393:         *   Specific code snippets or configurations that were successful.
394:         *   Decisions made, especially if confirmed with user input.
395:         *   Any deviations from the initial plan and the reasoning.
396:     *   The objective is to continuously enrich the subtask's details, creating a log of the implementation journey that helps the AI (and human developers) learn, adapt, and avoid repeating errors.
397: 
398: 7.  **Review & Update Rules (Post-Implementation):**
399:     *   Once the implementation for the subtask is functionally complete, review all code changes and the relevant chat history.
400:     *   Identify any new or modified code patterns, conventions, or best practices established during the implementation.
401:     *   Create new or update existing rules following internal guidelines (previously linked to `cursor_rules.md` and `self_improve.md`).
402: 
403: 8.  **Mark Task Complete:**
404:     *   After verifying the implementation and updating any necessary rules, mark the subtask as completed: `set_task_status` / `task-master set-status --id=<subtaskId> --status=done`.
405: 
406: 9.  **Commit Changes (If using Git):**
407:     *   Stage the relevant code changes and any updated/new rule files (`git add .`).
408:     *   Craft a comprehensive Git commit message summarizing the work done for the subtask, including both code implementation and any rule adjustments.
409:     *   Execute the commit command directly in the terminal (e.g., `git commit -m 'feat(module): Implement feature X for subtask <subtaskId>\n\n- Details about changes...\n- Updated rule Y for pattern Z'`).
410:     *   Consider if a Changeset is needed according to internal versioning guidelines (previously linked to `changeset.md`). If so, run `npm run changeset`, stage the generated file, and amend the commit or create a new one.
411: 
412: 10. **Proceed to Next Subtask:**
413:     *   Identify the next subtask (e.g., using `next_task` / `task-master next`).
414: 
415: ## Code Analysis & Refactoring Techniques
416: 
417: - **Top-Level Function Search**:
418:     - Useful for understanding module structure or planning refactors.
419:     - Use grep/ripgrep to find exported functions/constants:
420:       `rg "export (async function|function|const) \w+"` or similar patterns.
421:     - Can help compare functions between files during migrations or identify potential naming conflicts.
422: 
423: ---
424: *This workflow provides a general guideline. Adapt it based on your specific project needs and team practices.*
</file>

<file path=".clinerules/self_improve.md">
 1: ---
 2: description: Guidelines for continuously improving Cline rules based on emerging code patterns and best practices.
 3: globs: **/*
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Rule Improvement Triggers:**
 8:   - New code patterns not covered by existing rules
 9:   - Repeated similar implementations across files
10:   - Common error patterns that could be prevented
11:   - New libraries or tools being used consistently
12:   - Emerging best practices in the codebase
13: 
14: - **Analysis Process:**
15:   - Compare new code with existing rules
16:   - Identify patterns that should be standardized
17:   - Look for references to external documentation
18:   - Check for consistent error handling patterns
19:   - Monitor test patterns and coverage
20: 
21: - **Rule Updates:**
22:   - **Add New Rules When:**
23:     - A new technology/pattern is used in 3+ files
24:     - Common bugs could be prevented by a rule
25:     - Code reviews repeatedly mention the same feedback
26:     - New security or performance patterns emerge
27: 
28:   - **Modify Existing Rules When:**
29:     - Better examples exist in the codebase
30:     - Additional edge cases are discovered
31:     - Related rules have been updated
32:     - Implementation details have changed
33: 
34: - **Example Pattern Recognition:**
35:   ```typescript
36:   // If you see repeated patterns like:
37:   const data = await prisma.user.findMany({
38:     select: { id: true, email: true },
39:     where: { status: 'ACTIVE' }
40:   });
41:   
42:   // Consider adding to [prisma.md](.clinerules/prisma.md):
43:   // - Standard select fields
44:   // - Common where conditions
45:   // - Performance optimization patterns
46:   ```
47: 
48: - **Rule Quality Checks:**
49:   - Rules should be actionable and specific
50:   - Examples should come from actual code
51:   - References should be up to date
52:   - Patterns should be consistently enforced
53: 
54: - **Continuous Improvement:**
55:   - Monitor code review comments
56:   - Track common development questions
57:   - Update rules after major refactors
58:   - Add links to relevant documentation
59:   - Cross-reference related rules
60: 
61: - **Rule Deprecation:**
62:   - Mark outdated patterns as deprecated
63:   - Remove rules that no longer apply
64:   - Update references to deprecated rules
65:   - Document migration paths for old patterns
66: 
67: - **Documentation Updates:**
68:   - Keep examples synchronized with code
69:   - Update references to external docs
70:   - Maintain links between related rules
71:   - Document breaking changes
72: Follow [cline_rules.md](.clinerules/cline_rules.md) for proper rule formatting and structure.
</file>

<file path=".clinerules/taskmaster.md">
  1: ---
  2: description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Tool & Command Reference
  8: 
  9: This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like Cline, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.
 10: 
 11: **Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback. 
 12: 
 13: **Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.
 14: 
 15: **🏷️ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.
 16: 
 17: ---
 18: 
 19: ## Initialization & Setup
 20: 
 21: ### 1. Initialize Project (`init`)
 22: 
 23: *   **MCP Tool:** `initialize_project`
 24: *   **CLI Command:** `task-master init [options]`
 25: *   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
 26: *   **Key CLI Options:**
 27:     *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
 28:     *   `--description <text>`: `Provide a brief description for your project.`
 29:     *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
 30:     *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
 31: *   **Usage:** Run this once at the beginning of a new project.
 32: *   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
 33: *   **Key MCP Parameters/Options:**
 34:     *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
 35:     *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
 36:     *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
 37:     *   `authorName`: `Author name.` (CLI: `--author <author>`)
 38:     *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
 39:     *   `addAliases`: `Add shell aliases tm and taskmaster. Default is false.` (CLI: `--aliases`)
 40:     *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
 41: *   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like Cline. Operates on the current working directory of the MCP server. 
 42: *   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt. 
 43: *   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.
 44: 
 45: ### 2. Parse PRD (`parse_prd`)
 46: 
 47: *   **MCP Tool:** `parse_prd`
 48: *   **CLI Command:** `task-master parse-prd [file] [options]`
 49: *   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
 50: *   **Key Parameters/Options:**
 51:     *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
 52:     *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
 53:     *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
 54:     *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
 55: *   **Usage:** Useful for bootstrapping a project from an existing requirements document.
 56: *   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
 57: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.
 58: 
 59: ---
 60: 
 61: ## AI Model Configuration
 62: 
 63: ### 2. Manage Models (`models`)
 64: *   **MCP Tool:** `models`
 65: *   **CLI Command:** `task-master models [options]`
 66: *   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
 67: *   **Key MCP Parameters/Options:**
 68:     *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
 69:     *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
 70:     *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
 71:     *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
 72:     *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
 73:     *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
 74:     *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
 75: *   **Key CLI Options:**
 76:     *   `--set-main <model_id>`: `Set the primary model.`
 77:     *   `--set-research <model_id>`: `Set the research model.`
 78:     *   `--set-fallback <model_id>`: `Set the fallback model.`
 79:     *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
 80:     *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
 81:     *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
 82:     *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
 83: *   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
 84: *   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
 85: *   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
 86: *   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
 87: *   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80. 
 88: *   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.
 89: 
 90: ---
 91: 
 92: ## Task Listing & Viewing
 93: 
 94: ### 3. Get Tasks (`get_tasks`)
 95: 
 96: *   **MCP Tool:** `get_tasks`
 97: *   **CLI Command:** `task-master list [options]`
 98: *   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
 99: *   **Key Parameters/Options:**
100:     *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
101:     *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
102:     *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
103:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
104: *   **Usage:** Get an overview of the project status, often used at the start of a work session.
105: 
106: ### 4. Get Next Task (`next_task`)
107: 
108: *   **MCP Tool:** `next_task`
109: *   **CLI Command:** `task-master next [options]`
110: *   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
111: *   **Key Parameters/Options:**
112:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
113:     *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
114: *   **Usage:** Identify what to work on next according to the plan.
115: 
116: ### 5. Get Task Details (`get_task`)
117: 
118: *   **MCP Tool:** `get_task`
119: *   **CLI Command:** `task-master show [id] [options]`
120: *   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
121: *   **Key Parameters/Options:**
122:     *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
123:     *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
124:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
125: *   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
126: *   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.
127: 
128: ---
129: 
130: ## Task Creation & Modification
131: 
132: ### 6. Add Task (`add_task`)
133: 
134: *   **MCP Tool:** `add_task`
135: *   **CLI Command:** `task-master add-task [options]`
136: *   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
137: *   **Key Parameters/Options:**
138:     *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
139:     *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
140:     *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
141:     *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
142:     *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
143:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
144: *   **Usage:** Quickly add newly identified tasks during development.
145: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
146: 
147: ### 7. Add Subtask (`add_subtask`)
148: 
149: *   **MCP Tool:** `add_subtask`
150: *   **CLI Command:** `task-master add-subtask [options]`
151: *   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
152: *   **Key Parameters/Options:**
153:     *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
154:     *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
155:     *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
156:     *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
157:     *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
158:     *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
159:     *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
160:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after adding the subtask.` (CLI: `--skip-generate`)
161:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
162:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
163: *   **Usage:** Break down tasks manually or reorganize existing tasks.
164: 
165: ### 8. Update Tasks (`update`)
166: 
167: *   **MCP Tool:** `update`
168: *   **CLI Command:** `task-master update [options]`
169: *   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
170: *   **Key Parameters/Options:**
171:     *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
172:     *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
173:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
174:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
175:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
176: *   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
177: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
178: 
179: ### 9. Update Task (`update_task`)
180: 
181: *   **MCP Tool:** `update_task`
182: *   **CLI Command:** `task-master update-task [options]`
183: *   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
184: *   **Key Parameters/Options:**
185:     *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
186:     *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
187:     *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
188:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
189:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
190:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
191: *   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
192: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
193: 
194: ### 10. Update Subtask (`update_subtask`)
195: 
196: *   **MCP Tool:** `update_subtask`
197: *   **CLI Command:** `task-master update-subtask [options]`
198: *   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
199: *   **Key Parameters/Options:**
200:     *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
201:     *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
202:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
203:     *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
204:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
205: *   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
206: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
207: 
208: ### 11. Set Task Status (`set_task_status`)
209: 
210: *   **MCP Tool:** `set_task_status`
211: *   **CLI Command:** `task-master set-status [options]`
212: *   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
213: *   **Key Parameters/Options:**
214:     *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
215:     *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
216:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
217:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
218: *   **Usage:** Mark progress as tasks move through the development cycle.
219: 
220: ### 12. Remove Task (`remove_task`)
221: 
222: *   **MCP Tool:** `remove_task`
223: *   **CLI Command:** `task-master remove-task [options]`
224: *   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
225: *   **Key Parameters/Options:**
226:     *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
227:     *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
228:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
229:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
230: *   **Usage:** Permanently delete tasks or subtasks that are no longer needed in the project.
231: *   **Notes:** Use with caution as this operation cannot be undone. Consider using 'blocked', 'cancelled', or 'deferred' status instead if you just want to exclude a task from active planning but keep it for reference. The command automatically cleans up dependency references in other tasks.
232: 
233: ---
234: 
235: ## Task Structure & Breakdown
236: 
237: ### 13. Expand Task (`expand_task`)
238: 
239: *   **MCP Tool:** `expand_task`
240: *   **CLI Command:** `task-master expand [options]`
241: *   **Description:** `Use Taskmaster's AI to break down a complex task into smaller, manageable subtasks. Appends subtasks by default.`
242: *   **Key Parameters/Options:**
243:     *   `id`: `The ID of the specific Taskmaster task you want to break down into subtasks.` (CLI: `-i, --id <id>`)
244:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create. Uses complexity analysis/defaults otherwise.` (CLI: `-n, --num <number>`)
245:     *   `research`: `Enable Taskmaster to use the research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
246:     *   `prompt`: `Optional: Provide extra context or specific instructions to Taskmaster for generating the subtasks.` (CLI: `-p, --prompt <text>`)
247:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones. Default is false (append).` (CLI: `--force`)
248:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
249:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
250: *   **Usage:** Generate a detailed implementation plan for a complex task before starting coding. Automatically uses complexity report recommendations if available and `num` is not specified.
251: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
252: 
253: ### 14. Expand All Tasks (`expand_all`)
254: 
255: *   **MCP Tool:** `expand_all`
256: *   **CLI Command:** `task-master expand --all [options]` (Note: CLI uses the `expand` command with the `--all` flag)
257: *   **Description:** `Tell Taskmaster to automatically expand all eligible pending/in-progress tasks based on complexity analysis or defaults. Appends subtasks by default.`
258: *   **Key Parameters/Options:**
259:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create per task.` (CLI: `-n, --num <number>`)
260:     *   `research`: `Enable research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
261:     *   `prompt`: `Optional: Provide extra context for Taskmaster to apply generally during expansion.` (CLI: `-p, --prompt <text>`)
262:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones for each eligible task. Default is false (append).` (CLI: `--force`)
263:     *   `tag`: `Specify which tag context to expand. Defaults to the current active tag.` (CLI: `--tag <name>`)
264:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
265: *   **Usage:** Useful after initial task generation or complexity analysis to break down multiple tasks at once.
266: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
267: 
268: ### 15. Clear Subtasks (`clear_subtasks`)
269: 
270: *   **MCP Tool:** `clear_subtasks`
271: *   **CLI Command:** `task-master clear-subtasks [options]`
272: *   **Description:** `Remove all subtasks from one or more specified Taskmaster parent tasks.`
273: *   **Key Parameters/Options:**
274:     *   `id`: `The ID(s) of the Taskmaster parent task(s) whose subtasks you want to remove, e.g., '15' or '16,18'. Required unless using `all`.) (CLI: `-i, --id <ids>`)
275:     *   `all`: `Tell Taskmaster to remove subtasks from all parent tasks.` (CLI: `--all`)
276:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
277:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
278: *   **Usage:** Used before regenerating subtasks with `expand_task` if the previous breakdown needs replacement.
279: 
280: ### 16. Remove Subtask (`remove_subtask`)
281: 
282: *   **MCP Tool:** `remove_subtask`
283: *   **CLI Command:** `task-master remove-subtask [options]`
284: *   **Description:** `Remove a subtask from its Taskmaster parent, optionally converting it into a standalone task.`
285: *   **Key Parameters/Options:**
286:     *   `id`: `Required. The ID(s) of the Taskmaster subtask(s) to remove, e.g., '15.2' or '16.1,16.3'.` (CLI: `-i, --id <id>`)
287:     *   `convert`: `If used, Taskmaster will turn the subtask into a regular top-level task instead of deleting it.` (CLI: `-c, --convert`)
288:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after removing the subtask.` (CLI: `--skip-generate`)
289:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
290:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
291: *   **Usage:** Delete unnecessary subtasks or promote a subtask to a top-level task.
292: 
293: ### 17. Move Task (`move_task`)
294: 
295: *   **MCP Tool:** `move_task`
296: *   **CLI Command:** `task-master move [options]`
297: *   **Description:** `Move a task or subtask to a new position within the task hierarchy.`
298: *   **Key Parameters/Options:**
299:     *   `from`: `Required. ID of the task/subtask to move (e.g., "5" or "5.2"). Can be comma-separated for multiple tasks.` (CLI: `--from <id>`)
300:     *   `to`: `Required. ID of the destination (e.g., "7" or "7.3"). Must match the number of source IDs if comma-separated.` (CLI: `--to <id>`)
301:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
302:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
303: *   **Usage:** Reorganize tasks by moving them within the hierarchy. Supports various scenarios like:
304:     *   Moving a task to become a subtask
305:     *   Moving a subtask to become a standalone task
306:     *   Moving a subtask to a different parent
307:     *   Reordering subtasks within the same parent
308:     *   Moving a task to a new, non-existent ID (automatically creates placeholders)
309:     *   Moving multiple tasks at once with comma-separated IDs
310: *   **Validation Features:**
311:     *   Allows moving tasks to non-existent destination IDs (creates placeholder tasks)
312:     *   Prevents moving to existing task IDs that already have content (to avoid overwriting)
313:     *   Validates that source tasks exist before attempting to move them
314:     *   Maintains proper parent-child relationships
315: *   **Example CLI:** `task-master move --from=5.2 --to=7.3` to move subtask 5.2 to become subtask 7.3.
316: *   **Example Multi-Move:** `task-master move --from=10,11,12 --to=16,17,18` to move multiple tasks to new positions.
317: *   **Common Use:** Resolving merge conflicts in tasks.json when multiple team members create tasks on different branches.
318: 
319: ---
320: 
321: ## Dependency Management
322: 
323: ### 18. Add Dependency (`add_dependency`)
324: 
325: *   **MCP Tool:** `add_dependency`
326: *   **CLI Command:** `task-master add-dependency [options]`
327: *   **Description:** `Define a dependency in Taskmaster, making one task a prerequisite for another.`
328: *   **Key Parameters/Options:**
329:     *   `id`: `Required. The ID of the Taskmaster task that will depend on another.` (CLI: `-i, --id <id>`)
330:     *   `dependsOn`: `Required. The ID of the Taskmaster task that must be completed first, the prerequisite.` (CLI: `-d, --depends-on <id>`)
331:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
332:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <path>`)
333: *   **Usage:** Establish the correct order of execution between tasks.
334: 
335: ### 19. Remove Dependency (`remove_dependency`)
336: 
337: *   **MCP Tool:** `remove_dependency`
338: *   **CLI Command:** `task-master remove-dependency [options]`
339: *   **Description:** `Remove a dependency relationship between two Taskmaster tasks.`
340: *   **Key Parameters/Options:**
341:     *   `id`: `Required. The ID of the Taskmaster task you want to remove a prerequisite from.` (CLI: `-i, --id <id>`)
342:     *   `dependsOn`: `Required. The ID of the Taskmaster task that should no longer be a prerequisite.` (CLI: `-d, --depends-on <id>`)
343:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
344:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
345: *   **Usage:** Update task relationships when the order of execution changes.
346: 
347: ### 20. Validate Dependencies (`validate_dependencies`)
348: 
349: *   **MCP Tool:** `validate_dependencies`
350: *   **CLI Command:** `task-master validate-dependencies [options]`
351: *   **Description:** `Check your Taskmaster tasks for dependency issues (like circular references or links to non-existent tasks) without making changes.`
352: *   **Key Parameters/Options:**
353:     *   `tag`: `Specify which tag context to validate. Defaults to the current active tag.` (CLI: `--tag <name>`)
354:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
355: *   **Usage:** Audit the integrity of your task dependencies.
356: 
357: ### 21. Fix Dependencies (`fix_dependencies`)
358: 
359: *   **MCP Tool:** `fix_dependencies`
360: *   **CLI Command:** `task-master fix-dependencies [options]`
361: *   **Description:** `Automatically fix dependency issues (like circular references or links to non-existent tasks) in your Taskmaster tasks.`
362: *   **Key Parameters/Options:**
363:     *   `tag`: `Specify which tag context to fix dependencies in. Defaults to the current active tag.` (CLI: `--tag <name>`)
364:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
365: *   **Usage:** Clean up dependency errors automatically.
366: 
367: ---
368: 
369: ## Analysis & Reporting
370: 
371: ### 22. Analyze Project Complexity (`analyze_project_complexity`)
372: 
373: *   **MCP Tool:** `analyze_project_complexity`
374: *   **CLI Command:** `task-master analyze-complexity [options]`
375: *   **Description:** `Have Taskmaster analyze your tasks to determine their complexity and suggest which ones need to be broken down further.`
376: *   **Key Parameters/Options:**
377:     *   `output`: `Where to save the complexity analysis report. Default is '.taskmaster/reports/task-complexity-report.json' (or '..._tagname.json' if a tag is used).` (CLI: `-o, --output <file>`)
378:     *   `threshold`: `The minimum complexity score (1-10) that should trigger a recommendation to expand a task.` (CLI: `-t, --threshold <number>`)
379:     *   `research`: `Enable research role for more accurate complexity analysis. Requires appropriate API key.` (CLI: `-r, --research`)
380:     *   `tag`: `Specify which tag context to analyze. Defaults to the current active tag.` (CLI: `--tag <name>`)
381:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
382: *   **Usage:** Used before breaking down tasks to identify which ones need the most attention.
383: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
384: 
385: ### 23. View Complexity Report (`complexity_report`)
386: 
387: *   **MCP Tool:** `complexity_report`
388: *   **CLI Command:** `task-master complexity-report [options]`
389: *   **Description:** `Display the task complexity analysis report in a readable format.`
390: *   **Key Parameters/Options:**
391:     *   `tag`: `Specify which tag context to show the report for. Defaults to the current active tag.` (CLI: `--tag <name>`)
392:     *   `file`: `Path to the complexity report (default: '.taskmaster/reports/task-complexity-report.json').` (CLI: `-f, --file <file>`)
393: *   **Usage:** Review and understand the complexity analysis results after running analyze-complexity.
394: 
395: ---
396: 
397: ## File Management
398: 
399: ### 24. Generate Task Files (`generate`)
400: 
401: *   **MCP Tool:** `generate`
402: *   **CLI Command:** `task-master generate [options]`
403: *   **Description:** `Create or update individual Markdown files for each task based on your tasks.json.`
404: *   **Key Parameters/Options:**
405:     *   `output`: `The directory where Taskmaster should save the task files (default: in a 'tasks' directory).` (CLI: `-o, --output <directory>`)
406:     *   `tag`: `Specify which tag context to generate files for. Defaults to the current active tag.` (CLI: `--tag <name>`)
407:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
408: *   **Usage:** Run this after making changes to tasks.json to keep individual task files up to date. This command is now manual and no longer runs automatically.
409: 
410: ---
411: 
412: ## AI-Powered Research
413: 
414: ### 25. Research (`research`)
415: 
416: *   **MCP Tool:** `research`
417: *   **CLI Command:** `task-master research [options]`
418: *   **Description:** `Perform AI-powered research queries with project context to get fresh, up-to-date information beyond the AI's knowledge cutoff.`
419: *   **Key Parameters/Options:**
420:     *   `query`: `Required. Research query/prompt (e.g., "What are the latest best practices for React Query v5?").` (CLI: `[query]` positional or `-q, --query <text>`)
421:     *   `taskIds`: `Comma-separated list of task/subtask IDs from the current tag context (e.g., "15,16.2,17").` (CLI: `-i, --id <ids>`)
422:     *   `filePaths`: `Comma-separated list of file paths for context (e.g., "src/api.js,docs/readme.md").` (CLI: `-f, --files <paths>`)
423:     *   `customContext`: `Additional custom context text to include in the research.` (CLI: `-c, --context <text>`)
424:     *   `includeProjectTree`: `Include project file tree structure in context (default: false).` (CLI: `--tree`)
425:     *   `detailLevel`: `Detail level for the research response: 'low', 'medium', 'high' (default: medium).` (CLI: `--detail <level>`)
426:     *   `saveTo`: `Task or subtask ID (e.g., "15", "15.2") to automatically save the research conversation to.` (CLI: `--save-to <id>`)
427:     *   `saveFile`: `If true, saves the research conversation to a markdown file in '.taskmaster/docs/research/'.` (CLI: `--save-file`)
428:     *   `noFollowup`: `Disables the interactive follow-up question menu in the CLI.` (CLI: `--no-followup`)
429:     *   `tag`: `Specify which tag context to use for task-based context gathering. Defaults to the current active tag.` (CLI: `--tag <name>`)
430:     *   `projectRoot`: `The directory of the project. Must be an absolute path.` (CLI: Determined automatically)
431: *   **Usage:** **This is a POWERFUL tool that agents should use FREQUENTLY** to:
432:     *   Get fresh information beyond knowledge cutoff dates
433:     *   Research latest best practices, library updates, security patches
434:     *   Find implementation examples for specific technologies
435:     *   Validate approaches against current industry standards
436:     *   Get contextual advice based on project files and tasks
437: *   **When to Consider Using Research:**
438:     *   **Before implementing any task** - Research current best practices
439:     *   **When encountering new technologies** - Get up-to-date implementation guidance (libraries, apis, etc)
440:     *   **For security-related tasks** - Find latest security recommendations
441:     *   **When updating dependencies** - Research breaking changes and migration guides
442:     *   **For performance optimization** - Get current performance best practices
443:     *   **When debugging complex issues** - Research known solutions and workarounds
444: *   **Research + Action Pattern:**
445:     *   Use `research` to gather fresh information
446:     *   Use `update_subtask` to commit findings with timestamps
447:     *   Use `update_task` to incorporate research into task details
448:     *   Use `add_task` with research flag for informed task creation
449: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. The research provides FRESH data beyond the AI's training cutoff, making it invaluable for current best practices and recent developments.
450: 
451: ---
452: 
453: ## Tag Management
454: 
455: This new suite of commands allows you to manage different task contexts (tags).
456: 
457: ### 26. List Tags (`tags`)
458: 
459: *   **MCP Tool:** `list_tags`
460: *   **CLI Command:** `task-master tags [options]`
461: *   **Description:** `List all available tags with task counts, completion status, and other metadata.`
462: *   **Key Parameters/Options:**
463:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
464:     *   `--show-metadata`: `Include detailed metadata in the output (e.g., creation date, description).` (CLI: `--show-metadata`)
465: 
466: ### 27. Add Tag (`add_tag`)
467: 
468: *   **MCP Tool:** `add_tag`
469: *   **CLI Command:** `task-master add-tag <tagName> [options]`
470: *   **Description:** `Create a new, empty tag context, or copy tasks from another tag.`
471: *   **Key Parameters/Options:**
472:     *   `tagName`: `Name of the new tag to create (alphanumeric, hyphens, underscores).` (CLI: `<tagName>` positional)
473:     *   `--from-branch`: `Creates a tag with a name derived from the current git branch, ignoring the <tagName> argument.` (CLI: `--from-branch`)
474:     *   `--copy-from-current`: `Copy tasks from the currently active tag to the new tag.` (CLI: `--copy-from-current`)
475:     *   `--copy-from <tag>`: `Copy tasks from a specific source tag to the new tag.` (CLI: `--copy-from <tag>`)
476:     *   `--description <text>`: `Provide an optional description for the new tag.` (CLI: `-d, --description <text>`)
477:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
478: 
479: ### 28. Delete Tag (`delete_tag`)
480: 
481: *   **MCP Tool:** `delete_tag`
482: *   **CLI Command:** `task-master delete-tag <tagName> [options]`
483: *   **Description:** `Permanently delete a tag and all of its associated tasks.`
484: *   **Key Parameters/Options:**
485:     *   `tagName`: `Name of the tag to delete.` (CLI: `<tagName>` positional)
486:     *   `--yes`: `Skip the confirmation prompt.` (CLI: `-y, --yes`)
487:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
488: 
489: ### 29. Use Tag (`use_tag`)
490: 
491: *   **MCP Tool:** `use_tag`
492: *   **CLI Command:** `task-master use-tag <tagName>`
493: *   **Description:** `Switch your active task context to a different tag.`
494: *   **Key Parameters/Options:**
495:     *   `tagName`: `Name of the tag to switch to.` (CLI: `<tagName>` positional)
496:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
497: 
498: ### 30. Rename Tag (`rename_tag`)
499: 
500: *   **MCP Tool:** `rename_tag`
501: *   **CLI Command:** `task-master rename-tag <oldName> <newName>`
502: *   **Description:** `Rename an existing tag.`
503: *   **Key Parameters/Options:**
504:     *   `oldName`: `The current name of the tag.` (CLI: `<oldName>` positional)
505:     *   `newName`: `The new name for the tag.` (CLI: `<newName>` positional)
506:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
507: 
508: ### 31. Copy Tag (`copy_tag`)
509: 
510: *   **MCP Tool:** `copy_tag`
511: *   **CLI Command:** `task-master copy-tag <sourceName> <targetName> [options]`
512: *   **Description:** `Copy an entire tag context, including all its tasks and metadata, to a new tag.`
513: *   **Key Parameters/Options:**
514:     *   `sourceName`: `Name of the tag to copy from.` (CLI: `<sourceName>` positional)
515:     *   `targetName`: `Name of the new tag to create.` (CLI: `<targetName>` positional)
516:     *   `--description <text>`: `Optional description for the new tag.` (CLI: `-d, --description <text>`)
517: 
518: ---
519: 
520: ## Miscellaneous
521: 
522: ### 32. Sync Readme (`sync-readme`) -- experimental
523: 
524: *   **MCP Tool:** N/A
525: *   **CLI Command:** `task-master sync-readme [options]`
526: *   **Description:** `Exports your task list to your project's README.md file, useful for showcasing progress.`
527: *   **Key Parameters/Options:**
528:     *   `status`: `Filter tasks by status (e.g., 'pending', 'done').` (CLI: `-s, --status <status>`)
529:     *   `withSubtasks`: `Include subtasks in the export.` (CLI: `--with-subtasks`)
530:     *   `tag`: `Specify which tag context to export from. Defaults to the current active tag.` (CLI: `--tag <name>`)
531: 
532: ---
533: 
534: ## Environment Variables Configuration (Updated)
535: 
536: Taskmaster primarily uses the **`.taskmaster/config.json`** file (in project root) for configuration (models, parameters, logging level, etc.), managed via `task-master models --setup`.
537: 
538: Environment variables are used **only** for sensitive API keys related to AI providers and specific overrides like the Ollama base URL:
539: 
540: *   **API Keys (Required for corresponding provider):**
541:     *   `ANTHROPIC_API_KEY`
542:     *   `PERPLEXITY_API_KEY`
543:     *   `OPENAI_API_KEY`
544:     *   `GOOGLE_API_KEY`
545:     *   `MISTRAL_API_KEY`
546:     *   `AZURE_OPENAI_API_KEY` (Requires `AZURE_OPENAI_ENDPOINT` too)
547:     *   `OPENROUTER_API_KEY`
548:     *   `XAI_API_KEY`
549:     *   `OLLAMA_API_KEY` (Requires `OLLAMA_BASE_URL` too)
550: *   **Endpoints (Optional/Provider Specific inside .taskmaster/config.json):**
551:     *   `AZURE_OPENAI_ENDPOINT`
552:     *   `OLLAMA_BASE_URL` (Default: `http://localhost:11434/api`)
553: 
554: **Set API keys** in your **`.env`** file in the project root (for CLI use) or within the `env` section of your **`.cline/mcp.json`** file (for MCP/Cline integration). All other settings (model choice, max tokens, temperature, log level, custom endpoints) are managed in `.taskmaster/config.json` via `task-master models` command or `models` MCP tool.
555: 
556: ---
557: 
558: For details on how these commands fit into the development process, see the [dev_workflow.md](.clinerules/dev_workflow.md).
</file>

<file path=".cursor/mcp.json">
 1: {
 2: 	"mcpServers": {
 3: 		"task-master-ai": {
 4: 			"command": "npx",
 5: 			"args": ["-y", "--package=task-master-ai", "task-master-ai"],
 6: 			"env": {
 7: 				"ANTHROPIC_API_KEY": "ANTHROPIC_API_KEY_HERE",
 8: 				"PERPLEXITY_API_KEY": "PERPLEXITY_API_KEY_HERE",
 9: 				"OPENAI_API_KEY": "OPENAI_API_KEY_HERE",
10: 				"GOOGLE_API_KEY": "GOOGLE_API_KEY_HERE",
11: 				"XAI_API_KEY": "XAI_API_KEY_HERE",
12: 				"OPENROUTER_API_KEY": "OPENROUTER_API_KEY_HERE",
13: 				"MISTRAL_API_KEY": "MISTRAL_API_KEY_HERE",
14: 				"AZURE_OPENAI_API_KEY": "AZURE_OPENAI_API_KEY_HERE",
15: 				"OLLAMA_API_KEY": "OLLAMA_API_KEY_HERE"
16: 			}
17: 		}
18: 	}
19: }
</file>

<file path=".github/instructions/dev_workflow.md">
  1: ---
  2: description: Guide for using Taskmaster to manage task-driven development workflows
  3: applyTo: "**/*"
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Development Workflow
  8: 
  9: This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.
 10: 
 11: - **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
 12: - **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.
 13: 
 14: ## The Basic Loop
 15: The fundamental development cycle you will facilitate is:
 16: 1.  **`list`**: Show the user what needs to be done.
 17: 2.  **`next`**: Help the user decide what to work on.
 18: 3.  **`show <id>`**: Provide details for a specific task.
 19: 4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
 20: 5.  **Implement**: The user writes the code and tests.
 21: 6.  **`update-subtask`**: Log progress and findings on behalf of the user.
 22: 7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
 23: 8.  **Repeat**.
 24: 
 25: All your standard command executions should operate on the user's current task context, which defaults to `master`.
 26: 
 27: ---
 28: 
 29: ## Standard Development Workflow Process
 30: 
 31: ### Simple Workflow (Default Starting Point)
 32: 
 33: For new projects or when users are getting started, operate within the `master` tag context:
 34: 
 35: -   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
 36: -   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules vscode,windsurf`) or manage them later with `task-master rules add/remove` commands  
 37: -   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
 38: -   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
 39: -   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
 40: -   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
 41: -   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
 42: -   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
 43: -   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
 44: -   Implement code following task details, dependencies, and project standards
 45: -   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
 46: -   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)
 47: 
 48: ---
 49: 
 50: ## Leveling Up: Agent-Led Multi-Context Workflows
 51: 
 52: While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.
 53: 
 54: **Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.
 55: 
 56: ### When to Introduce Tags: Your Decision Patterns
 57: 
 58: Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.
 59: 
 60: #### Pattern 1: Simple Git Feature Branching
 61: This is the most common and direct use case for tags.
 62: 
 63: - **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
 64: - **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
 65: - **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
 66: - **Tool to Use**: `task-master add-tag --from-branch`
 67: 
 68: #### Pattern 2: Team Collaboration
 69: - **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
 70: - **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
 71: - **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
 72: - **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`
 73: 
 74: #### Pattern 3: Experiments or Risky Refactors
 75: - **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
 76: - **Your Action**: Propose creating a sandboxed tag for the experimental work.
 77: - **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
 78: - **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`
 79: 
 80: #### Pattern 4: Large Feature Initiatives (PRD-Driven)
 81: This is a more structured approach for significant new features or epics.
 82: 
 83: - **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
 84: - **Your Action**: Propose a comprehensive, PRD-driven workflow.
 85: - **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
 86: - **Your Implementation Flow**:
 87:     1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
 88:     2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
 89:     3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
 90:     4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.
 91: 
 92: #### Pattern 5: Version-Based Development
 93: Tailor your approach based on the project maturity indicated by tag names.
 94: 
 95: - **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
 96:   - **Your Approach**: Focus on speed and functionality over perfection
 97:   - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
 98:   - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
 99:   - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
100:   - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*
101: 
102: - **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
103:   - **Your Approach**: Emphasize robustness, testing, and maintainability
104:   - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
105:   - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
106:   - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
107:   - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*
108: 
109: ### Advanced Workflow (Tag-Based & PRD-Driven)
110: 
111: **When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
112: - User mentions teammates or collaboration needs
113: - Project has grown to 15+ tasks with mixed priorities
114: - User creates feature branches or mentions major initiatives
115: - User initializes Taskmaster on an existing, complex codebase
116: - User describes large features that would benefit from dedicated planning
117: 
118: **Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.
119: 
120: #### Master List Strategy (High-Value Focus)
121: Once you transition to tag-based workflows, the `master` tag should ideally contain only:
122: - **High-level deliverables** that provide significant business value
123: - **Major milestones** and epic-level features
124: - **Critical infrastructure** work that affects the entire project
125: - **Release-blocking** items
126: 
127: **What NOT to put in master**:
128: - Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
129: - Refactoring work (create dedicated tags like `refactor-auth`)
130: - Experimental features (use `experiment-*` tags)
131: - Team member-specific tasks (use person-specific tags)
132: 
133: #### PRD-Driven Feature Development
134: 
135: **For New Major Features**:
136: 1. **Identify the Initiative**: When user describes a significant feature
137: 2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
138: 3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
139: 4. **Parse & Prepare**: 
140:    - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
141:    - `analyze_project_complexity --tag=feature-[name] --research`
142:    - `expand_all --tag=feature-[name] --research`
143: 5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag
144: 
145: **For Existing Codebase Analysis**:
146: When users initialize Taskmaster on existing projects:
147: 1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
148: 2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
149: 3. **Strategic PRD Creation**: Co-author PRDs that include:
150:    - Current state analysis (based on your codebase research)
151:    - Proposed improvements or new features
152:    - Implementation strategy considering existing code
153: 4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
154: 5. **Master List Curation**: Keep only the most valuable initiatives in master
155: 
156: The parse-prd's `--append` flag enables the user to parse multple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.
157: 
158: ### Workflow Transition Examples
159: 
160: **Example 1: Simple → Team-Based**
161: ```
162: User: "Alice is going to help with the API work"
163: Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
164: Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
165: ```
166: 
167: **Example 2: Simple → PRD-Driven**
168: ```
169: User: "I want to add a complete user dashboard with analytics, user management, and reporting"
170: Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
171: Actions: 
172: 1. add_tag feature-dashboard --description="User dashboard with analytics and management"
173: 2. Collaborate on PRD creation
174: 3. parse_prd dashboard-prd.txt --tag=feature-dashboard
175: 4. Add high-level "User Dashboard" task to master
176: ```
177: 
178: **Example 3: Existing Project → Strategic Planning**
179: ```
180: User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
181: Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
182: Actions:
183: 1. research "Current React app architecture and improvement opportunities" --tree --files=src/
184: 2. Collaborate on improvement PRD based on findings
185: 3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
186: 4. Keep only major improvement initiatives in master
187: ```
188: 
189: ---
190: 
191: ## Primary Interaction: MCP Server vs. CLI
192: 
193: Taskmaster offers two primary ways to interact:
194: 
195: 1.  **MCP Server (Recommended for Integrated Tools)**:
196:     - For AI agents and integrated development environments (like VS Code), interacting via the **MCP server is the preferred method**.
197:     - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
198:     - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
199:     - Refer to @`mcp.md` for details on the MCP architecture and available tools.
200:     - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
201:     - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
202:     - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.
203: 
204: 2.  **`task-master` CLI (For Users & Fallback)**:
205:     - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
206:     - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
207:     - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
208:     - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
209:     - Refer to @`taskmaster.md` for a detailed command reference.
210:     - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.
211: 
212: ## How the Tag System Works (For Your Reference)
213: 
214: - **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
215: - **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
216: - **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
217: - **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
218: - **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.
219: 
220: ---
221: 
222: ## Task Complexity Analysis
223: 
224: -   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
225: -   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
226: -   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
227: -   Use analysis results to determine appropriate subtask allocation
228: -   Note that reports are automatically used by the `expand_task` tool/command
229: 
230: ## Task Breakdown Process
231: 
232: -   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
233: -   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
234: -   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
235: -   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
236: -   Use `--prompt="<context>"` to provide additional context when needed.
237: -   Review and adjust generated subtasks as necessary.
238: -   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
239: -   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.
240: 
241: ## Implementation Drift Handling
242: 
243: -   When implementation differs significantly from planned approach
244: -   When future tasks need modification due to current implementation choices
245: -   When new dependencies or requirements emerge
246: -   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
247: -   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.
248: 
249: ## Task Status Management
250: 
251: -   Use 'pending' for tasks ready to be worked on
252: -   Use 'done' for completed and verified tasks
253: -   Use 'deferred' for postponed tasks
254: -   Add custom status values as needed for project-specific workflows
255: 
256: ## Task Structure Fields
257: 
258: - **id**: Unique identifier for the task (Example: `1`, `1.1`)
259: - **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
260: - **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
261: - **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
262: - **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
263:     - Dependencies are displayed with status indicators (✅ for completed, ⏱️ for pending)
264:     - This helps quickly identify which prerequisite tasks are blocking work
265: - **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
266: - **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`) 
267: - **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`) 
268: - **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`) 
269: - Refer to task structure details (previously linked to `tasks.md`).
270: 
271: ## Configuration Management (Updated)
272: 
273: Taskmaster configuration is managed through two main mechanisms:
274: 
275: 1.  **`.taskmaster/config.json` File (Primary):**
276:     *   Located in the project root directory.
277:     *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
278:     *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
279:     *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
280:     *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
281:     *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.
282: 
283: 2.  **Environment Variables (`.env` / `mcp.json`):**
284:     *   Used **only** for sensitive API keys and specific endpoint URLs.
285:     *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
286:     *   For MCP/VS Code integration, configure these keys in the `env` section of `.vscode/mcp.json`.
287:     *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).
288: 
289: 3.  **`.taskmaster/state.json` File (Tagged System State):**
290:     *   Tracks current tag context and migration status.
291:     *   Automatically created during tagged system migration.
292:     *   Contains: `currentTag`, `lastSwitched`, `migrationNoticeShown`.
293: 
294: **Important:** Non-API key settings (like model selections, `MAX_TOKENS`, `TASKMASTER_LOG_LEVEL`) are **no longer configured via environment variables**. Use the `task-master models` command (or `--setup` for interactive configuration) or the `models` MCP tool.
295: **If AI commands FAIL in MCP** verify that the API key for the selected provider is present in the `env` section of `.vscode/mcp.json`.
296: **If AI commands FAIL in CLI** verify that the API key for the selected provider is present in the `.env` file in the root of the project.
297: 
298: ## Rules Management
299: 
300: Taskmaster supports multiple AI coding assistant rule sets that can be configured during project initialization or managed afterward:
301: 
302: - **Available Profiles**: Claude Code, Cline, Codex, VS Code, Roo Code, Trae, Windsurf (claude, cline, codex, vscode, roo, trae, windsurf)
303: - **During Initialization**: Use `task-master init --rules vscode,windsurf` to specify which rule sets to include
304: - **After Initialization**: Use `task-master rules add <profiles>` or `task-master rules remove <profiles>` to manage rule sets
305: - **Interactive Setup**: Use `task-master rules setup` to launch an interactive prompt for selecting rule profiles
306: - **Default Behavior**: If no `--rules` flag is specified during initialization, all available rule profiles are included
307: - **Rule Structure**: Each profile creates its own directory (e.g., `.github/instructions`, `.roo/rules`) with appropriate configuration files
308: 
309: ## Determining the Next Task
310: 
311: - Run `next_task` / `task-master next` to show the next task to work on.
312: - The command identifies tasks with all dependencies satisfied
313: - Tasks are prioritized by priority level, dependency count, and ID
314: - The command shows comprehensive task information including:
315:     - Basic task details and description
316:     - Implementation details
317:     - Subtasks (if they exist)
318:     - Contextual suggested actions
319: - Recommended before starting any new development work
320: - Respects your project's dependency structure
321: - Ensures tasks are completed in the appropriate sequence
322: - Provides ready-to-use commands for common task actions
323: 
324: ## Viewing Specific Task Details
325: 
326: - Run `get_task` / `task-master show <id>` to view a specific task.
327: - Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
328: - Displays comprehensive information similar to the next command, but for a specific task
329: - For parent tasks, shows all subtasks and their current status
330: - For subtasks, shows parent task information and relationship
331: - Provides contextual suggested actions appropriate for the specific task
332: - Useful for examining task details before implementation or checking status
333: 
334: ## Managing Task Dependencies
335: 
336: - Use `add_dependency` / `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency.
337: - Use `remove_dependency` / `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency.
338: - The system prevents circular dependencies and duplicate dependency entries
339: - Dependencies are checked for existence before being added or removed
340: - Task files are automatically regenerated after dependency changes
341: - Dependencies are visualized with status indicators in task listings and files
342: 
343: ## Task Reorganization
344: 
345: - Use `move_task` / `task-master move --from=<id> --to=<id>` to move tasks or subtasks within the hierarchy
346: - This command supports several use cases:
347:   - Moving a standalone task to become a subtask (e.g., `--from=5 --to=7`)
348:   - Moving a subtask to become a standalone task (e.g., `--from=5.2 --to=7`) 
349:   - Moving a subtask to a different parent (e.g., `--from=5.2 --to=7.3`)
350:   - Reordering subtasks within the same parent (e.g., `--from=5.2 --to=5.4`)
351:   - Moving a task to a new, non-existent ID position (e.g., `--from=5 --to=25`)
352:   - Moving multiple tasks at once using comma-separated IDs (e.g., `--from=10,11,12 --to=16,17,18`)
353: - The system includes validation to prevent data loss:
354:   - Allows moving to non-existent IDs by creating placeholder tasks
355:   - Prevents moving to existing task IDs that have content (to avoid overwriting)
356:   - Validates source tasks exist before attempting to move them
357: - The system maintains proper parent-child relationships and dependency integrity
358: - Task files are automatically regenerated after the move operation
359: - This provides greater flexibility in organizing and refining your task structure as project understanding evolves
360: - This is especially useful when dealing with potential merge conflicts arising from teams creating tasks on separate branches. Solve these conflicts very easily by moving your tasks and keeping theirs.
361: 
362: ## Iterative Subtask Implementation
363: 
364: Once a task has been broken down into subtasks using `expand_task` or similar methods, follow this iterative process for implementation:
365: 
366: 1.  **Understand the Goal (Preparation):**
367:     *   Use `get_task` / `task-master show <subtaskId>` (see @`taskmaster.md`) to thoroughly understand the specific goals and requirements of the subtask.
368: 
369: 2.  **Initial Exploration & Planning (Iteration 1):**
370:     *   This is the first attempt at creating a concrete implementation plan.
371:     *   Explore the codebase to identify the precise files, functions, and even specific lines of code that will need modification.
372:     *   Determine the intended code changes (diffs) and their locations.
373:     *   Gather *all* relevant details from this exploration phase.
374: 
375: 3.  **Log the Plan:**
376:     *   Run `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<detailed plan>'`.
377:     *   Provide the *complete and detailed* findings from the exploration phase in the prompt. Include file paths, line numbers, proposed diffs, reasoning, and any potential challenges identified. Do not omit details. The goal is to create a rich, timestamped log within the subtask's `details`.
378: 
379: 4.  **Verify the Plan:**
380:     *   Run `get_task` / `task-master show <subtaskId>` again to confirm that the detailed implementation plan has been successfully appended to the subtask's details.
381: 
382: 5.  **Begin Implementation:**
383:     *   Set the subtask status using `set_task_status` / `task-master set-status --id=<subtaskId> --status=in-progress`.
384:     *   Start coding based on the logged plan.
385: 
386: 6.  **Refine and Log Progress (Iteration 2+):**
387:     *   As implementation progresses, you will encounter challenges, discover nuances, or confirm successful approaches.
388:     *   **Before appending new information**: Briefly review the *existing* details logged in the subtask (using `get_task` or recalling from context) to ensure the update adds fresh insights and avoids redundancy.
389:     *   **Regularly** use `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<update details>\n- What worked...\n- What didn't work...'` to append new findings.
390:     *   **Crucially, log:**
391:         *   What worked ("fundamental truths" discovered).
392:         *   What didn't work and why (to avoid repeating mistakes).
393:         *   Specific code snippets or configurations that were successful.
394:         *   Decisions made, especially if confirmed with user input.
395:         *   Any deviations from the initial plan and the reasoning.
396:     *   The objective is to continuously enrich the subtask's details, creating a log of the implementation journey that helps the AI (and human developers) learn, adapt, and avoid repeating errors.
397: 
398: 7.  **Review & Update Rules (Post-Implementation):**
399:     *   Once the implementation for the subtask is functionally complete, review all code changes and the relevant chat history.
400:     *   Identify any new or modified code patterns, conventions, or best practices established during the implementation.
401:     *   Create new or update existing rules following internal guidelines (previously linked to `cursor_rules.md` and `self_improve.md`).
402: 
403: 8.  **Mark Task Complete:**
404:     *   After verifying the implementation and updating any necessary rules, mark the subtask as completed: `set_task_status` / `task-master set-status --id=<subtaskId> --status=done`.
405: 
406: 9.  **Commit Changes (If using Git):**
407:     *   Stage the relevant code changes and any updated/new rule files (`git add .`).
408:     *   Craft a comprehensive Git commit message summarizing the work done for the subtask, including both code implementation and any rule adjustments.
409:     *   Execute the commit command directly in the terminal (e.g., `git commit -m 'feat(module): Implement feature X for subtask <subtaskId>\n\n- Details about changes...\n- Updated rule Y for pattern Z'`).
410:     *   Consider if a Changeset is needed according to internal versioning guidelines (previously linked to `changeset.md`). If so, run `npm run changeset`, stage the generated file, and amend the commit or create a new one.
411: 
412: 10. **Proceed to Next Subtask:**
413:     *   Identify the next subtask (e.g., using `next_task` / `task-master next`).
414: 
415: ## Code Analysis & Refactoring Techniques
416: 
417: - **Top-Level Function Search**:
418:     - Useful for understanding module structure or planning refactors.
419:     - Use grep/ripgrep to find exported functions/constants:
420:       `rg "export (async function|function|const) \w+"` or similar patterns.
421:     - Can help compare functions between files during migrations or identify potential naming conflicts.
422: 
423: ---
424: *This workflow provides a general guideline. Adapt it based on your specific project needs and team practices.*
</file>

<file path=".github/instructions/self_improve.md">
 1: ---
 2: description: Guidelines for continuously improving VS Code rules based on emerging code patterns and best practices.
 3: applyTo: "**/*"
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Rule Improvement Triggers:**
 8:   - New code patterns not covered by existing rules
 9:   - Repeated similar implementations across files
10:   - Common error patterns that could be prevented
11:   - New libraries or tools being used consistently
12:   - Emerging best practices in the codebase
13: 
14: - **Analysis Process:**
15:   - Compare new code with existing rules
16:   - Identify patterns that should be standardized
17:   - Look for references to external documentation
18:   - Check for consistent error handling patterns
19:   - Monitor test patterns and coverage
20: 
21: - **Rule Updates:**
22:   - **Add New Rules When:**
23:     - A new technology/pattern is used in 3+ files
24:     - Common bugs could be prevented by a rule
25:     - Code reviews repeatedly mention the same feedback
26:     - New security or performance patterns emerge
27: 
28:   - **Modify Existing Rules When:**
29:     - Better examples exist in the codebase
30:     - Additional edge cases are discovered
31:     - Related rules have been updated
32:     - Implementation details have changed
33: 
34: - **Example Pattern Recognition:**
35:   ```typescript
36:   // If you see repeated patterns like:
37:   const data = await prisma.user.findMany({
38:     select: { id: true, email: true },
39:     where: { status: 'ACTIVE' }
40:   });
41:   
42:   // Consider adding to [prisma.md](.github/instructions/prisma.md):
43:   // - Standard select fields
44:   // - Common where conditions
45:   // - Performance optimization patterns
46:   ```
47: 
48: - **Rule Quality Checks:**
49:   - Rules should be actionable and specific
50:   - Examples should come from actual code
51:   - References should be up to date
52:   - Patterns should be consistently enforced
53: 
54: - **Continuous Improvement:**
55:   - Monitor code review comments
56:   - Track common development questions
57:   - Update rules after major refactors
58:   - Add links to relevant documentation
59:   - Cross-reference related rules
60: 
61: - **Rule Deprecation:**
62:   - Mark outdated patterns as deprecated
63:   - Remove rules that no longer apply
64:   - Update references to deprecated rules
65:   - Document migration paths for old patterns
66: 
67: - **Documentation Updates:**
68:   - Keep examples synchronized with code
69:   - Update references to external docs
70:   - Maintain links between related rules
71:   - Document breaking changes
72: Follow [vscode_rules.md](.github/instructions/vscode_rules.md) for proper rule formatting and structure.
</file>

<file path=".github/instructions/taskmaster.md">
  1: ---
  2: description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
  3: applyTo: "**/*"
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Tool & Command Reference
  8: 
  9: This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like VS Code, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.
 10: 
 11: **Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback. 
 12: 
 13: **Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.
 14: 
 15: **🏷️ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.
 16: 
 17: ---
 18: 
 19: ## Initialization & Setup
 20: 
 21: ### 1. Initialize Project (`init`)
 22: 
 23: *   **MCP Tool:** `initialize_project`
 24: *   **CLI Command:** `task-master init [options]`
 25: *   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
 26: *   **Key CLI Options:**
 27:     *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
 28:     *   `--description <text>`: `Provide a brief description for your project.`
 29:     *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
 30:     *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
 31: *   **Usage:** Run this once at the beginning of a new project.
 32: *   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
 33: *   **Key MCP Parameters/Options:**
 34:     *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
 35:     *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
 36:     *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
 37:     *   `authorName`: `Author name.` (CLI: `--author <author>`)
 38:     *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
 39:     *   `addAliases`: `Add shell aliases tm and taskmaster. Default is false.` (CLI: `--aliases`)
 40:     *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
 41: *   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like VS Code. Operates on the current working directory of the MCP server. 
 42: *   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt. 
 43: *   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.
 44: 
 45: ### 2. Parse PRD (`parse_prd`)
 46: 
 47: *   **MCP Tool:** `parse_prd`
 48: *   **CLI Command:** `task-master parse-prd [file] [options]`
 49: *   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
 50: *   **Key Parameters/Options:**
 51:     *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
 52:     *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
 53:     *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
 54:     *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
 55: *   **Usage:** Useful for bootstrapping a project from an existing requirements document.
 56: *   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
 57: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.
 58: 
 59: ---
 60: 
 61: ## AI Model Configuration
 62: 
 63: ### 2. Manage Models (`models`)
 64: *   **MCP Tool:** `models`
 65: *   **CLI Command:** `task-master models [options]`
 66: *   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
 67: *   **Key MCP Parameters/Options:**
 68:     *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
 69:     *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
 70:     *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
 71:     *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
 72:     *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
 73:     *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
 74:     *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
 75: *   **Key CLI Options:**
 76:     *   `--set-main <model_id>`: `Set the primary model.`
 77:     *   `--set-research <model_id>`: `Set the research model.`
 78:     *   `--set-fallback <model_id>`: `Set the fallback model.`
 79:     *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
 80:     *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
 81:     *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
 82:     *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
 83: *   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
 84: *   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
 85: *   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
 86: *   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
 87: *   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80. 
 88: *   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.
 89: 
 90: ---
 91: 
 92: ## Task Listing & Viewing
 93: 
 94: ### 3. Get Tasks (`get_tasks`)
 95: 
 96: *   **MCP Tool:** `get_tasks`
 97: *   **CLI Command:** `task-master list [options]`
 98: *   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
 99: *   **Key Parameters/Options:**
100:     *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
101:     *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
102:     *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
103:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
104: *   **Usage:** Get an overview of the project status, often used at the start of a work session.
105: 
106: ### 4. Get Next Task (`next_task`)
107: 
108: *   **MCP Tool:** `next_task`
109: *   **CLI Command:** `task-master next [options]`
110: *   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
111: *   **Key Parameters/Options:**
112:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
113:     *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
114: *   **Usage:** Identify what to work on next according to the plan.
115: 
116: ### 5. Get Task Details (`get_task`)
117: 
118: *   **MCP Tool:** `get_task`
119: *   **CLI Command:** `task-master show [id] [options]`
120: *   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
121: *   **Key Parameters/Options:**
122:     *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
123:     *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
124:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
125: *   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
126: *   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.
127: 
128: ---
129: 
130: ## Task Creation & Modification
131: 
132: ### 6. Add Task (`add_task`)
133: 
134: *   **MCP Tool:** `add_task`
135: *   **CLI Command:** `task-master add-task [options]`
136: *   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
137: *   **Key Parameters/Options:**
138:     *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
139:     *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
140:     *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
141:     *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
142:     *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
143:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
144: *   **Usage:** Quickly add newly identified tasks during development.
145: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
146: 
147: ### 7. Add Subtask (`add_subtask`)
148: 
149: *   **MCP Tool:** `add_subtask`
150: *   **CLI Command:** `task-master add-subtask [options]`
151: *   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
152: *   **Key Parameters/Options:**
153:     *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
154:     *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
155:     *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
156:     *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
157:     *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
158:     *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
159:     *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
160:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after adding the subtask.` (CLI: `--skip-generate`)
161:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
162:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
163: *   **Usage:** Break down tasks manually or reorganize existing tasks.
164: 
165: ### 8. Update Tasks (`update`)
166: 
167: *   **MCP Tool:** `update`
168: *   **CLI Command:** `task-master update [options]`
169: *   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
170: *   **Key Parameters/Options:**
171:     *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
172:     *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
173:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
174:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
175:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
176: *   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
177: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
178: 
179: ### 9. Update Task (`update_task`)
180: 
181: *   **MCP Tool:** `update_task`
182: *   **CLI Command:** `task-master update-task [options]`
183: *   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
184: *   **Key Parameters/Options:**
185:     *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
186:     *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
187:     *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
188:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
189:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
190:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
191: *   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
192: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
193: 
194: ### 10. Update Subtask (`update_subtask`)
195: 
196: *   **MCP Tool:** `update_subtask`
197: *   **CLI Command:** `task-master update-subtask [options]`
198: *   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
199: *   **Key Parameters/Options:**
200:     *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
201:     *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
202:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
203:     *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
204:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
205: *   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
206: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
207: 
208: ### 11. Set Task Status (`set_task_status`)
209: 
210: *   **MCP Tool:** `set_task_status`
211: *   **CLI Command:** `task-master set-status [options]`
212: *   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
213: *   **Key Parameters/Options:**
214:     *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
215:     *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
216:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
217:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
218: *   **Usage:** Mark progress as tasks move through the development cycle.
219: 
220: ### 12. Remove Task (`remove_task`)
221: 
222: *   **MCP Tool:** `remove_task`
223: *   **CLI Command:** `task-master remove-task [options]`
224: *   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
225: *   **Key Parameters/Options:**
226:     *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
227:     *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
228:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
229:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
230: *   **Usage:** Permanently delete tasks or subtasks that are no longer needed in the project.
231: *   **Notes:** Use with caution as this operation cannot be undone. Consider using 'blocked', 'cancelled', or 'deferred' status instead if you just want to exclude a task from active planning but keep it for reference. The command automatically cleans up dependency references in other tasks.
232: 
233: ---
234: 
235: ## Task Structure & Breakdown
236: 
237: ### 13. Expand Task (`expand_task`)
238: 
239: *   **MCP Tool:** `expand_task`
240: *   **CLI Command:** `task-master expand [options]`
241: *   **Description:** `Use Taskmaster's AI to break down a complex task into smaller, manageable subtasks. Appends subtasks by default.`
242: *   **Key Parameters/Options:**
243:     *   `id`: `The ID of the specific Taskmaster task you want to break down into subtasks.` (CLI: `-i, --id <id>`)
244:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create. Uses complexity analysis/defaults otherwise.` (CLI: `-n, --num <number>`)
245:     *   `research`: `Enable Taskmaster to use the research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
246:     *   `prompt`: `Optional: Provide extra context or specific instructions to Taskmaster for generating the subtasks.` (CLI: `-p, --prompt <text>`)
247:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones. Default is false (append).` (CLI: `--force`)
248:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
249:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
250: *   **Usage:** Generate a detailed implementation plan for a complex task before starting coding. Automatically uses complexity report recommendations if available and `num` is not specified.
251: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
252: 
253: ### 14. Expand All Tasks (`expand_all`)
254: 
255: *   **MCP Tool:** `expand_all`
256: *   **CLI Command:** `task-master expand --all [options]` (Note: CLI uses the `expand` command with the `--all` flag)
257: *   **Description:** `Tell Taskmaster to automatically expand all eligible pending/in-progress tasks based on complexity analysis or defaults. Appends subtasks by default.`
258: *   **Key Parameters/Options:**
259:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create per task.` (CLI: `-n, --num <number>`)
260:     *   `research`: `Enable research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
261:     *   `prompt`: `Optional: Provide extra context for Taskmaster to apply generally during expansion.` (CLI: `-p, --prompt <text>`)
262:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones for each eligible task. Default is false (append).` (CLI: `--force`)
263:     *   `tag`: `Specify which tag context to expand. Defaults to the current active tag.` (CLI: `--tag <name>`)
264:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
265: *   **Usage:** Useful after initial task generation or complexity analysis to break down multiple tasks at once.
266: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
267: 
268: ### 15. Clear Subtasks (`clear_subtasks`)
269: 
270: *   **MCP Tool:** `clear_subtasks`
271: *   **CLI Command:** `task-master clear-subtasks [options]`
272: *   **Description:** `Remove all subtasks from one or more specified Taskmaster parent tasks.`
273: *   **Key Parameters/Options:**
274:     *   `id`: `The ID(s) of the Taskmaster parent task(s) whose subtasks you want to remove, e.g., '15' or '16,18'. Required unless using `all`.) (CLI: `-i, --id <ids>`)
275:     *   `all`: `Tell Taskmaster to remove subtasks from all parent tasks.` (CLI: `--all`)
276:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
277:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
278: *   **Usage:** Used before regenerating subtasks with `expand_task` if the previous breakdown needs replacement.
279: 
280: ### 16. Remove Subtask (`remove_subtask`)
281: 
282: *   **MCP Tool:** `remove_subtask`
283: *   **CLI Command:** `task-master remove-subtask [options]`
284: *   **Description:** `Remove a subtask from its Taskmaster parent, optionally converting it into a standalone task.`
285: *   **Key Parameters/Options:**
286:     *   `id`: `Required. The ID(s) of the Taskmaster subtask(s) to remove, e.g., '15.2' or '16.1,16.3'.` (CLI: `-i, --id <id>`)
287:     *   `convert`: `If used, Taskmaster will turn the subtask into a regular top-level task instead of deleting it.` (CLI: `-c, --convert`)
288:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after removing the subtask.` (CLI: `--skip-generate`)
289:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
290:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
291: *   **Usage:** Delete unnecessary subtasks or promote a subtask to a top-level task.
292: 
293: ### 17. Move Task (`move_task`)
294: 
295: *   **MCP Tool:** `move_task`
296: *   **CLI Command:** `task-master move [options]`
297: *   **Description:** `Move a task or subtask to a new position within the task hierarchy.`
298: *   **Key Parameters/Options:**
299:     *   `from`: `Required. ID of the task/subtask to move (e.g., "5" or "5.2"). Can be comma-separated for multiple tasks.` (CLI: `--from <id>`)
300:     *   `to`: `Required. ID of the destination (e.g., "7" or "7.3"). Must match the number of source IDs if comma-separated.` (CLI: `--to <id>`)
301:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
302:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
303: *   **Usage:** Reorganize tasks by moving them within the hierarchy. Supports various scenarios like:
304:     *   Moving a task to become a subtask
305:     *   Moving a subtask to become a standalone task
306:     *   Moving a subtask to a different parent
307:     *   Reordering subtasks within the same parent
308:     *   Moving a task to a new, non-existent ID (automatically creates placeholders)
309:     *   Moving multiple tasks at once with comma-separated IDs
310: *   **Validation Features:**
311:     *   Allows moving tasks to non-existent destination IDs (creates placeholder tasks)
312:     *   Prevents moving to existing task IDs that already have content (to avoid overwriting)
313:     *   Validates that source tasks exist before attempting to move them
314:     *   Maintains proper parent-child relationships
315: *   **Example CLI:** `task-master move --from=5.2 --to=7.3` to move subtask 5.2 to become subtask 7.3.
316: *   **Example Multi-Move:** `task-master move --from=10,11,12 --to=16,17,18` to move multiple tasks to new positions.
317: *   **Common Use:** Resolving merge conflicts in tasks.json when multiple team members create tasks on different branches.
318: 
319: ---
320: 
321: ## Dependency Management
322: 
323: ### 18. Add Dependency (`add_dependency`)
324: 
325: *   **MCP Tool:** `add_dependency`
326: *   **CLI Command:** `task-master add-dependency [options]`
327: *   **Description:** `Define a dependency in Taskmaster, making one task a prerequisite for another.`
328: *   **Key Parameters/Options:**
329:     *   `id`: `Required. The ID of the Taskmaster task that will depend on another.` (CLI: `-i, --id <id>`)
330:     *   `dependsOn`: `Required. The ID of the Taskmaster task that must be completed first, the prerequisite.` (CLI: `-d, --depends-on <id>`)
331:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
332:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <path>`)
333: *   **Usage:** Establish the correct order of execution between tasks.
334: 
335: ### 19. Remove Dependency (`remove_dependency`)
336: 
337: *   **MCP Tool:** `remove_dependency`
338: *   **CLI Command:** `task-master remove-dependency [options]`
339: *   **Description:** `Remove a dependency relationship between two Taskmaster tasks.`
340: *   **Key Parameters/Options:**
341:     *   `id`: `Required. The ID of the Taskmaster task you want to remove a prerequisite from.` (CLI: `-i, --id <id>`)
342:     *   `dependsOn`: `Required. The ID of the Taskmaster task that should no longer be a prerequisite.` (CLI: `-d, --depends-on <id>`)
343:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
344:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
345: *   **Usage:** Update task relationships when the order of execution changes.
346: 
347: ### 20. Validate Dependencies (`validate_dependencies`)
348: 
349: *   **MCP Tool:** `validate_dependencies`
350: *   **CLI Command:** `task-master validate-dependencies [options]`
351: *   **Description:** `Check your Taskmaster tasks for dependency issues (like circular references or links to non-existent tasks) without making changes.`
352: *   **Key Parameters/Options:**
353:     *   `tag`: `Specify which tag context to validate. Defaults to the current active tag.` (CLI: `--tag <name>`)
354:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
355: *   **Usage:** Audit the integrity of your task dependencies.
356: 
357: ### 21. Fix Dependencies (`fix_dependencies`)
358: 
359: *   **MCP Tool:** `fix_dependencies`
360: *   **CLI Command:** `task-master fix-dependencies [options]`
361: *   **Description:** `Automatically fix dependency issues (like circular references or links to non-existent tasks) in your Taskmaster tasks.`
362: *   **Key Parameters/Options:**
363:     *   `tag`: `Specify which tag context to fix dependencies in. Defaults to the current active tag.` (CLI: `--tag <name>`)
364:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
365: *   **Usage:** Clean up dependency errors automatically.
366: 
367: ---
368: 
369: ## Analysis & Reporting
370: 
371: ### 22. Analyze Project Complexity (`analyze_project_complexity`)
372: 
373: *   **MCP Tool:** `analyze_project_complexity`
374: *   **CLI Command:** `task-master analyze-complexity [options]`
375: *   **Description:** `Have Taskmaster analyze your tasks to determine their complexity and suggest which ones need to be broken down further.`
376: *   **Key Parameters/Options:**
377:     *   `output`: `Where to save the complexity analysis report. Default is '.taskmaster/reports/task-complexity-report.json' (or '..._tagname.json' if a tag is used).` (CLI: `-o, --output <file>`)
378:     *   `threshold`: `The minimum complexity score (1-10) that should trigger a recommendation to expand a task.` (CLI: `-t, --threshold <number>`)
379:     *   `research`: `Enable research role for more accurate complexity analysis. Requires appropriate API key.` (CLI: `-r, --research`)
380:     *   `tag`: `Specify which tag context to analyze. Defaults to the current active tag.` (CLI: `--tag <name>`)
381:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
382: *   **Usage:** Used before breaking down tasks to identify which ones need the most attention.
383: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
384: 
385: ### 23. View Complexity Report (`complexity_report`)
386: 
387: *   **MCP Tool:** `complexity_report`
388: *   **CLI Command:** `task-master complexity-report [options]`
389: *   **Description:** `Display the task complexity analysis report in a readable format.`
390: *   **Key Parameters/Options:**
391:     *   `tag`: `Specify which tag context to show the report for. Defaults to the current active tag.` (CLI: `--tag <name>`)
392:     *   `file`: `Path to the complexity report (default: '.taskmaster/reports/task-complexity-report.json').` (CLI: `-f, --file <file>`)
393: *   **Usage:** Review and understand the complexity analysis results after running analyze-complexity.
394: 
395: ---
396: 
397: ## File Management
398: 
399: ### 24. Generate Task Files (`generate`)
400: 
401: *   **MCP Tool:** `generate`
402: *   **CLI Command:** `task-master generate [options]`
403: *   **Description:** `Create or update individual Markdown files for each task based on your tasks.json.`
404: *   **Key Parameters/Options:**
405:     *   `output`: `The directory where Taskmaster should save the task files (default: in a 'tasks' directory).` (CLI: `-o, --output <directory>`)
406:     *   `tag`: `Specify which tag context to generate files for. Defaults to the current active tag.` (CLI: `--tag <name>`)
407:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
408: *   **Usage:** Run this after making changes to tasks.json to keep individual task files up to date. This command is now manual and no longer runs automatically.
409: 
410: ---
411: 
412: ## AI-Powered Research
413: 
414: ### 25. Research (`research`)
415: 
416: *   **MCP Tool:** `research`
417: *   **CLI Command:** `task-master research [options]`
418: *   **Description:** `Perform AI-powered research queries with project context to get fresh, up-to-date information beyond the AI's knowledge cutoff.`
419: *   **Key Parameters/Options:**
420:     *   `query`: `Required. Research query/prompt (e.g., "What are the latest best practices for React Query v5?").` (CLI: `[query]` positional or `-q, --query <text>`)
421:     *   `taskIds`: `Comma-separated list of task/subtask IDs from the current tag context (e.g., "15,16.2,17").` (CLI: `-i, --id <ids>`)
422:     *   `filePaths`: `Comma-separated list of file paths for context (e.g., "src/api.js,docs/readme.md").` (CLI: `-f, --files <paths>`)
423:     *   `customContext`: `Additional custom context text to include in the research.` (CLI: `-c, --context <text>`)
424:     *   `includeProjectTree`: `Include project file tree structure in context (default: false).` (CLI: `--tree`)
425:     *   `detailLevel`: `Detail level for the research response: 'low', 'medium', 'high' (default: medium).` (CLI: `--detail <level>`)
426:     *   `saveTo`: `Task or subtask ID (e.g., "15", "15.2") to automatically save the research conversation to.` (CLI: `--save-to <id>`)
427:     *   `saveFile`: `If true, saves the research conversation to a markdown file in '.taskmaster/docs/research/'.` (CLI: `--save-file`)
428:     *   `noFollowup`: `Disables the interactive follow-up question menu in the CLI.` (CLI: `--no-followup`)
429:     *   `tag`: `Specify which tag context to use for task-based context gathering. Defaults to the current active tag.` (CLI: `--tag <name>`)
430:     *   `projectRoot`: `The directory of the project. Must be an absolute path.` (CLI: Determined automatically)
431: *   **Usage:** **This is a POWERFUL tool that agents should use FREQUENTLY** to:
432:     *   Get fresh information beyond knowledge cutoff dates
433:     *   Research latest best practices, library updates, security patches
434:     *   Find implementation examples for specific technologies
435:     *   Validate approaches against current industry standards
436:     *   Get contextual advice based on project files and tasks
437: *   **When to Consider Using Research:**
438:     *   **Before implementing any task** - Research current best practices
439:     *   **When encountering new technologies** - Get up-to-date implementation guidance (libraries, apis, etc)
440:     *   **For security-related tasks** - Find latest security recommendations
441:     *   **When updating dependencies** - Research breaking changes and migration guides
442:     *   **For performance optimization** - Get current performance best practices
443:     *   **When debugging complex issues** - Research known solutions and workarounds
444: *   **Research + Action Pattern:**
445:     *   Use `research` to gather fresh information
446:     *   Use `update_subtask` to commit findings with timestamps
447:     *   Use `update_task` to incorporate research into task details
448:     *   Use `add_task` with research flag for informed task creation
449: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. The research provides FRESH data beyond the AI's training cutoff, making it invaluable for current best practices and recent developments.
450: 
451: ---
452: 
453: ## Tag Management
454: 
455: This new suite of commands allows you to manage different task contexts (tags).
456: 
457: ### 26. List Tags (`tags`)
458: 
459: *   **MCP Tool:** `list_tags`
460: *   **CLI Command:** `task-master tags [options]`
461: *   **Description:** `List all available tags with task counts, completion status, and other metadata.`
462: *   **Key Parameters/Options:**
463:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
464:     *   `--show-metadata`: `Include detailed metadata in the output (e.g., creation date, description).` (CLI: `--show-metadata`)
465: 
466: ### 27. Add Tag (`add_tag`)
467: 
468: *   **MCP Tool:** `add_tag`
469: *   **CLI Command:** `task-master add-tag <tagName> [options]`
470: *   **Description:** `Create a new, empty tag context, or copy tasks from another tag.`
471: *   **Key Parameters/Options:**
472:     *   `tagName`: `Name of the new tag to create (alphanumeric, hyphens, underscores).` (CLI: `<tagName>` positional)
473:     *   `--from-branch`: `Creates a tag with a name derived from the current git branch, ignoring the <tagName> argument.` (CLI: `--from-branch`)
474:     *   `--copy-from-current`: `Copy tasks from the currently active tag to the new tag.` (CLI: `--copy-from-current`)
475:     *   `--copy-from <tag>`: `Copy tasks from a specific source tag to the new tag.` (CLI: `--copy-from <tag>`)
476:     *   `--description <text>`: `Provide an optional description for the new tag.` (CLI: `-d, --description <text>`)
477:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
478: 
479: ### 28. Delete Tag (`delete_tag`)
480: 
481: *   **MCP Tool:** `delete_tag`
482: *   **CLI Command:** `task-master delete-tag <tagName> [options]`
483: *   **Description:** `Permanently delete a tag and all of its associated tasks.`
484: *   **Key Parameters/Options:**
485:     *   `tagName`: `Name of the tag to delete.` (CLI: `<tagName>` positional)
486:     *   `--yes`: `Skip the confirmation prompt.` (CLI: `-y, --yes`)
487:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
488: 
489: ### 29. Use Tag (`use_tag`)
490: 
491: *   **MCP Tool:** `use_tag`
492: *   **CLI Command:** `task-master use-tag <tagName>`
493: *   **Description:** `Switch your active task context to a different tag.`
494: *   **Key Parameters/Options:**
495:     *   `tagName`: `Name of the tag to switch to.` (CLI: `<tagName>` positional)
496:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
497: 
498: ### 30. Rename Tag (`rename_tag`)
499: 
500: *   **MCP Tool:** `rename_tag`
501: *   **CLI Command:** `task-master rename-tag <oldName> <newName>`
502: *   **Description:** `Rename an existing tag.`
503: *   **Key Parameters/Options:**
504:     *   `oldName`: `The current name of the tag.` (CLI: `<oldName>` positional)
505:     *   `newName`: `The new name for the tag.` (CLI: `<newName>` positional)
506:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
507: 
508: ### 31. Copy Tag (`copy_tag`)
509: 
510: *   **MCP Tool:** `copy_tag`
511: *   **CLI Command:** `task-master copy-tag <sourceName> <targetName> [options]`
512: *   **Description:** `Copy an entire tag context, including all its tasks and metadata, to a new tag.`
513: *   **Key Parameters/Options:**
514:     *   `sourceName`: `Name of the tag to copy from.` (CLI: `<sourceName>` positional)
515:     *   `targetName`: `Name of the new tag to create.` (CLI: `<targetName>` positional)
516:     *   `--description <text>`: `Optional description for the new tag.` (CLI: `-d, --description <text>`)
517: 
518: ---
519: 
520: ## Miscellaneous
521: 
522: ### 32. Sync Readme (`sync-readme`) -- experimental
523: 
524: *   **MCP Tool:** N/A
525: *   **CLI Command:** `task-master sync-readme [options]`
526: *   **Description:** `Exports your task list to your project's README.md file, useful for showcasing progress.`
527: *   **Key Parameters/Options:**
528:     *   `status`: `Filter tasks by status (e.g., 'pending', 'done').` (CLI: `-s, --status <status>`)
529:     *   `withSubtasks`: `Include subtasks in the export.` (CLI: `--with-subtasks`)
530:     *   `tag`: `Specify which tag context to export from. Defaults to the current active tag.` (CLI: `--tag <name>`)
531: 
532: ---
533: 
534: ## Environment Variables Configuration (Updated)
535: 
536: Taskmaster primarily uses the **`.taskmaster/config.json`** file (in project root) for configuration (models, parameters, logging level, etc.), managed via `task-master models --setup`.
537: 
538: Environment variables are used **only** for sensitive API keys related to AI providers and specific overrides like the Ollama base URL:
539: 
540: *   **API Keys (Required for corresponding provider):**
541:     *   `ANTHROPIC_API_KEY`
542:     *   `PERPLEXITY_API_KEY`
543:     *   `OPENAI_API_KEY`
544:     *   `GOOGLE_API_KEY`
545:     *   `MISTRAL_API_KEY`
546:     *   `AZURE_OPENAI_API_KEY` (Requires `AZURE_OPENAI_ENDPOINT` too)
547:     *   `OPENROUTER_API_KEY`
548:     *   `XAI_API_KEY`
549:     *   `OLLAMA_API_KEY` (Requires `OLLAMA_BASE_URL` too)
550: *   **Endpoints (Optional/Provider Specific inside .taskmaster/config.json):**
551:     *   `AZURE_OPENAI_ENDPOINT`
552:     *   `OLLAMA_BASE_URL` (Default: `http://localhost:11434/api`)
553: 
554: **Set API keys** in your **`.env`** file in the project root (for CLI use) or within the `env` section of your **`.vscode/mcp.json`** file (for MCP/VS Code integration). All other settings (model choice, max tokens, temperature, log level, custom endpoints) are managed in `.taskmaster/config.json` via `task-master models` command or `models` MCP tool.
555: 
556: ---
557: 
558: For details on how these commands fit into the development process, see the [dev_workflow.md](.github/instructions/dev_workflow.md).
</file>

<file path=".github/instructions/vscode_rules.md">
 1: ---
 2: description: Guidelines for creating and maintaining VS Code rules to ensure consistency and effectiveness.
 3: applyTo: ".github/instructions/*.md"
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Required Rule Structure:**
 8:   ```markdown
 9:   ---
10:   description: Clear, one-line description of what the rule enforces
11:   globs: path/to/files/*.ext, other/path/**/*
12:   alwaysApply: boolean
13:   ---
14: 
15:   - **Main Points in Bold**
16:     - Sub-points with details
17:     - Examples and explanations
18:   ```
19: 
20: - **File References:**
21:   - Use `[filename](mdc:path/to/file)` ([filename](mdc:filename)) to reference files
22:   - Example: [prisma.md](.github/instructions/prisma.md) for rule references
23:   - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references
24: 
25: - **Code Examples:**
26:   - Use language-specific code blocks
27:   ```typescript
28:   // ✅ DO: Show good examples
29:   const goodExample = true;
30:   
31:   // ❌ DON'T: Show anti-patterns
32:   const badExample = false;
33:   ```
34: 
35: - **Rule Content Guidelines:**
36:   - Start with high-level overview
37:   - Include specific, actionable requirements
38:   - Show examples of correct implementation
39:   - Reference existing code when possible
40:   - Keep rules DRY by referencing other rules
41: 
42: - **Rule Maintenance:**
43:   - Update rules when new patterns emerge
44:   - Add examples from actual codebase
45:   - Remove outdated patterns
46:   - Cross-reference related rules
47: 
48: - **Best Practices:**
49:   - Use bullet points for clarity
50:   - Keep descriptions concise
51:   - Include both DO and DON'T examples
52:   - Reference actual code over theoretical examples
53:   - Use consistent formatting across rules
</file>

<file path=".roo/rules/dev_workflow.md">
  1: ---
  2: description: Guide for using Taskmaster to manage task-driven development workflows
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Development Workflow
  8: 
  9: This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.
 10: 
 11: - **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
 12: - **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.
 13: 
 14: ## The Basic Loop
 15: The fundamental development cycle you will facilitate is:
 16: 1.  **`list`**: Show the user what needs to be done.
 17: 2.  **`next`**: Help the user decide what to work on.
 18: 3.  **`show <id>`**: Provide details for a specific task.
 19: 4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
 20: 5.  **Implement**: The user writes the code and tests.
 21: 6.  **`update-subtask`**: Log progress and findings on behalf of the user.
 22: 7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
 23: 8.  **Repeat**.
 24: 
 25: All your standard command executions should operate on the user's current task context, which defaults to `master`.
 26: 
 27: ---
 28: 
 29: ## Standard Development Workflow Process
 30: 
 31: ### Simple Workflow (Default Starting Point)
 32: 
 33: For new projects or when users are getting started, operate within the `master` tag context:
 34: 
 35: -   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
 36: -   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules roo,windsurf`) or manage them later with `task-master rules add/remove` commands  
 37: -   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
 38: -   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
 39: -   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
 40: -   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
 41: -   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
 42: -   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
 43: -   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
 44: -   Implement code following task details, dependencies, and project standards
 45: -   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
 46: -   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)
 47: 
 48: ---
 49: 
 50: ## Leveling Up: Agent-Led Multi-Context Workflows
 51: 
 52: While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.
 53: 
 54: **Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.
 55: 
 56: ### When to Introduce Tags: Your Decision Patterns
 57: 
 58: Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.
 59: 
 60: #### Pattern 1: Simple Git Feature Branching
 61: This is the most common and direct use case for tags.
 62: 
 63: - **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
 64: - **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
 65: - **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
 66: - **Tool to Use**: `task-master add-tag --from-branch`
 67: 
 68: #### Pattern 2: Team Collaboration
 69: - **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
 70: - **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
 71: - **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
 72: - **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`
 73: 
 74: #### Pattern 3: Experiments or Risky Refactors
 75: - **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
 76: - **Your Action**: Propose creating a sandboxed tag for the experimental work.
 77: - **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
 78: - **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`
 79: 
 80: #### Pattern 4: Large Feature Initiatives (PRD-Driven)
 81: This is a more structured approach for significant new features or epics.
 82: 
 83: - **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
 84: - **Your Action**: Propose a comprehensive, PRD-driven workflow.
 85: - **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
 86: - **Your Implementation Flow**:
 87:     1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
 88:     2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
 89:     3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
 90:     4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.
 91: 
 92: #### Pattern 5: Version-Based Development
 93: Tailor your approach based on the project maturity indicated by tag names.
 94: 
 95: - **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
 96:   - **Your Approach**: Focus on speed and functionality over perfection
 97:   - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
 98:   - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
 99:   - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
100:   - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*
101: 
102: - **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
103:   - **Your Approach**: Emphasize robustness, testing, and maintainability
104:   - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
105:   - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
106:   - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
107:   - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*
108: 
109: ### Advanced Workflow (Tag-Based & PRD-Driven)
110: 
111: **When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
112: - User mentions teammates or collaboration needs
113: - Project has grown to 15+ tasks with mixed priorities
114: - User creates feature branches or mentions major initiatives
115: - User initializes Taskmaster on an existing, complex codebase
116: - User describes large features that would benefit from dedicated planning
117: 
118: **Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.
119: 
120: #### Master List Strategy (High-Value Focus)
121: Once you transition to tag-based workflows, the `master` tag should ideally contain only:
122: - **High-level deliverables** that provide significant business value
123: - **Major milestones** and epic-level features
124: - **Critical infrastructure** work that affects the entire project
125: - **Release-blocking** items
126: 
127: **What NOT to put in master**:
128: - Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
129: - Refactoring work (create dedicated tags like `refactor-auth`)
130: - Experimental features (use `experiment-*` tags)
131: - Team member-specific tasks (use person-specific tags)
132: 
133: #### PRD-Driven Feature Development
134: 
135: **For New Major Features**:
136: 1. **Identify the Initiative**: When user describes a significant feature
137: 2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
138: 3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
139: 4. **Parse & Prepare**: 
140:    - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
141:    - `analyze_project_complexity --tag=feature-[name] --research`
142:    - `expand_all --tag=feature-[name] --research`
143: 5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag
144: 
145: **For Existing Codebase Analysis**:
146: When users initialize Taskmaster on existing projects:
147: 1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
148: 2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
149: 3. **Strategic PRD Creation**: Co-author PRDs that include:
150:    - Current state analysis (based on your codebase research)
151:    - Proposed improvements or new features
152:    - Implementation strategy considering existing code
153: 4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
154: 5. **Master List Curation**: Keep only the most valuable initiatives in master
155: 
156: The parse-prd's `--append` flag enables the user to parse multple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.
157: 
158: ### Workflow Transition Examples
159: 
160: **Example 1: Simple → Team-Based**
161: ```
162: User: "Alice is going to help with the API work"
163: Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
164: Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
165: ```
166: 
167: **Example 2: Simple → PRD-Driven**
168: ```
169: User: "I want to add a complete user dashboard with analytics, user management, and reporting"
170: Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
171: Actions: 
172: 1. add_tag feature-dashboard --description="User dashboard with analytics and management"
173: 2. Collaborate on PRD creation
174: 3. parse_prd dashboard-prd.txt --tag=feature-dashboard
175: 4. Add high-level "User Dashboard" task to master
176: ```
177: 
178: **Example 3: Existing Project → Strategic Planning**
179: ```
180: User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
181: Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
182: Actions:
183: 1. research "Current React app architecture and improvement opportunities" --tree --files=src/
184: 2. Collaborate on improvement PRD based on findings
185: 3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
186: 4. Keep only major improvement initiatives in master
187: ```
188: 
189: ---
190: 
191: ## Primary Interaction: MCP Server vs. CLI
192: 
193: Taskmaster offers two primary ways to interact:
194: 
195: 1.  **MCP Server (Recommended for Integrated Tools)**:
196:     - For AI agents and integrated development environments (like Roo Code), interacting via the **MCP server is the preferred method**.
197:     - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
198:     - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
199:     - Refer to @`mcp.md` for details on the MCP architecture and available tools.
200:     - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
201:     - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
202:     - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.
203: 
204: 2.  **`task-master` CLI (For Users & Fallback)**:
205:     - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
206:     - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
207:     - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
208:     - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
209:     - Refer to @`taskmaster.md` for a detailed command reference.
210:     - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.
211: 
212: ## How the Tag System Works (For Your Reference)
213: 
214: - **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
215: - **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
216: - **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
217: - **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
218: - **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.
219: 
220: ---
221: 
222: ## Task Complexity Analysis
223: 
224: -   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
225: -   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
226: -   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
227: -   Use analysis results to determine appropriate subtask allocation
228: -   Note that reports are automatically used by the `expand_task` tool/command
229: 
230: ## Task Breakdown Process
231: 
232: -   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
233: -   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
234: -   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
235: -   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
236: -   Use `--prompt="<context>"` to provide additional context when needed.
237: -   Review and adjust generated subtasks as necessary.
238: -   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
239: -   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.
240: 
241: ## Implementation Drift Handling
242: 
243: -   When implementation differs significantly from planned approach
244: -   When future tasks need modification due to current implementation choices
245: -   When new dependencies or requirements emerge
246: -   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
247: -   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.
248: 
249: ## Task Status Management
250: 
251: -   Use 'pending' for tasks ready to be worked on
252: -   Use 'done' for completed and verified tasks
253: -   Use 'deferred' for postponed tasks
254: -   Add custom status values as needed for project-specific workflows
255: 
256: ## Task Structure Fields
257: 
258: - **id**: Unique identifier for the task (Example: `1`, `1.1`)
259: - **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
260: - **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
261: - **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
262: - **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
263:     - Dependencies are displayed with status indicators (✅ for completed, ⏱️ for pending)
264:     - This helps quickly identify which prerequisite tasks are blocking work
265: - **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
266: - **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`) 
267: - **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`) 
268: - **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`) 
269: - Refer to task structure details (previously linked to `tasks.md`).
270: 
271: ## Configuration Management (Updated)
272: 
273: Taskmaster configuration is managed through two main mechanisms:
274: 
275: 1.  **`.taskmaster/config.json` File (Primary):**
276:     *   Located in the project root directory.
277:     *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
278:     *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
279:     *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
280:     *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
281:     *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.
282: 
283: 2.  **Environment Variables (`.env` / `mcp.json`):**
284:     *   Used **only** for sensitive API keys and specific endpoint URLs.
285:     *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
286:     *   For MCP/Roo Code integration, configure these keys in the `env` section of `.roo/mcp.json`.
287:     *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).
288: 
289: 3.  **`.taskmaster/state.json` File (Tagged System State):**
290:     *   Tracks current tag context and migration status.
291:     *   Automatically created during tagged system migration.
292:     *   Contains: `currentTag`, `lastSwitched`, `migrationNoticeShown`.
293: 
294: **Important:** Non-API key settings (like model selections, `MAX_TOKENS`, `TASKMASTER_LOG_LEVEL`) are **no longer configured via environment variables**. Use the `task-master models` command (or `--setup` for interactive configuration) or the `models` MCP tool.
295: **If AI commands FAIL in MCP** verify that the API key for the selected provider is present in the `env` section of `.roo/mcp.json`.
296: **If AI commands FAIL in CLI** verify that the API key for the selected provider is present in the `.env` file in the root of the project.
297: 
298: ## Rules Management
299: 
300: Taskmaster supports multiple AI coding assistant rule sets that can be configured during project initialization or managed afterward:
301: 
302: - **Available Profiles**: Claude Code, Cline, Codex, Roo Code, Roo Code, Trae, Windsurf (claude, cline, codex, roo, roo, trae, windsurf)
303: - **During Initialization**: Use `task-master init --rules roo,windsurf` to specify which rule sets to include
304: - **After Initialization**: Use `task-master rules add <profiles>` or `task-master rules remove <profiles>` to manage rule sets
305: - **Interactive Setup**: Use `task-master rules setup` to launch an interactive prompt for selecting rule profiles
306: - **Default Behavior**: If no `--rules` flag is specified during initialization, all available rule profiles are included
307: - **Rule Structure**: Each profile creates its own directory (e.g., `.roo/rules`, `.roo/rules`) with appropriate configuration files
308: 
309: ## Determining the Next Task
310: 
311: - Run `next_task` / `task-master next` to show the next task to work on.
312: - The command identifies tasks with all dependencies satisfied
313: - Tasks are prioritized by priority level, dependency count, and ID
314: - The command shows comprehensive task information including:
315:     - Basic task details and description
316:     - Implementation details
317:     - Subtasks (if they exist)
318:     - Contextual suggested actions
319: - Recommended before starting any new development work
320: - Respects your project's dependency structure
321: - Ensures tasks are completed in the appropriate sequence
322: - Provides ready-to-use commands for common task actions
323: 
324: ## Viewing Specific Task Details
325: 
326: - Run `get_task` / `task-master show <id>` to view a specific task.
327: - Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
328: - Displays comprehensive information similar to the next command, but for a specific task
329: - For parent tasks, shows all subtasks and their current status
330: - For subtasks, shows parent task information and relationship
331: - Provides contextual suggested actions appropriate for the specific task
332: - Useful for examining task details before implementation or checking status
333: 
334: ## Managing Task Dependencies
335: 
336: - Use `add_dependency` / `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency.
337: - Use `remove_dependency` / `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency.
338: - The system prevents circular dependencies and duplicate dependency entries
339: - Dependencies are checked for existence before being added or removed
340: - Task files are automatically regenerated after dependency changes
341: - Dependencies are visualized with status indicators in task listings and files
342: 
343: ## Task Reorganization
344: 
345: - Use `move_task` / `task-master move --from=<id> --to=<id>` to move tasks or subtasks within the hierarchy
346: - This command supports several use cases:
347:   - Moving a standalone task to become a subtask (e.g., `--from=5 --to=7`)
348:   - Moving a subtask to become a standalone task (e.g., `--from=5.2 --to=7`) 
349:   - Moving a subtask to a different parent (e.g., `--from=5.2 --to=7.3`)
350:   - Reordering subtasks within the same parent (e.g., `--from=5.2 --to=5.4`)
351:   - Moving a task to a new, non-existent ID position (e.g., `--from=5 --to=25`)
352:   - Moving multiple tasks at once using comma-separated IDs (e.g., `--from=10,11,12 --to=16,17,18`)
353: - The system includes validation to prevent data loss:
354:   - Allows moving to non-existent IDs by creating placeholder tasks
355:   - Prevents moving to existing task IDs that have content (to avoid overwriting)
356:   - Validates source tasks exist before attempting to move them
357: - The system maintains proper parent-child relationships and dependency integrity
358: - Task files are automatically regenerated after the move operation
359: - This provides greater flexibility in organizing and refining your task structure as project understanding evolves
360: - This is especially useful when dealing with potential merge conflicts arising from teams creating tasks on separate branches. Solve these conflicts very easily by moving your tasks and keeping theirs.
361: 
362: ## Iterative Subtask Implementation
363: 
364: Once a task has been broken down into subtasks using `expand_task` or similar methods, follow this iterative process for implementation:
365: 
366: 1.  **Understand the Goal (Preparation):**
367:     *   Use `get_task` / `task-master show <subtaskId>` (see @`taskmaster.md`) to thoroughly understand the specific goals and requirements of the subtask.
368: 
369: 2.  **Initial Exploration & Planning (Iteration 1):**
370:     *   This is the first attempt at creating a concrete implementation plan.
371:     *   Explore the codebase to identify the precise files, functions, and even specific lines of code that will need modification.
372:     *   Determine the intended code changes (diffs) and their locations.
373:     *   Gather *all* relevant details from this exploration phase.
374: 
375: 3.  **Log the Plan:**
376:     *   Run `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<detailed plan>'`.
377:     *   Provide the *complete and detailed* findings from the exploration phase in the prompt. Include file paths, line numbers, proposed diffs, reasoning, and any potential challenges identified. Do not omit details. The goal is to create a rich, timestamped log within the subtask's `details`.
378: 
379: 4.  **Verify the Plan:**
380:     *   Run `get_task` / `task-master show <subtaskId>` again to confirm that the detailed implementation plan has been successfully appended to the subtask's details.
381: 
382: 5.  **Begin Implementation:**
383:     *   Set the subtask status using `set_task_status` / `task-master set-status --id=<subtaskId> --status=in-progress`.
384:     *   Start coding based on the logged plan.
385: 
386: 6.  **Refine and Log Progress (Iteration 2+):**
387:     *   As implementation progresses, you will encounter challenges, discover nuances, or confirm successful approaches.
388:     *   **Before appending new information**: Briefly review the *existing* details logged in the subtask (using `get_task` or recalling from context) to ensure the update adds fresh insights and avoids redundancy.
389:     *   **Regularly** use `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<update details>\n- What worked...\n- What didn't work...'` to append new findings.
390:     *   **Crucially, log:**
391:         *   What worked ("fundamental truths" discovered).
392:         *   What didn't work and why (to avoid repeating mistakes).
393:         *   Specific code snippets or configurations that were successful.
394:         *   Decisions made, especially if confirmed with user input.
395:         *   Any deviations from the initial plan and the reasoning.
396:     *   The objective is to continuously enrich the subtask's details, creating a log of the implementation journey that helps the AI (and human developers) learn, adapt, and avoid repeating errors.
397: 
398: 7.  **Review & Update Rules (Post-Implementation):**
399:     *   Once the implementation for the subtask is functionally complete, review all code changes and the relevant chat history.
400:     *   Identify any new or modified code patterns, conventions, or best practices established during the implementation.
401:     *   Create new or update existing rules following internal guidelines (previously linked to `cursor_rules.md` and `self_improve.md`).
402: 
403: 8.  **Mark Task Complete:**
404:     *   After verifying the implementation and updating any necessary rules, mark the subtask as completed: `set_task_status` / `task-master set-status --id=<subtaskId> --status=done`.
405: 
406: 9.  **Commit Changes (If using Git):**
407:     *   Stage the relevant code changes and any updated/new rule files (`git add .`).
408:     *   Craft a comprehensive Git commit message summarizing the work done for the subtask, including both code implementation and any rule adjustments.
409:     *   Execute the commit command directly in the terminal (e.g., `git commit -m 'feat(module): Implement feature X for subtask <subtaskId>\n\n- Details about changes...\n- Updated rule Y for pattern Z'`).
410:     *   Consider if a Changeset is needed according to internal versioning guidelines (previously linked to `changeset.md`). If so, run `npm run changeset`, stage the generated file, and amend the commit or create a new one.
411: 
412: 10. **Proceed to Next Subtask:**
413:     *   Identify the next subtask (e.g., using `next_task` / `task-master next`).
414: 
415: ## Code Analysis & Refactoring Techniques
416: 
417: - **Top-Level Function Search**:
418:     - Useful for understanding module structure or planning refactors.
419:     - Use grep/ripgrep to find exported functions/constants:
420:       `rg "export (async function|function|const) \w+"` or similar patterns.
421:     - Can help compare functions between files during migrations or identify potential naming conflicts.
422: 
423: ---
424: *This workflow provides a general guideline. Adapt it based on your specific project needs and team practices.*
</file>

<file path=".roo/rules/roo_rules.md">
 1: ---
 2: description: Guidelines for creating and maintaining Roo Code rules to ensure consistency and effectiveness.
 3: globs: .roo/rules/*.md
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Required Rule Structure:**
 8:   ```markdown
 9:   ---
10:   description: Clear, one-line description of what the rule enforces
11:   globs: path/to/files/*.ext, other/path/**/*
12:   alwaysApply: boolean
13:   ---
14: 
15:   - **Main Points in Bold**
16:     - Sub-points with details
17:     - Examples and explanations
18:   ```
19: 
20: - **File References:**
21:   - Use `[filename](mdc:path/to/file)` ([filename](mdc:filename)) to reference files
22:   - Example: [prisma.md](.roo/rules/prisma.md) for rule references
23:   - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references
24: 
25: - **Code Examples:**
26:   - Use language-specific code blocks
27:   ```typescript
28:   // ✅ DO: Show good examples
29:   const goodExample = true;
30:   
31:   // ❌ DON'T: Show anti-patterns
32:   const badExample = false;
33:   ```
34: 
35: - **Rule Content Guidelines:**
36:   - Start with high-level overview
37:   - Include specific, actionable requirements
38:   - Show examples of correct implementation
39:   - Reference existing code when possible
40:   - Keep rules DRY by referencing other rules
41: 
42: - **Rule Maintenance:**
43:   - Update rules when new patterns emerge
44:   - Add examples from actual codebase
45:   - Remove outdated patterns
46:   - Cross-reference related rules
47: 
48: - **Best Practices:**
49:   - Use bullet points for clarity
50:   - Keep descriptions concise
51:   - Include both DO and DON'T examples
52:   - Reference actual code over theoretical examples
53:   - Use consistent formatting across rules
</file>

<file path=".roo/rules/self_improve.md">
 1: ---
 2: description: Guidelines for continuously improving Roo Code rules based on emerging code patterns and best practices.
 3: globs: **/*
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Rule Improvement Triggers:**
 8:   - New code patterns not covered by existing rules
 9:   - Repeated similar implementations across files
10:   - Common error patterns that could be prevented
11:   - New libraries or tools being used consistently
12:   - Emerging best practices in the codebase
13: 
14: - **Analysis Process:**
15:   - Compare new code with existing rules
16:   - Identify patterns that should be standardized
17:   - Look for references to external documentation
18:   - Check for consistent error handling patterns
19:   - Monitor test patterns and coverage
20: 
21: - **Rule Updates:**
22:   - **Add New Rules When:**
23:     - A new technology/pattern is used in 3+ files
24:     - Common bugs could be prevented by a rule
25:     - Code reviews repeatedly mention the same feedback
26:     - New security or performance patterns emerge
27: 
28:   - **Modify Existing Rules When:**
29:     - Better examples exist in the codebase
30:     - Additional edge cases are discovered
31:     - Related rules have been updated
32:     - Implementation details have changed
33: 
34: - **Example Pattern Recognition:**
35:   ```typescript
36:   // If you see repeated patterns like:
37:   const data = await prisma.user.findMany({
38:     select: { id: true, email: true },
39:     where: { status: 'ACTIVE' }
40:   });
41:   
42:   // Consider adding to [prisma.md](.roo/rules/prisma.md):
43:   // - Standard select fields
44:   // - Common where conditions
45:   // - Performance optimization patterns
46:   ```
47: 
48: - **Rule Quality Checks:**
49:   - Rules should be actionable and specific
50:   - Examples should come from actual code
51:   - References should be up to date
52:   - Patterns should be consistently enforced
53: 
54: - **Continuous Improvement:**
55:   - Monitor code review comments
56:   - Track common development questions
57:   - Update rules after major refactors
58:   - Add links to relevant documentation
59:   - Cross-reference related rules
60: 
61: - **Rule Deprecation:**
62:   - Mark outdated patterns as deprecated
63:   - Remove rules that no longer apply
64:   - Update references to deprecated rules
65:   - Document migration paths for old patterns
66: 
67: - **Documentation Updates:**
68:   - Keep examples synchronized with code
69:   - Update references to external docs
70:   - Maintain links between related rules
71:   - Document breaking changes
72: Follow [roo_rules.md](.roo/rules/roo_rules.md) for proper rule formatting and structure.
</file>

<file path=".roo/rules/taskmaster.md">
  1: ---
  2: description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Tool & Command Reference
  8: 
  9: This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like Roo Code, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.
 10: 
 11: **Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback. 
 12: 
 13: **Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.
 14: 
 15: **🏷️ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.
 16: 
 17: ---
 18: 
 19: ## Initialization & Setup
 20: 
 21: ### 1. Initialize Project (`init`)
 22: 
 23: *   **MCP Tool:** `initialize_project`
 24: *   **CLI Command:** `task-master init [options]`
 25: *   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
 26: *   **Key CLI Options:**
 27:     *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
 28:     *   `--description <text>`: `Provide a brief description for your project.`
 29:     *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
 30:     *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
 31: *   **Usage:** Run this once at the beginning of a new project.
 32: *   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
 33: *   **Key MCP Parameters/Options:**
 34:     *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
 35:     *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
 36:     *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
 37:     *   `authorName`: `Author name.` (CLI: `--author <author>`)
 38:     *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
 39:     *   `addAliases`: `Add shell aliases tm and taskmaster. Default is false.` (CLI: `--aliases`)
 40:     *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
 41: *   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like Roo Code. Operates on the current working directory of the MCP server. 
 42: *   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt. 
 43: *   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.
 44: 
 45: ### 2. Parse PRD (`parse_prd`)
 46: 
 47: *   **MCP Tool:** `parse_prd`
 48: *   **CLI Command:** `task-master parse-prd [file] [options]`
 49: *   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
 50: *   **Key Parameters/Options:**
 51:     *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
 52:     *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
 53:     *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
 54:     *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
 55: *   **Usage:** Useful for bootstrapping a project from an existing requirements document.
 56: *   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
 57: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.
 58: 
 59: ---
 60: 
 61: ## AI Model Configuration
 62: 
 63: ### 2. Manage Models (`models`)
 64: *   **MCP Tool:** `models`
 65: *   **CLI Command:** `task-master models [options]`
 66: *   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
 67: *   **Key MCP Parameters/Options:**
 68:     *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
 69:     *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
 70:     *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
 71:     *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
 72:     *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
 73:     *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
 74:     *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
 75: *   **Key CLI Options:**
 76:     *   `--set-main <model_id>`: `Set the primary model.`
 77:     *   `--set-research <model_id>`: `Set the research model.`
 78:     *   `--set-fallback <model_id>`: `Set the fallback model.`
 79:     *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
 80:     *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
 81:     *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
 82:     *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
 83: *   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
 84: *   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
 85: *   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
 86: *   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
 87: *   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80. 
 88: *   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.
 89: 
 90: ---
 91: 
 92: ## Task Listing & Viewing
 93: 
 94: ### 3. Get Tasks (`get_tasks`)
 95: 
 96: *   **MCP Tool:** `get_tasks`
 97: *   **CLI Command:** `task-master list [options]`
 98: *   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
 99: *   **Key Parameters/Options:**
100:     *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
101:     *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
102:     *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
103:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
104: *   **Usage:** Get an overview of the project status, often used at the start of a work session.
105: 
106: ### 4. Get Next Task (`next_task`)
107: 
108: *   **MCP Tool:** `next_task`
109: *   **CLI Command:** `task-master next [options]`
110: *   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
111: *   **Key Parameters/Options:**
112:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
113:     *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
114: *   **Usage:** Identify what to work on next according to the plan.
115: 
116: ### 5. Get Task Details (`get_task`)
117: 
118: *   **MCP Tool:** `get_task`
119: *   **CLI Command:** `task-master show [id] [options]`
120: *   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
121: *   **Key Parameters/Options:**
122:     *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
123:     *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
124:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
125: *   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
126: *   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.
127: 
128: ---
129: 
130: ## Task Creation & Modification
131: 
132: ### 6. Add Task (`add_task`)
133: 
134: *   **MCP Tool:** `add_task`
135: *   **CLI Command:** `task-master add-task [options]`
136: *   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
137: *   **Key Parameters/Options:**
138:     *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
139:     *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
140:     *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
141:     *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
142:     *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
143:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
144: *   **Usage:** Quickly add newly identified tasks during development.
145: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
146: 
147: ### 7. Add Subtask (`add_subtask`)
148: 
149: *   **MCP Tool:** `add_subtask`
150: *   **CLI Command:** `task-master add-subtask [options]`
151: *   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
152: *   **Key Parameters/Options:**
153:     *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
154:     *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
155:     *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
156:     *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
157:     *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
158:     *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
159:     *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
160:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after adding the subtask.` (CLI: `--skip-generate`)
161:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
162:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
163: *   **Usage:** Break down tasks manually or reorganize existing tasks.
164: 
165: ### 8. Update Tasks (`update`)
166: 
167: *   **MCP Tool:** `update`
168: *   **CLI Command:** `task-master update [options]`
169: *   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
170: *   **Key Parameters/Options:**
171:     *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
172:     *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
173:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
174:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
175:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
176: *   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
177: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
178: 
179: ### 9. Update Task (`update_task`)
180: 
181: *   **MCP Tool:** `update_task`
182: *   **CLI Command:** `task-master update-task [options]`
183: *   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
184: *   **Key Parameters/Options:**
185:     *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
186:     *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
187:     *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
188:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
189:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
190:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
191: *   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
192: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
193: 
194: ### 10. Update Subtask (`update_subtask`)
195: 
196: *   **MCP Tool:** `update_subtask`
197: *   **CLI Command:** `task-master update-subtask [options]`
198: *   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
199: *   **Key Parameters/Options:**
200:     *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
201:     *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
202:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
203:     *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
204:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
205: *   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
206: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
207: 
208: ### 11. Set Task Status (`set_task_status`)
209: 
210: *   **MCP Tool:** `set_task_status`
211: *   **CLI Command:** `task-master set-status [options]`
212: *   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
213: *   **Key Parameters/Options:**
214:     *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
215:     *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
216:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
217:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
218: *   **Usage:** Mark progress as tasks move through the development cycle.
219: 
220: ### 12. Remove Task (`remove_task`)
221: 
222: *   **MCP Tool:** `remove_task`
223: *   **CLI Command:** `task-master remove-task [options]`
224: *   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
225: *   **Key Parameters/Options:**
226:     *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
227:     *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
228:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
229:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
230: *   **Usage:** Permanently delete tasks or subtasks that are no longer needed in the project.
231: *   **Notes:** Use with caution as this operation cannot be undone. Consider using 'blocked', 'cancelled', or 'deferred' status instead if you just want to exclude a task from active planning but keep it for reference. The command automatically cleans up dependency references in other tasks.
232: 
233: ---
234: 
235: ## Task Structure & Breakdown
236: 
237: ### 13. Expand Task (`expand_task`)
238: 
239: *   **MCP Tool:** `expand_task`
240: *   **CLI Command:** `task-master expand [options]`
241: *   **Description:** `Use Taskmaster's AI to break down a complex task into smaller, manageable subtasks. Appends subtasks by default.`
242: *   **Key Parameters/Options:**
243:     *   `id`: `The ID of the specific Taskmaster task you want to break down into subtasks.` (CLI: `-i, --id <id>`)
244:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create. Uses complexity analysis/defaults otherwise.` (CLI: `-n, --num <number>`)
245:     *   `research`: `Enable Taskmaster to use the research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
246:     *   `prompt`: `Optional: Provide extra context or specific instructions to Taskmaster for generating the subtasks.` (CLI: `-p, --prompt <text>`)
247:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones. Default is false (append).` (CLI: `--force`)
248:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
249:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
250: *   **Usage:** Generate a detailed implementation plan for a complex task before starting coding. Automatically uses complexity report recommendations if available and `num` is not specified.
251: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
252: 
253: ### 14. Expand All Tasks (`expand_all`)
254: 
255: *   **MCP Tool:** `expand_all`
256: *   **CLI Command:** `task-master expand --all [options]` (Note: CLI uses the `expand` command with the `--all` flag)
257: *   **Description:** `Tell Taskmaster to automatically expand all eligible pending/in-progress tasks based on complexity analysis or defaults. Appends subtasks by default.`
258: *   **Key Parameters/Options:**
259:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create per task.` (CLI: `-n, --num <number>`)
260:     *   `research`: `Enable research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
261:     *   `prompt`: `Optional: Provide extra context for Taskmaster to apply generally during expansion.` (CLI: `-p, --prompt <text>`)
262:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones for each eligible task. Default is false (append).` (CLI: `--force`)
263:     *   `tag`: `Specify which tag context to expand. Defaults to the current active tag.` (CLI: `--tag <name>`)
264:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
265: *   **Usage:** Useful after initial task generation or complexity analysis to break down multiple tasks at once.
266: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
267: 
268: ### 15. Clear Subtasks (`clear_subtasks`)
269: 
270: *   **MCP Tool:** `clear_subtasks`
271: *   **CLI Command:** `task-master clear-subtasks [options]`
272: *   **Description:** `Remove all subtasks from one or more specified Taskmaster parent tasks.`
273: *   **Key Parameters/Options:**
274:     *   `id`: `The ID(s) of the Taskmaster parent task(s) whose subtasks you want to remove, e.g., '15' or '16,18'. Required unless using `all`.) (CLI: `-i, --id <ids>`)
275:     *   `all`: `Tell Taskmaster to remove subtasks from all parent tasks.` (CLI: `--all`)
276:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
277:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
278: *   **Usage:** Used before regenerating subtasks with `expand_task` if the previous breakdown needs replacement.
279: 
280: ### 16. Remove Subtask (`remove_subtask`)
281: 
282: *   **MCP Tool:** `remove_subtask`
283: *   **CLI Command:** `task-master remove-subtask [options]`
284: *   **Description:** `Remove a subtask from its Taskmaster parent, optionally converting it into a standalone task.`
285: *   **Key Parameters/Options:**
286:     *   `id`: `Required. The ID(s) of the Taskmaster subtask(s) to remove, e.g., '15.2' or '16.1,16.3'.` (CLI: `-i, --id <id>`)
287:     *   `convert`: `If used, Taskmaster will turn the subtask into a regular top-level task instead of deleting it.` (CLI: `-c, --convert`)
288:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after removing the subtask.` (CLI: `--skip-generate`)
289:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
290:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
291: *   **Usage:** Delete unnecessary subtasks or promote a subtask to a top-level task.
292: 
293: ### 17. Move Task (`move_task`)
294: 
295: *   **MCP Tool:** `move_task`
296: *   **CLI Command:** `task-master move [options]`
297: *   **Description:** `Move a task or subtask to a new position within the task hierarchy.`
298: *   **Key Parameters/Options:**
299:     *   `from`: `Required. ID of the task/subtask to move (e.g., "5" or "5.2"). Can be comma-separated for multiple tasks.` (CLI: `--from <id>`)
300:     *   `to`: `Required. ID of the destination (e.g., "7" or "7.3"). Must match the number of source IDs if comma-separated.` (CLI: `--to <id>`)
301:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
302:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
303: *   **Usage:** Reorganize tasks by moving them within the hierarchy. Supports various scenarios like:
304:     *   Moving a task to become a subtask
305:     *   Moving a subtask to become a standalone task
306:     *   Moving a subtask to a different parent
307:     *   Reordering subtasks within the same parent
308:     *   Moving a task to a new, non-existent ID (automatically creates placeholders)
309:     *   Moving multiple tasks at once with comma-separated IDs
310: *   **Validation Features:**
311:     *   Allows moving tasks to non-existent destination IDs (creates placeholder tasks)
312:     *   Prevents moving to existing task IDs that already have content (to avoid overwriting)
313:     *   Validates that source tasks exist before attempting to move them
314:     *   Maintains proper parent-child relationships
315: *   **Example CLI:** `task-master move --from=5.2 --to=7.3` to move subtask 5.2 to become subtask 7.3.
316: *   **Example Multi-Move:** `task-master move --from=10,11,12 --to=16,17,18` to move multiple tasks to new positions.
317: *   **Common Use:** Resolving merge conflicts in tasks.json when multiple team members create tasks on different branches.
318: 
319: ---
320: 
321: ## Dependency Management
322: 
323: ### 18. Add Dependency (`add_dependency`)
324: 
325: *   **MCP Tool:** `add_dependency`
326: *   **CLI Command:** `task-master add-dependency [options]`
327: *   **Description:** `Define a dependency in Taskmaster, making one task a prerequisite for another.`
328: *   **Key Parameters/Options:**
329:     *   `id`: `Required. The ID of the Taskmaster task that will depend on another.` (CLI: `-i, --id <id>`)
330:     *   `dependsOn`: `Required. The ID of the Taskmaster task that must be completed first, the prerequisite.` (CLI: `-d, --depends-on <id>`)
331:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
332:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <path>`)
333: *   **Usage:** Establish the correct order of execution between tasks.
334: 
335: ### 19. Remove Dependency (`remove_dependency`)
336: 
337: *   **MCP Tool:** `remove_dependency`
338: *   **CLI Command:** `task-master remove-dependency [options]`
339: *   **Description:** `Remove a dependency relationship between two Taskmaster tasks.`
340: *   **Key Parameters/Options:**
341:     *   `id`: `Required. The ID of the Taskmaster task you want to remove a prerequisite from.` (CLI: `-i, --id <id>`)
342:     *   `dependsOn`: `Required. The ID of the Taskmaster task that should no longer be a prerequisite.` (CLI: `-d, --depends-on <id>`)
343:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
344:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
345: *   **Usage:** Update task relationships when the order of execution changes.
346: 
347: ### 20. Validate Dependencies (`validate_dependencies`)
348: 
349: *   **MCP Tool:** `validate_dependencies`
350: *   **CLI Command:** `task-master validate-dependencies [options]`
351: *   **Description:** `Check your Taskmaster tasks for dependency issues (like circular references or links to non-existent tasks) without making changes.`
352: *   **Key Parameters/Options:**
353:     *   `tag`: `Specify which tag context to validate. Defaults to the current active tag.` (CLI: `--tag <name>`)
354:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
355: *   **Usage:** Audit the integrity of your task dependencies.
356: 
357: ### 21. Fix Dependencies (`fix_dependencies`)
358: 
359: *   **MCP Tool:** `fix_dependencies`
360: *   **CLI Command:** `task-master fix-dependencies [options]`
361: *   **Description:** `Automatically fix dependency issues (like circular references or links to non-existent tasks) in your Taskmaster tasks.`
362: *   **Key Parameters/Options:**
363:     *   `tag`: `Specify which tag context to fix dependencies in. Defaults to the current active tag.` (CLI: `--tag <name>`)
364:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
365: *   **Usage:** Clean up dependency errors automatically.
366: 
367: ---
368: 
369: ## Analysis & Reporting
370: 
371: ### 22. Analyze Project Complexity (`analyze_project_complexity`)
372: 
373: *   **MCP Tool:** `analyze_project_complexity`
374: *   **CLI Command:** `task-master analyze-complexity [options]`
375: *   **Description:** `Have Taskmaster analyze your tasks to determine their complexity and suggest which ones need to be broken down further.`
376: *   **Key Parameters/Options:**
377:     *   `output`: `Where to save the complexity analysis report. Default is '.taskmaster/reports/task-complexity-report.json' (or '..._tagname.json' if a tag is used).` (CLI: `-o, --output <file>`)
378:     *   `threshold`: `The minimum complexity score (1-10) that should trigger a recommendation to expand a task.` (CLI: `-t, --threshold <number>`)
379:     *   `research`: `Enable research role for more accurate complexity analysis. Requires appropriate API key.` (CLI: `-r, --research`)
380:     *   `tag`: `Specify which tag context to analyze. Defaults to the current active tag.` (CLI: `--tag <name>`)
381:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
382: *   **Usage:** Used before breaking down tasks to identify which ones need the most attention.
383: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
384: 
385: ### 23. View Complexity Report (`complexity_report`)
386: 
387: *   **MCP Tool:** `complexity_report`
388: *   **CLI Command:** `task-master complexity-report [options]`
389: *   **Description:** `Display the task complexity analysis report in a readable format.`
390: *   **Key Parameters/Options:**
391:     *   `tag`: `Specify which tag context to show the report for. Defaults to the current active tag.` (CLI: `--tag <name>`)
392:     *   `file`: `Path to the complexity report (default: '.taskmaster/reports/task-complexity-report.json').` (CLI: `-f, --file <file>`)
393: *   **Usage:** Review and understand the complexity analysis results after running analyze-complexity.
394: 
395: ---
396: 
397: ## File Management
398: 
399: ### 24. Generate Task Files (`generate`)
400: 
401: *   **MCP Tool:** `generate`
402: *   **CLI Command:** `task-master generate [options]`
403: *   **Description:** `Create or update individual Markdown files for each task based on your tasks.json.`
404: *   **Key Parameters/Options:**
405:     *   `output`: `The directory where Taskmaster should save the task files (default: in a 'tasks' directory).` (CLI: `-o, --output <directory>`)
406:     *   `tag`: `Specify which tag context to generate files for. Defaults to the current active tag.` (CLI: `--tag <name>`)
407:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
408: *   **Usage:** Run this after making changes to tasks.json to keep individual task files up to date. This command is now manual and no longer runs automatically.
409: 
410: ---
411: 
412: ## AI-Powered Research
413: 
414: ### 25. Research (`research`)
415: 
416: *   **MCP Tool:** `research`
417: *   **CLI Command:** `task-master research [options]`
418: *   **Description:** `Perform AI-powered research queries with project context to get fresh, up-to-date information beyond the AI's knowledge cutoff.`
419: *   **Key Parameters/Options:**
420:     *   `query`: `Required. Research query/prompt (e.g., "What are the latest best practices for React Query v5?").` (CLI: `[query]` positional or `-q, --query <text>`)
421:     *   `taskIds`: `Comma-separated list of task/subtask IDs from the current tag context (e.g., "15,16.2,17").` (CLI: `-i, --id <ids>`)
422:     *   `filePaths`: `Comma-separated list of file paths for context (e.g., "src/api.js,docs/readme.md").` (CLI: `-f, --files <paths>`)
423:     *   `customContext`: `Additional custom context text to include in the research.` (CLI: `-c, --context <text>`)
424:     *   `includeProjectTree`: `Include project file tree structure in context (default: false).` (CLI: `--tree`)
425:     *   `detailLevel`: `Detail level for the research response: 'low', 'medium', 'high' (default: medium).` (CLI: `--detail <level>`)
426:     *   `saveTo`: `Task or subtask ID (e.g., "15", "15.2") to automatically save the research conversation to.` (CLI: `--save-to <id>`)
427:     *   `saveFile`: `If true, saves the research conversation to a markdown file in '.taskmaster/docs/research/'.` (CLI: `--save-file`)
428:     *   `noFollowup`: `Disables the interactive follow-up question menu in the CLI.` (CLI: `--no-followup`)
429:     *   `tag`: `Specify which tag context to use for task-based context gathering. Defaults to the current active tag.` (CLI: `--tag <name>`)
430:     *   `projectRoot`: `The directory of the project. Must be an absolute path.` (CLI: Determined automatically)
431: *   **Usage:** **This is a POWERFUL tool that agents should use FREQUENTLY** to:
432:     *   Get fresh information beyond knowledge cutoff dates
433:     *   Research latest best practices, library updates, security patches
434:     *   Find implementation examples for specific technologies
435:     *   Validate approaches against current industry standards
436:     *   Get contextual advice based on project files and tasks
437: *   **When to Consider Using Research:**
438:     *   **Before implementing any task** - Research current best practices
439:     *   **When encountering new technologies** - Get up-to-date implementation guidance (libraries, apis, etc)
440:     *   **For security-related tasks** - Find latest security recommendations
441:     *   **When updating dependencies** - Research breaking changes and migration guides
442:     *   **For performance optimization** - Get current performance best practices
443:     *   **When debugging complex issues** - Research known solutions and workarounds
444: *   **Research + Action Pattern:**
445:     *   Use `research` to gather fresh information
446:     *   Use `update_subtask` to commit findings with timestamps
447:     *   Use `update_task` to incorporate research into task details
448:     *   Use `add_task` with research flag for informed task creation
449: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. The research provides FRESH data beyond the AI's training cutoff, making it invaluable for current best practices and recent developments.
450: 
451: ---
452: 
453: ## Tag Management
454: 
455: This new suite of commands allows you to manage different task contexts (tags).
456: 
457: ### 26. List Tags (`tags`)
458: 
459: *   **MCP Tool:** `list_tags`
460: *   **CLI Command:** `task-master tags [options]`
461: *   **Description:** `List all available tags with task counts, completion status, and other metadata.`
462: *   **Key Parameters/Options:**
463:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
464:     *   `--show-metadata`: `Include detailed metadata in the output (e.g., creation date, description).` (CLI: `--show-metadata`)
465: 
466: ### 27. Add Tag (`add_tag`)
467: 
468: *   **MCP Tool:** `add_tag`
469: *   **CLI Command:** `task-master add-tag <tagName> [options]`
470: *   **Description:** `Create a new, empty tag context, or copy tasks from another tag.`
471: *   **Key Parameters/Options:**
472:     *   `tagName`: `Name of the new tag to create (alphanumeric, hyphens, underscores).` (CLI: `<tagName>` positional)
473:     *   `--from-branch`: `Creates a tag with a name derived from the current git branch, ignoring the <tagName> argument.` (CLI: `--from-branch`)
474:     *   `--copy-from-current`: `Copy tasks from the currently active tag to the new tag.` (CLI: `--copy-from-current`)
475:     *   `--copy-from <tag>`: `Copy tasks from a specific source tag to the new tag.` (CLI: `--copy-from <tag>`)
476:     *   `--description <text>`: `Provide an optional description for the new tag.` (CLI: `-d, --description <text>`)
477:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
478: 
479: ### 28. Delete Tag (`delete_tag`)
480: 
481: *   **MCP Tool:** `delete_tag`
482: *   **CLI Command:** `task-master delete-tag <tagName> [options]`
483: *   **Description:** `Permanently delete a tag and all of its associated tasks.`
484: *   **Key Parameters/Options:**
485:     *   `tagName`: `Name of the tag to delete.` (CLI: `<tagName>` positional)
486:     *   `--yes`: `Skip the confirmation prompt.` (CLI: `-y, --yes`)
487:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
488: 
489: ### 29. Use Tag (`use_tag`)
490: 
491: *   **MCP Tool:** `use_tag`
492: *   **CLI Command:** `task-master use-tag <tagName>`
493: *   **Description:** `Switch your active task context to a different tag.`
494: *   **Key Parameters/Options:**
495:     *   `tagName`: `Name of the tag to switch to.` (CLI: `<tagName>` positional)
496:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
497: 
498: ### 30. Rename Tag (`rename_tag`)
499: 
500: *   **MCP Tool:** `rename_tag`
501: *   **CLI Command:** `task-master rename-tag <oldName> <newName>`
502: *   **Description:** `Rename an existing tag.`
503: *   **Key Parameters/Options:**
504:     *   `oldName`: `The current name of the tag.` (CLI: `<oldName>` positional)
505:     *   `newName`: `The new name for the tag.` (CLI: `<newName>` positional)
506:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
507: 
508: ### 31. Copy Tag (`copy_tag`)
509: 
510: *   **MCP Tool:** `copy_tag`
511: *   **CLI Command:** `task-master copy-tag <sourceName> <targetName> [options]`
512: *   **Description:** `Copy an entire tag context, including all its tasks and metadata, to a new tag.`
513: *   **Key Parameters/Options:**
514:     *   `sourceName`: `Name of the tag to copy from.` (CLI: `<sourceName>` positional)
515:     *   `targetName`: `Name of the new tag to create.` (CLI: `<targetName>` positional)
516:     *   `--description <text>`: `Optional description for the new tag.` (CLI: `-d, --description <text>`)
517: 
518: ---
519: 
520: ## Miscellaneous
521: 
522: ### 32. Sync Readme (`sync-readme`) -- experimental
523: 
524: *   **MCP Tool:** N/A
525: *   **CLI Command:** `task-master sync-readme [options]`
526: *   **Description:** `Exports your task list to your project's README.md file, useful for showcasing progress.`
527: *   **Key Parameters/Options:**
528:     *   `status`: `Filter tasks by status (e.g., 'pending', 'done').` (CLI: `-s, --status <status>`)
529:     *   `withSubtasks`: `Include subtasks in the export.` (CLI: `--with-subtasks`)
530:     *   `tag`: `Specify which tag context to export from. Defaults to the current active tag.` (CLI: `--tag <name>`)
531: 
532: ---
533: 
534: ## Environment Variables Configuration (Updated)
535: 
536: Taskmaster primarily uses the **`.taskmaster/config.json`** file (in project root) for configuration (models, parameters, logging level, etc.), managed via `task-master models --setup`.
537: 
538: Environment variables are used **only** for sensitive API keys related to AI providers and specific overrides like the Ollama base URL:
539: 
540: *   **API Keys (Required for corresponding provider):**
541:     *   `ANTHROPIC_API_KEY`
542:     *   `PERPLEXITY_API_KEY`
543:     *   `OPENAI_API_KEY`
544:     *   `GOOGLE_API_KEY`
545:     *   `MISTRAL_API_KEY`
546:     *   `AZURE_OPENAI_API_KEY` (Requires `AZURE_OPENAI_ENDPOINT` too)
547:     *   `OPENROUTER_API_KEY`
548:     *   `XAI_API_KEY`
549:     *   `OLLAMA_API_KEY` (Requires `OLLAMA_BASE_URL` too)
550: *   **Endpoints (Optional/Provider Specific inside .taskmaster/config.json):**
551:     *   `AZURE_OPENAI_ENDPOINT`
552:     *   `OLLAMA_BASE_URL` (Default: `http://localhost:11434/api`)
553: 
554: **Set API keys** in your **`.env`** file in the project root (for CLI use) or within the `env` section of your **`.roo/mcp.json`** file (for MCP/Roo Code integration). All other settings (model choice, max tokens, temperature, log level, custom endpoints) are managed in `.taskmaster/config.json` via `task-master models` command or `models` MCP tool.
555: 
556: ---
557: 
558: For details on how these commands fit into the development process, see the [dev_workflow.md](.roo/rules/dev_workflow.md).
</file>

<file path=".roo/mcp.json">
 1: {
 2: 	"mcpServers": {
 3: 		"task-master-ai": {
 4: 			"command": "npx",
 5: 			"args": ["-y", "--package=task-master-ai", "task-master-ai"],
 6: 			"env": {
 7: 				"ANTHROPIC_API_KEY": "ANTHROPIC_API_KEY_HERE",
 8: 				"PERPLEXITY_API_KEY": "PERPLEXITY_API_KEY_HERE",
 9: 				"OPENAI_API_KEY": "OPENAI_API_KEY_HERE",
10: 				"GOOGLE_API_KEY": "GOOGLE_API_KEY_HERE",
11: 				"XAI_API_KEY": "XAI_API_KEY_HERE",
12: 				"OPENROUTER_API_KEY": "OPENROUTER_API_KEY_HERE",
13: 				"MISTRAL_API_KEY": "MISTRAL_API_KEY_HERE",
14: 				"AZURE_OPENAI_API_KEY": "AZURE_OPENAI_API_KEY_HERE",
15: 				"OLLAMA_API_KEY": "OLLAMA_API_KEY_HERE"
16: 			}
17: 		}
18: 	}
19: }
</file>

<file path=".trae/rules/dev_workflow.md">
  1: ---
  2: description: Guide for using Taskmaster to manage task-driven development workflows
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Development Workflow
  8: 
  9: This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.
 10: 
 11: - **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
 12: - **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.
 13: 
 14: ## The Basic Loop
 15: The fundamental development cycle you will facilitate is:
 16: 1.  **`list`**: Show the user what needs to be done.
 17: 2.  **`next`**: Help the user decide what to work on.
 18: 3.  **`show <id>`**: Provide details for a specific task.
 19: 4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
 20: 5.  **Implement**: The user writes the code and tests.
 21: 6.  **`update-subtask`**: Log progress and findings on behalf of the user.
 22: 7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
 23: 8.  **Repeat**.
 24: 
 25: All your standard command executions should operate on the user's current task context, which defaults to `master`.
 26: 
 27: ---
 28: 
 29: ## Standard Development Workflow Process
 30: 
 31: ### Simple Workflow (Default Starting Point)
 32: 
 33: For new projects or when users are getting started, operate within the `master` tag context:
 34: 
 35: -   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
 36: -   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules trae,windsurf`) or manage them later with `task-master rules add/remove` commands  
 37: -   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
 38: -   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
 39: -   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
 40: -   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
 41: -   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
 42: -   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
 43: -   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
 44: -   Implement code following task details, dependencies, and project standards
 45: -   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
 46: -   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)
 47: 
 48: ---
 49: 
 50: ## Leveling Up: Agent-Led Multi-Context Workflows
 51: 
 52: While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.
 53: 
 54: **Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.
 55: 
 56: ### When to Introduce Tags: Your Decision Patterns
 57: 
 58: Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.
 59: 
 60: #### Pattern 1: Simple Git Feature Branching
 61: This is the most common and direct use case for tags.
 62: 
 63: - **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
 64: - **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
 65: - **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
 66: - **Tool to Use**: `task-master add-tag --from-branch`
 67: 
 68: #### Pattern 2: Team Collaboration
 69: - **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
 70: - **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
 71: - **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
 72: - **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`
 73: 
 74: #### Pattern 3: Experiments or Risky Refactors
 75: - **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
 76: - **Your Action**: Propose creating a sandboxed tag for the experimental work.
 77: - **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
 78: - **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`
 79: 
 80: #### Pattern 4: Large Feature Initiatives (PRD-Driven)
 81: This is a more structured approach for significant new features or epics.
 82: 
 83: - **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
 84: - **Your Action**: Propose a comprehensive, PRD-driven workflow.
 85: - **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
 86: - **Your Implementation Flow**:
 87:     1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
 88:     2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
 89:     3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
 90:     4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.
 91: 
 92: #### Pattern 5: Version-Based Development
 93: Tailor your approach based on the project maturity indicated by tag names.
 94: 
 95: - **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
 96:   - **Your Approach**: Focus on speed and functionality over perfection
 97:   - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
 98:   - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
 99:   - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
100:   - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*
101: 
102: - **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
103:   - **Your Approach**: Emphasize robustness, testing, and maintainability
104:   - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
105:   - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
106:   - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
107:   - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*
108: 
109: ### Advanced Workflow (Tag-Based & PRD-Driven)
110: 
111: **When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
112: - User mentions teammates or collaboration needs
113: - Project has grown to 15+ tasks with mixed priorities
114: - User creates feature branches or mentions major initiatives
115: - User initializes Taskmaster on an existing, complex codebase
116: - User describes large features that would benefit from dedicated planning
117: 
118: **Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.
119: 
120: #### Master List Strategy (High-Value Focus)
121: Once you transition to tag-based workflows, the `master` tag should ideally contain only:
122: - **High-level deliverables** that provide significant business value
123: - **Major milestones** and epic-level features
124: - **Critical infrastructure** work that affects the entire project
125: - **Release-blocking** items
126: 
127: **What NOT to put in master**:
128: - Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
129: - Refactoring work (create dedicated tags like `refactor-auth`)
130: - Experimental features (use `experiment-*` tags)
131: - Team member-specific tasks (use person-specific tags)
132: 
133: #### PRD-Driven Feature Development
134: 
135: **For New Major Features**:
136: 1. **Identify the Initiative**: When user describes a significant feature
137: 2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
138: 3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
139: 4. **Parse & Prepare**: 
140:    - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
141:    - `analyze_project_complexity --tag=feature-[name] --research`
142:    - `expand_all --tag=feature-[name] --research`
143: 5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag
144: 
145: **For Existing Codebase Analysis**:
146: When users initialize Taskmaster on existing projects:
147: 1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
148: 2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
149: 3. **Strategic PRD Creation**: Co-author PRDs that include:
150:    - Current state analysis (based on your codebase research)
151:    - Proposed improvements or new features
152:    - Implementation strategy considering existing code
153: 4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
154: 5. **Master List Curation**: Keep only the most valuable initiatives in master
155: 
156: The parse-prd's `--append` flag enables the user to parse multple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.
157: 
158: ### Workflow Transition Examples
159: 
160: **Example 1: Simple → Team-Based**
161: ```
162: User: "Alice is going to help with the API work"
163: Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
164: Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
165: ```
166: 
167: **Example 2: Simple → PRD-Driven**
168: ```
169: User: "I want to add a complete user dashboard with analytics, user management, and reporting"
170: Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
171: Actions: 
172: 1. add_tag feature-dashboard --description="User dashboard with analytics and management"
173: 2. Collaborate on PRD creation
174: 3. parse_prd dashboard-prd.txt --tag=feature-dashboard
175: 4. Add high-level "User Dashboard" task to master
176: ```
177: 
178: **Example 3: Existing Project → Strategic Planning**
179: ```
180: User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
181: Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
182: Actions:
183: 1. research "Current React app architecture and improvement opportunities" --tree --files=src/
184: 2. Collaborate on improvement PRD based on findings
185: 3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
186: 4. Keep only major improvement initiatives in master
187: ```
188: 
189: ---
190: 
191: ## Primary Interaction: MCP Server vs. CLI
192: 
193: Taskmaster offers two primary ways to interact:
194: 
195: 1.  **MCP Server (Recommended for Integrated Tools)**:
196:     - For AI agents and integrated development environments (like Trae), interacting via the **MCP server is the preferred method**.
197:     - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
198:     - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
199:     - Refer to @`mcp.md` for details on the MCP architecture and available tools.
200:     - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
201:     - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
202:     - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.
203: 
204: 2.  **`task-master` CLI (For Users & Fallback)**:
205:     - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
206:     - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
207:     - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
208:     - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
209:     - Refer to @`taskmaster.md` for a detailed command reference.
210:     - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.
211: 
212: ## How the Tag System Works (For Your Reference)
213: 
214: - **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
215: - **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
216: - **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
217: - **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
218: - **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.
219: 
220: ---
221: 
222: ## Task Complexity Analysis
223: 
224: -   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
225: -   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
226: -   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
227: -   Use analysis results to determine appropriate subtask allocation
228: -   Note that reports are automatically used by the `expand_task` tool/command
229: 
230: ## Task Breakdown Process
231: 
232: -   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
233: -   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
234: -   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
235: -   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
236: -   Use `--prompt="<context>"` to provide additional context when needed.
237: -   Review and adjust generated subtasks as necessary.
238: -   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
239: -   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.
240: 
241: ## Implementation Drift Handling
242: 
243: -   When implementation differs significantly from planned approach
244: -   When future tasks need modification due to current implementation choices
245: -   When new dependencies or requirements emerge
246: -   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
247: -   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.
248: 
249: ## Task Status Management
250: 
251: -   Use 'pending' for tasks ready to be worked on
252: -   Use 'done' for completed and verified tasks
253: -   Use 'deferred' for postponed tasks
254: -   Add custom status values as needed for project-specific workflows
255: 
256: ## Task Structure Fields
257: 
258: - **id**: Unique identifier for the task (Example: `1`, `1.1`)
259: - **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
260: - **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
261: - **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
262: - **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
263:     - Dependencies are displayed with status indicators (✅ for completed, ⏱️ for pending)
264:     - This helps quickly identify which prerequisite tasks are blocking work
265: - **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
266: - **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`) 
267: - **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`) 
268: - **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`) 
269: - Refer to task structure details (previously linked to `tasks.md`).
270: 
271: ## Configuration Management (Updated)
272: 
273: Taskmaster configuration is managed through two main mechanisms:
274: 
275: 1.  **`.taskmaster/config.json` File (Primary):**
276:     *   Located in the project root directory.
277:     *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
278:     *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
279:     *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
280:     *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
281:     *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.
282: 
283: 2.  **Environment Variables (`.env` / `mcp.json`):**
284:     *   Used **only** for sensitive API keys and specific endpoint URLs.
285:     *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
286:     *   For MCP/Trae integration, configure these keys in the `env` section of `.trae/mcp.json`.
287:     *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).
288: 
289: 3.  **`.taskmaster/state.json` File (Tagged System State):**
290:     *   Tracks current tag context and migration status.
291:     *   Automatically created during tagged system migration.
292:     *   Contains: `currentTag`, `lastSwitched`, `migrationNoticeShown`.
293: 
294: **Important:** Non-API key settings (like model selections, `MAX_TOKENS`, `TASKMASTER_LOG_LEVEL`) are **no longer configured via environment variables**. Use the `task-master models` command (or `--setup` for interactive configuration) or the `models` MCP tool.
295: **If AI commands FAIL in MCP** verify that the API key for the selected provider is present in the `env` section of `.trae/mcp.json`.
296: **If AI commands FAIL in CLI** verify that the API key for the selected provider is present in the `.env` file in the root of the project.
297: 
298: ## Rules Management
299: 
300: Taskmaster supports multiple AI coding assistant rule sets that can be configured during project initialization or managed afterward:
301: 
302: - **Available Profiles**: Claude Code, Cline, Codex, Trae, Roo Code, Trae, Windsurf (claude, cline, codex, trae, roo, trae, windsurf)
303: - **During Initialization**: Use `task-master init --rules trae,windsurf` to specify which rule sets to include
304: - **After Initialization**: Use `task-master rules add <profiles>` or `task-master rules remove <profiles>` to manage rule sets
305: - **Interactive Setup**: Use `task-master rules setup` to launch an interactive prompt for selecting rule profiles
306: - **Default Behavior**: If no `--rules` flag is specified during initialization, all available rule profiles are included
307: - **Rule Structure**: Each profile creates its own directory (e.g., `.trae/rules`, `.roo/rules`) with appropriate configuration files
308: 
309: ## Determining the Next Task
310: 
311: - Run `next_task` / `task-master next` to show the next task to work on.
312: - The command identifies tasks with all dependencies satisfied
313: - Tasks are prioritized by priority level, dependency count, and ID
314: - The command shows comprehensive task information including:
315:     - Basic task details and description
316:     - Implementation details
317:     - Subtasks (if they exist)
318:     - Contextual suggested actions
319: - Recommended before starting any new development work
320: - Respects your project's dependency structure
321: - Ensures tasks are completed in the appropriate sequence
322: - Provides ready-to-use commands for common task actions
323: 
324: ## Viewing Specific Task Details
325: 
326: - Run `get_task` / `task-master show <id>` to view a specific task.
327: - Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
328: - Displays comprehensive information similar to the next command, but for a specific task
329: - For parent tasks, shows all subtasks and their current status
330: - For subtasks, shows parent task information and relationship
331: - Provides contextual suggested actions appropriate for the specific task
332: - Useful for examining task details before implementation or checking status
333: 
334: ## Managing Task Dependencies
335: 
336: - Use `add_dependency` / `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency.
337: - Use `remove_dependency` / `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency.
338: - The system prevents circular dependencies and duplicate dependency entries
339: - Dependencies are checked for existence before being added or removed
340: - Task files are automatically regenerated after dependency changes
341: - Dependencies are visualized with status indicators in task listings and files
342: 
343: ## Task Reorganization
344: 
345: - Use `move_task` / `task-master move --from=<id> --to=<id>` to move tasks or subtasks within the hierarchy
346: - This command supports several use cases:
347:   - Moving a standalone task to become a subtask (e.g., `--from=5 --to=7`)
348:   - Moving a subtask to become a standalone task (e.g., `--from=5.2 --to=7`) 
349:   - Moving a subtask to a different parent (e.g., `--from=5.2 --to=7.3`)
350:   - Reordering subtasks within the same parent (e.g., `--from=5.2 --to=5.4`)
351:   - Moving a task to a new, non-existent ID position (e.g., `--from=5 --to=25`)
352:   - Moving multiple tasks at once using comma-separated IDs (e.g., `--from=10,11,12 --to=16,17,18`)
353: - The system includes validation to prevent data loss:
354:   - Allows moving to non-existent IDs by creating placeholder tasks
355:   - Prevents moving to existing task IDs that have content (to avoid overwriting)
356:   - Validates source tasks exist before attempting to move them
357: - The system maintains proper parent-child relationships and dependency integrity
358: - Task files are automatically regenerated after the move operation
359: - This provides greater flexibility in organizing and refining your task structure as project understanding evolves
360: - This is especially useful when dealing with potential merge conflicts arising from teams creating tasks on separate branches. Solve these conflicts very easily by moving your tasks and keeping theirs.
361: 
362: ## Iterative Subtask Implementation
363: 
364: Once a task has been broken down into subtasks using `expand_task` or similar methods, follow this iterative process for implementation:
365: 
366: 1.  **Understand the Goal (Preparation):**
367:     *   Use `get_task` / `task-master show <subtaskId>` (see @`taskmaster.md`) to thoroughly understand the specific goals and requirements of the subtask.
368: 
369: 2.  **Initial Exploration & Planning (Iteration 1):**
370:     *   This is the first attempt at creating a concrete implementation plan.
371:     *   Explore the codebase to identify the precise files, functions, and even specific lines of code that will need modification.
372:     *   Determine the intended code changes (diffs) and their locations.
373:     *   Gather *all* relevant details from this exploration phase.
374: 
375: 3.  **Log the Plan:**
376:     *   Run `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<detailed plan>'`.
377:     *   Provide the *complete and detailed* findings from the exploration phase in the prompt. Include file paths, line numbers, proposed diffs, reasoning, and any potential challenges identified. Do not omit details. The goal is to create a rich, timestamped log within the subtask's `details`.
378: 
379: 4.  **Verify the Plan:**
380:     *   Run `get_task` / `task-master show <subtaskId>` again to confirm that the detailed implementation plan has been successfully appended to the subtask's details.
381: 
382: 5.  **Begin Implementation:**
383:     *   Set the subtask status using `set_task_status` / `task-master set-status --id=<subtaskId> --status=in-progress`.
384:     *   Start coding based on the logged plan.
385: 
386: 6.  **Refine and Log Progress (Iteration 2+):**
387:     *   As implementation progresses, you will encounter challenges, discover nuances, or confirm successful approaches.
388:     *   **Before appending new information**: Briefly review the *existing* details logged in the subtask (using `get_task` or recalling from context) to ensure the update adds fresh insights and avoids redundancy.
389:     *   **Regularly** use `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<update details>\n- What worked...\n- What didn't work...'` to append new findings.
390:     *   **Crucially, log:**
391:         *   What worked ("fundamental truths" discovered).
392:         *   What didn't work and why (to avoid repeating mistakes).
393:         *   Specific code snippets or configurations that were successful.
394:         *   Decisions made, especially if confirmed with user input.
395:         *   Any deviations from the initial plan and the reasoning.
396:     *   The objective is to continuously enrich the subtask's details, creating a log of the implementation journey that helps the AI (and human developers) learn, adapt, and avoid repeating errors.
397: 
398: 7.  **Review & Update Rules (Post-Implementation):**
399:     *   Once the implementation for the subtask is functionally complete, review all code changes and the relevant chat history.
400:     *   Identify any new or modified code patterns, conventions, or best practices established during the implementation.
401:     *   Create new or update existing rules following internal guidelines (previously linked to `cursor_rules.md` and `self_improve.md`).
402: 
403: 8.  **Mark Task Complete:**
404:     *   After verifying the implementation and updating any necessary rules, mark the subtask as completed: `set_task_status` / `task-master set-status --id=<subtaskId> --status=done`.
405: 
406: 9.  **Commit Changes (If using Git):**
407:     *   Stage the relevant code changes and any updated/new rule files (`git add .`).
408:     *   Craft a comprehensive Git commit message summarizing the work done for the subtask, including both code implementation and any rule adjustments.
409:     *   Execute the commit command directly in the terminal (e.g., `git commit -m 'feat(module): Implement feature X for subtask <subtaskId>\n\n- Details about changes...\n- Updated rule Y for pattern Z'`).
410:     *   Consider if a Changeset is needed according to internal versioning guidelines (previously linked to `changeset.md`). If so, run `npm run changeset`, stage the generated file, and amend the commit or create a new one.
411: 
412: 10. **Proceed to Next Subtask:**
413:     *   Identify the next subtask (e.g., using `next_task` / `task-master next`).
414: 
415: ## Code Analysis & Refactoring Techniques
416: 
417: - **Top-Level Function Search**:
418:     - Useful for understanding module structure or planning refactors.
419:     - Use grep/ripgrep to find exported functions/constants:
420:       `rg "export (async function|function|const) \w+"` or similar patterns.
421:     - Can help compare functions between files during migrations or identify potential naming conflicts.
422: 
423: ---
424: *This workflow provides a general guideline. Adapt it based on your specific project needs and team practices.*
</file>

<file path=".trae/rules/self_improve.md">
 1: ---
 2: description: Guidelines for continuously improving Trae rules based on emerging code patterns and best practices.
 3: globs: **/*
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Rule Improvement Triggers:**
 8:   - New code patterns not covered by existing rules
 9:   - Repeated similar implementations across files
10:   - Common error patterns that could be prevented
11:   - New libraries or tools being used consistently
12:   - Emerging best practices in the codebase
13: 
14: - **Analysis Process:**
15:   - Compare new code with existing rules
16:   - Identify patterns that should be standardized
17:   - Look for references to external documentation
18:   - Check for consistent error handling patterns
19:   - Monitor test patterns and coverage
20: 
21: - **Rule Updates:**
22:   - **Add New Rules When:**
23:     - A new technology/pattern is used in 3+ files
24:     - Common bugs could be prevented by a rule
25:     - Code reviews repeatedly mention the same feedback
26:     - New security or performance patterns emerge
27: 
28:   - **Modify Existing Rules When:**
29:     - Better examples exist in the codebase
30:     - Additional edge cases are discovered
31:     - Related rules have been updated
32:     - Implementation details have changed
33: 
34: - **Example Pattern Recognition:**
35:   ```typescript
36:   // If you see repeated patterns like:
37:   const data = await prisma.user.findMany({
38:     select: { id: true, email: true },
39:     where: { status: 'ACTIVE' }
40:   });
41:   
42:   // Consider adding to [prisma.md](.trae/rules/prisma.md):
43:   // - Standard select fields
44:   // - Common where conditions
45:   // - Performance optimization patterns
46:   ```
47: 
48: - **Rule Quality Checks:**
49:   - Rules should be actionable and specific
50:   - Examples should come from actual code
51:   - References should be up to date
52:   - Patterns should be consistently enforced
53: 
54: - **Continuous Improvement:**
55:   - Monitor code review comments
56:   - Track common development questions
57:   - Update rules after major refactors
58:   - Add links to relevant documentation
59:   - Cross-reference related rules
60: 
61: - **Rule Deprecation:**
62:   - Mark outdated patterns as deprecated
63:   - Remove rules that no longer apply
64:   - Update references to deprecated rules
65:   - Document migration paths for old patterns
66: 
67: - **Documentation Updates:**
68:   - Keep examples synchronized with code
69:   - Update references to external docs
70:   - Maintain links between related rules
71:   - Document breaking changes
72: Follow [trae_rules.md](.trae/rules/trae_rules.md) for proper rule formatting and structure.
</file>

<file path=".trae/rules/taskmaster.md">
  1: ---
  2: description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Tool & Command Reference
  8: 
  9: This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like Trae, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.
 10: 
 11: **Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback. 
 12: 
 13: **Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.
 14: 
 15: **🏷️ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.
 16: 
 17: ---
 18: 
 19: ## Initialization & Setup
 20: 
 21: ### 1. Initialize Project (`init`)
 22: 
 23: *   **MCP Tool:** `initialize_project`
 24: *   **CLI Command:** `task-master init [options]`
 25: *   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
 26: *   **Key CLI Options:**
 27:     *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
 28:     *   `--description <text>`: `Provide a brief description for your project.`
 29:     *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
 30:     *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
 31: *   **Usage:** Run this once at the beginning of a new project.
 32: *   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
 33: *   **Key MCP Parameters/Options:**
 34:     *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
 35:     *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
 36:     *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
 37:     *   `authorName`: `Author name.` (CLI: `--author <author>`)
 38:     *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
 39:     *   `addAliases`: `Add shell aliases tm and taskmaster. Default is false.` (CLI: `--aliases`)
 40:     *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
 41: *   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like Trae. Operates on the current working directory of the MCP server. 
 42: *   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt. 
 43: *   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.
 44: 
 45: ### 2. Parse PRD (`parse_prd`)
 46: 
 47: *   **MCP Tool:** `parse_prd`
 48: *   **CLI Command:** `task-master parse-prd [file] [options]`
 49: *   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
 50: *   **Key Parameters/Options:**
 51:     *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
 52:     *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
 53:     *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
 54:     *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
 55: *   **Usage:** Useful for bootstrapping a project from an existing requirements document.
 56: *   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
 57: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.
 58: 
 59: ---
 60: 
 61: ## AI Model Configuration
 62: 
 63: ### 2. Manage Models (`models`)
 64: *   **MCP Tool:** `models`
 65: *   **CLI Command:** `task-master models [options]`
 66: *   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
 67: *   **Key MCP Parameters/Options:**
 68:     *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
 69:     *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
 70:     *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
 71:     *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
 72:     *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
 73:     *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
 74:     *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
 75: *   **Key CLI Options:**
 76:     *   `--set-main <model_id>`: `Set the primary model.`
 77:     *   `--set-research <model_id>`: `Set the research model.`
 78:     *   `--set-fallback <model_id>`: `Set the fallback model.`
 79:     *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
 80:     *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
 81:     *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
 82:     *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
 83: *   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
 84: *   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
 85: *   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
 86: *   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
 87: *   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80. 
 88: *   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.
 89: 
 90: ---
 91: 
 92: ## Task Listing & Viewing
 93: 
 94: ### 3. Get Tasks (`get_tasks`)
 95: 
 96: *   **MCP Tool:** `get_tasks`
 97: *   **CLI Command:** `task-master list [options]`
 98: *   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
 99: *   **Key Parameters/Options:**
100:     *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
101:     *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
102:     *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
103:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
104: *   **Usage:** Get an overview of the project status, often used at the start of a work session.
105: 
106: ### 4. Get Next Task (`next_task`)
107: 
108: *   **MCP Tool:** `next_task`
109: *   **CLI Command:** `task-master next [options]`
110: *   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
111: *   **Key Parameters/Options:**
112:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
113:     *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
114: *   **Usage:** Identify what to work on next according to the plan.
115: 
116: ### 5. Get Task Details (`get_task`)
117: 
118: *   **MCP Tool:** `get_task`
119: *   **CLI Command:** `task-master show [id] [options]`
120: *   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
121: *   **Key Parameters/Options:**
122:     *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
123:     *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
124:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
125: *   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
126: *   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.
127: 
128: ---
129: 
130: ## Task Creation & Modification
131: 
132: ### 6. Add Task (`add_task`)
133: 
134: *   **MCP Tool:** `add_task`
135: *   **CLI Command:** `task-master add-task [options]`
136: *   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
137: *   **Key Parameters/Options:**
138:     *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
139:     *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
140:     *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
141:     *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
142:     *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
143:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
144: *   **Usage:** Quickly add newly identified tasks during development.
145: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
146: 
147: ### 7. Add Subtask (`add_subtask`)
148: 
149: *   **MCP Tool:** `add_subtask`
150: *   **CLI Command:** `task-master add-subtask [options]`
151: *   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
152: *   **Key Parameters/Options:**
153:     *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
154:     *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
155:     *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
156:     *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
157:     *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
158:     *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
159:     *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
160:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after adding the subtask.` (CLI: `--skip-generate`)
161:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
162:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
163: *   **Usage:** Break down tasks manually or reorganize existing tasks.
164: 
165: ### 8. Update Tasks (`update`)
166: 
167: *   **MCP Tool:** `update`
168: *   **CLI Command:** `task-master update [options]`
169: *   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
170: *   **Key Parameters/Options:**
171:     *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
172:     *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
173:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
174:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
175:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
176: *   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
177: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
178: 
179: ### 9. Update Task (`update_task`)
180: 
181: *   **MCP Tool:** `update_task`
182: *   **CLI Command:** `task-master update-task [options]`
183: *   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
184: *   **Key Parameters/Options:**
185:     *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
186:     *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
187:     *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
188:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
189:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
190:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
191: *   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
192: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
193: 
194: ### 10. Update Subtask (`update_subtask`)
195: 
196: *   **MCP Tool:** `update_subtask`
197: *   **CLI Command:** `task-master update-subtask [options]`
198: *   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
199: *   **Key Parameters/Options:**
200:     *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
201:     *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
202:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
203:     *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
204:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
205: *   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
206: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
207: 
208: ### 11. Set Task Status (`set_task_status`)
209: 
210: *   **MCP Tool:** `set_task_status`
211: *   **CLI Command:** `task-master set-status [options]`
212: *   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
213: *   **Key Parameters/Options:**
214:     *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
215:     *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
216:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
217:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
218: *   **Usage:** Mark progress as tasks move through the development cycle.
219: 
220: ### 12. Remove Task (`remove_task`)
221: 
222: *   **MCP Tool:** `remove_task`
223: *   **CLI Command:** `task-master remove-task [options]`
224: *   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
225: *   **Key Parameters/Options:**
226:     *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
227:     *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
228:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
229:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
230: *   **Usage:** Permanently delete tasks or subtasks that are no longer needed in the project.
231: *   **Notes:** Use with caution as this operation cannot be undone. Consider using 'blocked', 'cancelled', or 'deferred' status instead if you just want to exclude a task from active planning but keep it for reference. The command automatically cleans up dependency references in other tasks.
232: 
233: ---
234: 
235: ## Task Structure & Breakdown
236: 
237: ### 13. Expand Task (`expand_task`)
238: 
239: *   **MCP Tool:** `expand_task`
240: *   **CLI Command:** `task-master expand [options]`
241: *   **Description:** `Use Taskmaster's AI to break down a complex task into smaller, manageable subtasks. Appends subtasks by default.`
242: *   **Key Parameters/Options:**
243:     *   `id`: `The ID of the specific Taskmaster task you want to break down into subtasks.` (CLI: `-i, --id <id>`)
244:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create. Uses complexity analysis/defaults otherwise.` (CLI: `-n, --num <number>`)
245:     *   `research`: `Enable Taskmaster to use the research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
246:     *   `prompt`: `Optional: Provide extra context or specific instructions to Taskmaster for generating the subtasks.` (CLI: `-p, --prompt <text>`)
247:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones. Default is false (append).` (CLI: `--force`)
248:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
249:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
250: *   **Usage:** Generate a detailed implementation plan for a complex task before starting coding. Automatically uses complexity report recommendations if available and `num` is not specified.
251: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
252: 
253: ### 14. Expand All Tasks (`expand_all`)
254: 
255: *   **MCP Tool:** `expand_all`
256: *   **CLI Command:** `task-master expand --all [options]` (Note: CLI uses the `expand` command with the `--all` flag)
257: *   **Description:** `Tell Taskmaster to automatically expand all eligible pending/in-progress tasks based on complexity analysis or defaults. Appends subtasks by default.`
258: *   **Key Parameters/Options:**
259:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create per task.` (CLI: `-n, --num <number>`)
260:     *   `research`: `Enable research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
261:     *   `prompt`: `Optional: Provide extra context for Taskmaster to apply generally during expansion.` (CLI: `-p, --prompt <text>`)
262:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones for each eligible task. Default is false (append).` (CLI: `--force`)
263:     *   `tag`: `Specify which tag context to expand. Defaults to the current active tag.` (CLI: `--tag <name>`)
264:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
265: *   **Usage:** Useful after initial task generation or complexity analysis to break down multiple tasks at once.
266: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
267: 
268: ### 15. Clear Subtasks (`clear_subtasks`)
269: 
270: *   **MCP Tool:** `clear_subtasks`
271: *   **CLI Command:** `task-master clear-subtasks [options]`
272: *   **Description:** `Remove all subtasks from one or more specified Taskmaster parent tasks.`
273: *   **Key Parameters/Options:**
274:     *   `id`: `The ID(s) of the Taskmaster parent task(s) whose subtasks you want to remove, e.g., '15' or '16,18'. Required unless using `all`.) (CLI: `-i, --id <ids>`)
275:     *   `all`: `Tell Taskmaster to remove subtasks from all parent tasks.` (CLI: `--all`)
276:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
277:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
278: *   **Usage:** Used before regenerating subtasks with `expand_task` if the previous breakdown needs replacement.
279: 
280: ### 16. Remove Subtask (`remove_subtask`)
281: 
282: *   **MCP Tool:** `remove_subtask`
283: *   **CLI Command:** `task-master remove-subtask [options]`
284: *   **Description:** `Remove a subtask from its Taskmaster parent, optionally converting it into a standalone task.`
285: *   **Key Parameters/Options:**
286:     *   `id`: `Required. The ID(s) of the Taskmaster subtask(s) to remove, e.g., '15.2' or '16.1,16.3'.` (CLI: `-i, --id <id>`)
287:     *   `convert`: `If used, Taskmaster will turn the subtask into a regular top-level task instead of deleting it.` (CLI: `-c, --convert`)
288:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after removing the subtask.` (CLI: `--skip-generate`)
289:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
290:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
291: *   **Usage:** Delete unnecessary subtasks or promote a subtask to a top-level task.
292: 
293: ### 17. Move Task (`move_task`)
294: 
295: *   **MCP Tool:** `move_task`
296: *   **CLI Command:** `task-master move [options]`
297: *   **Description:** `Move a task or subtask to a new position within the task hierarchy.`
298: *   **Key Parameters/Options:**
299:     *   `from`: `Required. ID of the task/subtask to move (e.g., "5" or "5.2"). Can be comma-separated for multiple tasks.` (CLI: `--from <id>`)
300:     *   `to`: `Required. ID of the destination (e.g., "7" or "7.3"). Must match the number of source IDs if comma-separated.` (CLI: `--to <id>`)
301:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
302:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
303: *   **Usage:** Reorganize tasks by moving them within the hierarchy. Supports various scenarios like:
304:     *   Moving a task to become a subtask
305:     *   Moving a subtask to become a standalone task
306:     *   Moving a subtask to a different parent
307:     *   Reordering subtasks within the same parent
308:     *   Moving a task to a new, non-existent ID (automatically creates placeholders)
309:     *   Moving multiple tasks at once with comma-separated IDs
310: *   **Validation Features:**
311:     *   Allows moving tasks to non-existent destination IDs (creates placeholder tasks)
312:     *   Prevents moving to existing task IDs that already have content (to avoid overwriting)
313:     *   Validates that source tasks exist before attempting to move them
314:     *   Maintains proper parent-child relationships
315: *   **Example CLI:** `task-master move --from=5.2 --to=7.3` to move subtask 5.2 to become subtask 7.3.
316: *   **Example Multi-Move:** `task-master move --from=10,11,12 --to=16,17,18` to move multiple tasks to new positions.
317: *   **Common Use:** Resolving merge conflicts in tasks.json when multiple team members create tasks on different branches.
318: 
319: ---
320: 
321: ## Dependency Management
322: 
323: ### 18. Add Dependency (`add_dependency`)
324: 
325: *   **MCP Tool:** `add_dependency`
326: *   **CLI Command:** `task-master add-dependency [options]`
327: *   **Description:** `Define a dependency in Taskmaster, making one task a prerequisite for another.`
328: *   **Key Parameters/Options:**
329:     *   `id`: `Required. The ID of the Taskmaster task that will depend on another.` (CLI: `-i, --id <id>`)
330:     *   `dependsOn`: `Required. The ID of the Taskmaster task that must be completed first, the prerequisite.` (CLI: `-d, --depends-on <id>`)
331:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
332:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <path>`)
333: *   **Usage:** Establish the correct order of execution between tasks.
334: 
335: ### 19. Remove Dependency (`remove_dependency`)
336: 
337: *   **MCP Tool:** `remove_dependency`
338: *   **CLI Command:** `task-master remove-dependency [options]`
339: *   **Description:** `Remove a dependency relationship between two Taskmaster tasks.`
340: *   **Key Parameters/Options:**
341:     *   `id`: `Required. The ID of the Taskmaster task you want to remove a prerequisite from.` (CLI: `-i, --id <id>`)
342:     *   `dependsOn`: `Required. The ID of the Taskmaster task that should no longer be a prerequisite.` (CLI: `-d, --depends-on <id>`)
343:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
344:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
345: *   **Usage:** Update task relationships when the order of execution changes.
346: 
347: ### 20. Validate Dependencies (`validate_dependencies`)
348: 
349: *   **MCP Tool:** `validate_dependencies`
350: *   **CLI Command:** `task-master validate-dependencies [options]`
351: *   **Description:** `Check your Taskmaster tasks for dependency issues (like circular references or links to non-existent tasks) without making changes.`
352: *   **Key Parameters/Options:**
353:     *   `tag`: `Specify which tag context to validate. Defaults to the current active tag.` (CLI: `--tag <name>`)
354:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
355: *   **Usage:** Audit the integrity of your task dependencies.
356: 
357: ### 21. Fix Dependencies (`fix_dependencies`)
358: 
359: *   **MCP Tool:** `fix_dependencies`
360: *   **CLI Command:** `task-master fix-dependencies [options]`
361: *   **Description:** `Automatically fix dependency issues (like circular references or links to non-existent tasks) in your Taskmaster tasks.`
362: *   **Key Parameters/Options:**
363:     *   `tag`: `Specify which tag context to fix dependencies in. Defaults to the current active tag.` (CLI: `--tag <name>`)
364:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
365: *   **Usage:** Clean up dependency errors automatically.
366: 
367: ---
368: 
369: ## Analysis & Reporting
370: 
371: ### 22. Analyze Project Complexity (`analyze_project_complexity`)
372: 
373: *   **MCP Tool:** `analyze_project_complexity`
374: *   **CLI Command:** `task-master analyze-complexity [options]`
375: *   **Description:** `Have Taskmaster analyze your tasks to determine their complexity and suggest which ones need to be broken down further.`
376: *   **Key Parameters/Options:**
377:     *   `output`: `Where to save the complexity analysis report. Default is '.taskmaster/reports/task-complexity-report.json' (or '..._tagname.json' if a tag is used).` (CLI: `-o, --output <file>`)
378:     *   `threshold`: `The minimum complexity score (1-10) that should trigger a recommendation to expand a task.` (CLI: `-t, --threshold <number>`)
379:     *   `research`: `Enable research role for more accurate complexity analysis. Requires appropriate API key.` (CLI: `-r, --research`)
380:     *   `tag`: `Specify which tag context to analyze. Defaults to the current active tag.` (CLI: `--tag <name>`)
381:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
382: *   **Usage:** Used before breaking down tasks to identify which ones need the most attention.
383: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
384: 
385: ### 23. View Complexity Report (`complexity_report`)
386: 
387: *   **MCP Tool:** `complexity_report`
388: *   **CLI Command:** `task-master complexity-report [options]`
389: *   **Description:** `Display the task complexity analysis report in a readable format.`
390: *   **Key Parameters/Options:**
391:     *   `tag`: `Specify which tag context to show the report for. Defaults to the current active tag.` (CLI: `--tag <name>`)
392:     *   `file`: `Path to the complexity report (default: '.taskmaster/reports/task-complexity-report.json').` (CLI: `-f, --file <file>`)
393: *   **Usage:** Review and understand the complexity analysis results after running analyze-complexity.
394: 
395: ---
396: 
397: ## File Management
398: 
399: ### 24. Generate Task Files (`generate`)
400: 
401: *   **MCP Tool:** `generate`
402: *   **CLI Command:** `task-master generate [options]`
403: *   **Description:** `Create or update individual Markdown files for each task based on your tasks.json.`
404: *   **Key Parameters/Options:**
405:     *   `output`: `The directory where Taskmaster should save the task files (default: in a 'tasks' directory).` (CLI: `-o, --output <directory>`)
406:     *   `tag`: `Specify which tag context to generate files for. Defaults to the current active tag.` (CLI: `--tag <name>`)
407:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
408: *   **Usage:** Run this after making changes to tasks.json to keep individual task files up to date. This command is now manual and no longer runs automatically.
409: 
410: ---
411: 
412: ## AI-Powered Research
413: 
414: ### 25. Research (`research`)
415: 
416: *   **MCP Tool:** `research`
417: *   **CLI Command:** `task-master research [options]`
418: *   **Description:** `Perform AI-powered research queries with project context to get fresh, up-to-date information beyond the AI's knowledge cutoff.`
419: *   **Key Parameters/Options:**
420:     *   `query`: `Required. Research query/prompt (e.g., "What are the latest best practices for React Query v5?").` (CLI: `[query]` positional or `-q, --query <text>`)
421:     *   `taskIds`: `Comma-separated list of task/subtask IDs from the current tag context (e.g., "15,16.2,17").` (CLI: `-i, --id <ids>`)
422:     *   `filePaths`: `Comma-separated list of file paths for context (e.g., "src/api.js,docs/readme.md").` (CLI: `-f, --files <paths>`)
423:     *   `customContext`: `Additional custom context text to include in the research.` (CLI: `-c, --context <text>`)
424:     *   `includeProjectTree`: `Include project file tree structure in context (default: false).` (CLI: `--tree`)
425:     *   `detailLevel`: `Detail level for the research response: 'low', 'medium', 'high' (default: medium).` (CLI: `--detail <level>`)
426:     *   `saveTo`: `Task or subtask ID (e.g., "15", "15.2") to automatically save the research conversation to.` (CLI: `--save-to <id>`)
427:     *   `saveFile`: `If true, saves the research conversation to a markdown file in '.taskmaster/docs/research/'.` (CLI: `--save-file`)
428:     *   `noFollowup`: `Disables the interactive follow-up question menu in the CLI.` (CLI: `--no-followup`)
429:     *   `tag`: `Specify which tag context to use for task-based context gathering. Defaults to the current active tag.` (CLI: `--tag <name>`)
430:     *   `projectRoot`: `The directory of the project. Must be an absolute path.` (CLI: Determined automatically)
431: *   **Usage:** **This is a POWERFUL tool that agents should use FREQUENTLY** to:
432:     *   Get fresh information beyond knowledge cutoff dates
433:     *   Research latest best practices, library updates, security patches
434:     *   Find implementation examples for specific technologies
435:     *   Validate approaches against current industry standards
436:     *   Get contextual advice based on project files and tasks
437: *   **When to Consider Using Research:**
438:     *   **Before implementing any task** - Research current best practices
439:     *   **When encountering new technologies** - Get up-to-date implementation guidance (libraries, apis, etc)
440:     *   **For security-related tasks** - Find latest security recommendations
441:     *   **When updating dependencies** - Research breaking changes and migration guides
442:     *   **For performance optimization** - Get current performance best practices
443:     *   **When debugging complex issues** - Research known solutions and workarounds
444: *   **Research + Action Pattern:**
445:     *   Use `research` to gather fresh information
446:     *   Use `update_subtask` to commit findings with timestamps
447:     *   Use `update_task` to incorporate research into task details
448:     *   Use `add_task` with research flag for informed task creation
449: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. The research provides FRESH data beyond the AI's training cutoff, making it invaluable for current best practices and recent developments.
450: 
451: ---
452: 
453: ## Tag Management
454: 
455: This new suite of commands allows you to manage different task contexts (tags).
456: 
457: ### 26. List Tags (`tags`)
458: 
459: *   **MCP Tool:** `list_tags`
460: *   **CLI Command:** `task-master tags [options]`
461: *   **Description:** `List all available tags with task counts, completion status, and other metadata.`
462: *   **Key Parameters/Options:**
463:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
464:     *   `--show-metadata`: `Include detailed metadata in the output (e.g., creation date, description).` (CLI: `--show-metadata`)
465: 
466: ### 27. Add Tag (`add_tag`)
467: 
468: *   **MCP Tool:** `add_tag`
469: *   **CLI Command:** `task-master add-tag <tagName> [options]`
470: *   **Description:** `Create a new, empty tag context, or copy tasks from another tag.`
471: *   **Key Parameters/Options:**
472:     *   `tagName`: `Name of the new tag to create (alphanumeric, hyphens, underscores).` (CLI: `<tagName>` positional)
473:     *   `--from-branch`: `Creates a tag with a name derived from the current git branch, ignoring the <tagName> argument.` (CLI: `--from-branch`)
474:     *   `--copy-from-current`: `Copy tasks from the currently active tag to the new tag.` (CLI: `--copy-from-current`)
475:     *   `--copy-from <tag>`: `Copy tasks from a specific source tag to the new tag.` (CLI: `--copy-from <tag>`)
476:     *   `--description <text>`: `Provide an optional description for the new tag.` (CLI: `-d, --description <text>`)
477:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
478: 
479: ### 28. Delete Tag (`delete_tag`)
480: 
481: *   **MCP Tool:** `delete_tag`
482: *   **CLI Command:** `task-master delete-tag <tagName> [options]`
483: *   **Description:** `Permanently delete a tag and all of its associated tasks.`
484: *   **Key Parameters/Options:**
485:     *   `tagName`: `Name of the tag to delete.` (CLI: `<tagName>` positional)
486:     *   `--yes`: `Skip the confirmation prompt.` (CLI: `-y, --yes`)
487:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
488: 
489: ### 29. Use Tag (`use_tag`)
490: 
491: *   **MCP Tool:** `use_tag`
492: *   **CLI Command:** `task-master use-tag <tagName>`
493: *   **Description:** `Switch your active task context to a different tag.`
494: *   **Key Parameters/Options:**
495:     *   `tagName`: `Name of the tag to switch to.` (CLI: `<tagName>` positional)
496:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
497: 
498: ### 30. Rename Tag (`rename_tag`)
499: 
500: *   **MCP Tool:** `rename_tag`
501: *   **CLI Command:** `task-master rename-tag <oldName> <newName>`
502: *   **Description:** `Rename an existing tag.`
503: *   **Key Parameters/Options:**
504:     *   `oldName`: `The current name of the tag.` (CLI: `<oldName>` positional)
505:     *   `newName`: `The new name for the tag.` (CLI: `<newName>` positional)
506:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
507: 
508: ### 31. Copy Tag (`copy_tag`)
509: 
510: *   **MCP Tool:** `copy_tag`
511: *   **CLI Command:** `task-master copy-tag <sourceName> <targetName> [options]`
512: *   **Description:** `Copy an entire tag context, including all its tasks and metadata, to a new tag.`
513: *   **Key Parameters/Options:**
514:     *   `sourceName`: `Name of the tag to copy from.` (CLI: `<sourceName>` positional)
515:     *   `targetName`: `Name of the new tag to create.` (CLI: `<targetName>` positional)
516:     *   `--description <text>`: `Optional description for the new tag.` (CLI: `-d, --description <text>`)
517: 
518: ---
519: 
520: ## Miscellaneous
521: 
522: ### 32. Sync Readme (`sync-readme`) -- experimental
523: 
524: *   **MCP Tool:** N/A
525: *   **CLI Command:** `task-master sync-readme [options]`
526: *   **Description:** `Exports your task list to your project's README.md file, useful for showcasing progress.`
527: *   **Key Parameters/Options:**
528:     *   `status`: `Filter tasks by status (e.g., 'pending', 'done').` (CLI: `-s, --status <status>`)
529:     *   `withSubtasks`: `Include subtasks in the export.` (CLI: `--with-subtasks`)
530:     *   `tag`: `Specify which tag context to export from. Defaults to the current active tag.` (CLI: `--tag <name>`)
531: 
532: ---
533: 
534: ## Environment Variables Configuration (Updated)
535: 
536: Taskmaster primarily uses the **`.taskmaster/config.json`** file (in project root) for configuration (models, parameters, logging level, etc.), managed via `task-master models --setup`.
537: 
538: Environment variables are used **only** for sensitive API keys related to AI providers and specific overrides like the Ollama base URL:
539: 
540: *   **API Keys (Required for corresponding provider):**
541:     *   `ANTHROPIC_API_KEY`
542:     *   `PERPLEXITY_API_KEY`
543:     *   `OPENAI_API_KEY`
544:     *   `GOOGLE_API_KEY`
545:     *   `MISTRAL_API_KEY`
546:     *   `AZURE_OPENAI_API_KEY` (Requires `AZURE_OPENAI_ENDPOINT` too)
547:     *   `OPENROUTER_API_KEY`
548:     *   `XAI_API_KEY`
549:     *   `OLLAMA_API_KEY` (Requires `OLLAMA_BASE_URL` too)
550: *   **Endpoints (Optional/Provider Specific inside .taskmaster/config.json):**
551:     *   `AZURE_OPENAI_ENDPOINT`
552:     *   `OLLAMA_BASE_URL` (Default: `http://localhost:11434/api`)
553: 
554: **Set API keys** in your **`.env`** file in the project root (for CLI use) or within the `env` section of your **`.trae/mcp.json`** file (for MCP/Trae integration). All other settings (model choice, max tokens, temperature, log level, custom endpoints) are managed in `.taskmaster/config.json` via `task-master models` command or `models` MCP tool.
555: 
556: ---
557: 
558: For details on how these commands fit into the development process, see the [dev_workflow.md](.trae/rules/dev_workflow.md).
</file>

<file path=".trae/rules/trae_rules.md">
 1: ---
 2: description: Guidelines for creating and maintaining Trae rules to ensure consistency and effectiveness.
 3: globs: .trae/rules/*.md
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Required Rule Structure:**
 8:   ```markdown
 9:   ---
10:   description: Clear, one-line description of what the rule enforces
11:   globs: path/to/files/*.ext, other/path/**/*
12:   alwaysApply: boolean
13:   ---
14: 
15:   - **Main Points in Bold**
16:     - Sub-points with details
17:     - Examples and explanations
18:   ```
19: 
20: - **File References:**
21:   - Use `[filename](mdc:path/to/file)` ([filename](mdc:filename)) to reference files
22:   - Example: [prisma.md](.trae/rules/prisma.md) for rule references
23:   - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references
24: 
25: - **Code Examples:**
26:   - Use language-specific code blocks
27:   ```typescript
28:   // ✅ DO: Show good examples
29:   const goodExample = true;
30:   
31:   // ❌ DON'T: Show anti-patterns
32:   const badExample = false;
33:   ```
34: 
35: - **Rule Content Guidelines:**
36:   - Start with high-level overview
37:   - Include specific, actionable requirements
38:   - Show examples of correct implementation
39:   - Reference existing code when possible
40:   - Keep rules DRY by referencing other rules
41: 
42: - **Rule Maintenance:**
43:   - Update rules when new patterns emerge
44:   - Add examples from actual codebase
45:   - Remove outdated patterns
46:   - Cross-reference related rules
47: 
48: - **Best Practices:**
49:   - Use bullet points for clarity
50:   - Keep descriptions concise
51:   - Include both DO and DON'T examples
52:   - Reference actual code over theoretical examples
53:   - Use consistent formatting across rules
</file>

<file path=".windsurf/rules/dev_workflow.md">
  1: ---
  2: description: Guide for using Taskmaster to manage task-driven development workflows
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Development Workflow
  8: 
  9: This guide outlines the standard process for using Taskmaster to manage software development projects. It is written as a set of instructions for you, the AI agent.
 10: 
 11: - **Your Default Stance**: For most projects, the user can work directly within the `master` task context. Your initial actions should operate on this default context unless a clear pattern for multi-context work emerges.
 12: - **Your Goal**: Your role is to elevate the user's workflow by intelligently introducing advanced features like **Tagged Task Lists** when you detect the appropriate context. Do not force tags on the user; suggest them as a helpful solution to a specific need.
 13: 
 14: ## The Basic Loop
 15: The fundamental development cycle you will facilitate is:
 16: 1.  **`list`**: Show the user what needs to be done.
 17: 2.  **`next`**: Help the user decide what to work on.
 18: 3.  **`show <id>`**: Provide details for a specific task.
 19: 4.  **`expand <id>`**: Break down a complex task into smaller, manageable subtasks.
 20: 5.  **Implement**: The user writes the code and tests.
 21: 6.  **`update-subtask`**: Log progress and findings on behalf of the user.
 22: 7.  **`set-status`**: Mark tasks and subtasks as `done` as work is completed.
 23: 8.  **Repeat**.
 24: 
 25: All your standard command executions should operate on the user's current task context, which defaults to `master`.
 26: 
 27: ---
 28: 
 29: ## Standard Development Workflow Process
 30: 
 31: ### Simple Workflow (Default Starting Point)
 32: 
 33: For new projects or when users are getting started, operate within the `master` tag context:
 34: 
 35: -   Start new projects by running `initialize_project` tool / `task-master init` or `parse_prd` / `task-master parse-prd --input='<prd-file.txt>'` (see @`taskmaster.md`) to generate initial tasks.json with tagged structure
 36: -   Configure rule sets during initialization with `--rules` flag (e.g., `task-master init --rules windsurf,windsurf`) or manage them later with `task-master rules add/remove` commands  
 37: -   Begin coding sessions with `get_tasks` / `task-master list` (see @`taskmaster.md`) to see current tasks, status, and IDs
 38: -   Determine the next task to work on using `next_task` / `task-master next` (see @`taskmaster.md`)
 39: -   Analyze task complexity with `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) before breaking down tasks
 40: -   Review complexity report using `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`)
 41: -   Select tasks based on dependencies (all marked 'done'), priority level, and ID order
 42: -   View specific task details using `get_task` / `task-master show <id>` (see @`taskmaster.md`) to understand implementation requirements
 43: -   Break down complex tasks using `expand_task` / `task-master expand --id=<id> --force --research` (see @`taskmaster.md`) with appropriate flags like `--force` (to replace existing subtasks) and `--research`
 44: -   Implement code following task details, dependencies, and project standards
 45: -   Mark completed tasks with `set_task_status` / `task-master set-status --id=<id> --status=done` (see @`taskmaster.md`)
 46: -   Update dependent tasks when implementation differs from original plan using `update` / `task-master update --from=<id> --prompt="..."` or `update_task` / `task-master update-task --id=<id> --prompt="..."` (see @`taskmaster.md`)
 47: 
 48: ---
 49: 
 50: ## Leveling Up: Agent-Led Multi-Context Workflows
 51: 
 52: While the basic workflow is powerful, your primary opportunity to add value is by identifying when to introduce **Tagged Task Lists**. These patterns are your tools for creating a more organized and efficient development environment for the user, especially if you detect agentic or parallel development happening across the same session.
 53: 
 54: **Critical Principle**: Most users should never see a difference in their experience. Only introduce advanced workflows when you detect clear indicators that the project has evolved beyond simple task management.
 55: 
 56: ### When to Introduce Tags: Your Decision Patterns
 57: 
 58: Here are the patterns to look for. When you detect one, you should propose the corresponding workflow to the user.
 59: 
 60: #### Pattern 1: Simple Git Feature Branching
 61: This is the most common and direct use case for tags.
 62: 
 63: - **Trigger**: The user creates a new git branch (e.g., `git checkout -b feature/user-auth`).
 64: - **Your Action**: Propose creating a new tag that mirrors the branch name to isolate the feature's tasks from `master`.
 65: - **Your Suggested Prompt**: *"I see you've created a new branch named 'feature/user-auth'. To keep all related tasks neatly organized and separate from your main list, I can create a corresponding task tag for you. This helps prevent merge conflicts in your `tasks.json` file later. Shall I create the 'feature-user-auth' tag?"*
 66: - **Tool to Use**: `task-master add-tag --from-branch`
 67: 
 68: #### Pattern 2: Team Collaboration
 69: - **Trigger**: The user mentions working with teammates (e.g., "My teammate Alice is handling the database schema," or "I need to review Bob's work on the API.").
 70: - **Your Action**: Suggest creating a separate tag for the user's work to prevent conflicts with shared master context.
 71: - **Your Suggested Prompt**: *"Since you're working with Alice, I can create a separate task context for your work to avoid conflicts. This way, Alice can continue working with the master list while you have your own isolated context. When you're ready to merge your work, we can coordinate the tasks back to master. Shall I create a tag for your current work?"*
 72: - **Tool to Use**: `task-master add-tag my-work --copy-from-current --description="My tasks while collaborating with Alice"`
 73: 
 74: #### Pattern 3: Experiments or Risky Refactors
 75: - **Trigger**: The user wants to try something that might not be kept (e.g., "I want to experiment with switching our state management library," or "Let's refactor the old API module, but I want to keep the current tasks as a reference.").
 76: - **Your Action**: Propose creating a sandboxed tag for the experimental work.
 77: - **Your Suggested Prompt**: *"This sounds like a great experiment. To keep these new tasks separate from our main plan, I can create a temporary 'experiment-zustand' tag for this work. If we decide not to proceed, we can simply delete the tag without affecting the main task list. Sound good?"*
 78: - **Tool to Use**: `task-master add-tag experiment-zustand --description="Exploring Zustand migration"`
 79: 
 80: #### Pattern 4: Large Feature Initiatives (PRD-Driven)
 81: This is a more structured approach for significant new features or epics.
 82: 
 83: - **Trigger**: The user describes a large, multi-step feature that would benefit from a formal plan.
 84: - **Your Action**: Propose a comprehensive, PRD-driven workflow.
 85: - **Your Suggested Prompt**: *"This sounds like a significant new feature. To manage this effectively, I suggest we create a dedicated task context for it. Here's the plan: I'll create a new tag called 'feature-xyz', then we can draft a Product Requirements Document (PRD) together to scope the work. Once the PRD is ready, I'll automatically generate all the necessary tasks within that new tag. How does that sound?"*
 86: - **Your Implementation Flow**:
 87:     1.  **Create an empty tag**: `task-master add-tag feature-xyz --description "Tasks for the new XYZ feature"`. You can also start by creating a git branch if applicable, and then create the tag from that branch.
 88:     2.  **Collaborate & Create PRD**: Work with the user to create a detailed PRD file (e.g., `.taskmaster/docs/feature-xyz-prd.txt`).
 89:     3.  **Parse PRD into the new tag**: `task-master parse-prd .taskmaster/docs/feature-xyz-prd.txt --tag feature-xyz`
 90:     4.  **Prepare the new task list**: Follow up by suggesting `analyze-complexity` and `expand-all` for the newly created tasks within the `feature-xyz` tag.
 91: 
 92: #### Pattern 5: Version-Based Development
 93: Tailor your approach based on the project maturity indicated by tag names.
 94: 
 95: - **Prototype/MVP Tags** (`prototype`, `mvp`, `poc`, `v0.x`):
 96:   - **Your Approach**: Focus on speed and functionality over perfection
 97:   - **Task Generation**: Create tasks that emphasize "get it working" over "get it perfect"
 98:   - **Complexity Level**: Lower complexity, fewer subtasks, more direct implementation paths
 99:   - **Research Prompts**: Include context like "This is a prototype - prioritize speed and basic functionality over optimization"
100:   - **Example Prompt Addition**: *"Since this is for the MVP, I'll focus on tasks that get core functionality working quickly rather than over-engineering."*
101: 
102: - **Production/Mature Tags** (`v1.0+`, `production`, `stable`):
103:   - **Your Approach**: Emphasize robustness, testing, and maintainability
104:   - **Task Generation**: Include comprehensive error handling, testing, documentation, and optimization
105:   - **Complexity Level**: Higher complexity, more detailed subtasks, thorough implementation paths
106:   - **Research Prompts**: Include context like "This is for production - prioritize reliability, performance, and maintainability"
107:   - **Example Prompt Addition**: *"Since this is for production, I'll ensure tasks include proper error handling, testing, and documentation."*
108: 
109: ### Advanced Workflow (Tag-Based & PRD-Driven)
110: 
111: **When to Transition**: Recognize when the project has evolved (or has initiated a project which existing code) beyond simple task management. Look for these indicators:
112: - User mentions teammates or collaboration needs
113: - Project has grown to 15+ tasks with mixed priorities
114: - User creates feature branches or mentions major initiatives
115: - User initializes Taskmaster on an existing, complex codebase
116: - User describes large features that would benefit from dedicated planning
117: 
118: **Your Role in Transition**: Guide the user to a more sophisticated workflow that leverages tags for organization and PRDs for comprehensive planning.
119: 
120: #### Master List Strategy (High-Value Focus)
121: Once you transition to tag-based workflows, the `master` tag should ideally contain only:
122: - **High-level deliverables** that provide significant business value
123: - **Major milestones** and epic-level features
124: - **Critical infrastructure** work that affects the entire project
125: - **Release-blocking** items
126: 
127: **What NOT to put in master**:
128: - Detailed implementation subtasks (these go in feature-specific tags' parent tasks)
129: - Refactoring work (create dedicated tags like `refactor-auth`)
130: - Experimental features (use `experiment-*` tags)
131: - Team member-specific tasks (use person-specific tags)
132: 
133: #### PRD-Driven Feature Development
134: 
135: **For New Major Features**:
136: 1. **Identify the Initiative**: When user describes a significant feature
137: 2. **Create Dedicated Tag**: `add_tag feature-[name] --description="[Feature description]"`
138: 3. **Collaborative PRD Creation**: Work with user to create comprehensive PRD in `.taskmaster/docs/feature-[name]-prd.txt`
139: 4. **Parse & Prepare**: 
140:    - `parse_prd .taskmaster/docs/feature-[name]-prd.txt --tag=feature-[name]`
141:    - `analyze_project_complexity --tag=feature-[name] --research`
142:    - `expand_all --tag=feature-[name] --research`
143: 5. **Add Master Reference**: Create a high-level task in `master` that references the feature tag
144: 
145: **For Existing Codebase Analysis**:
146: When users initialize Taskmaster on existing projects:
147: 1. **Codebase Discovery**: Use your native tools for producing deep context about the code base. You may use `research` tool with `--tree` and `--files` to collect up to date information using the existing architecture as context.
148: 2. **Collaborative Assessment**: Work with user to identify improvement areas, technical debt, or new features
149: 3. **Strategic PRD Creation**: Co-author PRDs that include:
150:    - Current state analysis (based on your codebase research)
151:    - Proposed improvements or new features
152:    - Implementation strategy considering existing code
153: 4. **Tag-Based Organization**: Parse PRDs into appropriate tags (`refactor-api`, `feature-dashboard`, `tech-debt`, etc.)
154: 5. **Master List Curation**: Keep only the most valuable initiatives in master
155: 
156: The parse-prd's `--append` flag enables the user to parse multple PRDs within tags or across tags. PRDs should be focused and the number of tasks they are parsed into should be strategically chosen relative to the PRD's complexity and level of detail.
157: 
158: ### Workflow Transition Examples
159: 
160: **Example 1: Simple → Team-Based**
161: ```
162: User: "Alice is going to help with the API work"
163: Your Response: "Great! To avoid conflicts, I'll create a separate task context for your work. Alice can continue with the master list while you work in your own context. When you're ready to merge, we can coordinate the tasks back together."
164: Action: add_tag my-api-work --copy-from-current --description="My API tasks while collaborating with Alice"
165: ```
166: 
167: **Example 2: Simple → PRD-Driven**
168: ```
169: User: "I want to add a complete user dashboard with analytics, user management, and reporting"
170: Your Response: "This sounds like a major feature that would benefit from detailed planning. Let me create a dedicated context for this work and we can draft a PRD together to ensure we capture all requirements."
171: Actions: 
172: 1. add_tag feature-dashboard --description="User dashboard with analytics and management"
173: 2. Collaborate on PRD creation
174: 3. parse_prd dashboard-prd.txt --tag=feature-dashboard
175: 4. Add high-level "User Dashboard" task to master
176: ```
177: 
178: **Example 3: Existing Project → Strategic Planning**
179: ```
180: User: "I just initialized Taskmaster on my existing React app. It's getting messy and I want to improve it."
181: Your Response: "Let me research your codebase to understand the current architecture, then we can create a strategic plan for improvements."
182: Actions:
183: 1. research "Current React app architecture and improvement opportunities" --tree --files=src/
184: 2. Collaborate on improvement PRD based on findings
185: 3. Create tags for different improvement areas (refactor-components, improve-state-management, etc.)
186: 4. Keep only major improvement initiatives in master
187: ```
188: 
189: ---
190: 
191: ## Primary Interaction: MCP Server vs. CLI
192: 
193: Taskmaster offers two primary ways to interact:
194: 
195: 1.  **MCP Server (Recommended for Integrated Tools)**:
196:     - For AI agents and integrated development environments (like Windsurf), interacting via the **MCP server is the preferred method**.
197:     - The MCP server exposes Taskmaster functionality through a set of tools (e.g., `get_tasks`, `add_subtask`).
198:     - This method offers better performance, structured data exchange, and richer error handling compared to CLI parsing.
199:     - Refer to @`mcp.md` for details on the MCP architecture and available tools.
200:     - A comprehensive list and description of MCP tools and their corresponding CLI commands can be found in @`taskmaster.md`.
201:     - **Restart the MCP server** if core logic in `scripts/modules` or MCP tool/direct function definitions change.
202:     - **Note**: MCP tools fully support tagged task lists with complete tag management capabilities.
203: 
204: 2.  **`task-master` CLI (For Users & Fallback)**:
205:     - The global `task-master` command provides a user-friendly interface for direct terminal interaction.
206:     - It can also serve as a fallback if the MCP server is inaccessible or a specific function isn't exposed via MCP.
207:     - Install globally with `npm install -g task-master-ai` or use locally via `npx task-master-ai ...`.
208:     - The CLI commands often mirror the MCP tools (e.g., `task-master list` corresponds to `get_tasks`).
209:     - Refer to @`taskmaster.md` for a detailed command reference.
210:     - **Tagged Task Lists**: CLI fully supports the new tagged system with seamless migration.
211: 
212: ## How the Tag System Works (For Your Reference)
213: 
214: - **Data Structure**: Tasks are organized into separate contexts (tags) like "master", "feature-branch", or "v2.0".
215: - **Silent Migration**: Existing projects automatically migrate to use a "master" tag with zero disruption.
216: - **Context Isolation**: Tasks in different tags are completely separate. Changes in one tag do not affect any other tag.
217: - **Manual Control**: The user is always in control. There is no automatic switching. You facilitate switching by using `use-tag <name>`.
218: - **Full CLI & MCP Support**: All tag management commands are available through both the CLI and MCP tools for you to use. Refer to @`taskmaster.md` for a full command list.
219: 
220: ---
221: 
222: ## Task Complexity Analysis
223: 
224: -   Run `analyze_project_complexity` / `task-master analyze-complexity --research` (see @`taskmaster.md`) for comprehensive analysis
225: -   Review complexity report via `complexity_report` / `task-master complexity-report` (see @`taskmaster.md`) for a formatted, readable version.
226: -   Focus on tasks with highest complexity scores (8-10) for detailed breakdown
227: -   Use analysis results to determine appropriate subtask allocation
228: -   Note that reports are automatically used by the `expand_task` tool/command
229: 
230: ## Task Breakdown Process
231: 
232: -   Use `expand_task` / `task-master expand --id=<id>`. It automatically uses the complexity report if found, otherwise generates default number of subtasks.
233: -   Use `--num=<number>` to specify an explicit number of subtasks, overriding defaults or complexity report recommendations.
234: -   Add `--research` flag to leverage Perplexity AI for research-backed expansion.
235: -   Add `--force` flag to clear existing subtasks before generating new ones (default is to append).
236: -   Use `--prompt="<context>"` to provide additional context when needed.
237: -   Review and adjust generated subtasks as necessary.
238: -   Use `expand_all` tool or `task-master expand --all` to expand multiple pending tasks at once, respecting flags like `--force` and `--research`.
239: -   If subtasks need complete replacement (regardless of the `--force` flag on `expand`), clear them first with `clear_subtasks` / `task-master clear-subtasks --id=<id>`.
240: 
241: ## Implementation Drift Handling
242: 
243: -   When implementation differs significantly from planned approach
244: -   When future tasks need modification due to current implementation choices
245: -   When new dependencies or requirements emerge
246: -   Use `update` / `task-master update --from=<futureTaskId> --prompt='<explanation>\nUpdate context...' --research` to update multiple future tasks.
247: -   Use `update_task` / `task-master update-task --id=<taskId> --prompt='<explanation>\nUpdate context...' --research` to update a single specific task.
248: 
249: ## Task Status Management
250: 
251: -   Use 'pending' for tasks ready to be worked on
252: -   Use 'done' for completed and verified tasks
253: -   Use 'deferred' for postponed tasks
254: -   Add custom status values as needed for project-specific workflows
255: 
256: ## Task Structure Fields
257: 
258: - **id**: Unique identifier for the task (Example: `1`, `1.1`)
259: - **title**: Brief, descriptive title (Example: `"Initialize Repo"`)
260: - **description**: Concise summary of what the task involves (Example: `"Create a new repository, set up initial structure."`)
261: - **status**: Current state of the task (Example: `"pending"`, `"done"`, `"deferred"`)
262: - **dependencies**: IDs of prerequisite tasks (Example: `[1, 2.1]`)
263:     - Dependencies are displayed with status indicators (✅ for completed, ⏱️ for pending)
264:     - This helps quickly identify which prerequisite tasks are blocking work
265: - **priority**: Importance level (Example: `"high"`, `"medium"`, `"low"`)
266: - **details**: In-depth implementation instructions (Example: `"Use GitHub client ID/secret, handle callback, set session token."`) 
267: - **testStrategy**: Verification approach (Example: `"Deploy and call endpoint to confirm 'Hello World' response."`) 
268: - **subtasks**: List of smaller, more specific tasks (Example: `[{"id": 1, "title": "Configure OAuth", ...}]`) 
269: - Refer to task structure details (previously linked to `tasks.md`).
270: 
271: ## Configuration Management (Updated)
272: 
273: Taskmaster configuration is managed through two main mechanisms:
274: 
275: 1.  **`.taskmaster/config.json` File (Primary):**
276:     *   Located in the project root directory.
277:     *   Stores most configuration settings: AI model selections (main, research, fallback), parameters (max tokens, temperature), logging level, default subtasks/priority, project name, etc.
278:     *   **Tagged System Settings**: Includes `global.defaultTag` (defaults to "master") and `tags` section for tag management configuration.
279:     *   **Managed via `task-master models --setup` command.** Do not edit manually unless you know what you are doing.
280:     *   **View/Set specific models via `task-master models` command or `models` MCP tool.**
281:     *   Created automatically when you run `task-master models --setup` for the first time or during tagged system migration.
282: 
283: 2.  **Environment Variables (`.env` / `mcp.json`):**
284:     *   Used **only** for sensitive API keys and specific endpoint URLs.
285:     *   Place API keys (one per provider) in a `.env` file in the project root for CLI usage.
286:     *   For MCP/Windsurf integration, configure these keys in the `env` section of `.windsurf/mcp.json`.
287:     *   Available keys/variables: See `assets/env.example` or the Configuration section in the command reference (previously linked to `taskmaster.md`).
288: 
289: 3.  **`.taskmaster/state.json` File (Tagged System State):**
290:     *   Tracks current tag context and migration status.
291:     *   Automatically created during tagged system migration.
292:     *   Contains: `currentTag`, `lastSwitched`, `migrationNoticeShown`.
293: 
294: **Important:** Non-API key settings (like model selections, `MAX_TOKENS`, `TASKMASTER_LOG_LEVEL`) are **no longer configured via environment variables**. Use the `task-master models` command (or `--setup` for interactive configuration) or the `models` MCP tool.
295: **If AI commands FAIL in MCP** verify that the API key for the selected provider is present in the `env` section of `.windsurf/mcp.json`.
296: **If AI commands FAIL in CLI** verify that the API key for the selected provider is present in the `.env` file in the root of the project.
297: 
298: ## Rules Management
299: 
300: Taskmaster supports multiple AI coding assistant rule sets that can be configured during project initialization or managed afterward:
301: 
302: - **Available Profiles**: Claude Code, Cline, Codex, Windsurf, Roo Code, Trae, Windsurf (claude, cline, codex, windsurf, roo, trae, windsurf)
303: - **During Initialization**: Use `task-master init --rules windsurf,windsurf` to specify which rule sets to include
304: - **After Initialization**: Use `task-master rules add <profiles>` or `task-master rules remove <profiles>` to manage rule sets
305: - **Interactive Setup**: Use `task-master rules setup` to launch an interactive prompt for selecting rule profiles
306: - **Default Behavior**: If no `--rules` flag is specified during initialization, all available rule profiles are included
307: - **Rule Structure**: Each profile creates its own directory (e.g., `.windsurf/rules`, `.roo/rules`) with appropriate configuration files
308: 
309: ## Determining the Next Task
310: 
311: - Run `next_task` / `task-master next` to show the next task to work on.
312: - The command identifies tasks with all dependencies satisfied
313: - Tasks are prioritized by priority level, dependency count, and ID
314: - The command shows comprehensive task information including:
315:     - Basic task details and description
316:     - Implementation details
317:     - Subtasks (if they exist)
318:     - Contextual suggested actions
319: - Recommended before starting any new development work
320: - Respects your project's dependency structure
321: - Ensures tasks are completed in the appropriate sequence
322: - Provides ready-to-use commands for common task actions
323: 
324: ## Viewing Specific Task Details
325: 
326: - Run `get_task` / `task-master show <id>` to view a specific task.
327: - Use dot notation for subtasks: `task-master show 1.2` (shows subtask 2 of task 1)
328: - Displays comprehensive information similar to the next command, but for a specific task
329: - For parent tasks, shows all subtasks and their current status
330: - For subtasks, shows parent task information and relationship
331: - Provides contextual suggested actions appropriate for the specific task
332: - Useful for examining task details before implementation or checking status
333: 
334: ## Managing Task Dependencies
335: 
336: - Use `add_dependency` / `task-master add-dependency --id=<id> --depends-on=<id>` to add a dependency.
337: - Use `remove_dependency` / `task-master remove-dependency --id=<id> --depends-on=<id>` to remove a dependency.
338: - The system prevents circular dependencies and duplicate dependency entries
339: - Dependencies are checked for existence before being added or removed
340: - Task files are automatically regenerated after dependency changes
341: - Dependencies are visualized with status indicators in task listings and files
342: 
343: ## Task Reorganization
344: 
345: - Use `move_task` / `task-master move --from=<id> --to=<id>` to move tasks or subtasks within the hierarchy
346: - This command supports several use cases:
347:   - Moving a standalone task to become a subtask (e.g., `--from=5 --to=7`)
348:   - Moving a subtask to become a standalone task (e.g., `--from=5.2 --to=7`) 
349:   - Moving a subtask to a different parent (e.g., `--from=5.2 --to=7.3`)
350:   - Reordering subtasks within the same parent (e.g., `--from=5.2 --to=5.4`)
351:   - Moving a task to a new, non-existent ID position (e.g., `--from=5 --to=25`)
352:   - Moving multiple tasks at once using comma-separated IDs (e.g., `--from=10,11,12 --to=16,17,18`)
353: - The system includes validation to prevent data loss:
354:   - Allows moving to non-existent IDs by creating placeholder tasks
355:   - Prevents moving to existing task IDs that have content (to avoid overwriting)
356:   - Validates source tasks exist before attempting to move them
357: - The system maintains proper parent-child relationships and dependency integrity
358: - Task files are automatically regenerated after the move operation
359: - This provides greater flexibility in organizing and refining your task structure as project understanding evolves
360: - This is especially useful when dealing with potential merge conflicts arising from teams creating tasks on separate branches. Solve these conflicts very easily by moving your tasks and keeping theirs.
361: 
362: ## Iterative Subtask Implementation
363: 
364: Once a task has been broken down into subtasks using `expand_task` or similar methods, follow this iterative process for implementation:
365: 
366: 1.  **Understand the Goal (Preparation):**
367:     *   Use `get_task` / `task-master show <subtaskId>` (see @`taskmaster.md`) to thoroughly understand the specific goals and requirements of the subtask.
368: 
369: 2.  **Initial Exploration & Planning (Iteration 1):**
370:     *   This is the first attempt at creating a concrete implementation plan.
371:     *   Explore the codebase to identify the precise files, functions, and even specific lines of code that will need modification.
372:     *   Determine the intended code changes (diffs) and their locations.
373:     *   Gather *all* relevant details from this exploration phase.
374: 
375: 3.  **Log the Plan:**
376:     *   Run `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<detailed plan>'`.
377:     *   Provide the *complete and detailed* findings from the exploration phase in the prompt. Include file paths, line numbers, proposed diffs, reasoning, and any potential challenges identified. Do not omit details. The goal is to create a rich, timestamped log within the subtask's `details`.
378: 
379: 4.  **Verify the Plan:**
380:     *   Run `get_task` / `task-master show <subtaskId>` again to confirm that the detailed implementation plan has been successfully appended to the subtask's details.
381: 
382: 5.  **Begin Implementation:**
383:     *   Set the subtask status using `set_task_status` / `task-master set-status --id=<subtaskId> --status=in-progress`.
384:     *   Start coding based on the logged plan.
385: 
386: 6.  **Refine and Log Progress (Iteration 2+):**
387:     *   As implementation progresses, you will encounter challenges, discover nuances, or confirm successful approaches.
388:     *   **Before appending new information**: Briefly review the *existing* details logged in the subtask (using `get_task` or recalling from context) to ensure the update adds fresh insights and avoids redundancy.
389:     *   **Regularly** use `update_subtask` / `task-master update-subtask --id=<subtaskId> --prompt='<update details>\n- What worked...\n- What didn't work...'` to append new findings.
390:     *   **Crucially, log:**
391:         *   What worked ("fundamental truths" discovered).
392:         *   What didn't work and why (to avoid repeating mistakes).
393:         *   Specific code snippets or configurations that were successful.
394:         *   Decisions made, especially if confirmed with user input.
395:         *   Any deviations from the initial plan and the reasoning.
396:     *   The objective is to continuously enrich the subtask's details, creating a log of the implementation journey that helps the AI (and human developers) learn, adapt, and avoid repeating errors.
397: 
398: 7.  **Review & Update Rules (Post-Implementation):**
399:     *   Once the implementation for the subtask is functionally complete, review all code changes and the relevant chat history.
400:     *   Identify any new or modified code patterns, conventions, or best practices established during the implementation.
401:     *   Create new or update existing rules following internal guidelines (previously linked to `cursor_rules.md` and `self_improve.md`).
402: 
403: 8.  **Mark Task Complete:**
404:     *   After verifying the implementation and updating any necessary rules, mark the subtask as completed: `set_task_status` / `task-master set-status --id=<subtaskId> --status=done`.
405: 
406: 9.  **Commit Changes (If using Git):**
407:     *   Stage the relevant code changes and any updated/new rule files (`git add .`).
408:     *   Craft a comprehensive Git commit message summarizing the work done for the subtask, including both code implementation and any rule adjustments.
409:     *   Execute the commit command directly in the terminal (e.g., `git commit -m 'feat(module): Implement feature X for subtask <subtaskId>\n\n- Details about changes...\n- Updated rule Y for pattern Z'`).
410:     *   Consider if a Changeset is needed according to internal versioning guidelines (previously linked to `changeset.md`). If so, run `npm run changeset`, stage the generated file, and amend the commit or create a new one.
411: 
412: 10. **Proceed to Next Subtask:**
413:     *   Identify the next subtask (e.g., using `next_task` / `task-master next`).
414: 
415: ## Code Analysis & Refactoring Techniques
416: 
417: - **Top-Level Function Search**:
418:     - Useful for understanding module structure or planning refactors.
419:     - Use grep/ripgrep to find exported functions/constants:
420:       `rg "export (async function|function|const) \w+"` or similar patterns.
421:     - Can help compare functions between files during migrations or identify potential naming conflicts.
422: 
423: ---
424: *This workflow provides a general guideline. Adapt it based on your specific project needs and team practices.*
</file>

<file path=".windsurf/rules/self_improve.md">
 1: ---
 2: description: Guidelines for continuously improving Windsurf rules based on emerging code patterns and best practices.
 3: globs: **/*
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Rule Improvement Triggers:**
 8:   - New code patterns not covered by existing rules
 9:   - Repeated similar implementations across files
10:   - Common error patterns that could be prevented
11:   - New libraries or tools being used consistently
12:   - Emerging best practices in the codebase
13: 
14: - **Analysis Process:**
15:   - Compare new code with existing rules
16:   - Identify patterns that should be standardized
17:   - Look for references to external documentation
18:   - Check for consistent error handling patterns
19:   - Monitor test patterns and coverage
20: 
21: - **Rule Updates:**
22:   - **Add New Rules When:**
23:     - A new technology/pattern is used in 3+ files
24:     - Common bugs could be prevented by a rule
25:     - Code reviews repeatedly mention the same feedback
26:     - New security or performance patterns emerge
27: 
28:   - **Modify Existing Rules When:**
29:     - Better examples exist in the codebase
30:     - Additional edge cases are discovered
31:     - Related rules have been updated
32:     - Implementation details have changed
33: 
34: - **Example Pattern Recognition:**
35:   ```typescript
36:   // If you see repeated patterns like:
37:   const data = await prisma.user.findMany({
38:     select: { id: true, email: true },
39:     where: { status: 'ACTIVE' }
40:   });
41:   
42:   // Consider adding to [prisma.md](.windsurf/rules/prisma.md):
43:   // - Standard select fields
44:   // - Common where conditions
45:   // - Performance optimization patterns
46:   ```
47: 
48: - **Rule Quality Checks:**
49:   - Rules should be actionable and specific
50:   - Examples should come from actual code
51:   - References should be up to date
52:   - Patterns should be consistently enforced
53: 
54: - **Continuous Improvement:**
55:   - Monitor code review comments
56:   - Track common development questions
57:   - Update rules after major refactors
58:   - Add links to relevant documentation
59:   - Cross-reference related rules
60: 
61: - **Rule Deprecation:**
62:   - Mark outdated patterns as deprecated
63:   - Remove rules that no longer apply
64:   - Update references to deprecated rules
65:   - Document migration paths for old patterns
66: 
67: - **Documentation Updates:**
68:   - Keep examples synchronized with code
69:   - Update references to external docs
70:   - Maintain links between related rules
71:   - Document breaking changes
72: Follow [windsurf_rules.md](.windsurf/rules/windsurf_rules.md) for proper rule formatting and structure.
</file>

<file path=".windsurf/rules/taskmaster.md">
  1: ---
  2: description: Comprehensive reference for Taskmaster MCP tools and CLI commands.
  3: globs: **/*
  4: alwaysApply: true
  5: ---
  6: 
  7: # Taskmaster Tool & Command Reference
  8: 
  9: This document provides a detailed reference for interacting with Taskmaster, covering both the recommended MCP tools, suitable for integrations like Windsurf, and the corresponding `task-master` CLI commands, designed for direct user interaction or fallback.
 10: 
 11: **Note:** For interacting with Taskmaster programmatically or via integrated tools, using the **MCP tools is strongly recommended** due to better performance, structured data, and error handling. The CLI commands serve as a user-friendly alternative and fallback. 
 12: 
 13: **Important:** Several MCP tools involve AI processing... The AI-powered tools include `parse_prd`, `analyze_project_complexity`, `update_subtask`, `update_task`, `update`, `expand_all`, `expand_task`, and `add_task`.
 14: 
 15: **🏷️ Tagged Task Lists System:** Task Master now supports **tagged task lists** for multi-context task management. This allows you to maintain separate, isolated lists of tasks for different features, branches, or experiments. Existing projects are seamlessly migrated to use a default "master" tag. Most commands now support a `--tag <name>` flag to specify which context to operate on. If omitted, commands use the currently active tag.
 16: 
 17: ---
 18: 
 19: ## Initialization & Setup
 20: 
 21: ### 1. Initialize Project (`init`)
 22: 
 23: *   **MCP Tool:** `initialize_project`
 24: *   **CLI Command:** `task-master init [options]`
 25: *   **Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project.`
 26: *   **Key CLI Options:**
 27:     *   `--name <name>`: `Set the name for your project in Taskmaster's configuration.`
 28:     *   `--description <text>`: `Provide a brief description for your project.`
 29:     *   `--version <version>`: `Set the initial version for your project, e.g., '0.1.0'.`
 30:     *   `-y, --yes`: `Initialize Taskmaster quickly using default settings without interactive prompts.`
 31: *   **Usage:** Run this once at the beginning of a new project.
 32: *   **MCP Variant Description:** `Set up the basic Taskmaster file structure and configuration in the current directory for a new project by running the 'task-master init' command.`
 33: *   **Key MCP Parameters/Options:**
 34:     *   `projectName`: `Set the name for your project.` (CLI: `--name <name>`)
 35:     *   `projectDescription`: `Provide a brief description for your project.` (CLI: `--description <text>`)
 36:     *   `projectVersion`: `Set the initial version for your project, e.g., '0.1.0'.` (CLI: `--version <version>`)
 37:     *   `authorName`: `Author name.` (CLI: `--author <author>`)
 38:     *   `skipInstall`: `Skip installing dependencies. Default is false.` (CLI: `--skip-install`)
 39:     *   `addAliases`: `Add shell aliases tm and taskmaster. Default is false.` (CLI: `--aliases`)
 40:     *   `yes`: `Skip prompts and use defaults/provided arguments. Default is false.` (CLI: `-y, --yes`)
 41: *   **Usage:** Run this once at the beginning of a new project, typically via an integrated tool like Windsurf. Operates on the current working directory of the MCP server. 
 42: *   **Important:** Once complete, you *MUST* parse a prd in order to generate tasks. There will be no tasks files until then. The next step after initializing should be to create a PRD using the example PRD in .taskmaster/templates/example_prd.txt. 
 43: *   **Tagging:** Use the `--tag` option to parse the PRD into a specific, non-default tag context. If the tag doesn't exist, it will be created automatically. Example: `task-master parse-prd spec.txt --tag=new-feature`.
 44: 
 45: ### 2. Parse PRD (`parse_prd`)
 46: 
 47: *   **MCP Tool:** `parse_prd`
 48: *   **CLI Command:** `task-master parse-prd [file] [options]`
 49: *   **Description:** `Parse a Product Requirements Document, PRD, or text file with Taskmaster to automatically generate an initial set of tasks in tasks.json.`
 50: *   **Key Parameters/Options:**
 51:     *   `input`: `Path to your PRD or requirements text file that Taskmaster should parse for tasks.` (CLI: `[file]` positional or `-i, --input <file>`)
 52:     *   `output`: `Specify where Taskmaster should save the generated 'tasks.json' file. Defaults to '.taskmaster/tasks/tasks.json'.` (CLI: `-o, --output <file>`)
 53:     *   `numTasks`: `Approximate number of top-level tasks Taskmaster should aim to generate from the document.` (CLI: `-n, --num-tasks <number>`)
 54:     *   `force`: `Use this to allow Taskmaster to overwrite an existing 'tasks.json' without asking for confirmation.` (CLI: `-f, --force`)
 55: *   **Usage:** Useful for bootstrapping a project from an existing requirements document.
 56: *   **Notes:** Task Master will strictly adhere to any specific requirements mentioned in the PRD, such as libraries, database schemas, frameworks, tech stacks, etc., while filling in any gaps where the PRD isn't fully specified. Tasks are designed to provide the most direct implementation path while avoiding over-engineering.
 57: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress. If the user does not have a PRD, suggest discussing their idea and then use the example PRD in `.taskmaster/templates/example_prd.txt` as a template for creating the PRD based on their idea, for use with `parse-prd`.
 58: 
 59: ---
 60: 
 61: ## AI Model Configuration
 62: 
 63: ### 2. Manage Models (`models`)
 64: *   **MCP Tool:** `models`
 65: *   **CLI Command:** `task-master models [options]`
 66: *   **Description:** `View the current AI model configuration or set specific models for different roles (main, research, fallback). Allows setting custom model IDs for Ollama and OpenRouter.`
 67: *   **Key MCP Parameters/Options:**
 68:     *   `setMain <model_id>`: `Set the primary model ID for task generation/updates.` (CLI: `--set-main <model_id>`)
 69:     *   `setResearch <model_id>`: `Set the model ID for research-backed operations.` (CLI: `--set-research <model_id>`)
 70:     *   `setFallback <model_id>`: `Set the model ID to use if the primary fails.` (CLI: `--set-fallback <model_id>`)
 71:     *   `ollama <boolean>`: `Indicates the set model ID is a custom Ollama model.` (CLI: `--ollama`)
 72:     *   `openrouter <boolean>`: `Indicates the set model ID is a custom OpenRouter model.` (CLI: `--openrouter`)
 73:     *   `listAvailableModels <boolean>`: `If true, lists available models not currently assigned to a role.` (CLI: No direct equivalent; CLI lists available automatically)
 74:     *   `projectRoot <string>`: `Optional. Absolute path to the project root directory.` (CLI: Determined automatically)
 75: *   **Key CLI Options:**
 76:     *   `--set-main <model_id>`: `Set the primary model.`
 77:     *   `--set-research <model_id>`: `Set the research model.`
 78:     *   `--set-fallback <model_id>`: `Set the fallback model.`
 79:     *   `--ollama`: `Specify that the provided model ID is for Ollama (use with --set-*).`
 80:     *   `--openrouter`: `Specify that the provided model ID is for OpenRouter (use with --set-*). Validates against OpenRouter API.`
 81:     *   `--bedrock`: `Specify that the provided model ID is for AWS Bedrock (use with --set-*).`
 82:     *   `--setup`: `Run interactive setup to configure models, including custom Ollama/OpenRouter IDs.`
 83: *   **Usage (MCP):** Call without set flags to get current config. Use `setMain`, `setResearch`, or `setFallback` with a valid model ID to update the configuration. Use `listAvailableModels: true` to get a list of unassigned models. To set a custom model, provide the model ID and set `ollama: true` or `openrouter: true`.
 84: *   **Usage (CLI):** Run without flags to view current configuration and available models. Use set flags to update specific roles. Use `--setup` for guided configuration, including custom models. To set a custom model via flags, use `--set-<role>=<model_id>` along with either `--ollama` or `--openrouter`.
 85: *   **Notes:** Configuration is stored in `.taskmaster/config.json` in the project root. This command/tool modifies that file. Use `listAvailableModels` or `task-master models` to see internally supported models. OpenRouter custom models are validated against their live API. Ollama custom models are not validated live.
 86: *   **API note:** API keys for selected AI providers (based on their model) need to exist in the mcp.json file to be accessible in MCP context. The API keys must be present in the local .env file for the CLI to be able to read them.
 87: *   **Model costs:** The costs in supported models are expressed in dollars. An input/output value of 3 is $3.00. A value of 0.8 is $0.80. 
 88: *   **Warning:** DO NOT MANUALLY EDIT THE .taskmaster/config.json FILE. Use the included commands either in the MCP or CLI format as needed. Always prioritize MCP tools when available and use the CLI as a fallback.
 89: 
 90: ---
 91: 
 92: ## Task Listing & Viewing
 93: 
 94: ### 3. Get Tasks (`get_tasks`)
 95: 
 96: *   **MCP Tool:** `get_tasks`
 97: *   **CLI Command:** `task-master list [options]`
 98: *   **Description:** `List your Taskmaster tasks, optionally filtering by status and showing subtasks.`
 99: *   **Key Parameters/Options:**
100:     *   `status`: `Show only Taskmaster tasks matching this status (or multiple statuses, comma-separated), e.g., 'pending' or 'done,in-progress'.` (CLI: `-s, --status <status>`)
101:     *   `withSubtasks`: `Include subtasks indented under their parent tasks in the list.` (CLI: `--with-subtasks`)
102:     *   `tag`: `Specify which tag context to list tasks from. Defaults to the current active tag.` (CLI: `--tag <name>`)
103:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
104: *   **Usage:** Get an overview of the project status, often used at the start of a work session.
105: 
106: ### 4. Get Next Task (`next_task`)
107: 
108: *   **MCP Tool:** `next_task`
109: *   **CLI Command:** `task-master next [options]`
110: *   **Description:** `Ask Taskmaster to show the next available task you can work on, based on status and completed dependencies.`
111: *   **Key Parameters/Options:**
112:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
113:     *   `tag`: `Specify which tag context to use. Defaults to the current active tag.` (CLI: `--tag <name>`)
114: *   **Usage:** Identify what to work on next according to the plan.
115: 
116: ### 5. Get Task Details (`get_task`)
117: 
118: *   **MCP Tool:** `get_task`
119: *   **CLI Command:** `task-master show [id] [options]`
120: *   **Description:** `Display detailed information for one or more specific Taskmaster tasks or subtasks by ID.`
121: *   **Key Parameters/Options:**
122:     *   `id`: `Required. The ID of the Taskmaster task (e.g., '15'), subtask (e.g., '15.2'), or a comma-separated list of IDs ('1,5,10.2') you want to view.` (CLI: `[id]` positional or `-i, --id <id>`)
123:     *   `tag`: `Specify which tag context to get the task(s) from. Defaults to the current active tag.` (CLI: `--tag <name>`)
124:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
125: *   **Usage:** Understand the full details for a specific task. When multiple IDs are provided, a summary table is shown.
126: *   **CRITICAL INFORMATION** If you need to collect information from multiple tasks, use comma-separated IDs (i.e. 1,2,3) to receive an array of tasks. Do not needlessly get tasks one at a time if you need to get many as that is wasteful.
127: 
128: ---
129: 
130: ## Task Creation & Modification
131: 
132: ### 6. Add Task (`add_task`)
133: 
134: *   **MCP Tool:** `add_task`
135: *   **CLI Command:** `task-master add-task [options]`
136: *   **Description:** `Add a new task to Taskmaster by describing it; AI will structure it.`
137: *   **Key Parameters/Options:**
138:     *   `prompt`: `Required. Describe the new task you want Taskmaster to create, e.g., "Implement user authentication using JWT".` (CLI: `-p, --prompt <text>`)
139:     *   `dependencies`: `Specify the IDs of any Taskmaster tasks that must be completed before this new one can start, e.g., '12,14'.` (CLI: `-d, --dependencies <ids>`)
140:     *   `priority`: `Set the priority for the new task: 'high', 'medium', or 'low'. Default is 'medium'.` (CLI: `--priority <priority>`)
141:     *   `research`: `Enable Taskmaster to use the research role for potentially more informed task creation.` (CLI: `-r, --research`)
142:     *   `tag`: `Specify which tag context to add the task to. Defaults to the current active tag.` (CLI: `--tag <name>`)
143:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
144: *   **Usage:** Quickly add newly identified tasks during development.
145: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
146: 
147: ### 7. Add Subtask (`add_subtask`)
148: 
149: *   **MCP Tool:** `add_subtask`
150: *   **CLI Command:** `task-master add-subtask [options]`
151: *   **Description:** `Add a new subtask to a Taskmaster parent task, or convert an existing task into a subtask.`
152: *   **Key Parameters/Options:**
153:     *   `id` / `parent`: `Required. The ID of the Taskmaster task that will be the parent.` (MCP: `id`, CLI: `-p, --parent <id>`)
154:     *   `taskId`: `Use this if you want to convert an existing top-level Taskmaster task into a subtask of the specified parent.` (CLI: `-i, --task-id <id>`)
155:     *   `title`: `Required if not using taskId. The title for the new subtask Taskmaster should create.` (CLI: `-t, --title <title>`)
156:     *   `description`: `A brief description for the new subtask.` (CLI: `-d, --description <text>`)
157:     *   `details`: `Provide implementation notes or details for the new subtask.` (CLI: `--details <text>`)
158:     *   `dependencies`: `Specify IDs of other tasks or subtasks, e.g., '15' or '16.1', that must be done before this new subtask.` (CLI: `--dependencies <ids>`)
159:     *   `status`: `Set the initial status for the new subtask. Default is 'pending'.` (CLI: `-s, --status <status>`)
160:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after adding the subtask.` (CLI: `--skip-generate`)
161:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
162:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
163: *   **Usage:** Break down tasks manually or reorganize existing tasks.
164: 
165: ### 8. Update Tasks (`update`)
166: 
167: *   **MCP Tool:** `update`
168: *   **CLI Command:** `task-master update [options]`
169: *   **Description:** `Update multiple upcoming tasks in Taskmaster based on new context or changes, starting from a specific task ID.`
170: *   **Key Parameters/Options:**
171:     *   `from`: `Required. The ID of the first task Taskmaster should update. All tasks with this ID or higher that are not 'done' will be considered.` (CLI: `--from <id>`)
172:     *   `prompt`: `Required. Explain the change or new context for Taskmaster to apply to the tasks, e.g., "We are now using React Query instead of Redux Toolkit for data fetching".` (CLI: `-p, --prompt <text>`)
173:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
174:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
175:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
176: *   **Usage:** Handle significant implementation changes or pivots that affect multiple future tasks. Example CLI: `task-master update --from='18' --prompt='Switching to React Query.\nNeed to refactor data fetching...'`
177: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
178: 
179: ### 9. Update Task (`update_task`)
180: 
181: *   **MCP Tool:** `update_task`
182: *   **CLI Command:** `task-master update-task [options]`
183: *   **Description:** `Modify a specific Taskmaster task by ID, incorporating new information or changes. By default, this replaces the existing task details.`
184: *   **Key Parameters/Options:**
185:     *   `id`: `Required. The specific ID of the Taskmaster task, e.g., '15', you want to update.` (CLI: `-i, --id <id>`)
186:     *   `prompt`: `Required. Explain the specific changes or provide the new information Taskmaster should incorporate into this task.` (CLI: `-p, --prompt <text>`)
187:     *   `append`: `If true, appends the prompt content to the task's details with a timestamp, rather than replacing them. Behaves like update-subtask.` (CLI: `--append`)
188:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
189:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
190:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
191: *   **Usage:** Refine a specific task based on new understanding. Use `--append` to log progress without creating subtasks.
192: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
193: 
194: ### 10. Update Subtask (`update_subtask`)
195: 
196: *   **MCP Tool:** `update_subtask`
197: *   **CLI Command:** `task-master update-subtask [options]`
198: *   **Description:** `Append timestamped notes or details to a specific Taskmaster subtask without overwriting existing content. Intended for iterative implementation logging.`
199: *   **Key Parameters/Options:**
200:     *   `id`: `Required. The ID of the Taskmaster subtask, e.g., '5.2', to update with new information.` (CLI: `-i, --id <id>`)
201:     *   `prompt`: `Required. The information, findings, or progress notes to append to the subtask's details with a timestamp.` (CLI: `-p, --prompt <text>`)
202:     *   `research`: `Enable Taskmaster to use the research role for more informed updates. Requires appropriate API key.` (CLI: `-r, --research`)
203:     *   `tag`: `Specify which tag context the subtask belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
204:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
205: *   **Usage:** Log implementation progress, findings, and discoveries during subtask development. Each update is timestamped and appended to preserve the implementation journey.
206: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
207: 
208: ### 11. Set Task Status (`set_task_status`)
209: 
210: *   **MCP Tool:** `set_task_status`
211: *   **CLI Command:** `task-master set-status [options]`
212: *   **Description:** `Update the status of one or more Taskmaster tasks or subtasks, e.g., 'pending', 'in-progress', 'done'.`
213: *   **Key Parameters/Options:**
214:     *   `id`: `Required. The ID(s) of the Taskmaster task(s) or subtask(s), e.g., '15', '15.2', or '16,17.1', to update.` (CLI: `-i, --id <id>`)
215:     *   `status`: `Required. The new status to set, e.g., 'done', 'pending', 'in-progress', 'review', 'cancelled'.` (CLI: `-s, --status <status>`)
216:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
217:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
218: *   **Usage:** Mark progress as tasks move through the development cycle.
219: 
220: ### 12. Remove Task (`remove_task`)
221: 
222: *   **MCP Tool:** `remove_task`
223: *   **CLI Command:** `task-master remove-task [options]`
224: *   **Description:** `Permanently remove a task or subtask from the Taskmaster tasks list.`
225: *   **Key Parameters/Options:**
226:     *   `id`: `Required. The ID of the Taskmaster task, e.g., '5', or subtask, e.g., '5.2', to permanently remove.` (CLI: `-i, --id <id>`)
227:     *   `yes`: `Skip the confirmation prompt and immediately delete the task.` (CLI: `-y, --yes`)
228:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
229:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
230: *   **Usage:** Permanently delete tasks or subtasks that are no longer needed in the project.
231: *   **Notes:** Use with caution as this operation cannot be undone. Consider using 'blocked', 'cancelled', or 'deferred' status instead if you just want to exclude a task from active planning but keep it for reference. The command automatically cleans up dependency references in other tasks.
232: 
233: ---
234: 
235: ## Task Structure & Breakdown
236: 
237: ### 13. Expand Task (`expand_task`)
238: 
239: *   **MCP Tool:** `expand_task`
240: *   **CLI Command:** `task-master expand [options]`
241: *   **Description:** `Use Taskmaster's AI to break down a complex task into smaller, manageable subtasks. Appends subtasks by default.`
242: *   **Key Parameters/Options:**
243:     *   `id`: `The ID of the specific Taskmaster task you want to break down into subtasks.` (CLI: `-i, --id <id>`)
244:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create. Uses complexity analysis/defaults otherwise.` (CLI: `-n, --num <number>`)
245:     *   `research`: `Enable Taskmaster to use the research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
246:     *   `prompt`: `Optional: Provide extra context or specific instructions to Taskmaster for generating the subtasks.` (CLI: `-p, --prompt <text>`)
247:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones. Default is false (append).` (CLI: `--force`)
248:     *   `tag`: `Specify which tag context the task belongs to. Defaults to the current active tag.` (CLI: `--tag <name>`)
249:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
250: *   **Usage:** Generate a detailed implementation plan for a complex task before starting coding. Automatically uses complexity report recommendations if available and `num` is not specified.
251: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
252: 
253: ### 14. Expand All Tasks (`expand_all`)
254: 
255: *   **MCP Tool:** `expand_all`
256: *   **CLI Command:** `task-master expand --all [options]` (Note: CLI uses the `expand` command with the `--all` flag)
257: *   **Description:** `Tell Taskmaster to automatically expand all eligible pending/in-progress tasks based on complexity analysis or defaults. Appends subtasks by default.`
258: *   **Key Parameters/Options:**
259:     *   `num`: `Optional: Suggests how many subtasks Taskmaster should aim to create per task.` (CLI: `-n, --num <number>`)
260:     *   `research`: `Enable research role for more informed subtask generation. Requires appropriate API key.` (CLI: `-r, --research`)
261:     *   `prompt`: `Optional: Provide extra context for Taskmaster to apply generally during expansion.` (CLI: `-p, --prompt <text>`)
262:     *   `force`: `Optional: If true, clear existing subtasks before generating new ones for each eligible task. Default is false (append).` (CLI: `--force`)
263:     *   `tag`: `Specify which tag context to expand. Defaults to the current active tag.` (CLI: `--tag <name>`)
264:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
265: *   **Usage:** Useful after initial task generation or complexity analysis to break down multiple tasks at once.
266: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
267: 
268: ### 15. Clear Subtasks (`clear_subtasks`)
269: 
270: *   **MCP Tool:** `clear_subtasks`
271: *   **CLI Command:** `task-master clear-subtasks [options]`
272: *   **Description:** `Remove all subtasks from one or more specified Taskmaster parent tasks.`
273: *   **Key Parameters/Options:**
274:     *   `id`: `The ID(s) of the Taskmaster parent task(s) whose subtasks you want to remove, e.g., '15' or '16,18'. Required unless using `all`.) (CLI: `-i, --id <ids>`)
275:     *   `all`: `Tell Taskmaster to remove subtasks from all parent tasks.` (CLI: `--all`)
276:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
277:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
278: *   **Usage:** Used before regenerating subtasks with `expand_task` if the previous breakdown needs replacement.
279: 
280: ### 16. Remove Subtask (`remove_subtask`)
281: 
282: *   **MCP Tool:** `remove_subtask`
283: *   **CLI Command:** `task-master remove-subtask [options]`
284: *   **Description:** `Remove a subtask from its Taskmaster parent, optionally converting it into a standalone task.`
285: *   **Key Parameters/Options:**
286:     *   `id`: `Required. The ID(s) of the Taskmaster subtask(s) to remove, e.g., '15.2' or '16.1,16.3'.` (CLI: `-i, --id <id>`)
287:     *   `convert`: `If used, Taskmaster will turn the subtask into a regular top-level task instead of deleting it.` (CLI: `-c, --convert`)
288:     *   `skipGenerate`: `Prevent Taskmaster from automatically regenerating markdown task files after removing the subtask.` (CLI: `--skip-generate`)
289:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
290:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
291: *   **Usage:** Delete unnecessary subtasks or promote a subtask to a top-level task.
292: 
293: ### 17. Move Task (`move_task`)
294: 
295: *   **MCP Tool:** `move_task`
296: *   **CLI Command:** `task-master move [options]`
297: *   **Description:** `Move a task or subtask to a new position within the task hierarchy.`
298: *   **Key Parameters/Options:**
299:     *   `from`: `Required. ID of the task/subtask to move (e.g., "5" or "5.2"). Can be comma-separated for multiple tasks.` (CLI: `--from <id>`)
300:     *   `to`: `Required. ID of the destination (e.g., "7" or "7.3"). Must match the number of source IDs if comma-separated.` (CLI: `--to <id>`)
301:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
302:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
303: *   **Usage:** Reorganize tasks by moving them within the hierarchy. Supports various scenarios like:
304:     *   Moving a task to become a subtask
305:     *   Moving a subtask to become a standalone task
306:     *   Moving a subtask to a different parent
307:     *   Reordering subtasks within the same parent
308:     *   Moving a task to a new, non-existent ID (automatically creates placeholders)
309:     *   Moving multiple tasks at once with comma-separated IDs
310: *   **Validation Features:**
311:     *   Allows moving tasks to non-existent destination IDs (creates placeholder tasks)
312:     *   Prevents moving to existing task IDs that already have content (to avoid overwriting)
313:     *   Validates that source tasks exist before attempting to move them
314:     *   Maintains proper parent-child relationships
315: *   **Example CLI:** `task-master move --from=5.2 --to=7.3` to move subtask 5.2 to become subtask 7.3.
316: *   **Example Multi-Move:** `task-master move --from=10,11,12 --to=16,17,18` to move multiple tasks to new positions.
317: *   **Common Use:** Resolving merge conflicts in tasks.json when multiple team members create tasks on different branches.
318: 
319: ---
320: 
321: ## Dependency Management
322: 
323: ### 18. Add Dependency (`add_dependency`)
324: 
325: *   **MCP Tool:** `add_dependency`
326: *   **CLI Command:** `task-master add-dependency [options]`
327: *   **Description:** `Define a dependency in Taskmaster, making one task a prerequisite for another.`
328: *   **Key Parameters/Options:**
329:     *   `id`: `Required. The ID of the Taskmaster task that will depend on another.` (CLI: `-i, --id <id>`)
330:     *   `dependsOn`: `Required. The ID of the Taskmaster task that must be completed first, the prerequisite.` (CLI: `-d, --depends-on <id>`)
331:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
332:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <path>`)
333: *   **Usage:** Establish the correct order of execution between tasks.
334: 
335: ### 19. Remove Dependency (`remove_dependency`)
336: 
337: *   **MCP Tool:** `remove_dependency`
338: *   **CLI Command:** `task-master remove-dependency [options]`
339: *   **Description:** `Remove a dependency relationship between two Taskmaster tasks.`
340: *   **Key Parameters/Options:**
341:     *   `id`: `Required. The ID of the Taskmaster task you want to remove a prerequisite from.` (CLI: `-i, --id <id>`)
342:     *   `dependsOn`: `Required. The ID of the Taskmaster task that should no longer be a prerequisite.` (CLI: `-d, --depends-on <id>`)
343:     *   `tag`: `Specify which tag context to operate on. Defaults to the current active tag.` (CLI: `--tag <name>`)
344:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
345: *   **Usage:** Update task relationships when the order of execution changes.
346: 
347: ### 20. Validate Dependencies (`validate_dependencies`)
348: 
349: *   **MCP Tool:** `validate_dependencies`
350: *   **CLI Command:** `task-master validate-dependencies [options]`
351: *   **Description:** `Check your Taskmaster tasks for dependency issues (like circular references or links to non-existent tasks) without making changes.`
352: *   **Key Parameters/Options:**
353:     *   `tag`: `Specify which tag context to validate. Defaults to the current active tag.` (CLI: `--tag <name>`)
354:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
355: *   **Usage:** Audit the integrity of your task dependencies.
356: 
357: ### 21. Fix Dependencies (`fix_dependencies`)
358: 
359: *   **MCP Tool:** `fix_dependencies`
360: *   **CLI Command:** `task-master fix-dependencies [options]`
361: *   **Description:** `Automatically fix dependency issues (like circular references or links to non-existent tasks) in your Taskmaster tasks.`
362: *   **Key Parameters/Options:**
363:     *   `tag`: `Specify which tag context to fix dependencies in. Defaults to the current active tag.` (CLI: `--tag <name>`)
364:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
365: *   **Usage:** Clean up dependency errors automatically.
366: 
367: ---
368: 
369: ## Analysis & Reporting
370: 
371: ### 22. Analyze Project Complexity (`analyze_project_complexity`)
372: 
373: *   **MCP Tool:** `analyze_project_complexity`
374: *   **CLI Command:** `task-master analyze-complexity [options]`
375: *   **Description:** `Have Taskmaster analyze your tasks to determine their complexity and suggest which ones need to be broken down further.`
376: *   **Key Parameters/Options:**
377:     *   `output`: `Where to save the complexity analysis report. Default is '.taskmaster/reports/task-complexity-report.json' (or '..._tagname.json' if a tag is used).` (CLI: `-o, --output <file>`)
378:     *   `threshold`: `The minimum complexity score (1-10) that should trigger a recommendation to expand a task.` (CLI: `-t, --threshold <number>`)
379:     *   `research`: `Enable research role for more accurate complexity analysis. Requires appropriate API key.` (CLI: `-r, --research`)
380:     *   `tag`: `Specify which tag context to analyze. Defaults to the current active tag.` (CLI: `--tag <name>`)
381:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
382: *   **Usage:** Used before breaking down tasks to identify which ones need the most attention.
383: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. Please inform users to hang tight while the operation is in progress.
384: 
385: ### 23. View Complexity Report (`complexity_report`)
386: 
387: *   **MCP Tool:** `complexity_report`
388: *   **CLI Command:** `task-master complexity-report [options]`
389: *   **Description:** `Display the task complexity analysis report in a readable format.`
390: *   **Key Parameters/Options:**
391:     *   `tag`: `Specify which tag context to show the report for. Defaults to the current active tag.` (CLI: `--tag <name>`)
392:     *   `file`: `Path to the complexity report (default: '.taskmaster/reports/task-complexity-report.json').` (CLI: `-f, --file <file>`)
393: *   **Usage:** Review and understand the complexity analysis results after running analyze-complexity.
394: 
395: ---
396: 
397: ## File Management
398: 
399: ### 24. Generate Task Files (`generate`)
400: 
401: *   **MCP Tool:** `generate`
402: *   **CLI Command:** `task-master generate [options]`
403: *   **Description:** `Create or update individual Markdown files for each task based on your tasks.json.`
404: *   **Key Parameters/Options:**
405:     *   `output`: `The directory where Taskmaster should save the task files (default: in a 'tasks' directory).` (CLI: `-o, --output <directory>`)
406:     *   `tag`: `Specify which tag context to generate files for. Defaults to the current active tag.` (CLI: `--tag <name>`)
407:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
408: *   **Usage:** Run this after making changes to tasks.json to keep individual task files up to date. This command is now manual and no longer runs automatically.
409: 
410: ---
411: 
412: ## AI-Powered Research
413: 
414: ### 25. Research (`research`)
415: 
416: *   **MCP Tool:** `research`
417: *   **CLI Command:** `task-master research [options]`
418: *   **Description:** `Perform AI-powered research queries with project context to get fresh, up-to-date information beyond the AI's knowledge cutoff.`
419: *   **Key Parameters/Options:**
420:     *   `query`: `Required. Research query/prompt (e.g., "What are the latest best practices for React Query v5?").` (CLI: `[query]` positional or `-q, --query <text>`)
421:     *   `taskIds`: `Comma-separated list of task/subtask IDs from the current tag context (e.g., "15,16.2,17").` (CLI: `-i, --id <ids>`)
422:     *   `filePaths`: `Comma-separated list of file paths for context (e.g., "src/api.js,docs/readme.md").` (CLI: `-f, --files <paths>`)
423:     *   `customContext`: `Additional custom context text to include in the research.` (CLI: `-c, --context <text>`)
424:     *   `includeProjectTree`: `Include project file tree structure in context (default: false).` (CLI: `--tree`)
425:     *   `detailLevel`: `Detail level for the research response: 'low', 'medium', 'high' (default: medium).` (CLI: `--detail <level>`)
426:     *   `saveTo`: `Task or subtask ID (e.g., "15", "15.2") to automatically save the research conversation to.` (CLI: `--save-to <id>`)
427:     *   `saveFile`: `If true, saves the research conversation to a markdown file in '.taskmaster/docs/research/'.` (CLI: `--save-file`)
428:     *   `noFollowup`: `Disables the interactive follow-up question menu in the CLI.` (CLI: `--no-followup`)
429:     *   `tag`: `Specify which tag context to use for task-based context gathering. Defaults to the current active tag.` (CLI: `--tag <name>`)
430:     *   `projectRoot`: `The directory of the project. Must be an absolute path.` (CLI: Determined automatically)
431: *   **Usage:** **This is a POWERFUL tool that agents should use FREQUENTLY** to:
432:     *   Get fresh information beyond knowledge cutoff dates
433:     *   Research latest best practices, library updates, security patches
434:     *   Find implementation examples for specific technologies
435:     *   Validate approaches against current industry standards
436:     *   Get contextual advice based on project files and tasks
437: *   **When to Consider Using Research:**
438:     *   **Before implementing any task** - Research current best practices
439:     *   **When encountering new technologies** - Get up-to-date implementation guidance (libraries, apis, etc)
440:     *   **For security-related tasks** - Find latest security recommendations
441:     *   **When updating dependencies** - Research breaking changes and migration guides
442:     *   **For performance optimization** - Get current performance best practices
443:     *   **When debugging complex issues** - Research known solutions and workarounds
444: *   **Research + Action Pattern:**
445:     *   Use `research` to gather fresh information
446:     *   Use `update_subtask` to commit findings with timestamps
447:     *   Use `update_task` to incorporate research into task details
448:     *   Use `add_task` with research flag for informed task creation
449: *   **Important:** This MCP tool makes AI calls and can take up to a minute to complete. The research provides FRESH data beyond the AI's training cutoff, making it invaluable for current best practices and recent developments.
450: 
451: ---
452: 
453: ## Tag Management
454: 
455: This new suite of commands allows you to manage different task contexts (tags).
456: 
457: ### 26. List Tags (`tags`)
458: 
459: *   **MCP Tool:** `list_tags`
460: *   **CLI Command:** `task-master tags [options]`
461: *   **Description:** `List all available tags with task counts, completion status, and other metadata.`
462: *   **Key Parameters/Options:**
463:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
464:     *   `--show-metadata`: `Include detailed metadata in the output (e.g., creation date, description).` (CLI: `--show-metadata`)
465: 
466: ### 27. Add Tag (`add_tag`)
467: 
468: *   **MCP Tool:** `add_tag`
469: *   **CLI Command:** `task-master add-tag <tagName> [options]`
470: *   **Description:** `Create a new, empty tag context, or copy tasks from another tag.`
471: *   **Key Parameters/Options:**
472:     *   `tagName`: `Name of the new tag to create (alphanumeric, hyphens, underscores).` (CLI: `<tagName>` positional)
473:     *   `--from-branch`: `Creates a tag with a name derived from the current git branch, ignoring the <tagName> argument.` (CLI: `--from-branch`)
474:     *   `--copy-from-current`: `Copy tasks from the currently active tag to the new tag.` (CLI: `--copy-from-current`)
475:     *   `--copy-from <tag>`: `Copy tasks from a specific source tag to the new tag.` (CLI: `--copy-from <tag>`)
476:     *   `--description <text>`: `Provide an optional description for the new tag.` (CLI: `-d, --description <text>`)
477:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
478: 
479: ### 28. Delete Tag (`delete_tag`)
480: 
481: *   **MCP Tool:** `delete_tag`
482: *   **CLI Command:** `task-master delete-tag <tagName> [options]`
483: *   **Description:** `Permanently delete a tag and all of its associated tasks.`
484: *   **Key Parameters/Options:**
485:     *   `tagName`: `Name of the tag to delete.` (CLI: `<tagName>` positional)
486:     *   `--yes`: `Skip the confirmation prompt.` (CLI: `-y, --yes`)
487:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
488: 
489: ### 29. Use Tag (`use_tag`)
490: 
491: *   **MCP Tool:** `use_tag`
492: *   **CLI Command:** `task-master use-tag <tagName>`
493: *   **Description:** `Switch your active task context to a different tag.`
494: *   **Key Parameters/Options:**
495:     *   `tagName`: `Name of the tag to switch to.` (CLI: `<tagName>` positional)
496:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
497: 
498: ### 30. Rename Tag (`rename_tag`)
499: 
500: *   **MCP Tool:** `rename_tag`
501: *   **CLI Command:** `task-master rename-tag <oldName> <newName>`
502: *   **Description:** `Rename an existing tag.`
503: *   **Key Parameters/Options:**
504:     *   `oldName`: `The current name of the tag.` (CLI: `<oldName>` positional)
505:     *   `newName`: `The new name for the tag.` (CLI: `<newName>` positional)
506:     *   `file`: `Path to your Taskmaster 'tasks.json' file. Default relies on auto-detection.` (CLI: `-f, --file <file>`)
507: 
508: ### 31. Copy Tag (`copy_tag`)
509: 
510: *   **MCP Tool:** `copy_tag`
511: *   **CLI Command:** `task-master copy-tag <sourceName> <targetName> [options]`
512: *   **Description:** `Copy an entire tag context, including all its tasks and metadata, to a new tag.`
513: *   **Key Parameters/Options:**
514:     *   `sourceName`: `Name of the tag to copy from.` (CLI: `<sourceName>` positional)
515:     *   `targetName`: `Name of the new tag to create.` (CLI: `<targetName>` positional)
516:     *   `--description <text>`: `Optional description for the new tag.` (CLI: `-d, --description <text>`)
517: 
518: ---
519: 
520: ## Miscellaneous
521: 
522: ### 32. Sync Readme (`sync-readme`) -- experimental
523: 
524: *   **MCP Tool:** N/A
525: *   **CLI Command:** `task-master sync-readme [options]`
526: *   **Description:** `Exports your task list to your project's README.md file, useful for showcasing progress.`
527: *   **Key Parameters/Options:**
528:     *   `status`: `Filter tasks by status (e.g., 'pending', 'done').` (CLI: `-s, --status <status>`)
529:     *   `withSubtasks`: `Include subtasks in the export.` (CLI: `--with-subtasks`)
530:     *   `tag`: `Specify which tag context to export from. Defaults to the current active tag.` (CLI: `--tag <name>`)
531: 
532: ---
533: 
534: ## Environment Variables Configuration (Updated)
535: 
536: Taskmaster primarily uses the **`.taskmaster/config.json`** file (in project root) for configuration (models, parameters, logging level, etc.), managed via `task-master models --setup`.
537: 
538: Environment variables are used **only** for sensitive API keys related to AI providers and specific overrides like the Ollama base URL:
539: 
540: *   **API Keys (Required for corresponding provider):**
541:     *   `ANTHROPIC_API_KEY`
542:     *   `PERPLEXITY_API_KEY`
543:     *   `OPENAI_API_KEY`
544:     *   `GOOGLE_API_KEY`
545:     *   `MISTRAL_API_KEY`
546:     *   `AZURE_OPENAI_API_KEY` (Requires `AZURE_OPENAI_ENDPOINT` too)
547:     *   `OPENROUTER_API_KEY`
548:     *   `XAI_API_KEY`
549:     *   `OLLAMA_API_KEY` (Requires `OLLAMA_BASE_URL` too)
550: *   **Endpoints (Optional/Provider Specific inside .taskmaster/config.json):**
551:     *   `AZURE_OPENAI_ENDPOINT`
552:     *   `OLLAMA_BASE_URL` (Default: `http://localhost:11434/api`)
553: 
554: **Set API keys** in your **`.env`** file in the project root (for CLI use) or within the `env` section of your **`.windsurf/mcp.json`** file (for MCP/Windsurf integration). All other settings (model choice, max tokens, temperature, log level, custom endpoints) are managed in `.taskmaster/config.json` via `task-master models` command or `models` MCP tool.
555: 
556: ---
557: 
558: For details on how these commands fit into the development process, see the [dev_workflow.md](.windsurf/rules/dev_workflow.md).
</file>

<file path=".windsurf/rules/windsurf_rules.md">
 1: ---
 2: description: Guidelines for creating and maintaining Windsurf rules to ensure consistency and effectiveness.
 3: globs: .windsurf/rules/*.md
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Required Rule Structure:**
 8:   ```markdown
 9:   ---
10:   description: Clear, one-line description of what the rule enforces
11:   globs: path/to/files/*.ext, other/path/**/*
12:   alwaysApply: boolean
13:   ---
14: 
15:   - **Main Points in Bold**
16:     - Sub-points with details
17:     - Examples and explanations
18:   ```
19: 
20: - **File References:**
21:   - Use `[filename](mdc:path/to/file)` ([filename](mdc:filename)) to reference files
22:   - Example: [prisma.md](.windsurf/rules/prisma.md) for rule references
23:   - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references
24: 
25: - **Code Examples:**
26:   - Use language-specific code blocks
27:   ```typescript
28:   // ✅ DO: Show good examples
29:   const goodExample = true;
30:   
31:   // ❌ DON'T: Show anti-patterns
32:   const badExample = false;
33:   ```
34: 
35: - **Rule Content Guidelines:**
36:   - Start with high-level overview
37:   - Include specific, actionable requirements
38:   - Show examples of correct implementation
39:   - Reference existing code when possible
40:   - Keep rules DRY by referencing other rules
41: 
42: - **Rule Maintenance:**
43:   - Update rules when new patterns emerge
44:   - Add examples from actual codebase
45:   - Remove outdated patterns
46:   - Cross-reference related rules
47: 
48: - **Best Practices:**
49:   - Use bullet points for clarity
50:   - Keep descriptions concise
51:   - Include both DO and DON'T examples
52:   - Reference actual code over theoretical examples
53:   - Use consistent formatting across rules
</file>

<file path=".windsurf/mcp.json">
 1: {
 2: 	"mcpServers": {
 3: 		"task-master-ai": {
 4: 			"command": "npx",
 5: 			"args": ["-y", "--package=task-master-ai", "task-master-ai"],
 6: 			"env": {
 7: 				"ANTHROPIC_API_KEY": "ANTHROPIC_API_KEY_HERE",
 8: 				"PERPLEXITY_API_KEY": "PERPLEXITY_API_KEY_HERE",
 9: 				"OPENAI_API_KEY": "OPENAI_API_KEY_HERE",
10: 				"GOOGLE_API_KEY": "GOOGLE_API_KEY_HERE",
11: 				"XAI_API_KEY": "XAI_API_KEY_HERE",
12: 				"OPENROUTER_API_KEY": "OPENROUTER_API_KEY_HERE",
13: 				"MISTRAL_API_KEY": "MISTRAL_API_KEY_HERE",
14: 				"AZURE_OPENAI_API_KEY": "AZURE_OPENAI_API_KEY_HERE",
15: 				"OLLAMA_API_KEY": "OLLAMA_API_KEY_HERE"
16: 			}
17: 		}
18: 	}
19: }
</file>

<file path="llm_context/llm_agent_insights/code_documentation_standards.md">
  1: # Code Documentation Standards (JSDoc/TSDoc)
  2: 
  3: This document outlines the standards for code documentation within this project, leveraging JSDoc/TSDoc for TypeScript files. Adhering to these guidelines ensures consistency, clarity, and maintainability of our codebase, facilitating automated documentation generation and improving developer experience.
  4: 
  5: ## General Principles
  6: 
  7: *   **Clarity and Conciseness**: Documentation should be easy to understand and to the point. Avoid jargon where simpler terms suffice.
  8: *   **Accuracy**: Documentation must accurately reflect the code's current behavior. Update documentation whenever code changes.
  9: *   **Completeness**: All public APIs (functions, classes, interfaces, types, constants) and critical internal logic should be documented.
 10: *   **Consistency**: Follow the specified formatting and style guidelines throughout the codebase.
 11: 
 12: ## JSDoc/TSDoc Tags and Usage
 13: 
 14: Use the following JSDoc/TSDoc tags for comprehensive documentation:
 15: 
 16: ### 1. `@description` (or plain text at the beginning)
 17: *   **Purpose**: Provides a concise summary of the code element's purpose.
 18: *   **Placement**: At the beginning of the JSDoc block.
 19: *   **Example**:
 20:     ```typescript
 21:     /**
 22:      * @description Calculates the sum of two numbers.
 23:      * @param a - The first number.
 24:      * @param b - The second number.
 25:      * @returns The sum of a and b.
 26:      */
 27:     function add(a: number, b: number): number {
 28:       return a + b;
 29:     }
 30:     ```
 31: 
 32: ### 2. `@param {Type} name - Description`
 33: *   **Purpose**: Describes a function parameter.
 34: *   **`{Type}`**: The TypeScript type of the parameter (e.g., `{string}`, `{number[]}`, `{User}`).
 35: *   **`name`**: The name of the parameter.
 36: *   **Description**: A brief explanation of the parameter's role.
 37: *   **Example**: (See `add` function example above)
 38: 
 39: ### 3. `@returns {Type} - Description`
 40: *   **Purpose**: Describes the return value of a function.
 41: *   **`{Type}`**: The TypeScript type of the return value.
 42: *   **Description**: A brief explanation of what the function returns.
 43: *   **Example**: (See `add` function example above)
 44: 
 45: ### 4. `@example`
 46: *   **Purpose**: Provides a code example demonstrating how to use the documented element.
 47: *   **Placement**: After `@param` and `@returns` tags.
 48: *   **Example**:
 49:     ```typescript
 50:     /**
 51:      * @description Fetches user data from the API.
 52:      * @param userId - The ID of the user to fetch.
 53:      * @returns A Promise that resolves to the user data.
 54:      * @example
 55:      * ```typescript
 56:      * const user = await fetchUser(123);
 57:      * console.log(user.name);
 58:      * ```
 59:      */
 60:     async function fetchUser(userId: string): Promise<User> {
 61:       // ... implementation
 62:     }
 63:     ```
 64: 
 65: ### 5. `@typedef` and `@property`
 66: *   **Purpose**: Documents complex object types or interfaces that are not explicitly defined as `interface` or `type` but are used in parameters or return values.
 67: *   **Example**:
 68:     ```typescript
 69:     /**
 70:      * @typedef {object} UserProfile
 71:      * @property {string} id - The user's unique ID.
 72:      * @property {string} name - The user's full name.
 73:      * @property {string[]} roles - An array of roles assigned to the user.
 74:      */
 75: 
 76:     /**
 77:      * @description Creates a new user profile.
 78:      * @param {UserProfile} profileData - The data for the new user profile.
 79:      * @returns {UserProfile} The created user profile.
 80:      */
 81:     function createUser(profileData: UserProfile): UserProfile {
 82:       // ... implementation
 83:     }
 84:     ```
 85: 
 86: ### 6. `@deprecated`
 87: *   **Purpose**: Indicates that a function, class, or property is no longer recommended for use and may be removed in future versions.
 88: *   **Example**:
 89:     ```typescript
 90:     /**
 91:      * @description This function is deprecated. Use `newFunction` instead.
 92:      * @deprecated
 93:      */
 94:     function oldFunction() {
 95:       // ...
 96:     }
 97:     ```
 98: 
 99: ### 7. `@see`
100: *   **Purpose**: Refers to other related documentation or resources.
101: *   **Example**:
102:     ```typescript
103:     /**
104:      * @description Handles user authentication.
105:      * @see {@link https://example.com/auth-docs} for more details.
106:      * @see {@link User}
107:      */
108:     function authenticateUser() {
109:       // ...
110:     }
111:     ```
112: 
113: ### 8. `@ignore`
114: *   **Purpose**: Excludes a code element from the generated documentation. Use sparingly.
115: 
116: ## Formatting and Style
117: 
118: *   **Block Comments**: Use `/** ... */` for JSDoc/TSDoc blocks.
119: *   **Inline Comments**: Use `//` for short, single-line explanations within code blocks. Explain *why* something is done, not *what* is done (unless the "what" is complex).
120: *   **Indentation**: Match the indentation of the code it documents.
121: *   **Line Breaks**: Use line breaks to improve readability within long descriptions.
122: *   **Code Snippets**: Use Markdown code blocks (```typescript ... ```) within `@example` tags.
123: 
124: ## Coverage Requirements
125: 
126: *   **Functions/Methods**: Every function and method (public and private, unless trivial) must have a JSDoc/TSDoc block.
127: *   **Classes/Interfaces/Types**: Every class, interface, and type definition must have a JSDoc/TSDoc block.
128: *   **Module/File Headers**: Each file should ideally start with a brief description of its purpose.
129: *   **Constants/Variables**: Document important constants or variables, especially if their purpose isn't immediately obvious.
130: 
131: By following these standards, we aim to create a self-documenting codebase that is easy to understand, maintain, and extend.
</file>

<file path="llm_context/llm_agent_insights/README.md">
 1: # LLM Agent Insights
 2: 
 3: ## Agent Behavior Patterns
 4: - [x] Context window management strategies - Use sliding window and summarization techniques[1][3]
 5: - [x] Token optimization techniques - Prioritize critical information and structure it first[1][5]
 6: - [x] Multi-turn conversation patterns - Implement stateful conversation tracking[1][4]
 7: - [x] Error recovery strategies - Use fallback mechanisms and context-aware retries[1][5]
 8: - [x] Task decomposition approaches - Break complex tasks into atomic steps[1][5]
 9: 
10: ## Code Generation Best Practices
11: - [x] Incremental development patterns - Implement step-by-step implementation[1][3]
12: - [x] Code review and validation strategies - Use automated testing and peer review[1][5]
13: - [x] Testing integration workflows - Add tests for each generated component[1][4]
14: - [x] Documentation generation patterns - Generate inline documentation with context[1][2]
15: - [x] Refactoring approaches - Use automated refactoring tools[1][5]
16: 
17: ## Project-Specific Considerations
18: - [x] Payload 3 collection understanding - Map collections to context schemas[1][3]
19: - [x] Next.js app router navigation - Implement route-aware context[1][2]
20: - [x] TypeScript type inference - Use type annotations in prompts[1][4]
21: - [x] Database schema awareness - Integrate ORM definitions[1][5]
22: - [x] API endpoint patterns - Document endpoint structures[1][3]
23: 
24: ## Collaboration Patterns
25: - [x] Human-agent handoff strategies - Implement clear handoff points[1][4]
26: - [x] Code explanation techniques - Generate inline comments and documentation[1][2]
27: - [x] Progress tracking methods - Use task status reporting[1][5]
28: - [x] Decision documentation - Maintain decision logs[1][3]
29: - [x] Knowledge transfer patterns - Create knowledge base articles[1][4]
30: 
31: ## Performance Optimization
32: - [x] Response time optimization - Implement caching and parallel processing[1][5]
33: - [x] Context relevance scoring - Use TF-IDF and semantic similarity[1][4]
34: - [x] Tool selection strategies - Implement cost-benefit analysis[1][3]
35: - [x] Parallel processing patterns - Use async task execution[1][5]
36: - [x] Caching mechanisms - Implement LRU caching[1][2]
37: 
38: ## Best Practices
39: 1. **Context Management** - Use hybrid CAG + RAG approaches[1][5]
40: 2. **Task Execution** - Break tasks into atomic operations[1][5]
41: 3. **Validation** - Implement multi-step verification[1][2]
42: 4. **Documentation** - Generate context-aware docs[1][3]
43: 5. **Security** - Sanitize all inputs and outputs[1][5]
44: 
45: ```typescript
46: // Example task decomposition
47: const task = {
48:   id: 'refactor-component',
49:   steps: [
50:     'Analyze current implementation',
51:     'Identify refactoring opportunities',
52:     'Implement atomic changes',
53:     'Verify functionality',
54:     'Update documentation'
55:   ]
56: };
57: ```
58: 
59: ## Files to Create
60: - `context_management.md` - Context window optimization
61: - `code_generation_patterns.md` - Effective code generation
62: - `project_understanding.md` - Project-specific insights
63: - `collaboration_strategies.md` - Human-agent collaboration
64: - `performance_optimization.md` - Agent performance tuning
</file>

<file path="llm_context/mcp_tools/context7_advanced.md">
 1: # Context7 Advanced Usage
 2: 
 3: ## Dynamic Documentation Retrieval
 4: - [x] Library ID resolution strategies - Use enum-based approaches and dynamic schema adaptation[1][3]
 5: - [x] Topic-focused documentation queries - Implement with targeted search parameters[1][2]
 6: - [x] Token optimization for large docs - Use summarization and key point extraction[1][5]
 7: - [x] Multi-library integration patterns - Implement with chained context requests[1][4]
 8: - [x] Version-specific documentation - Specify exact package versions in requests[1][2]
 9: 
10: ```typescript
11: // Version-specific query example
12: const response = await fetch('https://context7-mcp.example.com/docs', {
13:   method: 'POST',
14:   headers: { 'Content-Type': 'application/json' },
15:   body: JSON.stringify({
16:     library: 'nextjs',
17:     version: '14.2.3',
18:     query: 'app router implementation'
19:   })
20: });
21: ```
22: 
23: ## Integration Patterns
24: - [x] Automated documentation updates - Implement webhook-based sync[1][3]
25: - [x] Context injection workflows - Use middleware for seamless integration[1][5]
26: - [x] Real-time documentation sync - Implement with SSE (Server-Sent Events)[1]
27: - [x] Custom library indexing - Extend with custom documentation sources[1][4]
28: - [x] Documentation caching strategies - Implement TTL-based caching[1][5]
29: 
30: ## Workflow Optimization
31: - [x] Context window management - Use sliding window technique[3][5]
32: - [x] Selective documentation loading - Implement relevance scoring[1][3]
33: - [x] Documentation relevance scoring - Use TF-IDF and semantic similarity[1][5]
34: - [x] Multi-step research patterns - Chain context requests for complex queries[1][4]
35: - [x] Documentation validation - Implement checksum verification[1]
36: 
37: ## Project-Specific Usage
38: - [x] Payload 3 documentation integration - Map collection schemas to context[1][3]
39: - [x] Next.js best practices retrieval - Use version-specific queries[1][2]
40: - [x] React patterns documentation - Implement component-focused queries[1]
41: - [x] TypeScript reference integration - Add type definition support[1][4]
42: - [x] UI library documentation - Integrate Shadcn UI references[1]
43: 
44: ## Implementation Strategies
45: 1. **Installation** - Use npm package `@upstash/context7`[2][5]
46: 2. **Configuration** - Set default libraries and versions[1][4]
47: 3. **Query Optimization** - Use specific keywords for better results[1][2]
48: 4. **Error Handling** - Implement fallback to generic docs[1][5]
49: 5. **Rate Limiting** - Use exponential backoff for retries[1][5]
50: 
51: ```bash
52: # Installation command
53: npm install @upstash/context7
54: ```
55: 
56: ## Best Practices
57: - Always specify library versions to avoid outdated docs[1][2]
58: - Use `use context7` directive in your queries[1][3]
59: - Combine with other MCP tools for enhanced capabilities[1][4]
60: - Monitor token usage for cost optimization[1][5]
61: - Verify critical code snippets before implementation[1][2]
</file>

<file path="llm_context/mcp_tools/README.md">
 1: # MCP Tools Integration
 2: 
 3: ## Core MCP Tools
 4: - [x] Context7 documentation retrieval patterns - Implement with selective subscriptions[1]
 5: - [x] Taskmaster project management integration - Use Zustand for task state management[1][3]
 6: - [x] Puppeteer browser automation workflows - Combine with Zustand for UI state[1][5]
 7: - [x] Supabase database operations - Implement with computed state patterns[1]
 8: - [x] Brave Search API integration - Use middleware for rate limiting[5]
 9: 
10: ## Development Workflow Tools
11: - [x] Magic-UI component generation - Implement with Zustand store slices[1]
12: - [x] Gemini CLI context optimization - Use computed state for derived values[1]
13: - [x] Repomix code context generation - Implement with selective store loading[1]
14: - [x] Browser tools for debugging - Use devtools middleware for state inspection[2][5]
15: - [x] Directus CMS integration - Model as events rather than setters[3]
16: 
17: ## Automation Patterns
18: - [x] CI/CD integration with MCP tools - Implement with async actions[4]
19: - [x] Automated testing workflows - Use mock store creation for tests[5]
20: - [x] Code generation pipelines - Implement with event-based actions[3]
21: - [x] Documentation generation - Use computed state for dynamic docs[1]
22: - [x] Performance monitoring - Implement with middleware logging[2][5]
23: 
24: ## Integration Strategies
25: - [x] Tool chaining patterns - Use Zustand for cross-tool state[1]
26: - [x] Error handling across tools - Implement with async action patterns[4]
27: - [x] Authentication management - Use Payload's auth flow with Zustand[3]
28: - [x] Rate limiting strategies - Implement with middleware[5]
29: - [x] Caching mechanisms - Use persist middleware with TTL[2]
30: 
31: ## Zustand Best Practices for MCP
32: 1. **Store Organization** - Create separate stores for distinct concerns[1]
33: 2. **Selective Subscriptions** - Subscribe only to needed state slices[1]
34: 3. **Computed State** - Derive values rather than recomputing[1]
35: 4. **Middleware Caution** - Align with application requirements[1]
36: 5. **Event Modeling** - Model actions as events, not setters[3]
37: 
38: ```typescript
39: // MCP tool integration example
40: import { create } from 'zustand';
41: import { devtools, persist } from 'zustand/middleware';
42: 
43: const useMCPStore = create(
44:   devtools(
45:     persist(
46:       (set) => ({
47:         tools: [],
48:         addTool: (tool) => set((state) => ({ tools: [...state.tools, tool] })),
49:         removeTool: (id) => set((state) => ({ 
50:           tools: state.tools.filter(t => t.id !== id) 
51:         })),
52:       }),
53:       { name: 'mcp-tools-store' }
54:     )
55:   )
56: );
57: ```
58: 
59: ## Files to Create
60: - `context7_advanced.md` - Advanced Context7 usage patterns
61: - `taskmaster_workflows.md` - Project management workflows
62: - `gemini_cli_optimization.md` - Context window optimization
63: - `repomix_automation.md` - Code context automation
64: - `tool_integration_patterns.md` - Cross-tool integration
</file>

<file path="llm_context/mcp_tools/repomix_automation.md">
 1: # Repomix Code Context Automation
 2: 
 3: ## Automated Context Generation
 4: - [x] File selection strategies - Use concise prompts and retrieve verified functions/APIs[1][3]
 5: - [x] Context filtering patterns - Incorporate project-specific conventions[1][4]
 6: - [x] Output format optimization - Use Context7 structured documentation[1][2]
 7: - [x] Integration with CI/CD - Pre-commit hooks with CI/CD pipelines[1][5]
 8: - [x] Selective code inclusion - Include verified snippets and APIs[1][3]
 9: 
10: ## Workflow Integration
11: - [x] Gemini CLI integration - Requires project-specific details
12: - [x] Pre-commit hook setup - Enforce code quality in CI/CD[1][5]
13: - [x] Automated documentation updates - Context7 dynamic fetching[1][2]
14: - [x] Context validation workflows - Requires workflow understanding
15: - [x] Multi-project support - Requires project-specific details
16: 
17: ## Optimization Strategies
18: - [x] Large codebase handling - Implement hierarchical context loading[1][3]
19: - [x] Context relevance scoring - Use TF-IDF and semantic similarity[1][4]
20: - [x] Incremental context updates - Implement change detection[1][5]
21: - [x] Performance optimization - Use caching and parallel processing[1][2]
22: - [x] Memory usage management - Implement LRU caching[1][5]
23: 
24: ## Project-Specific Patterns
25: - [x] Payload collection context - Map collection schemas to context[1][3]
26: - [x] Next.js app structure context - Use version-specific queries[1][2]
27: - [x] Component dependency mapping - Implement with AST analysis[1][4]
28: - [x] API endpoint documentation - Generate from route handlers[1][3]
29: - [x] Database schema context - Integrate with ORM definitions[1][5]
30: 
31: ## Implementation Goals
32: - [x] Automated context pipeline - Set up with GitHub Actions[1][5]
33: - [x] Smart file filtering - Use path patterns and relevance scoring[1][4]
34: - [x] Context quality metrics - Implement precision/recall tracking[1][3]
35: - [x] Integration testing - Add to CI/CD pipeline[1][5]
36: - [x] Performance monitoring - Track token usage and latency[1][2]
37: 
38: ## Best Practices
39: 1. **Installation** - Use npm package `@upstash/repomix`[1][2]
40: ```bash
41: npm install @upstash/repomix
42: ```
43: 2. **Configuration** - Set context sources and priorities[1][4]
44: ```json
45: {
46:   "sources": [
47:     { "type": "payload", "priority": 1 },
48:     { "type": "nextjs", "priority": 2 }
49:   ],
50:   "maxTokens": 4000,
51:   "refreshInterval": "1h"
52: }
53: ```
54: 3. **Query Optimization** - Use specific keywords for better results[1][2]
55: 4. **Error Handling** - Implement fallback strategies[1][5]
56: 5. **Version Control** - Sync with repository branches[1][3]
57: 
58: ## Context7 Integration
59: - Use `use context7` directive in prompts[1][2]
60: - Specify library versions to avoid outdated docs[1][3]
61: - Combine with other MCP tools for enhanced capabilities[1][4]
62: - Monitor token usage for cost optimization[1][5]
63: - Verify critical code snippets before implementation[1][2]
</file>

<file path="llm_context/payload3/data_models.md">
  1: # Payload 3.0 Data Models and Relationships
  2: 
  3: This document outlines the data models and their relationships within the Payload CMS, designed for a restaurant or similar business management system. It highlights key fields, relationships, and notes on Payload 3.0 features, including the Lexical WYSIWYG editor.
  4: 
  5: ## Collections Overview
  6: 
  7: ### 1. `Users`
  8: *   **Slug**: `users`
  9: *   **Purpose**: Manages user accounts, authentication, and authorization.
 10: *   **Key Fields**: `email` (default), `first_name`, `last_name`, `phone`, `employee_id`, `roles` (select, hasMany), `status` (select), `locations` (relationship to `locations`, hasMany), `primary_location` (relationship to `locations`), `employment_details` (group), `profile_photo` (relationship to `media`), `jobs` (relationship to `jobs`, hasMany).
 11: *   **Relationships**:
 12:     *   One-to-many with `Locations` (via `locations` and `primary_location`)
 13:     *   One-to-many with `Jobs` (via `jobs`)
 14:     *   One-to-one with `Media` (via `profile_photo`)
 15: *   **Payload 3.0 Notes**: Leverages Payload's built-in authentication (`auth: true`). The `roles` field is critical for Role-Based Access Control (RBAC).
 16: 
 17: ### 2. `Media`
 18: *   **Slug**: `media`
 19: *   **Purpose**: Handles file uploads (images, PDFs, videos).
 20: *   **Key Fields**: `alt` (text), `caption` (textarea), `uploadedBy` (relationship to `users`).
 21: *   **Configuration**: `upload: true` enables media capabilities. `imageSizes` are defined for responsive image handling.
 22: *   **Relationships**:
 23:     *   Many-to-one with `Users` (via `uploadedBy`)
 24: *   **Payload 3.0 Notes**: The `upload` property is a core feature for managing assets.
 25: 
 26: ### 3. `Contacts`
 27: *   **Slug**: `contacts`
 28: *   **Purpose**: Stores contact information for various entities (customers, vendors, contractors).
 29: *   **Key Fields**: `first_name`, `last_name`, `email`, `phone`, `company`, `contact_type`, `toast_id`, `brevo_id`, `vip_id`, `visit_frequency`, `last_visit`, `total_visits`, `average_spend`, `notes`, `marketing_consent`, `birthday`, `anniversary`.
 30: *   **Relationships**:
 31:     *   Many-to-many with `Locations` (via `associated_locations`)
 32:     *   Many-to-many with `Messages` (via `associated_messages`)
 33:     *   Many-to-one with `Locations` (via `preferred_location`)
 34: *   **Payload 3.0 Notes**: Demonstrates `beforeChange` and `afterChange` hooks for custom logic (e.g., auto-generating `vip_id`).
 35: 
 36: ### 4. `DietaryRestrictions`
 37: *   **Slug**: `dietary-restrictions`
 38: *   **Purpose**: Manages common dietary restrictions and allergies.
 39: *   **Key Fields**: `name`, `description`.
 40: *   **Relationships**: Expected to be related to `MenuItems` (not explicitly defined in provided files).
 41: 
 42: ### 5. `DrinkMenuItems`
 43: *   **Slug**: `drinkMenuItems`
 44: *   **Purpose**: Stores information about drink menu items.
 45: *   **Key Fields**: `name`, `description`, `price`, `category` (relationship to `drinkSubcategories`), `active`.
 46: *   **Relationships**:
 47:     *   Many-to-one with `DrinkSubcategories` (via `category`)
 48: 
 49: ### 6. `DrinkSubcategories`
 50: *   **Slug**: `drinkSubcategories`
 51: *   **Purpose**: Defines categories for drink menu items.
 52: *   **Key Fields**: `name`.
 53: *   **Relationships**:
 54:     *   One-to-many with `DrinkMenuItems`
 55: 
 56: ### 7. `EmployeeRatings`
 57: *   **Slug**: `employee-ratings`
 58: *   **Purpose**: Tracks employee performance ratings.
 59: *   **Key Fields**: `employee_id` (relationship to `users`), `location_id` (relationship to `locations`), `data_date`, `rating`, `manager_report_id` (relationship to `managerReports`), `employee_notes` (richText), `internal_notes` (textarea).
 60: *   **Relationships**:
 61:     *   Many-to-one with `Users` (via `employee_id`)
 62:     *   Many-to-one with `Locations` (via `location_id`)
 63:     *   Many-to-one with `ManagerReports` (via `manager_report_id`)
 64: *   **Payload 3.0 Notes**: Uses `richText` field type, powered by the Lexical WYSIWYG editor.
 65: 
 66: ### 8. `Features`
 67: *   **Slug**: `features`
 68: *   **Purpose**: Manages feature flags for the application.
 69: *   **Key Fields**: `name`, `enabled`.
 70: 
 71: ### 9. `HotspotLogins`
 72: *   **Slug**: `hotspot-logins`
 73: *   **Purpose**: Stores WiFi hotspot login data and customer information.
 74: *   **Key Fields**: `location` (relationship to `locations`), `customer_name`, `customer_email`, `marketing_consent`.
 75: *   **Relationships**:
 76:     *   Many-to-one with `Locations` (via `location`)
 77: 
 78: ### 10. `Incidents`
 79: *   **Slug**: `incidents`
 80: *   **Purpose**: Records incidents or issues.
 81: *   **Key Fields**: `title`, `description`, `date`, `location` (relationship to `locations`), `reportedBy` (relationship to `users`), `status`.
 82: *   **Relationships**:
 83:     *   Many-to-one with `Locations` (via `location`)
 84:     *   Many-to-one with `Users` (via `reportedBy`)
 85: 
 86: ### 11. `Jobs`
 87: *   **Slug**: `jobs`
 88: *   **Purpose**: Defines job roles or positions.
 89: *   **Key Fields**: `name`.
 90: *   **Relationships**:
 91:     *   One-to-many with `Users`
 92: 
 93: ### 12. `Locations`
 94: *   **Slug**: `locations`
 95: *   **Purpose**: Manages physical locations of the business.
 96: *   **Key Fields**: `name`, `address`, `city`, `state`, `zip`, `phone`, `email`.
 97: *   **Relationships**:
 98:     *   One-to-many with `Users`, `Contacts`, `HotspotLogins`, `Incidents`, `ManagerReports`, `QrFeedback`, `Reviews`, `ServerReports`, `Upgrades`, `Questions`.
 99: 
100: ### 13. `ManagerReports`
101: *   **Slug**: `managerReports`
102: *   **Purpose**: Stores daily or shift manager reports.
103: *   **Key Fields**: `title`, `date`, `manager` (relationship to `users`), `location` (relationship to `locations`), `notes`.
104: *   **Relationships**:
105:     *   Many-to-one with `Users` (via `manager`)
106:     *   Many-to-one with `Locations` (via `location`)
107:     *   One-to-many with `EmployeeRatings`
108: 
109: ### 14. `MessageTypes`
110: *   **Slug**: `message-types`
111: *   **Purpose**: Defines categories for customer messages.
112: *   **Key Fields**: `name`.
113: *   **Relationships**:
114:     *   One-to-many with `Messages`
115: 
116: ### 15. `Messages`
117: *   **Slug**: `messages`
118: *   **Purpose**: Manages customer messages and inquiries.
119: *   **Key Fields**: `status`, `priority`, `subject`, `from_name`, `from_email`, `from_phone`, `location` (relationship to `locations`), `message_type` (relationship to `message-types`), `message` (richText), `internal_notes` (richText), `assigned_to` (relationship to `users`), `response_sent`, `response_date`, `attachments` (relationship to `media`, hasMany).
120: *   **Relationships**:
121:     *   Many-to-one with `Locations` (via `location`)
122:     *   Many-to-one with `MessageTypes` (via `message_type`)
123:     *   Many-to-one with `Users` (via `assigned_to`)
124:     *   Many-to-many with `Media` (via `attachments`)
125: *   **Payload 3.0 Notes**: Uses `richText` fields for `message` and `internal_notes`, leveraging the Lexical WYSIWYG editor.
126: 
127: ### 16. `QrFeedback`
128: *   **Slug**: `qrFeedback`
129: *   **Purpose**: Collects feedback via QR codes.
130: *   **Key Fields**: `rating`, `comment`, `location` (relationship to `locations`), `user` (relationship to `users`).
131: *   **Relationships**:
132:     *   Many-to-one with `Locations` (via `location`)
133:     *   Many-to-one with `Users` (via `user`)
134: 
135: ### 17. `Questions`
136: *   **Slug**: `questions`
137: *   **Purpose**: Manages custom questions for reports.
138: *   **Key Fields**: `status`, `sort`, `question`, `shift_timing`, `shift_selection` (hasMany), `min_characters`, `locations` (relationship to `locations`, hasMany).
139: *   **Relationships**:
140:     *   Many-to-many with `Locations` (via `locations`)
141: 
142: ### 18. `ReviewKeywords`
143: *   **Slug**: `reviewKeywords`
144: *   **Purpose**: Defines keywords for reviews.
145: *   **Key Fields**: `keyword`.
146: *   **Relationships**:
147:     *   One-to-many with `Reviews`
148: 
149: ### 19. `Reviews`
150: *   **Slug**: `reviews`
151: *   **Purpose**: Stores customer reviews.
152: *   **Key Fields**: `title`, `rating`, `comment`, `user` (relationship to `users`), `location` (relationship to `locations`), `keywords` (relationship to `reviewKeywords`, hasMany).
153: *   **Relationships**:
154:     *   Many-to-one with `Users` (via `user`)
155:     *   Many-to-one with `Locations` (via `location`)
156:     *   Many-to-many with `ReviewKeywords` (via `keywords`)
157: 
158: ### 20. `ServerReports`
159: *   **Slug**: `serverReports`
160: *   **Purpose**: Stores server reports.
161: *   **Key Fields**: `title`, `date`, `server` (relationship to `users`), `location` (relationship to `locations`), `notes`.
162: *   **Relationships**:
163:     *   Many-to-one with `Users` (via `server`)
164:     *   Many-to-one with `Locations` (via `location`)
165: 
166: ### 21. `ShiftTypes`
167: *   **Slug**: `shiftTypes`
168: *   **Purpose**: Defines types of shifts.
169: *   **Key Fields**: `name`.
170: 
171: ### 22. `UpgradeTypes`
172: *   **Slug**: `upgrade-types`
173: *   **Purpose**: Defines categories for upgrades.
174: *   **Key Fields**: `name`.
175: *   **Relationships**:
176:     *   One-to-many with `Upgrades`
177: 
178: ### 23. `Upgrades`
179: *   **Slug**: `upgrades`
180: *   **Purpose**: Tracks system and facility upgrades.
181: *   **Key Fields**: `name`, `location` (relationship to `locations`), `upgrade_type` (relationship to `upgrade-types`), `status`, `description` (richText), `cost`, `vendor` (relationship to `contacts`), `scheduled_date`, `completion_date`, `notes` (richText), `attachments` (relationship to `media`, hasMany).
182: *   **Relationships**:
183:     *   Many-to-one with `Locations` (via `location`)
184:     *   Many-to-one with `UpgradeTypes` (via `upgrade_type`)
185:     *   Many-to-one with `Contacts` (via `vendor`)
186:     *   Many-to-many with `Media` (via `attachments`)
187: *   **Payload 3.0 Notes**: Uses `richText` fields for `description` and `notes`, leveraging the Lexical WYSIWYG editor.
188: 
189: ## Lexical WYSIWYG Editor in Payload 3.0
190: 
191: Payload 3.0 integrates the Lexical WYSIWYG editor for `richText` fields, offering a modern and extensible content editing experience. Key benefits include:
192: 
193: *   **Performance**: Designed for high performance and responsiveness.
194: *   **Extensibility**: Highly customizable with a plugin-based architecture, allowing for tailored editing features.
195: *   **Accessibility**: Built with accessibility in mind.
196: *   **Collaboration**: Supports collaborative editing features.
197: 
198: Developers can configure Lexical to include various formatting options, embeds, and custom elements, providing a powerful tool for content creators within the Payload admin panel.
</file>

<file path="llm_context/payload3/README.md">
 1: # Payload 3 CMS Documentation
 2: 
 3: ## Core Concepts
 4: - **Data Modeling**: Collections define data structures (e.g., `Users`, `Media`)
 5: - **Lexical Editor**: Rich text editor with block-based content
 6: - **Authentication**: Built-in user auth with access control
 7: - **REST & GraphQL**: Dual API endpoints
 8: 
 9: ## Best Practices
10: ```typescript
11: // Example collection configuration
12: export const Media: CollectionConfig = {
13:   slug: 'media',
14:   access: { read: () => true },
15:   upload: true,
16:   fields: [{ name: 'alt', type: 'text', required: true }]
17: }
18: ```
19: 
20: ## Data Loading Patterns
21: ```typescript
22: // Next.js data fetching with Tanstack Query
23: import { useQuery } from '@tanstack/react-query';
24: 
25: const fetchMedia = async () => {
26:   const res = await fetch('/api/media');
27:   return res.json();
28: };
29: 
30: function MediaGallery() {
31:   const { data } = useQuery({ queryKey: ['media'], queryFn: fetchMedia });
32:   // Render media items
33: }
</file>

<file path="llm_context/payload3/user_documentation.md">
 1: # User Guide: Payload CMS Data Management
 2: 
 3: This guide provides an overview of the data collections within the Payload CMS, explaining their purpose and how you can use them to manage your business operations. We'll also highlight key features like the rich text editor.
 4: 
 5: ## Understanding Your Data Collections
 6: 
 7: Payload CMS organizes your information into **Collections**, which are like tables in a database. Each collection is designed to manage a specific type of data, such as users, locations, or menu items. Here's a look at the main collections you'll be working with:
 8: 
 9: ### 1. Users
10: *   **Purpose**: Manages all user accounts, including staff (admins, managers, employees) and potentially customers. This is where you'll set up user roles and permissions.
11: *   **Key Information**: Email, first name, last name, phone, employee ID, assigned roles, employment status, associated locations, and profile photos.
12: 
13: ### 2. Media
14: *   **Purpose**: Stores all your uploaded files, such as images for menu items, documents, or videos. Payload automatically handles different image sizes for optimal display.
15: *   **Key Information**: Alternative text (for accessibility), captions, and who uploaded the file.
16: 
17: ### 3. Contacts
18: *   **Purpose**: Keeps track of contact information for various individuals or organizations you interact with, including customers, vendors, and contractors.
19: *   **Key Information**: Names, email, phone, company, contact type, visit history, and marketing preferences.
20: 
21: ### 4. Dietary Restrictions
22: *   **Purpose**: A list of common dietary restrictions and allergies (e.g., Gluten-Free, Vegan, Nut Allergy). This helps you categorize and manage menu items or customer preferences.
23: 
24: ### 5. Drink Menu Items
25: *   **Purpose**: Manages all the drinks offered on your menu.
26: *   **Key Information**: Drink name, description, price, and its category (e.g., Coffee, Tea, Soda).
27: 
28: ### 6. Drink Subcategories
29: *   **Purpose**: Organizes your drink menu items into specific subcategories.
30: 
31: ### 7. Employee Ratings
32: *   **Purpose**: Allows managers to record and track employee performance ratings.
33: *   **Key Information**: Employee, location, date of rating, rating score (1-5 stars), and notes.
34: 
35: ### 8. Features
36: *   **Purpose**: Used to enable or disable certain features within the application. This is typically managed by administrators.
37: 
38: ### 9. Hotspot Logins
39: *   **Purpose**: Records data from WiFi hotspot logins, including customer details and consent for marketing.
40: 
41: ### 10. Incidents
42: *   **Purpose**: For logging and tracking any incidents or issues that occur, such as equipment malfunctions or customer complaints.
43: *   **Key Information**: Title, description, date, location, who reported it, and current status.
44: 
45: ### 11. Jobs
46: *   **Purpose**: Defines different job roles or positions within your organization.
47: 
48: ### 12. Locations
49: *   **Purpose**: Manages information about all your physical business locations.
50: *   **Key Information**: Name, address, contact details.
51: 
52: ### 13. Manager Reports
53: *   **Purpose**: Stores daily or shift reports submitted by managers.
54: *   **Key Information**: Report title, date, manager, location, and notes.
55: 
56: ### 14. Message Types
57: *   **Purpose**: Categorizes incoming customer messages (e.g., General Inquiry, Complaint, Feedback).
58: 
59: ### 15. Messages
60: *   **Purpose**: Manages all customer messages and inquiries received through various channels.
61: *   **Key Information**: Status, priority, subject, sender details, message content, internal notes, assigned staff, and attachments.
62: 
63: ### 16. QR Feedback
64: *   **Purpose**: Collects customer feedback submitted via QR codes.
65: *   **Key Information**: Rating, comment, location, and associated user.
66: 
67: ### 17. Questions
68: *   **Purpose**: Manages custom questions that can be displayed on server or manager reports.
69: *   **Key Information**: Question text, when it should be displayed (AM/PM), which roles should see it, and minimum character requirements for answers.
70: 
71: ### 18. Review Keywords
72: *   **Purpose**: Defines keywords that can be associated with customer reviews.
73: 
74: ### 19. Reviews
75: *   **Purpose**: Stores customer reviews and feedback.
76: *   **Key Information**: Title, rating, comment, associated user, location, and relevant keywords.
77: 
78: ### 20. Server Reports
79: *   **Purpose**: Stores reports submitted by servers.
80: *   **Key Information**: Title, date, server, location, and notes.
81: 
82: ### 21. Shift Types
83: *   **Purpose**: Defines different types of shifts (e.g., Morning, Evening, Weekend).
84: 
85: ### 22. Upgrade Types
86: *   **Purpose**: Categorizes different types of system or facility upgrades (e.g., POS System, Kitchen Equipment).
87: 
88: ### 23. Upgrades
89: *   **Purpose**: Tracks ongoing or completed system and facility upgrades.
90: *   **Key Information**: Name, location, type of upgrade, status, description, cost, vendor, scheduled dates, and attachments.
91: 
92: ## Using the Rich Text Editor (Lexical WYSIWYG)
93: 
94: Several fields in Payload CMS, such as `Employee Notes` in Employee Ratings, `Message Content` and `Internal Notes` in Messages, and `Description` and `Notes` in Upgrades, use a powerful **Rich Text Editor**. This editor allows you to format text, add headings, lists, links, and more, similar to a word processor.
95: 
96: This editor is powered by **Lexical**, a modern and highly performant technology. This means you get a smooth and responsive experience when creating and editing content, ensuring your descriptions and notes are clear and well-formatted.
</file>

<file path="llm_context/responses/prompt_template.md">
  1: ```
  2: # LLM-Friendly Scripting Prompt for TypeScript Error Resolution in Payload CMS 3.0
  3: 
  4: # This script provides guidance for resolving common TypeScript compilation errors
  5: # in Payload CMS 3.0 projects, specifically related to import paths and
  6: # missing type annotations for Payload-specific functions.
  7: 
  8: # --- INPUT PARAMETERS ---
  9: # @param {string} error_type - The type of TypeScript error encountered (e.g., "import_path", "missing_type_annotation").
 10: # @param {string} file_path - The path to the file where the error is occurring.
 11: # @param {string} [code_snippet] - An optional code snippet related to the error for more specific analysis.
 12: # @param {string} [function_type] - For "missing_type_annotation" errors, specify the type of Payload function (e.g., "access_control", "hook", "condition").
 13: 
 14: # --- SCRIPT LOGIC ---
 15: 
 16: # 1. Handle Import Path Errors
 17: IF error_type == "import_path":
 18:     PRINT "## Resolving Import Path Errors in Payload CMS 3.0"
 19:     PRINT "Payload CMS 3.0 has consolidated many core types and utilities directly under the 'payload' package."
 20:     PRINT "You should update your imports from 'payload/types' to 'payload'."
 21:     PRINT ""
 22:     PRINT "### Incorrect Import (Payload 2.x style):"
 23:     PRINT "```typescript"
 24:     PRINT "import { CollectionConfig } from 'payload/types';"
 25:     PRINT "import { Field } from 'payload/types';"
 26:     PRINT "```"
 27:     PRINT ""
 28:     PRINT "### Correct Import (Payload 3.0 style):"
 29:     PRINT "```typescript"
 30:     PRINT "import { CollectionConfig, Field, Access, PayloadRequest, BeforeChangeHook, AfterChangeHook, CollectionBeforeChangeHook, CollectionAfterChangeHook } from 'payload';"
 31:     PRINT "```"
 32:     PRINT ""
 33:     PRINT "ACTION: In file '" + file_path + "', replace imports from 'payload/types' with direct imports from 'payload'."
 34: 
 35: # 2. Handle Missing Type Annotation Errors
 36: ELSE IF error_type == "missing_type_annotation":
 37:     PRINT "## Resolving Missing Type Annotations in Payload CMS 3.0"
 38:     PRINT "Payload CMS functions require specific type annotations for their parameters to ensure type safety and prevent errors."
 39:     PRINT ""
 40: 
 41:     IF function_type == "access_control":
 42:         PRINT "### Access Control Functions"
 43:         PRINT "Access control functions (e.g., `access.read`, `access.create`) receive an object with `req` (PayloadRequest), `doc`, `id`, and `collection`."
 44:         PRINT "You should also ensure your `PayloadRequest` interface is extended to include your custom `User` type."
 45:         PRINT ""
 46:         PRINT "### Correct Typing for Access Control:"
 47:         PRINT "```typescript"
 48:         PRINT "import { Access, PayloadRequest } from 'payload';"
 49:         PRINT "import { User } from '../payload-types'; // Adjust path to your User type"
 50:         PRINT ""
 51:         PRINT "export const isAdmin: Access<any, User> = ({ req }) => {"
 52:         PRINT "  return req.user?.role === 'admin';"
 53:         PRINT "};"
 54:         PRINT ""
 55:         PRINT "export const isAdminOrSelf: Access<any, User> = ({ req, id, doc }) => {"
 56:         PRINT "  if (req.user?.role === 'admin') { return true; }"
 57:         PRINT "  if (req.user && id === req.user.id) { return true; }"
 58:         PRINT "  if (req.user && doc && doc.owner === req.user.id) { return true; }"
 59:         PRINT "  return false;"
 60:         PRINT "};"
 61:         PRINT "```"
 62:         PRINT ""
 63:         PRINT "ACTION: In file '" + file_path + "', apply the correct type annotations for your access control functions. Ensure your `PayloadRequest` is extended with your `User` type."
 64: 
 65:     ELSE IF function_type == "hook":
 66:         PRINT "### Hooks (e.g., `beforeChange`, `afterChange`)"
 67:         PRINT "Hooks receive specific parameters depending on their type (e.g., `CollectionBeforeChangeHook`, `CollectionAfterChangeHook`)."
 68:         PRINT ""
 69:         PRINT "### Correct Typing for `beforeChange` Hook:"
 70:         PRINT "```typescript"
 71:         PRINT "import { CollectionBeforeChangeHook, PayloadRequest } from 'payload';"
 72:         PRINT "import { Product } from '../payload-types'; // Adjust path to your data type"
 73:         PRINT ""
 74:         PRINT "export const setProductOwner: CollectionBeforeChangeHook<Product> = async ({"
 75:         PRINT "  data, req, operation, originalDoc,"
 76:         PRINT "}) => {"
 77:         PRINT "  if (operation === 'create' && req.user) {"
 78:         PRINT "    return { ...data, owner: req.user.id };"
 79:         PRINT "  }"
 80:         PRINT "  return data;"
 81:         PRINT "};"
 82:         PRINT "```"
 83:         PRINT ""
 84:         PRINT "### Correct Typing for `afterChange` Hook:"
 85:         PRINT "```typescript"
 86:         PRINT "import { CollectionAfterChangeHook, PayloadRequest } from 'payload';"
 87:         PRINT "import { Order } from '../payload-types'; // Adjust path to your data type"
 88:         PRINT ""
 89:         PRINT "export const sendOrderConfirmation: CollectionAfterChangeHook<Order> = async ({"
 90:         PRINT "  doc, req, operation,"
 91:         PRINT "}) => {"
 92:         PRINT "  if (operation === 'create') {"
 93:         PRINT "    console.log(`Order ${doc.id} created.`);"
 94:         PRINT "  }"
 95:         PRINT "  return doc;"
 96:         PRINT "};"
 97:         PRINT "```"
 98:         PRINT ""
 99:         PRINT "ACTION: In file '" + file_path + "', apply the correct type annotations for your hook functions based on their type and parameters."
100: 
101:     ELSE IF function_type == "condition":
102:         PRINT "### Condition Functions (e.g., `fields[].admin.condition`)"
103:         PRINT "Condition functions typically receive `data` (the entire document data) and `siblingData` (data of fields at the same level)."
104:         PRINT ""
105:         PRINT "### Correct Typing for Condition Functions:"
106:         PRINT "```typescript"
107:         PRINT "import { Field } from 'payload';"
108:         PRINT "import { Product } from '../payload-types'; // Adjust path to your data type"
109:         PRINT ""
110:         PRINT "const drinkSizeField: Field = {"
111:         PRINT "  name: 'drinkSize',"
112:         PRINT "  type: 'select',"
113:         PRINT "  options: ['small', 'medium', 'large'],"
114:         PRINT "  admin: {"
115:         PRINT "    condition: (data: Product, siblingData: any) => {"
116:         PRINT "      return data.productType === 'drink';"
117:         PRINT "    },"
118:         PRINT "  },"
119:         PRINT "};"
120:         PRINT "```"
121:         PRINT ""
122:         PRINT "ACTION: In file '" + file_path + "', apply the correct type annotations for your field condition functions."
123: 
124:     ELSE:
125:         PRINT "## Missing Type Annotations"
126:         PRINT "Please specify the 'function_type' parameter (e.g., 'access_control', 'hook', 'condition') for more specific guidance on type annotations."
127:         PRINT "In general, ensure all function parameters in Payload-related functions are explicitly typed."
128:         PRINT "Refer to the Payload CMS 3.0 documentation for specific function signatures."
129: 
130: ELSE:
131:     PRINT "## Unknown Error Type"
132:     PRINT "Please specify a valid 'error_type' parameter (e.g., 'import_path', 'missing_type_annotation') for targeted assistance."
133: 
134: # --- END SCRIPT ---
135: ```
</file>

<file path="llm_context/responses/setup_verification.md">
 1: # Project Setup Verification for Payload 3.0 + Next.js
 2: 
 3: To ensure a robust setup for your Payload 3.0 + Next.js restaurant management system, perform the following verification checks:
 4: 
 5: ### 1. Build Process Verification
 6: 
 7: This step ensures that both your Next.js frontend and Payload backend can be successfully built for production.
 8: 
 9: *   **Next.js Build:**
10:     *   **Command:** `npm run build` (or `yarn build`, `pnpm build`) in your Next.js project root.
11:     *   **Check:** The command should complete without errors, indicating that Next.js has successfully compiled your application for production. Look for output similar to "Compiled successfully" or "Build complete". This will generate the `.next` directory.
12: 
13: *   **Payload Build (if separate):**
14:     *   Payload CMS typically builds as part of the Next.js build process if integrated within the same project. If you have a separate Payload backend, it might have its own build step.
15:     *   **Command (example for a separate Payload build):** `npm run payload:build` (or similar, check your `package.json` scripts).
16:     *   **Check:** Verify successful compilation of Payload's admin UI and server-side code.
17: 
18: ### 2. TypeScript Compilation Checks
19: 
20: Ensuring correct TypeScript compilation is crucial for type safety and catching errors early.
21: 
22: *   **Command:** `tsc --noEmit`
23:     *   **Description:** This command runs the TypeScript compiler to check for type errors without emitting any JavaScript files. It's a quick way to validate your TypeScript code.
24:     *   **Check:** The command should exit with no errors. Any output indicates type errors that need to be resolved.
25: 
26: *   **ESLint with TypeScript:**
27:     *   **Command:** `npm run lint` (or `yarn lint`, `pnpm lint`)
28:     *   **Description:** Assuming your ESLint is configured for TypeScript, this command will check for code style and potential issues.
29:     *   **Check:** The command should report no linting errors or warnings.
30: 
31: ### 3. Payload Connection Testing
32: 
33: Verify that your Next.js application can successfully connect to and interact with the Payload CMS backend.
34: 
35: *   **Start Payload/Next.js Development Server:**
36:     *   **Command:** `npm run dev` (or `yarn dev`, `pnpm dev`) in your project root.
37:     *   **Check:** Ensure both the Next.js frontend and Payload CMS backend (admin UI) are running and accessible, typically on `http://localhost:3000` and `http://localhost:3000/admin` respectively.
38: 
39: *   **Access Payload Admin UI:**
40:     *   **Check:** Navigate to `http://localhost:3000/admin` in your browser. You should see the Payload CMS login screen or dashboard. This confirms the Payload server is running and serving its admin interface.
41: 
42: *   **Test API Endpoints:**
43:     *   **Check:** Use a tool like Postman, Insomnia, `curl`, or your browser to hit a public Payload API endpoint (e.g., `http://localhost:3000/api/users` or `http://localhost:3000/api/media`).
44:     *   **Command (example using curl):** `curl http://localhost:3000/api/media`
45:     *   **Check:** You should receive a valid JSON response, even if it's an empty array, indicating that the API is reachable and functioning.
46: 
47: *   **Database Connection:**
48:     *   **Check:** When starting the Payload server, observe the console output for messages indicating a successful database connection (e.g., "Connected to MongoDB"). If there are connection errors, verify your `DATABASE_URI` environment variable.
49: 
50: ### 4. Dependency Validation
51: 
52: Ensure all project dependencies are correctly installed and compatible.
53: 
54: *   **Install Dependencies:**
55:     *   **Command:** `npm install` (or `yarn install`, `pnpm install`)
56:     *   **Check:** This command should complete without errors. Any errors here indicate issues with `package.json` or network connectivity.
57: 
58: *   **Check for Outdated Dependencies (Optional but Recommended):**
59:     *   **Command:** `npm outdated` (or `yarn outdated`, `pnpm outdated`)
60:     *   **Check:** This command lists outdated packages. While not strictly a "failure" if outdated, it's good practice to keep dependencies updated to avoid security vulnerabilities and compatibility issues.
61: 
62: *   **Verify `node_modules`:**
63:     *   **Check:** Ensure the `node_modules` directory exists in your project root and contains the installed packages. Its presence confirms that `npm install` (or equivalent) ran successfully.
64: 
65: By systematically performing these checks, you can ensure that your Payload 3.0 + Next.js project is correctly set up and ready for development.
</file>

<file path="llm_context/responses/typescript_error_resolution_v2.md">
  1: # Resolving Advanced TypeScript Errors in Payload CMS 3.0 Collections
  2: 
  3: This document provides guidance on fixing more advanced TypeScript errors in your Payload CMS 3.0 collection files, specifically addressing issues with extending User types, defining CollectionSlug unions, and implementing properly typed access control functions.
  4: 
  5: ## 1. Extending User Types (Adding `roles` and `locations`)
  6: 
  7: Payload CMS automatically generates a `payload-types.ts` file (or similar) that contains the TypeScript interfaces for your collections. To add custom properties like `roles` and `locations` to your `User` type, you need to extend the generated `User` interface.
  8: 
  9: This is typically done by augmenting the `payload` module or by directly modifying the generated `payload-types.ts` if you have custom fields on your `Users` collection.
 10: 
 11: **Assumed `payload-types.ts` structure (generated by Payload):**
 12: ```typescript
 13: // payload-types.ts (This file is often auto-generated by Payload)
 14: 
 15: export type User = {
 16:   id: string;
 17:   email: string;
 18:   // ... other default Payload user fields
 19:   createdAt: string;
 20:   updatedAt: string;
 21: };
 22: 
 23: // ... other collection types
 24: ```
 25: 
 26: **To extend the `User` type, you would typically add these fields to your `Users` collection definition in `src/collections/Users.ts` (or similar). Payload will then generate the `payload-types.ts` with these fields included.**
 27: 
 28: **Example `src/collections/Users.ts` with `roles` and `locations` fields:**
 29: 
 30: ```typescript
 31: import { CollectionConfig } from 'payload';
 32: 
 33: const Users: CollectionConfig = {
 34:   slug: 'users',
 35:   auth: true,
 36:   admin: {
 37:     use = 'email',
 38:   },
 39:   fields: [
 40:     // Email added by default
 41:     // Password added by default
 42:     {
 43:       name: 'roles',
 44:       type: 'select',
 45:       has  Many: true,
 46:       defaultValue: ['employee'],
 47:       options: [
 48:         {
 49:           label: 'Admin',
 50:           value: 'admin',
 51:         },
 52:         {
 53:           label: 'Employee',
 54:           value: 'employee',
 55:         },
 56:         {
 57:           label: 'Manager',
 58:           value: 'manager',
 59:         },
 60:       ],
 61:     },
 62:     {
 63:       name: 'locations',
 64:       type: 'relationship',
 65:       relationTo: 'locations', // Assuming you have a 'locations' collection
 66:       hasMany: true,
 67:     },
 68:   ],
 69: };
 70: 
 71: export default Users;
 72: ```
 73: 
 74: After adding these fields to your `Users` collection and running Payload (which triggers type generation), your `User` type in `payload-types.ts` should automatically include `roles` and `locations`:
 75: 
 76: ```typescript
 77: // payload-types.ts (After Payload generates types)
 78: 
 79: export type User = {
 80:   id: string;
 81:   email: string;
 82:   roles?: ('admin' | 'employee' | 'manager')[]; // Now includes roles
 83:   locations?: string[] | Location[]; // Now includes locations (adjust type based on your Location collection)
 84:   createdAt: string;
 85:   updatedAt: string;
 86: };
 87: 
 88: // ... other collection types
 89: ```
 90: 
 91: **If you need to manually augment the `PayloadRequest` to ensure `req.user` is correctly typed with your custom fields, you can create a declaration file (e.g., `src/types/payload-custom.d.ts`):**
 92: 
 93: ```typescript
 94: // src/types/payload-custom.d.ts
 95: 
 96: import { User as PayloadUser } from '../payload-types'; // Import the generated User type
 97: 
 98: declare module 'payload' {
 99:   export interface PayloadRequest {
100:     user?: PayloadUser; // Extend PayloadRequest to include your custom User type
101:   }
102: }
103: ```
104: 
105: ## 2. Defining CollectionSlug Unions
106: 
107: To ensure type safety when referring to collection slugs (names), you can create a union type that lists all your collection slugs. This is particularly useful for relationship fields or when dynamically referencing collections.
108: 
109: First, ensure your `payload-types.ts` (or similar generated file) exports a type that represents all your collection slugs. Payload 3.0 typically generates a `CollectionSlug` type.
110: 
111: **Example `payload-types.ts` (generated):**
112: 
113: ```typescript
114: // payload-types.ts
115: 
116: export type CollectionSlug = 'users' | 'media' | 'contacts' | 'locations'; // Example
117: 
118: // ... rest of the generated types
119: ```
120: 
121: If this `CollectionSlug` type is not automatically generated or doesn't include all your collections, you can define it manually:
122: 
123: ```typescript
124: // src/types/collection-slugs.ts (or similar)
125: 
126: export type AppCollectionSlug =
127:   | 'users'
128:   | 'media'
129:   | 'contacts'
130:   | 'dietaryRestrictions'
131:   | 'drinkMenuItems'
132:   | 'drinkSubcategories'
133:   | 'employeeRatings'
134:   | 'features'
135:   | 'hotspotLogins'
136:   | 'incidents'
137:   | 'jobs'
138:   | 'locations'
139:   | 'managerReports'
140:   | 'messages'
141:   | 'messageTypes'
142:   | 'qrFeedback'
143:   | 'questions'
144:   | 'reviewKeywords'
145:   | 'reviews'
146:   | 'serverReports'
147:   | 'shiftTypes'
148:   | 'upgrades'
149:   | 'upgradeTypes';
150: 
151: // You can then use AppCollectionSlug in your code:
152: // const myCollection: AppCollectionSlug = 'users';
153: ```
154: 
155: ## 3. Implementing Proper Access Controls with TypeScript
156: 
157: Access control functions in Payload 3.0 should be strongly typed using the `Access` type imported from `payload`. This type takes two generic arguments: `CollectionType` (the type of the collection the access function is for) and `UserType` (your custom user type).
158: 
159: **Key points for typed access control:**
160: *   Import `Access` and `PayloadRequest` from `'payload'`.
161: *   Import your custom `User` type (e.g., from `../payload-types`).
162: *   Destructure `req` from the access context and use `req.user` which should now be correctly typed with your custom `User` properties (like `roles` and `locations`).
163: 
164: **Example Access Control Functions with `roles` and `locations`:**
165: 
166: ```typescript
167: import { Access, PayloadRequest } from 'payload';
168: import { User, Location } from '../payload-types'; // Assuming User and Location types
169: 
170: // Access function to check if the user is an admin
171: export const isAdmin: Access<any, User> = ({ req }) => {
172:   return req.user?.roles?.includes('admin') || false;
173: };
174: 
175: // Access function to check if the user is an employee
176: export const isEmployee: Access<any, User> = ({ req }) => {
177:   return req.user?.roles?.includes('employee') || false;
178: };
179: 
180: // Access function to check if the user is a manager
181: export const isManager: Access<any, User> = ({ req }) => {
182:   return req.user?.roles?.includes('manager') || false;
183: };
184: 
185: // Access function to check if the user is an admin OR if the document belongs to one of their assigned locations
186: export const isAdminOrHasLocationAccess: Access<any, User> = ({ req, doc }) => {
187:   // Admins have full access
188:   if (req.user?.roles?.includes('admin')) {
189:     return true;
190:   }
191: 
192:   // If the user has locations assigned and the document has a 'location' field
193:   if (req.user?.locations && doc && doc.location) {
194:     // Ensure doc.location is a string (ID) or an object with an ID
195:     const docLocationId = typeof doc.location === 'object' ? doc.location.id : doc.location;
196: 
197:     // Check if the user's locations include the document's location
198:     return req.user.locations.some(userLocation => {
199:       const userLocationId = typeof userLocation === 'object' ? userLocation.id : userLocation;
200:       return userLocationId === docLocationId;
201:     });
202:   }
203: 
204:   return false;
205: };
206: 
207: // Example usage in a collection configuration (e.g., in src/collections/Orders.ts):
208: 
209: // export const Orders: CollectionConfig = {
210: //   slug: 'orders',
211: //   access: {
212: //     read: isAdminOrHasLocationAccess, // Only admins or users with matching location can read orders
213: //     create: isEmployee, // Only employees can create orders
214: //     update: isAdminOrHasLocationAccess, // Only admins or users with matching location can update orders
215: //     delete: isAdmin, // Only admins can delete orders
216: //   },
217: //   fields: [
218: //     {
219: //       name: 'location',
220: //       type: 'relationship',
221: //       relationTo: 'locations',
222: //       required: true,
223: //     },
224: //     // ... other fields
225: //   ],
226: // };
227: ```
228: 
229: By implementing these patterns, you should be able to resolve the TypeScript errors related to User types, CollectionSlug unions, and access control functions in your Payload CMS 3.0 project.
</file>

<file path="llm_context/responses/typescript_errors.md">
  1: # Resolving TypeScript Compilation Errors in Payload CMS 3.0
  2: 
  3: This document addresses common TypeScript compilation errors in Payload CMS 3.0 projects, specifically focusing on import path issues and missing type annotations for Payload-specific functions.
  4: 
  5: ## 1. Correct Import Patterns
  6: 
  7: In Payload CMS 3.0, many core types and utilities are now directly exported from the `payload` package, simplifying imports. The previous `payload/types` path is often no longer necessary for common types like `CollectionConfig`, `Field`, `Access`, `PayloadRequest`, etc.
  8: 
  9: **Incorrect Import (Payload 2.x style):**
 10: ```typescript
 11: import { CollectionConfig } from 'payload/types';
 12: import { Field } from 'payload/types';
 13: ```
 14: 
 15: **Correct Import (Payload 3.0 style):**
 16: ```typescript
 17: import { CollectionConfig, Field, Access, PayloadRequest, BeforeChangeHook, AfterChangeHook, CollectionBeforeChangeHook, CollectionAfterChangeHook } from 'payload';
 18: ```
 19: 
 20: **Action:** Update all your collection files and other Payload-related files to import these types directly from `'payload'`.
 21: 
 22: ## 2. Missing Type Annotations for Function Parameters
 23: 
 24: Payload CMS functions (access controls, hooks, field conditions) provide specific parameters that, when properly typed, eliminate many TypeScript errors and improve code clarity.
 25: 
 26: ### A. Access Control Functions
 27: 
 28: Access control functions (e.g., `access.read`, `access.create`, `access.update`, `access.delete`) receive an object with properties like `req` (the Express request object, extended by Payload), `doc` (the document being accessed/modified), `id`, and `collection`.
 29: 
 30: **Correct Typing for Access Control:**
 31: 
 32: ```typescript
 33: import { Access, PayloadRequest } from 'payload';
 34: import { User } from '../payload-types'; // Assuming you have a User type defined
 35: 
 36: export const isAdmin: Access<any, User> = ({ req }) => {
 37:   // req.user will be typed as User if you extend PayloadRequest correctly
 38:   return req.user?.role === 'admin';
 39: };
 40: 
 41: export const isAdminOrSelf: Access<any, User> = ({ req, id, doc }) => {
 42:   if (req.user?.role === 'admin') {
 43:     return true;
 44:   }
 45: 
 46:   // If the user is not an admin, they can only read/update their own document
 47:   if (req.user && id === req.user.id) {
 48:     return true;
 49:   }
 50: 
 51:   // For read access, if no specific ID is provided, allow if the user is logged in
 52:   // and the document's owner matches the current user (if applicable)
 53:   if (req.user && doc && doc.owner === req.user.id) {
 54:     return true;
 55:   }
 56: 
 57:   return false;
 58: };
 59: 
 60: // Example usage in a collection:
 61: // access: {
 62: //   read: isAdminOrSelf,
 63: //   create: isAdmin,
 64: //   update: isAdminOrSelf,
 65: //   delete: isAdmin,
 66: // },
 67: ```
 68: **Note on `PayloadRequest` and Custom User Types:**
 69: For `req.user` to be correctly typed, you often need to extend Payload's `PayloadRequest` interface to include your custom `User` type. This is typically done in a declaration file (e.g., `src/types/payload-custom.d.ts` or `src/payload-types.ts` if generated by Payload).
 70: 
 71: ```typescript
 72: // Example: src/payload-types.ts (or a custom .d.ts file)
 73: // This is often generated by Payload, but if not, you might need to declare it.
 74: declare module 'payload' {
 75:   export interface PayloadRequest {
 76:     user?: User; // Assuming 'User' is your custom user type
 77:   }
 78: }
 79: ```
 80: 
 81: ### B. Hooks (e.g., `beforeChange`, `afterChange`)
 82: 
 83: Hooks receive specific parameters depending on their type (e.g., `BeforeChangeHook`, `AfterChangeHook`). These parameters should be typed for clarity and error prevention.
 84: 
 85: **Correct Typing for `beforeChange` Hook:**
 86: 
 87: ```typescript
 88: import { CollectionBeforeChangeHook, PayloadRequest } from 'payload';
 89: import { Product, User } from '../payload-types'; // Assuming Product and User types
 90: 
 91: export const setProductOwner: CollectionBeforeChangeHook<Product> = async ({
 92:   data, // The data being saved
 93:   req,  // The PayloadRequest object
 94:   operation, // 'create' | 'update'
 95:   originalDoc, // The original document before the change (for 'update' operation)
 96: }) => {
 97:   if (operation === 'create' && req.user) {
 98:     // Ensure 'owner' field exists on your Product type
 99:     return {
100:       ...data,
101:       owner: req.user.id,
102:     };
103:   }
104:   return data;
105: };
106: 
107: // Example usage in a collection field:
108: // hooks: {
109: //   beforeChange: [setProductOwner],
110: // },
111: ```
112: 
113: **Correct Typing for `afterChange` Hook:**
114: 
115: ```typescript
116: import { CollectionAfterChangeHook, PayloadRequest } from 'payload';
117: import { Order, User } from '../payload-types'; // Assuming Order and User types
118: 
119: export const sendOrderConfirmation: CollectionAfterChangeHook<Order> = async ({
120:   doc, // The document after the change
121:   req, // The PayloadRequest object
122:   operation, // 'create' | 'update'
123: }) => {
124:   if (operation === 'create') {
125:     // Logic to send email, e.g., using a transactional email service
126:     console.log(`Order ${doc.id} created. Sending confirmation to ${doc.customerEmail}`);
127:   }
128:   return doc;
129: };
130: 
131: // Example usage in a collection:
132: // hooks: {
133: //   afterChange: [sendOrderConfirmation],
134: // },
135: ```
136: 
137: ### C. Condition Functions (e.g., `fields[].admin.condition`)
138: 
139: Field condition functions determine whether a field is shown or hidden in the admin UI based on other field values. They typically receive `data` (the entire document data) and `siblingData` (data of fields at the same level).
140: 
141: **Correct Typing for Condition Functions:**
142: 
143: ```typescript
144: import { Field } from 'payload';
145: import { Product } from '../payload-types'; // Assuming Product type
146: 
147: const productTypeField: Field = {
148:   name: 'productType',
149:   type: 'select',
150:   options: ['food', 'drink'],
151:   required: true,
152: };
153: 
154: const drinkSizeField: Field = {
155:   name: 'drinkSize',
156:   type: 'select',
157:   options: ['small', 'medium', 'large'],
158:   admin: {
159:     condition: (data: Product, siblingData: any) => {
160:       // Show 'drinkSize' only if 'productType' is 'drink'
161:       return data.productType === 'drink';
162:     },
163:   },
164: };
165: 
166: // Example usage in a collection fields array:
167: // fields: [
168: //   productTypeField,
169: //   drinkSizeField,
170: //   // ... other fields
171: // ],
172: ```
173: 
174: **Action:** Review all your access control, hook, and condition functions and apply the appropriate type annotations to their parameters. This will significantly reduce your TypeScript errors.
</file>

<file path="llm_context/state_management/README.md">
 1: # Zustand State Management
 2: 
 3: ## Store Patterns
 4: - [x] Store structure and organization - Split stores into slices for separate concerns
 5: - [x] Action patterns and naming conventions - Use `set` for simple updates and actions for complex logic
 6: - [x] State normalization strategies - Normalize nested data using entities pattern
 7: - [x] Middleware integration - Implement `persist` and `devtools` middleware
 8: ```typescript
 9: import { devtools, persist } from 'zustand/middleware';
10: 
11: const useStore = create(
12:   devtools(
13:     persist(
14:       (set) => ({
15:         count: 0,
16:         increment: () => set((state) => ({ count: state.count + 1 })),
17:       }),
18:       { name: 'count-store' }
19:     )
20:   )
21: );
22: ```
23: - [x] TypeScript integration - Define strict types for state and actions
24: 
25: ## Integration Patterns
26: - [x] Tanstack Query integration - Use Zustand for UI state and Tanstack for server state
27: - [x] Form state synchronization - Sync form state with Zustand using `useEffect`
28: - [x] Authentication state management - Implement with Payload's auth flow[3]
29: ```typescript
30: // Auth state example
31: const useAuthStore = create((set) => ({
32:   user: null,
33:   login: async (credentials) => {
34:     const res = await fetch('/api/login', { method: 'POST', body: JSON.stringify(credentials) });
35:     set({ user: await res.json() });
36:   },
37:   logout: () => set({ user: null })
38: }));
39: ```
40: - [x] UI state (modals, notifications) - Manage with dedicated Zustand slices
41: - [x] Real-time data updates - Combine with WebSockets for live updates
42: 
43: ## Performance Optimization
44: - [x] Selector patterns - Use `shallow` for object comparisons
45: - [x] Store slicing - Create independent slices for performance
46: - [x] Subscription patterns - Use `subscribe` for external updates
47: - [x] Memory leak prevention - Add cleanup functions to effects
48: - [x] State persistence - Implement with `persist` middleware
49: 
50: ## Testing Strategies
51: - [x] Store testing patterns - Test actions and state transitions
52: - [x] Mock store creation - Use `create` to mock store instances
53: - [x] Integration testing with React - Test components with store
54: - [x] State mutation testing - Verify immutability patterns
55: - [x] Async action testing - Mock API calls in tests
56: 
57: ## Payload CMS Integration
58: 1. **Version History** - Use Payload's versioning system for state snapshots[1]
59: 2. **Draft Management** - Implement draft states with Payload's draft mode[1]
60: 3. **Admin Hooks** - Use `useRouteTransition` for UI feedback[4]
61: 4. **Form State** - Integrate with Payload's Form Builder[2]
62: 
63: ## Files to Create
64: - `best_practices.md` - Zustand best practices
65: - `common_patterns.md` - Reusable store patterns
66: - `troubleshooting.md` - Common state management issues
67: - `integration_guides.md` - Integration with other libraries
</file>

<file path="llm_context/tanstack/README.md">
 1: # Tanstack Query & Tables
 2: 
 3: ## Table Implementation
 4: - [x] Column definitions for Payload collections - Use type-safe column definitions
 5: ```typescript
 6: const columns: ColumnDef<Collection>[] = [
 7:   { accessorKey: 'id', header: 'ID' },
 8:   { accessorKey: 'title', header: 'Title' }
 9: ]
10: ```
11: - [x] Sorting and filtering integration - Implement server-side sorting
12: - [x] Row selection patterns - Use `rowSelection` state
13: - [x] Custom cell renderers - Create reusable cell components
14: - [x] Export functionality - Implement CSV/Excel export
15: 
16: ## Integration Points
17: - [x] Zustand state management integration - Sync table state with Zustand
18: - [x] Form submission with query invalidation - Invalidate queries on submit
19: - [x] Real-time updates with WebSocket/SSE - Use `useQuery` with WebSockets
20: - [x] Performance optimization strategies - Virtualize large tables
21: 
22: ## Best Practices
23: 1. Use `keepPreviousData` for smooth pagination transitions
24: 2. Implement skeleton loaders for better UX
25: 3. Use column visibility controls for responsive tables
26: 4. Add global filtering with debouncing
27: 5. Implement server-side pagination for large datasets
</file>

<file path="llm_context/ui_patterns/README.md">
 1: # Shadcn UI Patterns
 2: 
 3: ## Component Consistency
 4: - [x] Theme configuration and customization - Use CSS variables and theme editors[3]
 5: - [x] Component composition strategies - Build reusable components with Payload's UI library[1][2][4]
 6: - [x] Color palette and design tokens - Implement with CSS variables and design systems[3]
 7: - [x] Typography scale and usage - Use consistent type scales with CSS variables[3]
 8: - [x] Spacing and layout patterns - Implement with Payload's Gutter component[3]
 9: 
10: ## Custom Component Development
11: 1. **Modal Implementation** [1]
12: ```typescript
13: import { Modal } from 'payload/components';
14: import { Button } from 'payload/components/elements';
15: 
16: const CustomModal = () => (
17:   <Modal header="Custom Modal" size="large">
18:     <div className="content">
19:       <p>Modal content here</p>
20:       <div className="delete-document__actions">
21:         <Button buttonStyle="secondary">Cancel</Button>
22:         <Button>Confirm</Button>
23:       </div>
24:     </div>
25:   </Modal>
26: );
27: ```
28: 2. **Dashboard Customization** [3]
29: ```typescript
30: import { Gutter } from 'payload/components/layout';
31: import { Header } from 'payload/components';
32: 
33: const CustomDashboard = () => (
34:   <Gutter>
35:     <Header title="Custom Dashboard" />
36:     <div className="dashboard-content">
37:       {/* Dashboard components */}
38:     </div>
39:   </Gutter>
40: );
41: ```
42: 3. **Field Component Overrides** [4]
43: ```typescript
44: const customField = {
45:   name: 'customSelect',
46:   type: 'text',
47:   admin: {
48:     components: {
49:       Field: CustomSelectField,
50:       Cell: CustomSelectCell,
51:       Filter: CustomSelectFilter
52:     }
53:   }
54: };
55: ```
56: 
57: ## Accessibility
58: - [x] ARIA label strategies - Implement with Payload's accessibility utilities[5]
59: - [x] Keyboard navigation - Ensure tab navigation and focus management[5]
60: - [x] Screen reader compatibility - Use semantic HTML and ARIA attributes[5]
61: - [x] Color contrast compliance - Meet WCAG 2.1 AA standards[5]
62: - [x] Focus management - Implement focus traps for modals[1][5]
63: 
64: ## Integration
65: - [x] Tailwind CSS configuration - Extend with custom themes[3]
66: - [x] Custom component creation - Use Payload's component API[2][4]
67: - [x] Theme switching implementation - Implement with CSS variables and context[3]
68: - [x] Animation and transition patterns - Use Framer Motion for complex animations[3]
69: 
70: ## Best Practices
71: 1. Use Payload's built-in components for consistency[1][2]
72: 2. Extend rather than replace core components[4]
73: 3. Implement responsive design with breakpoints[3]
74: 4. Use CSS variables for theming[3]
75: 5. Follow Payload's component composition patterns[2][4]
76: 
77: ## Files to Create
78: - `best_practices.md` - UI consistency guidelines
79: - `common_patterns.md` - Reusable component patterns
80: - `troubleshooting.md` - Common UI issues
81: - `integration_guides.md` - Integration with other libraries
</file>

<file path="llm_context/repomix_integration.md">
 1: # Repomix Integration Guide
 2: 
 3: ## Overview
 4: Repomix packages your entire repository into a single AI-friendly file. Integrating Repomix into our workflow enables:
 5: - Feeding the full codebase to LLMs without manual concatenation  
 6: - Automated token accounting to respect model context limits  
 7: - Security scans for secrets and sensitive data  
 8: 
 9: ## Installation
10: 
11: Using npx (no global install required):
12: ```bash
13: cd /Users/webdev/Projects/canvas-payloadv3
14: npx repomix@latest
15: ```
16: 
17: Or add as a dev dependency:
18: ```bash
19: npm install --save-dev repomix
20: ```
21: 
22: ## Configuration
23: 
24: Create `repomix.config.json` at project root:
25: ```json
26: {
27:   "output": "repomix-output.xml",
28:   "format": "xml",
29:   "ignore": ["node_modules/**", ".git/**"],
30:   "tokenCount": true,
31:   "detectSecrets": true
32: }
33: ```
34: 
35: ## Usage in Development
36: 
37: 1. Run `npx repomix --config=repomix.config.json`.
38: 2. Upload or attach `repomix-output.xml` when prompting the AI:
39:    > This file contains the entire repo. Please analyze architecture and suggest refactors.
40: 
41: ## CI / Automation
42: 
43: Add a workflow step in `.github/workflows/ci.yml`:
44: ```yaml
45: - name: Generate Repomix artifact
46:   run: npx repomix --config=repomix.config.json
47: 
48: - name: Upload AI context
49:   uses: actions/upload-artifact@v3
50:   with:
51:     name: repomix-artifact
52:     path: repomix-output.xml
53: ```
54: 
55: ## AI Prompt Examples
56: 
57: - **Initial review**  
58:   > "Here is the repository in one file. Identify unused code paths and suggest consolidation."
59: 
60: - **Refactor request**  
61:   > "Please update all React components to use hooks and context. Use the combined file."
62: 
63: - **Multi-file patch (Claude Artifacts)**  
64:   > "Generate updated files for API and data layer. Provide separate file contents."
65: 
66: ## Best Practices
67: 
68: - Commit `repomix.config.json` to source control.  
69: - Exclude large binary assets via `.gitignore`.  
70: - Regularly regenerate after significant merges.  
71: - Use token counters to alert if repository size exceeds model limits.
72: 
73: ## Further Reading
74: 
75: - [Official Repomix Guide](https://repomix.com/guide/)  
76: - [Advanced Usage & Plugins](https://repomix.com/usage)
</file>

<file path="open_tasks/api-and-data-fetching/01_audit_existing_data_fetching_patterns.md">
 1: # Task: Audit Existing Data Fetching Patterns
 2: 
 3: ## Overview
 4: This task involves a thorough audit of all existing data-fetching implementations in the codebase. The goal is to identify and document current patterns, flagging any instances that lack proper pagination, SSR support, or caching strategies, and to verify authentication token handling.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: - **Payload CMS**: Backend providing the REST and GraphQL APIs.
14: 
15: ### Best Practices
16: - **Authentication-Aware Queries**: Ensure that all queries that require authentication correctly include the user's token.
17: - **Pagination**: Use server-side pagination for large datasets to avoid performance bottlenecks.
18: - **Caching**: Implement a sensible caching strategy to reduce unnecessary network requests.
19: - **SSR**: Leverage Next.js's SSR capabilities to pre-fetch data on the server for faster initial page loads.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 29.1
24: **Title**: Audit Existing Data Fetching Patterns
25: **Description**: Identify and document all current data-fetching implementations across the codebase, mapping each useQuery/useMutation hook to its API endpoint. Flag instances lacking pagination, SSR support, or caching strategies, and verify authentication token handling in query functions.
26: **Dependencies**: []
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **Data Fetching Catalog**: A comprehensive list of all data-fetching implementations is created, including the hooks used, the API endpoints they call, and their current caching and pagination strategies.
31: 2.  **Issue Identification**: A report is generated that identifies all data-fetching implementations that are not following best practices, with clear recommendations for improvement.
32: 3.  **Testing**:
33:     - The catalog and issue report are reviewed for accuracy and completeness.
34:     - A plan is created for addressing the identified issues in a prioritized manner.
35: 
36: ## Progress Report
37: [Agent will fill this section]
38: 
39: ### Completed Tasks:
40: - Task ID [X]: [Status] - [Brief description of what was done]
41: 
42: ### Issues Encountered:
43: - [Document any problems or blockers]
44: 
45: ### Files Modified/Created:
46: - [List all files changed]
47: 
48: ### Ready for Commit: [Yes/No]
49: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/02_implement_ssr_hydration.md">
 1: # Task: Implement SSR Hydration
 2: 
 3: ## Overview
 4: This task focuses on enabling server-side rendering (SSR) for public routes to improve initial page load performance. This will be achieved by pre-fetching data on the server and passing it to the client for hydration.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: - **Next.js**: Frontend framework, with SSR capabilities.
14: 
15: ### Best Practices
16: - **`getQueryClient`**: Use a utility function to get a singleton instance of the query client on the server.
17: - **`HydrationBoundary`**: Wrap pages with `HydrationBoundary` to pass the dehydrated query cache from the server to the client.
18: - **`getServerSideProps`**: Use `getServerSideProps` to pre-fetch data on the server and pass it to the page component as props.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 29.2
23: **Title**: Implement SSR Hydration
24: **Description**: Enable server-side rendering (SSR) support for public routes by creating a getQueryClient utility, wrapping pages with HydrationBoundary, and prefetching critical data in getServerSideProps.
25: **Dependencies**: [29.1]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **`getQueryClient` Utility**: A `getQueryClient` utility function is created to provide a singleton instance of the query client.
30: 2.  **`HydrationBoundary` Wrapper**: All pages that require SSR are wrapped with the `HydrationBoundary` component.
31: 3.  **`getServerSideProps` Implementation**: `getServerSideProps` is implemented on the relevant pages to pre-fetch data and pass it to the `HydrationBoundary`.
32: 4.  **Testing**:
33:     - View the source of a server-rendered page and verify that the pre-fetched data is present in the initial HTML.
34:     - Use the browser's developer tools to confirm that no additional network request is made for the pre-fetched data on the initial page load.
35:     - Verify that the page hydrates correctly on the client without any flickering or layout shifts.
36: 
37: ## Progress Report
38: [Agent will fill this section]
39: 
40: ### Completed Tasks:
41: - Task ID [X]: [Status] - [Brief description of what was done]
42: 
43: ### Issues Encountered:
44: - [Document any problems or blockers]
45: 
46: ### Files Modified/Created:
47: - [List all files changed]
48: 
49: ### Ready for Commit: [Yes/No]
50: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/03_optimize_pagination_strategies.md">
 1: # Task: Optimize Pagination Strategies
 2: 
 3: ## Overview
 4: This task focuses on implementing smooth and efficient pagination for large datasets. This will involve using `keepPreviousData` for a better user experience and implementing cursor-based pagination for performance.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: - **Payload CMS**: Backend providing the REST and GraphQL APIs.
14: 
15: ### Best Practices
16: - **`keepPreviousData`**: Use the `keepPreviousData` option in `useQuery` to keep the previous page's data visible while the next page is being fetched. This prevents a jarring loading state.
17: - **Cursor-Based Pagination**: For very large datasets, use cursor-based pagination instead of offset-based pagination. This is more performant as it avoids the need for the database to count all previous records.
18: - **UI Skeletons**: Show UI skeletons or other loading indicators to provide feedback to the user while new pages are being fetched.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 29.3
23: **Title**: Optimize Pagination Strategies
24: **Description**: Implement smooth paginated data loading using keepPreviousData, cursor-based pagination for large datasets, and UI skeletons during transitions for collections with more than 50 items.
25: **Dependencies**: [29.2]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **`keepPreviousData` Implementation**: The `keepPreviousData` option is enabled on all paginated queries.
30: 2.  **Cursor-Based Pagination**: For all collections with more than 50 items, pagination is implemented using a cursor-based approach.
31: 3.  **UI Skeletons**: UI skeletons are displayed while new pages are being fetched.
32: 4.  **Testing**:
33:     - Navigate through a paginated list and verify that the previous page's data remains visible while the next page is loading.
34:     - Inspect the network requests to confirm that cursor-based pagination is being used for large collections.
35:     - Verify that UI skeletons are displayed correctly during page transitions.
36: 
37: ## Progress Report
38: [Agent will fill this section]
39: 
40: ### Completed Tasks:
41: - Task ID [X]: [Status] - [Brief description of what was done]
42: 
43: ### Issues Encountered:
44: - [Document any problems or blockers]
45: 
46: ### Files Modified/Created:
47: - [List all files changed]
48: 
49: ### Ready for Commit: [Yes/No]
50: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/04_enhance_caching_strategies.md">
 1: # Task: Enhance Caching Strategies
 2: 
 3: ## Overview
 4: This task focuses on reducing unnecessary network requests by defining granular query keys, setting appropriate cache lifetimes, and implementing automatic garbage collection.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: 
14: ### Best Practices
15: - **Granular Query Keys**: Use specific and descriptive query keys to avoid cache collisions and ensure that data is refetched only when necessary.
16: - **Cache Lifetimes**: Set the `staleTime` and `cacheTime` for each query based on how frequently the data is expected to change.
17: - **Garbage Collection**: TanStack Query's garbage collection will automatically remove unused queries from the cache.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 29.4
22: **Title**: Enhance Caching Strategies
23: **Description**: Reduce network requests by defining granular query keys, setting cache lifetimes based on data volatility, and implementing automatic garbage collection.
24: **Dependencies**: [29.3]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Granular Query Keys**: All queries use granular, unique keys that accurately reflect their data dependencies.
29: 2.  **Cache Lifetimes**: The `staleTime` and `cacheTime` are set to appropriate values for all queries.
30: 3.  **Testing**:
31:     - Use the TanStack Query Devtools to inspect the query cache and verify that keys are being generated correctly.
32:     - Verify that data is being cached and refetched as expected based on the configured lifetimes.
33:     - Confirm that unused queries are being garbage collected from the cache.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/05_implement_optimistic_updates.md">
 1: # Task: Implement Optimistic Updates
 2: 
 3: ## Overview
 4: This task focuses on improving the user experience for mutations by implementing optimistic updates. This will involve using the `onMutate` handler in TanStack Query to update the UI before the server has responded.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: 
14: ### Best Practices
15: - **`onMutate`**: Use the `onMutate` handler to optimistically update the local cache before a mutation is sent to the server.
16: - **Rollback on Error**: Implement the `onError` handler to roll back the optimistic update if the mutation fails.
17: - **High-Frequency Mutations**: Prioritize implementing optimistic updates for high-frequency mutations, such as updating an order status or submitting a form that requires immediate feedback.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 29.5
22: **Title**: Implement Optimistic Updates
23: **Description**: Improve user experience for mutations by adding onMutate handlers to rollback failed updates, focusing on high-frequency mutations such as order status updates and forms requiring immediate feedback.
24: **Dependencies**: [29.4]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **`onMutate` Implementation**: The `onMutate` handler is implemented for all high-frequency mutations.
29: 2.  **Rollback Implementation**: The `onError` handler is implemented to roll back the optimistic update if the mutation fails.
30: 3.  **Testing**:
31:     - Perform a mutation and verify that the UI updates instantly, before the server responds.
32:     - Manually force a mutation to fail (e.g., by disconnecting from the network) and verify that the UI correctly rolls back to its previous state.
33:     - Verify that the cache is correctly updated on a successful mutation.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/06_secure_authentication_aware_queries.md">
 1: # Task: Secure Authentication-Aware Queries
 2: 
 3: ## Overview
 4: This task focuses on integrating authentication with data fetching to ensure that users can only access the data they are authorized to see. This will involve creating an authentication interceptor for automatic token refresh and implementing role-based query enabling.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: - **Payload CMS**: Backend providing the REST and GraphQL APIs, as well as user and role data.
14: 
15: ### Best Practices
16: - **Auth Interceptor**: Create an interceptor (e.g., using `axios` or a custom fetch wrapper) that automatically attaches the user's authentication token to outgoing requests and handles token refresh logic.
17: - **Role-Based Query Enabling**: Use the `enabled` option in `useQuery` to conditionally enable or disable queries based on the user's role.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 29.6
22: **Title**: Secure Authentication-Aware Queries
23: **Description**: Integrate authentication with data fetching by creating an auth interceptor for automatic token refresh and implementing role-based query enabling using user roles from the Users collection.
24: **Dependencies**: [29.5]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Auth Interceptor**: An authentication interceptor is created and applied to all relevant queries.
29: 2.  **Role-Based Queries**: The `enabled` option is used to restrict access to queries based on user roles.
30: 3.  **Testing**:
31:     - Log in as a user with a specific role and verify that they can only access the data they are authorized to see.
32:     - Attempt to access a protected query without being logged in and verify that the request is blocked.
33:     - Simulate a token expiration and verify that the auth interceptor successfully refreshes the token and retries the original request.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/07_refactor_table_data_fetching.md">
 1: # Task: Refactor Table Data Fetching
 2: 
 3: ## Overview
 4: This task focuses on optimizing table components by implementing server-side sorting and filtering, adding virtualization for large datasets, integrating Zustand for state persistence, and developing CSV export functionality.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Table for displaying data, with TanStack Query for data fetching.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Table**: For creating tables and data grids.
13: - **TanStack Query**: Core library for data fetching and server state management.
14: - **Zustand**: For client-side state management.
15: - **TanStack Virtual**: For virtualizing large lists and tables.
16: 
17: ### Best Practices
18: - **Server-Side Operations**: For large tables, perform sorting, filtering, and pagination on the server to avoid sending large amounts of data to the client.
19: - **Virtualization**: Use a library like TanStack Virtual to render only the visible rows in a table, which can significantly improve performance for large datasets.
20: - **State Persistence**: Use Zustand to persist table state (e.g., filters, sorting, column order) across page loads.
21: - **CSV Export**: Provide a way for users to export table data to CSV format. This can be done by using the data from the query cache.
22: 
23: ## Task to Complete
24: 
25: ### Task ID: 29.7
26: **Title**: Refactor Table Data Fetching
27: **Description**: Optimize table components by implementing server-side sorting/filtering, adding virtualization for large datasets, integrating Zustand for state persistence, and developing CSV export using query cache data.
28: **Dependencies**: [29.6]
29: **Status**: pending
30: 
31: ## Success Test
32: 1.  **Server-Side Operations**: All tables that display large datasets are updated to use server-side sorting and filtering.
33: 2.  **Virtualization**: TanStack Virtual is implemented for all large tables.
34: 3.  **State Persistence**: The state of all tables is persisted using Zustand.
35: 4.  **CSV Export**: A CSV export button is added to all tables, and it correctly exports the table data.
36: 5.  **Testing**:
37:     - Verify that server-side sorting and filtering are working correctly by inspecting the network requests.
38:     - Scroll through a large table and verify that virtualization is working correctly by inspecting the DOM.
39:     - Change the state of a table (e.g., by applying a filter), reload the page, and verify that the state is restored.
40:     - Export a table to CSV and verify that the data is correct.
41: 
42: ## Progress Report
43: [Agent will fill this section]
44: 
45: ### Completed Tasks:
46: - Task ID [X]: [Status] - [Brief description of what was done]
47: 
48: ### Issues Encountered:
49: - [Document any problems or blockers]
50: 
51: ### Files Modified/Created:
52: - [List all files changed]
53: 
54: ### Ready for Commit: [Yes/No]
55: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/api-and-data-fetching/08_establish_monitoring_and_metrics.md">
 1: # Task: Establish Monitoring and Metrics
 2: 
 3: ## Overview
 4: This task focuses on tracking data-fetching performance by implementing query logging, tracking cache hit/miss ratios, and setting up performance alerts for slow queries.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses TanStack Query for all data fetching, with a focus on server-side rendering (SSR), caching, and optimistic updates.
10: 
11: ### Relevant Libraries & Tools
12: - **TanStack Query**: Core library for data fetching and server state management.
13: - **Sentry, Datadog, or similar**: (Recommended) for performance monitoring and alerting.
14: 
15: ### Best Practices
16: - **Query Logging**: Log all queries in development to help with debugging and performance tuning.
17: - **Cache Hit/Miss Ratio**: Track the cache hit/miss ratio to understand the effectiveness of your caching strategy.
18: - **Performance Alerts**: Set up alerts for slow queries so that you can proactively address performance issues.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 29.8
23: **Title**: Establish Monitoring and Metrics
24: **Description**: Track data-fetching performance by implementing query logging in development, tracking cache hit/miss ratios, and setting up performance alerts for slow queries, connecting to the existing logging system.
25: **Dependencies**: [29.7]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Query Logging**: Query logging is implemented in the development environment.
30: 2.  **Cache Metrics**: The cache hit/miss ratio is tracked and sent to a monitoring service.
31: 3.  **Performance Alerts**: Alerts are configured to trigger when a query exceeds a certain time threshold.
32: 4.  **Testing**:
33:     - Verify that queries are being logged in the development console.
34:     - Check the monitoring service to confirm that cache metrics are being received.
35:     - Intentionally introduce a slow query and verify that a performance alert is triggered.
36: 
37: ## Progress Report
38: [Agent will fill this section]
39: 
40: ### Completed Tasks:
41: - Task ID [X]: [Status] - [Brief description of what was done]
42: 
43: ### Issues Encountered:
44: - [Document any problems or blockers]
45: 
46: ### Files Modified/Created:
47: - [List all files changed]
48: 
49: ### Ready for Commit: [Yes/No]
50: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/ci-cd-and-deployment/01_dockerfile_security_audit.md">
 1: # Task: Dockerfile Security Audit
 2: 
 3: ## Overview
 4: This task involves a thorough security audit of all Dockerfiles in the project. The goal is to identify and remediate any security vulnerabilities and to ensure that the Docker images are built according to best practices.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is containerized using Docker for development and deployment.
10: 
11: ### Relevant Libraries & Tools
12: - **Docker**: For containerization.
13: - **Snyk or Trivy**: (Recommended) for container image vulnerability scanning.
14: 
15: ### Best Practices
16: - **Minimal Base Images**: Use minimal base images (e.g., `node:18-alpine`) to reduce the attack surface.
17: - **Non-Root User**: Run the application as a non-root user to limit the potential damage of a container breakout.
18: - **Read-Only Filesystem**: Where possible, run the container with a read-only filesystem to prevent modification of the container's contents.
19: - **Multi-Stage Builds**: Use multi-stage builds to keep the final image small and free of unnecessary build dependencies.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 31.1
24: **Title**: Dockerfile Security Audit
25: **Description**: Review all Dockerfiles for security best practices, including non-root user execution, read-only filesystems, minimized image layers, resource limits, and up-to-date base images. Generate a vulnerability report with remediation steps.
26: **Dependencies**: []
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **Dockerfile Audit**: All Dockerfiles are reviewed and updated to follow security best practices.
31: 2.  **Vulnerability Scan**: A vulnerability scan is performed on all Docker images, and all high-severity vulnerabilities are addressed.
32: 3.  **Testing**:
33:     - The Docker images build successfully after the changes.
34:     - The application runs correctly in the hardened containers.
35:     - The vulnerability scanner reports no high-severity vulnerabilities.
36: 
37: ## Progress Report
38: [Agent will fill this section]
39: 
40: ### Completed Tasks:
41: - Task ID [X]: [Status] - [Brief description of what was done]
42: 
43: ### Issues Encountered:
44: - [Document any problems or blockers]
45: 
46: ### Files Modified/Created:
47: - [List all files changed]
48: 
49: ### Ready for Commit: [Yes/No]
50: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/ci-cd-and-deployment/02_analyze_ci_cd_pipeline.md">
 1: # Task: Analyze CI/CD Pipeline
 2: 
 3: ## Overview
 4: This task involves mapping the existing deployment workflows and identifying any missing checks, particularly those specific to Large Language Models (LLMs), such as automated bias detection and performance benchmarking.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is deployed using a CI/CD pipeline, likely with GitHub Actions.
10: 
11: ### Relevant Libraries & Tools
12: - **GitHub Actions**: (or similar CI/CD tool)
13: - **LLM-specific tools**: (to be researched) for bias detection and performance benchmarking.
14: 
15: ### Best Practices
16: - **Comprehensive CI/CD**: A robust CI/CD pipeline should include steps for linting, testing, security scanning, and building before deploying.
17: - **LLM-Specific Checks**: For applications that use LLMs, it's important to include checks for bias, performance, and prompt injection.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 31.2
22: **Title**: CI/CD Pipeline Analysis
23: **Description**: Map existing deployment workflows and identify missing LLM-specific checks, such as automated bias detection, performance benchmarking, and version control for prompts/datasets.
24: **Dependencies**: [31.1]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Workflow Mapping**: The existing CI/CD pipeline is fully documented, including all steps and their purposes.
29: 2.  **Gap Analysis**: A report is generated that identifies any missing steps in the pipeline, with a focus on LLM-specific checks.
30: 3.  **Recommendations**: A set of recommendations is provided for improving the CI/CD pipeline, including the tools and techniques that can be used to implement the missing checks.
31: 4.  **Testing**:
32:     - The workflow documentation is reviewed for accuracy and completeness.
33:     - The gap analysis and recommendations are reviewed to ensure that they are practical and actionable.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/ci-cd-and-deployment/03_implement_secret_management.md">
 1: # Task: Implement Secret Management
 2: 
 3: ## Overview
 4: This task involves auditing the current secret storage locations, designing and implementing an integration with a dedicated secret management solution like HashiCorp Vault, and ensuring that all secrets are encrypted, rotated, and access is logged.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is deployed using a CI/CD pipeline.
10: 
11: ### Relevant Libraries & Tools
12: - **HashiCorp Vault**: (or similar) for secret management.
13: - **Docker**: For containerization.
14: 
15: ### Best Practices
16: - **Centralized Secret Management**: Use a dedicated secret management tool to store all secrets, rather than scattering them across environment variables and configuration files.
17: - **Encryption at Rest and in Transit**: Ensure that all secrets are encrypted both when they are stored and when they are transmitted over the network.
18: - **Access Control**: Implement strict access control policies to ensure that only authorized applications and users can access secrets.
19: - **Auditing**: Log all access to secrets to provide a clear audit trail.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 31.3
24: **Title**: Secret Management Implementation
25: **Description**: Audit current secret storage locations, design and implement integration with HashiCorp Vault, and ensure secrets are encrypted, rotated, and access is logged.
26: **Dependencies**: [31.1]
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **Secret Audit**: A comprehensive audit of all current secret storage locations is completed.
31: 2.  **Vault Integration**: The application is integrated with HashiCorp Vault for secret management.
32: 3.  **Secret Migration**: All secrets are migrated from their old locations to Vault.
33: 4.  **Testing**:
34:     - Verify that the application can successfully retrieve secrets from Vault.
35:     - Verify that access to secrets is correctly logged.
36:     - Attempt to access a secret with an unauthorized user and verify that the request is denied.
37: 
38: ## Progress Report
39: [Agent will fill this section]
40: 
41: ### Completed Tasks:
42: - Task ID [X]: [Status] - [Brief description of what was done]
43: 
44: ### Issues Encountered:
45: - [Document any problems or blockers]
46: 
47: ### Files Modified/Created:
48: - [List all files changed]
49: 
50: ### Ready for Commit: [Yes/No]
51: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/ci-cd-and-deployment/04_setup_environment_configuration.md">
 1: # Task: Setup Environment Configuration
 2: 
 3: ## Overview
 4: This task involves defining a matrix for environment-specific configurations (dev, staging, production), parameterizing environment variables, and implementing configuration validation tests.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is deployed to multiple environments (development, staging, production).
10: 
11: ### Relevant Libraries & Tools
12: - **Docker**: For containerization.
13: - **dotenv**: (or similar) for managing environment variables.
14: 
15: ### Best Practices
16: - **Environment-Specific Files**: Use separate configuration files for each environment (e.g., `.env.development`, `.env.production`).
17: - **Configuration Validation**: Implement a script that validates the environment configuration on application startup to ensure that all required variables are present and correctly formatted.
18: - **Parameterization**: Avoid hardcoding configuration values. Instead, use environment variables to parameterize the application.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 31.4
23: **Title**: Environment Configuration Setup
24: **Description**: Define a matrix for environment-specific configurations (dev, staging, production), parameterize environment variables, and implement configuration validation tests.
25: **Dependencies**: [31.2, 31.3]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Environment Configuration Matrix**: A document is created that defines the configuration for each environment.
30: 2.  **Parameterized Configuration**: All hardcoded configuration values are replaced with environment variables.
31: 3.  **Configuration Validation**: A validation script is implemented that runs on application startup.
32: 4.  **Testing**:
33:     - The application is deployed to each environment and verified that it is using the correct configuration.
34:     - The configuration validation script is tested by intentionally introducing an invalid configuration and verifying that the application fails to start.
35: 
36: ## Progress Report
37: [Agent will fill this section]
38: 
39: ### Completed Tasks:
40: - Task ID [X]: [Status] - [Brief description of what was done]
41: 
42: ### Issues Encountered:
43: - [Document any problems or blockers]
44: 
45: ### Files Modified/Created:
46: - [List all files changed]
47: 
48: ### Ready for Commit: [Yes/No]
49: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/ci-cd-and-deployment/05_integrate_monitoring.md">
 1: # Task: Integrate Monitoring
 2: 
 3: ## Overview
 4: This task involves implementing container activity logging and setting up a vulnerability alerting system to monitor Docker and CI/CD pipeline security events.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is deployed using a CI/CD pipeline.
10: 
11: ### Relevant Libraries & Tools
12: - **Docker**: For containerization.
13: - **Sentry, Datadog, or similar**: (Recommended) for monitoring and alerting.
14: 
15: ### Best Practices
16: - **Container Logging**: Log all container activity to a centralized logging service.
17: - **Vulnerability Alerting**: Set up alerts to be notified immediately when new vulnerabilities are discovered in your container images or dependencies.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 31.5
22: **Title**: Monitoring Integration
23: **Description**: Implement container activity logging and set up a vulnerability alerting system to monitor Docker and CI/CD pipeline security events.
24: **Dependencies**: [31.1, 31.3]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Container Logging**: All container logs are being sent to a centralized logging service.
29: 2.  **Vulnerability Alerting**: An alerting system is in place to notify the team of new vulnerabilities.
30: 3.  **Testing**:
31:     - Verify that container logs are appearing in the logging service.
32:     - Intentionally introduce a vulnerable dependency and verify that a vulnerability alert is triggered.
33: 
34: ## Progress Report
35: [Agent will fill this section]
36: 
37: ### Completed Tasks:
38: - Task ID [X]: [Status] - [Brief description of what was done]
39: 
40: ### Issues Encountered:
41: - [Document any problems or blockers]
42: 
43: ### Files Modified/Created:
44: - [List all files changed]
45: 
46: ### Ready for Commit: [Yes/No]
47: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/ci-cd-and-deployment/06_document_and_validate_workflows.md">
 1: # Task: Document and Validate Workflows
 2: 
 3: ## Overview
 4: This task involves documenting all updated workflows, including Docker, CI/CD, secret management, and environment configuration, and validating that all enhancements are correctly implemented and reproducible.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is deployed using a CI/CD pipeline.
10: 
11: ### Relevant Libraries & Tools
12: - **Markdown**: For documentation.
13: - **Docker**: For containerization.
14: - **GitHub Actions**: (or similar CI/CD tool)
15: 
16: ### Best Practices
17: - **Clear Documentation**: All workflows should be clearly documented so that new team members can easily understand them.
18: - **Reproducibility**: All workflows should be reproducible, meaning that they can be run multiple times with the same result.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 31.6
23: **Title**: Documentation and Workflow Validation
24: **Description**: Document all updated workflows, including Docker, CI/CD, secret management, and environment configuration. Validate that all enhancements are correctly implemented and reproducible.
25: **Dependencies**: [31.1, 31.2, 31.3, 31.4, 31.5]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Workflow Documentation**: All workflows are documented in a clear and concise manner.
30: 2.  **Workflow Validation**: All workflows are tested to ensure that they are reproducible and working as expected.
31: 3.  **Testing**:
32:     - The documentation is reviewed for accuracy and clarity.
33:     - The workflows are run multiple times to ensure that they are reproducible.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/documentation-and-guidelines/01_implement_automated_typescript_enforcement.md">
 1: # Task: Implement Automated Enforcement of TypeScript Typing Guidelines in Payload
 2: 
 3: ## Overview
 4: This task focuses on setting up and configuring automated linting and documentation generation to enforce TypeScript typing guidelines within the Payload CMS project.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The project emphasizes strong typing and clear documentation to ensure code quality and maintainability.
10: 
11: ### Relevant Libraries & Tools
12: - **ESLint**: For static analysis of code to find problems.
13: - **TypeScript ESLint**: ESLint plugin for TypeScript.
14: - **JSDoc/TSDoc**: For code documentation.
15: 
16: ### Best Practices
17: - **Automated Linting**: Integrate ESLint into the development workflow to automatically catch and fix typing issues.
18: - **Pre-commit Hooks**: Use pre-commit hooks (e.g., with Husky) to run linting and type checks before code is committed.
19: - **CI/CD Integration**: Include a linting step in the CI/CD pipeline to ensure that no code with typing issues is merged into the main branch.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 18
24: **Title**: Implement Automated Enforcement of TypeScript Typing Guidelines in Payload
25: **Description**: Set up and configured automated linting and documentation. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md`.
26: **Dependencies**: []
27: **Status**: in-progress
28: 
29: ## Success Test
30: 1.  **ESLint Configuration**: ESLint is configured with the `typescript-eslint` plugin and rules that enforce the project's typing guidelines.
31: 2.  **Pre-commit Hooks**: Pre-commit hooks are set up to run ESLint on staged files.
32: 3.  **CI/CD Integration**: The CI/CD pipeline is updated to include a linting step that fails the build if any typing issues are found.
33: 4.  **Testing**:
34:     - Intentionally introduce a TypeScript typing error and verify that the pre-commit hook prevents the code from being committed.
35:     - Push a branch with a typing error and verify that the CI/CD pipeline fails at the linting step.
36:     - Verify that the linter correctly identifies and reports on violations of the defined TSDoc/JSDoc standards.
37: 
38: ## Progress Report
39: [Agent will fill this section]
40: 
41: ### Completed Tasks:
42: - Task ID [X]: [Status] - [Brief description of what was done]
43: 
44: ### Issues Encountered:
45: - [Document any problems or blockers]
46: 
47: ### Files Modified/Created:
48: - [List all files changed]
49: 
50: ### Ready for Commit: [Yes/No]
51: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/documentation-and-guidelines/02_enforce_code_documentation_standards.md">
 1: # Task: Enforce Code Documentation Standards (Inline Comments & JSDoc/TSDoc)
 2: 
 3: ## Overview
 4: This task focuses on establishing and enforcing code documentation standards using JSDoc/TSDoc. This will improve the clarity and maintainability of the codebase.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The project emphasizes strong typing and clear documentation to ensure code quality and maintainability.
10: 
11: ### Relevant Libraries & Tools
12: - **JSDoc/TSDoc**: For code documentation.
13: - **ESLint**: For static analysis of code to find problems.
14: 
15: ### Best Practices
16: - **Clear Documentation**: All public functions, classes, and types should have clear and concise JSDoc/TSDoc comments.
17: - **Automated Checks**: Use ESLint to enforce documentation standards and check for missing or incomplete comments.
18: - **Code Review**: Make documentation a part of the code review process.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 19
23: **Title**: Enforce Code Documentation Standards (Inline Comments & JSDoc/TSDoc)
24: **Description**: Established and enforced code documentation standards using JSDoc/TSDoc. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage.
25: **Dependencies**: []
26: **Status**: in-progress
27: 
28: #### Subtasks:
29: - **Subtask ID**: 19.1 - Standards Definition
30:   - Description: Establish clear documentation standards and guidelines
31:   - Status: pending
32: - **Subtask ID**: 19.2 - Documentation Implementation
33:   - Description: Integrate documentation generation into development workflow
34:   - Status: pending
35: - **Subtask ID**: 19.3 - Linting/Pre-commit Setup
36:   - Description: Configure automated documentation checks
37:   - Status: pending
38: - **Subtask ID**: 19.4 - Code Review Integration
39:   - Description: Incorporate documentation verification in peer reviews
40:   - Status: pending
41: - **Subtask ID**: 19.5 - Onboarding & Training
42:   - Description: Educate team on documentation practices
43:   - Status: pending
44: - **Subtask ID**: 19.6 - Compliance Validation
45:   - Description: Implement ongoing documentation audits
46:   - Status: pending
47: 
48: ## Success Test
49: 1.  **Documentation Standards**: A clear set of documentation standards is defined and documented.
50: 2.  **ESLint Configuration**: ESLint is configured to enforce the documentation standards.
51: 3.  **Codebase Update**: All existing code is updated to comply with the new documentation standards.
52: 4.  **Testing**:
53:     - The linter correctly identifies and reports on violations of the documentation standards.
54:     - A code review process is established that includes a check for documentation quality.
55: 
56: ## Progress Report
57: [Agent will fill this section]
58: 
59: ### Completed Tasks:
60: - Task ID [X]: [Status] - [Brief description of what was done]
61: 
62: ### Issues Encountered:
63: - [Document any problems or blockers]
64: 
65: ### Files Modified/Created:
66: - [List all files changed]
67: 
68: ### Ready for Commit: [Yes/No]
69: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/forms-and-validation/01_audit_and_catalog_form_implementations.md">
 1: # Task: Audit and Catalog All Form Implementations Against Project Patterns
 2: 
 3: ## Overview
 4: This task involves a comprehensive audit of all existing form implementations in the codebase. The goal is to catalog each form, assess its compliance with established project patterns, and produce a gap analysis report.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a robust form system built with React Hook Form, Zod for validation, and Zustand for state management.
10: 
11: ### Relevant Libraries & Tools
12: - **React Hook Form**: Core form library.
13: - **Zod**: Schema validation.
14: - **Zustand**: State management for complex forms.
15: 
16: ### Best Practices
17: - **Schema Isolation**: Define separate Zod schemas for each step in multi-step forms and merge them for final validation.
18: - **State Management**: Use `FormProvider` and `useFormContext` for nested form components. Use Zustand for persisting form state across sessions or complex multi-step flows.
19: - **Conditional Fields**: Use `watch` to monitor field values and conditionally render other fields. Unregister fields when they are hidden to avoid validation errors.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 28.1
24: **Title**: Audit and Catalog All Form Implementations Against Project Patterns
25: **Description**: Catalog all form implementations in the codebase, referencing `complex_forms.md` for pattern compliance. Validate multi-step isolation using step schema merging (Section 1), dynamic field arrays with `useFieldArray` (Section 2), and conditional field handling via `watch`/`unregister` (Section 3). Output a gap analysis report with compliance status for each form.
26: **Dependencies**: []
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **Form Catalog**: A comprehensive list of all forms in the application is created, including their location in the codebase and their purpose.
31: 2.  **Compliance Check**: Each form is checked against the patterns defined in `llm_context/forms/complex_forms.md`.
32: 3.  **Gap Analysis Report**: A report is generated that details the compliance status of each form and identifies any deviations from the established patterns.
33: 4.  **Testing**:
34:     - The catalog is reviewed for completeness and accuracy.
35:     - The gap analysis report is reviewed to ensure that it correctly identifies all non-compliant forms and provides clear recommendations for remediation.
36: 
37: ## Progress Report
38: [Agent will fill this section]
39: 
40: ### Completed Tasks:
41: - Task ID [X]: [Status] - [Brief description of what was done]
42: 
43: ### Issues Encountered:
44: - [Document any problems or blockers]
45: 
46: ### Files Modified/Created:
47: - [List all files changed]
48: 
49: ### Ready for Commit: [Yes/No]
50: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/forms-and-validation/02_review_and_validate_form_composition.md">
 1: # Task: Review and Validate Form Composition, State, and Validation Layers
 2: 
 3: ## Overview
 4: This task focuses on assessing all forms for proper validation and state management. The goal is to audit Zod schema refinements, test async validation, and verify error handling.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a robust form system built with React Hook Form, Zod for validation, and Zustand for state management.
10: 
11: ### Relevant Libraries & Tools
12: - **React Hook Form**: Core form library.
13: - **Zod**: Schema validation.
14: - **Zustand**: State management for complex forms.
15: 
16: ### Best Practices
17: - **Zod Refinements**: Use Zod's `.refine()` method to enforce cross-field validation logic.
18: - **Async Validation**: Implement debouncing for async validation to avoid excessive server requests.
19: - **Error Handling**: Provide clear and immediate user feedback for validation errors.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 28.2
24: **Title**: Review and Validate Form Composition, State, and Validation Layers
25: **Description**: Assess all forms for proper validation and state management. Audit Zod schema refinements for cross-field logic (Section 3), test async validation debouncing (Section 5), and verify error handling matches `README.md` UX patterns. Produce a validation deficiency matrix with remediation priorities.
26: **Dependencies**: [28.1]
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **Zod Schema Audit**: All Zod schemas are reviewed to ensure that they correctly implement cross-field validation using `.refine()`.
31: 2.  **Async Validation Testing**: All forms with asynchronous validation are tested to ensure that debouncing is working correctly and that server errors are handled gracefully.
32: 3.  **Error Handling Verification**: The error handling for all forms is tested to ensure that it matches the UX patterns defined in the project's `README.md`.
33: 4.  **Validation Deficiency Matrix**: A document is produced that lists all identified validation issues, their severity, and a prioritized plan for remediation.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/forms-and-validation/03_assess_dynamic_fields_and_file_uploads.md">
 1: # Task: Assess Dynamic Fields and File Upload Workflows
 2: 
 3: ## Overview
 4: This task involves evaluating the implementation of dynamic field arrays and file upload components to ensure they are robust, secure, and provide a good user experience.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a robust form system built with React Hook Form, Zod for validation, and Zustand for state management.
10: 
11: ### Relevant Libraries & Tools
12: - **React Hook Form**: Core form library, specifically `useFieldArray`.
13: - **react-dropzone**: For the file upload UI.
14: - **Payload CMS**: For handling the backend of file uploads.
15: 
16: ### Best Practices
17: - **Dynamic Arrays**: Use the `id` provided by `useFieldArray` as the key for each item in the array to ensure proper re-rendering.
18: - **File Uploads**: Provide immediate feedback to the user, such as upload progress indicators and previews of the selected files. Handle upload errors gracefully.
19: - **Security**: For file uploads, implement server-side validation of file types and sizes, and consider virus scanning.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 28.3
24: **Title**: Assess Dynamic Fields and File Upload Workflows
25: **Description**: Evaluate dynamic field arrays and file upload implementations. Check `useFieldArray` usage (Section 2), conditional fields, and file uploads using `react-dropzone` (Section 6). Integrate Payload upload hooks from `README.md` and add upload progress indicators. Output a standardized upload component with test cases.
26: **Dependencies**: [28.2]
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **`useFieldArray` Audit**: All usages of `useFieldArray` are reviewed to ensure they are correctly implemented, especially in conjunction with conditional fields.
31: 2.  **File Upload Workflow Review**: The end-to-end file upload workflow is tested, from the user selecting a file to the file being successfully stored in the backend.
32: 3.  **Standardized Upload Component**: A standardized, reusable file upload component is created that includes progress indicators, file previews, and error handling.
33: 4.  **Testing**:
34:     - Unit tests are written for the new standardized upload component.
35:     - Integration tests are written to verify the complete file upload workflow.
36:     - Manual testing is performed to ensure a smooth user experience for both dynamic fields and file uploads.
37: 
38: ## Progress Report
39: [Agent will fill this section]
40: 
41: ### Completed Tasks:
42: - Task ID [X]: [Status] - [Brief description of what was done]
43: 
44: ### Issues Encountered:
45: - [Document any problems or blockers]
46: 
47: ### Files Modified/Created:
48: - [List all files changed]
49: 
50: ### Ready for Commit: [Yes/No]
51: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/forms-and-validation/04_review_accessibility_and_ux.md">
 1: # Task: Review Accessibility and User Experience Across All Forms
 2: 
 3: ## Overview
 4: This task involves conducting a thorough accessibility audit of all forms in the application to ensure they comply with WCAG 2.1 AA standards. The goal is to identify and fix any accessibility issues to provide a better user experience for all users.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a robust form system built with React Hook Form, Zod for validation, and Zustand for state management.
10: 
11: ### Relevant Libraries & Tools
12: - **Playwright**: For end-to-end testing, including accessibility checks.
13: - **Axe**: A popular accessibility testing tool that can be integrated with Playwright.
14: 
15: ### Best Practices
16: - **ARIA Roles**: Use appropriate ARIA roles and attributes to make forms accessible to screen readers (e.g., `aria-invalid`, `role="alert"`).
17: - **Keyboard Navigation**: Ensure that all form controls are focusable and can be operated using only the keyboard.
18: - **Contrast Ratios**: Check that all text and UI elements have sufficient color contrast.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 28.4
23: **Title**: Review Accessibility and User Experience Across All Forms
24: **Description**: Perform a WCAG 2.1 AA accessibility audit. Test ARIA roles and alert mechanisms (Section 7), keyboard navigation in multi-step flows, and contrast ratios in error states. Output an accessibility audit report with component-level fixes.
25: **Dependencies**: [28.3]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Accessibility Audit**: A comprehensive accessibility audit is performed on all forms using automated tools and manual testing.
30: 2.  **Audit Report**: A report is generated that details all identified accessibility issues, their severity, and recommended fixes.
31: 3.  **Remediation**: All critical and high-severity accessibility issues are addressed.
32: 4.  **Testing**:
33:     - Automated accessibility tests are added to the CI/CD pipeline to prevent regressions.
34:     - Manual testing is performed with a screen reader to verify that the forms are fully accessible.
35: 
36: ## Progress Report
37: [Agent will fill this section]
38: 
39: ### Completed Tasks:
40: - Task ID [X]: [Status] - [Brief description of what was done]
41: 
42: ### Issues Encountered:
43: - [Document any problems or blockers]
44: 
45: ### Files Modified/Created:
46: - [List all files changed]
47: 
48: ### Ready for Commit: [Yes/No]
49: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/forms-and-validation/05_update_subtasks_and_documentation.md">
 1: # Task: Update Subtasks, Expand Testing, and Synchronize Documentation
 2: 
 3: ## Overview
 4: This task involves updating all form-related subtasks based on the findings from the previous audits, expanding test coverage, and ensuring that all documentation is synchronized with the latest changes.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a robust form system built with React Hook Form, Zod for validation, and Zustand for state management.
10: 
11: ### Relevant Libraries & Tools
12: - **Vitest**: For unit and integration testing.
13: - **Playwright**: For end-to-end testing.
14: - **Taskmaster**: For task management.
15: 
16: ### Best Practices
17: - **Test Coverage**: Aim for high test coverage for all form-related logic, including unit tests for Zod schemas, integration tests for form components, and end-to-end tests for complex user flows.
18: - **Documentation**: Keep all documentation, including `README.md` files and task descriptions, up-to-date with the latest implementation details and best practices.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 28.5
23: **Title**: Update Subtasks, Expand Testing, and Synchronize Documentation
24: **Description**: Based on previous findings, update all subtasks, expand test coverage (Playwright for multi-step flows, Vitest for Zod schema, accessibility regression tests), and synchronize documentation. Map findings to `complex_forms.md`, add new examples to `README.md`, and create a troubleshooting guide.
25: **Dependencies**: [28.4]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Subtask Updates**: All form-related subtasks in Taskmaster are updated to reflect the findings from the audits.
30: 2.  **Expanded Test Coverage**: New tests are added to cover all aspects of the form system, including multi-step flows, Zod schemas, and accessibility.
31: 3.  **Synchronized Documentation**: The `complex_forms.md` and `README.md` files are updated with the latest information, and a new troubleshooting guide is created.
32: 4.  **Testing**:
33:     - All new and existing tests pass in the CI/CD pipeline.
34:     - The updated documentation is reviewed for accuracy and clarity.
35: 
36: ## Progress Report
37: [Agent will fill this section]
38: 
39: ### Completed Tasks:
40: - Task ID [X]: [Status] - [Brief description of what was done]
41: 
42: ### Issues Encountered:
43: - [Document any problems or blockers]
44: 
45: ### Files Modified/Created:
46: - [List all files changed]
47: 
48: ### Ready for Commit: [Yes/No]
49: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/security-and-authentication/01_implement_jwt_revocation.md">
 1: # Task: Implement JWT Revocation Mechanism
 2: 
 3: ## Overview
 4: This task involves creating a mechanism to revoke JSON Web Tokens (JWTs). This is a critical security feature to ensure that compromised or logged-out user tokens cannot be used to access protected resources.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a Payload CMS backend for data management and a Next.js frontend for the user interface. Authentication is handled through JWTs with secure cookies.
10: 
11: ### Relevant Libraries & Tools
12: - **Payload CMS**: Core backend and authentication provider.
13: - **Redis**: (or a similar in-memory store) is recommended for maintaining a blacklist of revoked tokens.
14: 
15: ### Best Practices
16: - **JWT Revocation**: A common pattern is to maintain a blacklist of revoked tokens. When a user logs out or changes their password, their token's unique identifier (e.g., `jti` claim) is added to the blacklist.
17: - **Token Expiry**: The blacklist should have a Time-To-Live (TTL) that matches the JWT's expiration time to prevent the list from growing indefinitely.
18: - **Middleware**: The token validation middleware should be updated to check against the blacklist.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 26.1
23: **Title**: Implement JWT Revocation Mechanism
24: **Description**: Create a JWT token blacklist mechanism using Redis cache and update authentication middleware to check token status.
25: **Dependencies**: None
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Implement Blacklist**: Set up a Redis cache (or alternative) to store revoked JWT identifiers.
30: 2.  **Update Logout**: When a user logs out, their JWT's `jti` is added to the blacklist with a TTL matching the token's expiry.
31: 3.  **Update Middleware**: The authentication middleware is updated to check if a token's `jti` is in the blacklist. If it is, the request is rejected with a 401 Unauthorized status.
32: 4.  **Testing**:
33:     - A user logs in and receives a JWT.
34:     - The user accesses a protected route successfully.
35:     - The user logs out.
36:     - The user attempts to access the protected route again with the same JWT and is denied access.
37: 
38: ## Progress Report
39: [Agent will fill this section]
40: 
41: ### Completed Tasks:
42: - Task ID [X]: [Status] - [Brief description of what was done]
43: 
44: ### Issues Encountered:
45: - [Document any problems or blockers]
46: 
47: ### Files Modified/Created:
48: - [List all files changed]
49: 
50: ### Ready for Commit: [Yes/No]
51: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/security-and-authentication/02_enhance_password_and_cookie_security.md">
 1: # Task: Enhance Password and Cookie Security
 2: 
 3: ## Overview
 4: This task focuses on strengthening the security of user passwords and the cookies used for session management. This involves using a strong hashing algorithm for passwords and configuring secure attributes for cookies.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a Payload CMS backend for data management and a Next.js frontend for the user interface. Authentication is handled through JWTs with secure cookies.
10: 
11: ### Relevant Libraries & Tools
12: - **Payload CMS**: Core backend and authentication provider.
13: - **bcrypt**: A library for hashing passwords.
14: 
15: ### Best Practices
16: - **Password Hashing**: Use a strong, adaptive hashing algorithm like bcrypt with a sufficient cost factor (e.g., 12 or higher) to protect against brute-force attacks.
17: - **Secure Cookies**: Configure cookies with the `HttpOnly` and `SameSite=Strict` attributes. `HttpOnly` prevents client-side scripts from accessing the cookie, mitigating XSS attacks. `SameSite=Strict` prevents the browser from sending the cookie along with cross-site requests, mitigating CSRF attacks.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 26.2
22: **Title**: Enhance Password and Cookie Security
23: **Description**: Implement bcrypt password hashing with a cost factor of 12 and configure HTTP-only, SameSite strict cookies.
24: **Dependencies**: [26.1]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Implement bcrypt Hashing**: The user registration and password reset flows use bcrypt with a cost factor of 12 to hash passwords before storing them in the database.
29: 2.  **Configure Secure Cookies**: All authentication-related cookies are set with the `HttpOnly` and `SameSite=Strict` attributes.
30: 3.  **Testing**:
31:     - Create a new user and verify that the password stored in the database is a bcrypt hash.
32:     - Log in and inspect the session cookie in the browser's developer tools to confirm that the `HttpOnly` and `SameSite` attributes are set correctly.
33:     - Attempt to access the cookie via JavaScript (`document.cookie`) and verify that it is not accessible.
34: 
35: ## Progress Report
36: [Agent will fill this section]
37: 
38: ### Completed Tasks:
39: - Task ID [X]: [Status] - [Brief description of what was done]
40: 
41: ### Issues Encountered:
42: - [Document any problems or blockers]
43: 
44: ### Files Modified/Created:
45: - [List all files changed]
46: 
47: ### Ready for Commit: [Yes/No]
48: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/security-and-authentication/03_apply_rate_limiting_and_input_validation.md">
 1: # Task: Apply Rate Limiting and Input Validation
 2: 
 3: ## Overview
 4: This task involves implementing rate limiting to prevent abuse of API endpoints and ensuring that all user input is validated against a strict schema.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a Payload CMS backend for data management and a Next.js frontend for the user interface. Authentication is handled through JWTs with secure cookies.
10: 
11: ### Relevant Libraries & Tools
12: - **Payload CMS**: Core backend and authentication provider.
13: - **Zod**: For schema validation.
14: - **Token Bucket Algorithm**: A common algorithm for rate limiting. Libraries like `express-rate-limit` can be used.
15: 
16: ### Best Practices
17: - **Rate Limiting**: Apply rate limiting to sensitive endpoints, especially authentication routes, to protect against brute-force attacks and denial-of-service attacks.
18: - **Input Validation**: All data from external sources (API requests, forms) should be validated against a Zod schema to ensure data integrity and prevent injection attacks.
19: 
20: ## Task to Complete
21: 
22: ### Task ID: 26.3
23: **Title**: Apply Rate Limiting and Input Validation
24: **Description**: Integrate a token bucket rate limiter for API routes and create input validation middleware using Zod schemas.
25: **Dependencies**: [26.2]
26: **Status**: pending
27: 
28: ## Success Test
29: 1.  **Implement Rate Limiting**: A rate limiter is applied to all authentication-related API routes (e.g., `/api/auth/login`, `/api/auth/password-reset-request`).
30: 2.  **Implement Input Validation**: A middleware is created that uses Zod schemas to validate the body of all incoming POST and PUT requests.
31: 3.  **Testing**:
32:     - Send multiple requests to a rate-limited endpoint in quick succession and verify that a 429 Too Many Requests error is returned after the limit is exceeded.
33:     - Send a request with an invalid body to an endpoint protected by the validation middleware and verify that a 400 Bad Request error is returned with a descriptive error message.
34:     - Send a valid request and verify that it is processed successfully.
35: 
36: ## Progress Report
37: [Agent will fill this section]
38: 
39: ### Completed Tasks:
40: - Task ID [X]: [Status] - [Brief description of what was done]
41: 
42: ### Issues Encountered:
43: - [Document any problems or blockers]
44: 
45: ### Files Modified/Created:
46: - [List all files changed]
47: 
48: ### Ready for Commit: [Yes/No]
49: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/security-and-authentication/04_refactor_middleware_and_centralize_access_control.md">
 1: # Task: Refactor Middleware and Centralize Access Control
 2: 
 3: ## Overview
 4: This task involves refactoring the existing middleware into modular components and centralizing all access control logic into a single, reusable module. This will improve the maintainability and security of the application.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application uses a Payload CMS backend for data management and a Next.js frontend for the user interface. Authentication is handled through JWTs with secure cookies.
10: 
11: ### Relevant Libraries & Tools
12: - **Payload CMS**: Core backend and authentication provider.
13: 
14: ### Best Practices
15: - **Modular Middleware**: Break down large middleware files into smaller, single-purpose modules (e.g., `authMiddleware.ts`, `rateLimitingMiddleware.ts`). This improves readability and reusability.
16: - **Centralized Access Control**: Create a single module that handles all role-based access control (RBAC) logic. This ensures that access control rules are consistent and easy to manage.
17: - **Audit Logging**: Integrate audit logging to track all access control decisions and other sensitive operations.
18: 
19: ## Task to Complete
20: 
21: ### Task ID: 26.4
22: **Title**: Refactor Middleware and Centralize Access Control
23: **Description**: Refactor authentication, validation, and rate limiting into modular middleware. Implement centralized access control and audit logging.
24: **Dependencies**: [26.3]
25: **Status**: pending
26: 
27: ## Success Test
28: 1.  **Modular Middleware**: The existing `middleware.ts` file is broken down into smaller, more focused middleware modules.
29: 2.  **Centralized RBAC**: A new `rbac.ts` module is created that exports functions for checking user roles and permissions. All access control checks throughout the application are updated to use this module.
30: 3.  **Audit Logging**: An audit logging system is integrated to log all significant events, such as failed login attempts and access control decisions.
31: 4.  **Testing**:
32:     - Unit tests are written for the new RBAC module to verify that it correctly enforces permissions.
33:     - Integration tests are written to verify that the new middleware pipeline works as expected.
34:     - Manually test various user roles and permissions to ensure that access control is working correctly across the application.
35: 
36: ## Progress Report
37: [Agent will fill this section]
38: 
39: ### Completed Tasks:
40: - Task ID [X]: [Status] - [Brief description of what was done]
41: 
42: ### Issues Encountered:
43: - [Document any problems or blockers]
44: 
45: ### Files Modified/Created:
46: - [List all files changed]
47: 
48: ### Ready for Commit: [Yes/No]
49: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="open_tasks/security-and-authentication/05_accessibility_testing_and_docker_hardening.md">
 1: # Task: Accessibility, Testing, and Docker Security Hardening
 2: 
 3: ## Overview
 4: This task focuses on improving the overall quality and security of the application by conducting accessibility testing, implementing automated security tests, and hardening the Docker configuration.
 5: 
 6: ## Context & Information
 7: ### Application Details
 8: - **Stack**: Payload CMS backend with NextJS frontend
 9: - **Architecture**: The application is containerized using Docker for development and deployment.
10: 
11: ### Relevant Libraries & Tools
12: - **Playwright**: For end-to-end testing, including accessibility checks.
13: - **Docker**: For containerization.
14: - **Snyk or Trivy**: (Recommended) for container image vulnerability scanning.
15: 
16: ### Best Practices
17: - **Accessibility (a11y)**: Ensure the application is usable by people with disabilities by following WCAG guidelines. Automated tools can catch many issues, but manual testing is also necessary.
18: - **Security Testing**: Integrate automated security scanning into the CI/CD pipeline to catch vulnerabilities early.
19: - **Docker Security**: Follow best practices for building secure Docker images, such as using minimal base images, running as a non-root user, and scanning for vulnerabilities.
20: 
21: ## Task to Complete
22: 
23: ### Task ID: 26.5
24: **Title**: Accessibility, Testing, and Docker Security Hardening
25: **Description**: Conduct accessibility testing, implement automated security tests, and harden Docker configuration.
26: **Dependencies**: [26.4]
27: **Status**: pending
28: 
29: ## Success Test
30: 1.  **Accessibility Audit**: An accessibility audit is performed on the application's forms and main UI components using a tool like Playwright's built-in accessibility checks or Axe. All critical issues are addressed.
31: 2.  **Automated Security Tests**: Automated security tests are added to the CI/CD pipeline. These could include dependency scanning, static application security testing (SAST), and container vulnerability scanning.
32: 3.  **Docker Hardening**: The application's Dockerfile is updated to follow security best practices, including:
33:     - Using a minimal base image (e.g., `node:18-alpine`).
34:     - Running the application as a non-root user.
35:     - Removing unnecessary packages and files from the final image.
36: 4.  **Testing**:
37:     - The accessibility tests pass in the CI/CD pipeline.
38:     - The security scanning tools do not report any high-severity vulnerabilities.
39:     - The Docker image builds successfully and the application runs correctly in the hardened container.
40: 
41: ## Progress Report
42: [Agent will fill this section]
43: 
44: ### Completed Tasks:
45: - Task ID [X]: [Status] - [Brief description of what was done]
46: 
47: ### Issues Encountered:
48: - [Document any problems or blockers]
49: 
50: ### Files Modified/Created:
51: - [List all files changed]
52: 
53: ### Ready for Commit: [Yes/No]
54: [If Yes, note that original taskmaster entries should be marked complete]
</file>

<file path="payload-backend/.next/server/static/webpack/761622449e9f097a.edge-runtime-webpack.hot-update.json">
1: {"c":[],"r":["middleware","edge-runtime-webpack"],"m":["(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/api/context.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/api/diag.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/api/metrics.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/api/propagation.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/api/trace.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/baggage/context-helpers.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/baggage/internal/baggage-impl.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/baggage/internal/symbol.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/baggage/utils.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/context-api.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/context/NoopContextManager.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/context/context.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/diag-api.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/diag/ComponentLogger.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/diag/consoleLogger.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/diag/internal/logLevelLogger.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/diag/types.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/index.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/internal/global-utils.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/internal/semver.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/metrics-api.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/metrics/Metric.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/metrics/NoopMeter.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/metrics/NoopMeterProvider.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/platform/browser/globalThis.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/propagation-api.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/propagation/NoopTextMapPropagator.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/propagation/TextMapPropagator.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace-api.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/NonRecordingSpan.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/NoopTracer.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/NoopTracerProvider.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/ProxyTracer.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/ProxyTracerProvider.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/SamplingResult.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/context-utils.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/internal/tracestate-impl.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/internal/tracestate-validators.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/internal/utils.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/invalid-span-constants.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/span_kind.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/spancontext-utils.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/status.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/trace/trace_flags.js","(middleware)/../../../Library/pnpm/global/5/.pnpm/@opentelemetry+api@1.9.0/node_modules/@opentelemetry/api/build/esm/version.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/build/webpack/loaders/next-middleware-loader.js?absolutePagePath=%2FUsers%2Fwebdev%2FProjects%2Fcanvas-payloadv3%2Fpayload-backend%2Fsrc%2Fmiddleware.ts&page=%2Fmiddleware&rootDir=%2FUsers%2Fwebdev%2FProjects%2Fcanvas-payloadv3%2Fpayload-backend&matchers=&preferredRegion=&middlewareConfig=e30%3D!","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/compiled/@edge-runtime/cookies/index.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/compiled/cookie/index.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/compiled/p-queue/index.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/compiled/react/cjs/react.react-server.development.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/compiled/react/react.react-server.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/compiled/ua-parser-js/ua-parser.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/api/server.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/app-router-headers.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/hooks-server-context.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/http-access-fallback/http-access-fallback.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/is-next-router-error.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/redirect-error.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/redirect-status-code.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/static-generation-bailout.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/lib/constants.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/lib/metadata/metadata-constants.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/lib/scheduler.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/after/after-context.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/after/after.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/after/builtin-request-context.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/after/index.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/api-utils/index.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/after-task-async-storage-instance.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/after-task-async-storage.external.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/async-local-storage.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/dynamic-rendering.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/async-storage/draft-mode-provider.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/async-storage/request-store.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/async-storage/work-store.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/dynamic-rendering-utils.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/internal-utils.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/cache-handlers/default.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/implicit-tags.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/incremental-cache/tags-manifest.external.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/lazy-result.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/lru-cache.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/trace/constants.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/lib/trace/tracer.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/request/connection.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/request/root-params.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/request/utils.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/revalidation-utils.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/use-cache/handlers.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/adapter.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/error.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/exports/index.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/get-edge-preview-props.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/globals.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/next-url.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/adapters/headers.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/adapters/reflect.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/adapters/request-cookies.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/cookies.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/fetch-event.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/image-response.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/request.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/response.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/url-pattern.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/spec-extension/user-agent.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/utils.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/web/web-on-close.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/get-hostname.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/i18n/detect-domain-locale.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/i18n/normalize-locale-path.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/invariant-error.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/is-thenable.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/page-path/ensure-leading-slash.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/add-locale.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/add-path-prefix.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/add-path-suffix.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/app-paths.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/format-next-pathname-info.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/get-next-pathname-info.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/parse-path.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/path-has-prefix.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/relativize-url.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/remove-path-prefix.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/router/utils/remove-trailing-slash.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/segment.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/shared/lib/utils/reflect-utils.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/experimental/testmode/context.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/experimental/testmode/fetch.js","(middleware)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/experimental/testmode/server-edge.js","(middleware)/./src/middleware.ts","(middleware)/./src/middleware/authentication.ts","(middleware)/./src/middleware/cors.ts","(middleware)/./src/middleware/rateLimiting.ts","(middleware)/./src/middleware/securityHeaders.ts","(shared)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/client/components/app-router-headers.js","(shared)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/async-local-storage.js","(shared)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/work-async-storage-instance.js","(shared)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/work-async-storage.external.js","(shared)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/work-unit-async-storage-instance.js","(shared)/./node_modules/.pnpm/next@15.3.2_@babel+core@7.27.7_@playwright+test@1.50.0_react-dom@19.1.0_react@19.1.0__react@19.1.0_sass@1.77.4/node_modules/next/dist/esm/server/app-render/work-unit-async-storage.external.js","buffer","node:async_hooks",""]}
</file>

<file path="payload-backend/.next/server/app-paths-manifest.json">
1: {}
</file>

<file path="payload-backend/.next/server/interception-route-rewrite-manifest.js">
1: self.__INTERCEPTION_ROUTE_REWRITE_MANIFEST="[]"
</file>

<file path="payload-backend/.next/server/middleware-manifest.json">
1: {
2:   "version": 3,
3:   "middleware": {},
4:   "functions": {},
5:   "sortedMiddleware": []
6: }
</file>

<file path="payload-backend/.next/server/pages-manifest.json">
1: {}
</file>

<file path="payload-backend/.next/server/server-reference-manifest.js">
1: self.__RSC_SERVER_MANIFEST="{\n  \"node\": {},\n  \"edge\": {},\n  \"encryptionKey\": \"process.env.NEXT_SERVER_ACTIONS_ENCRYPTION_KEY\"\n}"
</file>

<file path="payload-backend/.next/server/server-reference-manifest.json">
1: {
2:   "node": {},
3:   "edge": {},
4:   "encryptionKey": "KX4JJklMrE2id3C0v9DuNHIoC6N2BliWYMmkfjra+BM="
5: }
</file>

<file path="payload-backend/.next/types/package.json">
1: {"type": "module"}
</file>

<file path="prompts/architectural_review.md">
 1: Please act as an expert architect and developer for a Next.js application utilizing Payload 3.0, connected to a Postgres database on Supabase. Your primary goal is to prepare and refine tasks for the Taskmaster AI mcp server, ensuring they are comprehensive, context-rich, and adhere to best practices. You have access to a full library of relevant context in the ⁠llm_context folder.
 2: Here's your process:
 3: Phase 1: Holistic Context Assimilation & Initial Review
 4: 	1.	Thorough Context Reading: Begin by meticulously reading and internalizing all information within the ⁠llm_context folder. Develop a holistic understanding of the application's architecture, including:
 5: 	▪	Payload 3.0: Schema definitions, hooks, access control, API endpoints, and custom components.	▪	Next.js: Application structure, data fetching strategies (SSR, SSG, ISR, Client-side), component interactions, routing, and API routes.	▪	Supabase (Postgres): Database schema, RLS policies, functions, triggers, and integration patterns with Payload.	▪	Overall data flow, authentication mechanisms (e.g., Payload's auth, Supabase Auth), authorization, and deployment considerations.	▪	Identify the established best practices and design patterns currently in use across all layers.	2.	Initial Observations & Recommendations: Based on your comprehensive review, identify any:
 6: 	▪	Inconsistencies in naming conventions, data structures, or architectural patterns (e.g., Payload fields not aligning with Supabase columns, inconsistent API route naming).	▪	Areas where best practices could be more rigorously applied (e.g., security vulnerabilities, performance bottlenecks, maintainability improvements, code readability).	▪	Potential points of friction or areas for future improvement in the integration between Payload, Next.js, and Supabase.	▪	Opportunities to simplify complex patterns or enhance clarity in the existing codebase.
 7: Output: Provide a categorized list of these initial observations and recommendations, clearly stating the component(s) affected. Pause for confirmation before proceeding.
 8: Phase 2: Task Contextualization for Taskmaster AI
 9: 	1.	Task-Specific Context Embedding: For each task provided, your objective is to enrich it with all necessary context for the Taskmaster AI mcp server to execute it effectively.
10: 	▪	Identify Relevance: Determine which parts of the ⁠llm_context are directly relevant to the current task.	▪	Embed Directly: Where feasible and concise, embed the most critical context directly into the task description. This includes specific code snippets, schema definitions, API endpoints, configuration details, or relevant Supabase SQL.	▪	Link for Depth: If the relevant context is extensive (e.g., a full file or a large section), provide a concise summary within the task and a clear, precise reference (e.g., ⁠llm_context/payload/collections/Users.ts, ⁠llm_context/supabase/functions/my_function.sql) to the ⁠llm_context folder where the full details can be found.	▪	Break Down Complex Tasks: If a task requires an overwhelming amount of embedded context, or if its scope is too broad for a single, manageable unit for Taskmaster AI, propose breaking it down into smaller, more focused sub-tasks. Each sub-task should then be contextualized individually.
11: Output: For each task, provide a revised task description that includes embedded or linked context. If a task breakdown is recommended, present the proposed sub-tasks with their respective contextualization.
12: Phase 3: Inter-Component Impact Analysis
13: 	1.	Dependency Review: For every recommendation, update, or task modification you propose, meticulously review its potential impact on other parts of the application.
14: 	▪	Cross-Layer Implications: Consider how a change in one layer (e.g., a Payload schema change) might affect another (e.g., Next.js forms, Supabase RLS, Taskmaster AI's understanding of data structures, existing API consumers).	▪	Data Flow & API Contracts: Ensure that data flow remains consistent and that API contracts between Payload and Next.js are maintained or updated appropriately.	▪	Authentication & Authorization: Verify that security implications are considered and that access controls (Payload access, Supabase RLS) remain robust and consistent.	▪	User Experience: Briefly consider any potential UI/UX impacts if applicable, especially for Next.js frontend changes.
15: Output: For each proposed change or task, include a concise "Impact Analysis" section detailing potential effects on other components and how these effects are mitigated, addressed, or require further consideration.
16: Throughout this process, prioritize consistency, best practices, and patterns that are easy to understand and maintain. Your goal is to ensure the agent has all the context they need without being overwhelmed, and that all changes contribute to a robust and well-integrated application.
</file>

<file path="prompts/open_hands_agent.md">
 1: You are being assigned a group of related tasks from a larger Payload CMS project with NextJS frontend. Your job is to complete these tasks efficiently and report back your progress.
 2: 
 3: Project Context:
 4: 
 5: This is a Payload CMS application with NextJS frontend
 6: Review the Context & Information section above for specific architectural details, libraries, and best practices
 7: The llm_context/ folder contains additional project documentation you should reference
 8: Follow established code patterns and conventions outlined in the context section
 9: 
10: Your Responsibilities:
11: 
12: Read and understand the context - Thoroughly review the Context & Information section before starting
13: Complete tasks in dependency order - Check dependencies and complete prerequisite tasks first
14: Follow project conventions - Use the architectural patterns, libraries, and best practices specified
15: Test your implementations - Run relevant tests after each significant change
16: Document your work thoroughly - Update the Progress Report section with detailed notes
17: Handle blockers appropriately - If you encounter issues you cannot solve, document them clearly and continue with other tasks
18: 
19: Before You Start:
20: 
21: Review the Context & Information section completely
22: Identify which tasks have dependencies and plan your work order
23: Check if you have access to all required files and systems
24: Note any potential blockers or questions upfront
25: 
26: Working Guidelines:
27: 
28: Code Quality: Prioritize working, tested code over perfect code
29: Error Handling: Implement proper error handling and validation
30: Security: Follow security best practices outlined in the context
31: Performance: Consider performance implications of your implementations
32: Maintainability: Write clean, documented code that others can understand
33: 
34: Progress Reporting Format:
35: Update the Progress Report section with:
36: Completed Tasks:
37: 
38: Task ID [X]: Status - [Brief description of implementation]
39: Files modified: [list specific files]
40: Tests run: [which tests passed/failed]
41: Notes: [any important implementation details]
42: 
43: In Progress:
44: 
45: Task ID [X]: Status - [what you're currently working on]
46: Expected completion: [time estimate]
47: Current blockers: [any issues]
48: 
49: Issues/Blockers:
50: 
51: Task ID [X]: Issue - [detailed description of problem]
52: Attempted solutions: [what you tried]
53: Impact: [how this affects other tasks]
54: Recommendation: [suggested next steps]
55: 
56: Files Modified/Created:
57: 
58: [Full list of all files you've touched]
59: [Include brief description of changes made to each]
60: 
61: Testing Results:
62: 
63: [List tests run and results]
64: [Note any test failures and their status]
65: 
66: Commit Preparation:
67: When all tasks are complete:
68: 
69: Add section: READY FOR COMMIT: Yes
70: Include comprehensive commit message
71: List all taskmaster task IDs that should be marked complete
72: Summarize all changes made
73: 
74: Quality Checklist Before Marking Complete:
75: 
76:  All code follows project conventions from context
77:  Proper error handling implemented
78:  Security best practices applied
79:  Tests written and passing
80:  Documentation updated where needed
81:  No breaking changes introduced
82:  Dependencies properly handled
83: 
84: If You Get Stuck:
85: 
86: Document the specific issue and what you tried
87: Continue with other tasks if possible
88: Provide clear handoff notes for complex issues
89: Suggest alternative approaches if you have ideas
90: 
91: Remember:
92: 
93: Focus on completing working implementations
94: Document everything you do
95: When in doubt, refer back to the context section
96: Quality is important, but completion is the primary goal
</file>

<file path="scripts/merge-tasks.js">
 1: #!/usr/bin/env node
 2: /**
 3:  * scripts/merge-tasks.js
 4:  *
 5:  * Merge fields from original .taskmaster/tasks/tasks.json into tasks-updated.json.
 6:  * Copies description, details, testStrategy, priority, status, metadata and dependencies.
 7:  */
 8: 
 9: const fs = require('fs')
10: const path = require('path')
11: 
12: const originalPath = path.resolve(__dirname, '../.taskmaster/tasks/tasks.json')
13: const updatedPath = path.resolve(__dirname, '../tasks-updated.json')
14: 
15: function mergeTask(original, updated) {
16:   // copy core fields
17:   ;[
18:     'title',
19:     'description',
20:     'details',
21:     'testStrategy',
22:     'priority',
23:     'status',
24:     'dependencies',
25:   ].forEach((key) => {
26:     if (original[key] !== undefined) updated[key] = original[key]
27:   })
28:   // merge metadata
29:   if (original.metadata) updated.metadata = original.metadata
30: 
31:   // merge subtasks by id
32:   if (Array.isArray(original.subtasks) && Array.isArray(updated.subtasks)) {
33:     const origById = Object.fromEntries(original.subtasks.map((st) => [st.id, st]))
34:     updated.subtasks.forEach((st) => {
35:       const o = origById[st.id]
36:       if (o) {
37:         ;[
38:           'title',
39:           'description',
40:           'details',
41:           'testStrategy',
42:           'status',
43:           'dependencies',
44:           'parentTaskId',
45:         ].forEach((k) => {
46:           if (o[k] !== undefined) st[k] = o[k]
47:         })
48:       }
49:     })
50:   }
51:   return updated
52: }
53: 
54: function main() {
55:   const origJson = JSON.parse(fs.readFileSync(originalPath, 'utf-8'))
56:   const updJson = JSON.parse(fs.readFileSync(updatedPath, 'utf-8'))
57: 
58:   const origTasks = origJson.master.tasks
59:   const updTasks = updJson.master.tasks
60: 
61:   const origById = Object.fromEntries(origTasks.map((t) => [t.id, t]))
62: 
63:   const mergedTasks = updTasks.map((u) => {
64:     const o = origById[u.id]
65:     if (o) return mergeTask(o, u)
66:     return u
67:   })
68: 
69:   updJson.master.tasks = mergedTasks
70: 
71:   fs.writeFileSync(updatedPath, JSON.stringify(updJson, null, 2))
72:   console.log('tasks-updated.json merged successfully.')
73: }
74: 
75: main()
</file>

<file path="src/access/index.ts">
  1: import { Access, PayloadRequest } from 'payload';
  2: import { User } from '../payload-types'; // Adjust path as needed
  3: 
  4: /**
  5:  * @typedef {User & { roles?: string[]; locations?: string[]; }}
  6:  */
  7: type UserWithRoles = User & {
  8:   roles?: string[];
  9:   locations?: string[];
 10: };
 11: 
 12: /**
 13:  * Access control function to check if the user is an admin.
 14:  * @param {object} params - The parameters for the access function.
 15:  * @param {PayloadRequest} params.req - The Payload request object.
 16:  * @returns {boolean} True if the user is an admin, false otherwise.
 17:  */
 18: export const isAdmin: Access<any, UserWithRoles> = ({ req }) => {
 19:   return req.user?.roles?.includes('admin') || false;
 20: };
 21: 
 22: /**
 23:  * Access control function to check if the user is a manager.
 24:  * @param {object} params - The parameters for the access function.
 25:  * @param {PayloadRequest} params.req - The Payload request object.
 26:  * @returns {boolean} True if the user is a manager, false otherwise.
 27:  */
 28: export const isManager: Access<any, UserWithRoles> = ({ req }) => {
 29:   return req.user?.roles?.includes('manager') || false;
 30: };
 31: 
 32: /**
 33:  * Access control function to check if the user is a front-of-house employee.
 34:  * @param {object} params - The parameters for the access function.
 35:  * @param {PayloadRequest} params.req - The Payload request object.
 36:  * @returns {boolean} True if the user is a foh_employee, false otherwise.
 37:  */
 38: export const isFohEmployee: Access<any, UserWithRoles> = ({ req }) => {
 39:   return req.user?.roles?.includes('foh_employee') || false;
 40: };
 41: 
 42: /**
 43:  * Access control function to check if the user is a store manager.
 44:  * @param {object} params - The parameters for the access function.
 45:  * @param {PayloadRequest} params.req - The Payload request object.
 46:  * @returns {boolean} True if the user is a store manager, false otherwise.
 47:  */
 48: export const isStoreManager: Access<any, UserWithRoles> = ({ req }) => {
 49:   return req.user?.roles?.includes('store_manager') || false;
 50: };
 51: 
 52: /**
 53:  * Access control function to check if the user is a shift manager.
 54:  * @param {object} params - The parameters for the access function.
 55:  * @param {PayloadRequest} params.req - The Payload request object.
 56:  * @returns {boolean} True if the user is a shift manager, false otherwise.
 57:  */
 58: export const isShiftManager: Access<any, UserWithRoles> = ({ req }) => {
 59:   return req.user?.roles?.includes('shift_manager') || false;
 60: };
 61: 
 62: /**
 63:  * Access control function to check if the user is an admin or a manager.
 64:  * @param {object} params - The parameters for the access function.
 65:  * @param {PayloadRequest} params.req - The Payload request object.
 66:  * @returns {boolean} True if the user is an admin or a manager, false otherwise.
 67:  */
 68: export const isAdminOrManager: Access<any, UserWithRoles> = ({ req }) => {
 69:   return isAdmin({ req }) || isManager({ req });
 70: };
 71: 
 72: /**
 73:  * Access control function to check if the user is an admin or the owner of the document.
 74:  * @param {object} params - The parameters for the access function.
 75:  * @param {PayloadRequest} params.req - The Payload request object.
 76:  * @param {string} [params.id] - The ID of the document.
 77:  * @param {object} [params.doc] - The document object.
 78:  * @returns {boolean} True if the user is an admin or the owner of the document, false otherwise.
 79:  */
 80: export const isAdminOrSelf: Access<any, UserWithRoles> = ({ req, id, doc }) => {
 81:   if (isAdmin({ req })) return true;
 82:   if (req.user && id === req.user.id) return true;
 83:   if (req.user && doc && doc.id === req.user.id) return true; // Assuming doc.id is the user's ID
 84:   return false;
 85: };
 86: 
 87: /**
 88:  * Access control function to check if the user is an admin or has access to the location.
 89:  * @param {object} params - The parameters for the access function.
 90:  * @param {PayloadRequest} params.req - The Payload request object.
 91:  * @param {object} [params.doc] - The document object.
 92:  * @returns {boolean} True if the user is an admin or has access to the document's location, false otherwise.
 93:  */
 94: export const isAdminOrHasLocationAccess: Access<any, UserWithRoles> = ({ req, doc }) => {
 95:   if (isAdmin({ req })) return true;
 96: 
 97:   if (req.user?.locations && doc && doc.location) {
 98:     const docLocationId = typeof doc.location === 'object' ? doc.location.id : doc.location;
 99:     return req.user.locations.some(userLocation => {
100:       const userLocationId = typeof userLocation === 'object' ? userLocation.id : userLocation;
101:       return userLocationId === docLocationId;
102:     });
103:   }
104:   return false;
105: };
106: 
107: /**
108:  * Access control function to check if the user is authenticated.
109:  * @param {object} params - The parameters for the access function.
110:  * @param {PayloadRequest} params.req - The Payload request object.
111:  * @returns {boolean} True if the user is authenticated, false otherwise.
112:  */
113: export const isAuthenticated: Access<any, UserWithRoles> = ({ req }) => {
114:   return !!req.user;
115: };
116: 
117: /**
118:  * Access control function to check if the user can manage users.
119:  * @param {object} params - The parameters for the access function.
120:  * @param {PayloadRequest} params.req - The Payload request object.
121:  * @returns {boolean} True if the user can manage users, false otherwise.
122:  */
123: export const canManageUsers: Access<any, UserWithRoles> = ({ req }) => {
124:   return isAdmin({ req }) || isStoreManager({ req }) || isShiftManager({ req });
125: };
126: 
127: /**
128:  * Access control function to check if the user can read employee ratings.
129:  * Admins and managers can read all ratings. Employees can only see their own ratings.
130:  * @param {object} params - The parameters for the access function.
131:  * @param {PayloadRequest} params.req - The Payload request object.
132:  * @param {string} [params.id] - The ID of the document.
133:  * @param {object} [params.doc] - The document object.
134:  * @returns {boolean} True if the user can read employee ratings, false otherwise.
135:  */
136: export const canReadEmployeeRatings: Access<any, UserWithRoles> = ({ req, id, doc }) => {
137:   if (isAdmin({ req })) return true;
138:   if (isManager({ req })) return true;
139: 
140:   // Employees can only see their own ratings
141:   if (req.user && doc && doc.employee_id && typeof doc.employee_id === 'object' && doc.employee_id.id === req.user.id) {
142:     return true;
143:   }
144:   return false;
145: };
146: 
147: /**
148:  * Access control function to check if the user is the owner of the document or an admin.
149:  * @param {string} ownerField - The name of the field in the document that stores the owner's ID.
150:  * @returns {Access<any, UserWithRoles>} An access control function.
151:  */
152: export const isOwnerOrAdmin = (ownerField: string): Access<any, UserWithRoles> => ({ req, doc }) => {
153:   if (isAdmin({ req })) return true;
154: 
155:   if (req.user && doc && doc[ownerField]) {
156:     const ownerId = typeof doc[ownerField] === 'object' ? doc[ownerField].id : doc[ownerField];
157:     return ownerId === req.user.id;
158:   }
159:   return false;
160: };
</file>

<file path="src/access/rbac.ts">
 1: import { Access } from 'payload'
 2: import { User } from '../payload-types'
 3: 
 4: type UserWithRoles = User & {
 5:   roles?: string[]
 6:   locations?: string[]
 7: }
 8: 
 9: // Define roles and permissions
10: const rolesPermissions = {
11:   admin: ['read', 'create', 'update', 'delete'],
12:   store_manager: ['read', 'create', 'update'],
13:   shift_manager: ['read', 'update'],
14:   foh_employee: ['read'],
15:   user: ['read'],
16: }
17: 
18: // Access control hook to enforce RBAC on collections
19: export const rbacAccess: Access<any, UserWithRoles> = ({ req, operation }) => {
20:   const user = req.user
21:   if (!user || !user.roles) return false
22: 
23:   // Check if any of the user's roles allow the operation
24:   for (const role of user.roles) {
25:     const permissions = rolesPermissions[role]
26:     if (permissions && permissions.includes(operation)) {
27:       return true
28:     }
29:   }
30:   return false
31: }
</file>

<file path="src/app/(frontend)/components/forms/ArrayField.tsx">
 1: import React from 'react'
 2: import { FieldValues, useFieldArray, UseFormReturn } from 'react-hook-form'
 3: import { PayloadField } from '@/app/(frontend)/hooks/useCollectionSchema'
 4: import FieldRegistry from './FieldRegistry'
 5: 
 6: interface ArrayFieldProps<TFormValues extends FieldValues> {
 7:   field: PayloadField
 8:   formMethods: UseFormReturn<TFormValues>
 9: }
10: 
11: export const ArrayField = <TFormValues extends FieldValues>({
12:   field,
13:   formMethods,
14: }: ArrayFieldProps<TFormValues>) => {
15:   const { fields, append, remove } = useFieldArray({
16:     control: formMethods.control,
17:     name: field.name,
18:   })
19: 
20:   if (field.type !== 'array' || !field.fields) {
21:     return null
22:   }
23: 
24:   return (
25:     <div>
26:       <label>{field.label}</label>
27:       {fields.map((item, index) => (
28:         <div key={item.id}>
29:           {field.fields.map((subField) => (
30:             <FieldRegistry
31:               key={subField.name}
32:               field={{
33:                 ...subField,
34:                 name: `${field.name}.${index}.${subField.name}`,
35:               }}
36:               formMethods={formMethods}
37:             />
38:           ))}
39:           <button type="button" onClick={() => remove(index)}>
40:             Remove
41:           </button>
42:         </div>
43:       ))}
44:       <button type="button" onClick={() => append({})}>
45:         Add {field.label}
46:       </button>
47:     </div>
48:   )
49: }
</file>

<file path="src/app/(frontend)/components/forms/DynamicForm.test.tsx">
  1: import React from 'react';
  2: import { render, screen, waitFor } from '@testing-library/react';
  3: import userEvent from '@testing-library/user-event';
  4: import { QueryClient, QueryClientProvider } from '@tanstack/react-query';
  5: import { FormProvider, useForm } from 'react-hook-form';
  6: import DynamicForm from './DynamicForm';
  7: import { useCollectionSchema } from '@/app/(frontend)/hooks/useCollectionSchema';
  8: 
  9: // Mock the useCollectionSchema hook
 10: jest.mock('@/app/(frontend)/hooks/useCollectionSchema');
 11: 
 12: const mockUseCollectionSchema = useCollectionSchema as jest.Mock;
 13: 
 14: const queryClient = new QueryClient({
 15:   defaultOptions: {
 16:     queries: {
 17:       retry: false,
 18:     },
 19:   },
 20: });
 21: 
 22: const Wrapper: React.FC<{ children: React.ReactNode }> = ({ children }) => {
 23:   const methods = useForm();
 24:   return (
 25:     <QueryClientProvider client={queryClient}>
 26:       <FormProvider {...methods}>{children}</FormProvider>
 27:     </QueryClientProvider>
 28:   );
 29: };
 30: 
 31: describe('DynamicForm', () => {
 32:   beforeEach(() => {
 33:     mockUseCollectionSchema.mockClear();
 34:   });
 35: 
 36:   it('renders loading state initially', () => {
 37:     mockUseCollectionSchema.mockReturnValue({
 38:       data: undefined,
 39:       isLoading: true,
 40:       isError: false,
 41:       error: null,
 42:     });
 43: 
 44:     render(
 45:       <Wrapper>
 46:         <DynamicForm collectionSlug="testCollection" onSubmit={jest.fn()} />
 47:       </Wrapper>
 48:     );
 49: 
 50:     expect(screen.getByText('Loading form schema...')).toBeInTheDocument();
 51:   });
 52: 
 53:   it('renders error state if schema fetching fails', () => {
 54:     mockUseCollectionSchema.mockReturnValue({
 55:       data: undefined,
 56:       isLoading: false,
 57:       isError: true,
 58:       error: new Error('Failed to fetch schema'),
 59:     });
 60: 
 61:     render(
 62:       <Wrapper>
 63:         <DynamicForm collectionSlug="testCollection" onSubmit={jest.fn()} />
 64:       </Wrapper>
 65:     );
 66: 
 67:     expect(screen.getByText('Error loading form schema: Failed to fetch schema')).toBeInTheDocument();
 68:   });
 69: 
 70:   it('renders no schema message if schema is empty', () => {
 71:     mockUseCollectionSchema.mockReturnValue({
 72:       data: { fields: [] },
 73:       isLoading: false,
 74:       isError: false,
 75:       error: null,
 76:     });
 77: 
 78:     render(
 79:       <Wrapper>
 80:         <DynamicForm collectionSlug="testCollection" onSubmit={jest.fn()} />
 81:       </Wrapper>
 82:     );
 83: 
 84:     expect(screen.getByText('No schema found for testCollection or no fields defined.')).toBeInTheDocument();
 85:   });
 86: 
 87:   it('renders form fields based on schema and handles submission', async () => {
 88:     const mockSchema = {
 89:       fields: [
 90:         { name: 'name', label: 'Name', type: 'text', required: true },
 91:         { name: 'email', label: 'Email', type: 'email', required: true },
 92:         { name: 'age', label: 'Age', type: 'number', required: false },
 93:       ],
 94:     };
 95:     mockUseCollectionSchema.mockReturnValue({
 96:       data: mockSchema,
 97:       isLoading: false,
 98:       isError: false,
 99:       error: null,
100:     });
101: 
102:     const handleSubmit = jest.fn();
103: 
104:     render(
105:       <Wrapper>
106:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
107:       </Wrapper>
108:     );
109: 
110:     await waitFor(() => {
111:       expect(screen.getByLabelText(/Name/i)).toBeInTheDocument();
112:       expect(screen.getByLabelText(/Email/i)).toBeInTheDocument();
113:       expect(screen.getByLabelText(/Age/i)).toBeInTheDocument();
114:     });
115: 
116:     userEvent.type(screen.getByLabelText(/Name/i), 'John Doe');
117:     userEvent.type(screen.getByLabelText(/Email/i), 'john.doe@example.com');
118:     userEvent.type(screen.getByLabelText(/Age/i), '30');
119: 
120:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
121: 
122:     await waitFor(() => {
123:       expect(handleSubmit).toHaveBeenCalledWith({
124:         name: 'John Doe',
125:         email: 'john.doe@example.com',
126:         age: 30,
127:       });
128:     });
129:   });
130: 
131:   it('displays validation errors for required fields', async () => {
132:     const mockSchema = {
133:       fields: [
134:         { name: 'name', label: 'Name', type: 'text', required: true },
135:         { name: 'email', label: 'Email', type: 'email', required: true },
136:       ],
137:     };
138:     mockUseCollectionSchema.mockReturnValue({
139:       data: mockSchema,
140:       isLoading: false,
141:       isError: false,
142:       error: null,
143:     });
144: 
145:     const handleSubmit = jest.fn();
146: 
147:     render(
148:       <Wrapper>
149:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
150:       </Wrapper>
151:     );
152: 
153:     await waitFor(() => {
154:       expect(screen.getByLabelText(/Name/i)).toBeInTheDocument();
155:     });
156: 
157:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
158: 
159:     await waitFor(() => {
160:       expect(screen.getByText('Name is required')).toBeInTheDocument();
161:       expect(screen.getByText('Email is required')).toBeInTheDocument();
162:     });
163: 
164:     expect(handleSubmit).not.toHaveBeenCalled();
165:   });
166: 
167:   it('handles number field min/max validation', async () => {
168:     const mockSchema = {
169:       fields: [
170:         { name: 'age', label: 'Age', type: 'number', min: 18, max: 65, required: true },
171:       ],
172:     };
173:     mockUseCollectionSchema.mockReturnValue({
174:       data: mockSchema,
175:       isLoading: false,
176:       isError: false,
177:       error: null,
178:     });
179: 
180:     const handleSubmit = jest.fn();
181: 
182:     render(
183:       <Wrapper>
184:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
185:       </Wrapper>
186:     );
187: 
188:     await waitFor(() => {
189:       expect(screen.getByLabelText(/Age/i)).toBeInTheDocument();
190:     });
191: 
192:     userEvent.type(screen.getByLabelText(/Age/i), '10');
193:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
194: 
195:     await waitFor(() => {
196:       expect(screen.getByText('Must be at least 18')).toBeInTheDocument();
197:     });
198: 
199:     userEvent.clear(screen.getByLabelText(/Age/i));
200:     userEvent.type(screen.getByLabelText(/Age/i), '70');
201:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
202: 
203:     await waitFor(() => {
204:       expect(screen.getByText('Must be at most 65')).toBeInTheDocument();
205:     });
206: 
207:     userEvent.clear(screen.getByLabelText(/Age/i));
208:     userEvent.type(screen.getByLabelText(/Age/i), '25');
209:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
210: 
211:     await waitFor(() => {
212:       expect(handleSubmit).toHaveBeenCalledWith({ age: 25 });
213:     });
214:   });
215: 
216:   it('handles text field maxLength validation', async () => {
217:     const mockSchema = {
218:       fields: [
219:         { name: 'bio', label: 'Bio', type: 'text', maxLength: 10, required: true },
220:       ],
221:     };
222:     mockUseCollectionSchema.mockReturnValue({
223:       data: mockSchema,
224:       isLoading: false,
225:       isError: false,
226:       error: null,
227:     });
228: 
229:     const handleSubmit = jest.fn();
230: 
231:     render(
232:       <Wrapper>
233:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
234:       </Wrapper>
235:     );
236: 
237:     await waitFor(() => {
238:       expect(screen.getByLabelText(/Bio/i)).toBeInTheDocument();
239:     });
240: 
241:     userEvent.type(screen.getByLabelText(/Bio/i), 'This is a very long bio that exceeds the limit');
242:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
243: 
244:     await waitFor(() => {
245:       expect(screen.getByText('Must be at most 10 characters')).toBeInTheDocument();
246:     });
247: 
248:     userEvent.clear(screen.getByLabelText(/Bio/i));
249:     userEvent.type(screen.getByLabelText(/Bio/i), 'Short bio');
250:     userEvent.click(screen.getByRole('button', { name: /submit/i }));
251: 
252:     await waitFor(() => {
253:       expect(handleSubmit).toHaveBeenCalledWith({ bio: 'Short bio' });
254:     });
255:   });
256: });
</file>

<file path="src/app/(frontend)/components/forms/FieldRegistry.test.tsx">
  1: import React from 'react';
  2: import { render, screen } from '@testing-library/react';
  3: import { useForm, FormProvider } from 'react-hook-form';
  4: import FieldRegistry from './FieldRegistry';
  5: import { InputField } from './InputField';
  6: import { SelectField } from './SelectField';
  7: 
  8: // Mock child components
  9: jest.mock('./InputField', () => ({
 10:   InputField: jest.fn(() => <div data-testid="InputField" />),
 11: }));
 12: jest.mock('./SelectField', () => ({
 13:   SelectField: jest.fn(() => <div data-testid="SelectField" />),
 14: }));
 15: 
 16: describe('FieldRegistry', () => {
 17:   const Wrapper: React.FC<{ children: React.ReactNode }> = ({ children }) => {
 18:     const methods = useForm();
 19:     return <FormProvider {...methods}>{children}</FormProvider>;
 20:   };
 21: 
 22:   beforeEach(() => {
 23:     (InputField as jest.Mock).mockClear();
 24:     (SelectField as jest.Mock).mockClear();
 25:   });
 26: 
 27:   it('renders InputField for text type', () => {
 28:     const field = { name: 'testText', label: 'Test Text', type: 'text' };
 29:     render(
 30:       <Wrapper>
 31:         <FieldRegistry field={field} formMethods={useForm()} />
 32:       </Wrapper>
 33:     );
 34:     expect(InputField).toHaveBeenCalledWith(
 35:       expect.objectContaining({
 36:         name: 'testText',
 37:         label: 'Test Text',
 38:         type: 'text',
 39:       }),
 40:       {}
 41:     );
 42:     expect(screen.getByTestId('InputField')).toBeInTheDocument();
 43:   });
 44: 
 45:   it('renders InputField for email type', () => {
 46:     const field = { name: 'testEmail', label: 'Test Email', type: 'email' };
 47:     render(
 48:       <Wrapper>
 49:         <FieldRegistry field={field} formMethods={useForm()} />
 50:       </Wrapper>
 51:     );
 52:     expect(InputField).toHaveBeenCalledWith(
 53:       expect.objectContaining({
 54:         name: 'testEmail',
 55:         label: 'Test Email',
 56:         type: 'email',
 57:       }),
 58:       {}
 59:     );
 60:     expect(screen.getByTestId('InputField')).toBeInTheDocument();
 61:   });
 62: 
 63:   it('renders InputField for password type', () => {
 64:     const field = { name: 'testPassword', label: 'Test Password', type: 'password' };
 65:     render(
 66:       <Wrapper>
 67:         <FieldRegistry field={field} formMethods={useForm()} />
 68:       </Wrapper>
 69:     );
 70:     expect(InputField).toHaveBeenCalledWith(
 71:       expect.objectContaining({
 72:         name: 'testPassword',
 73:         label: 'Test Password',
 74:         type: 'password',
 75:       }),
 76:       {}
 77:     );
 78:     expect(screen.getByTestId('InputField')).toBeInTheDocument();
 79:   });
 80: 
 81:   it('renders InputField for number type', () => {
 82:     const field = { name: 'testNumber', label: 'Test Number', type: 'number' };
 83:     render(
 84:       <Wrapper>
 85:         <FieldRegistry field={field} formMethods={useForm()} />
 86:       </Wrapper>
 87:     );
 88:     expect(InputField).toHaveBeenCalledWith(
 89:       expect.objectContaining({
 90:         name: 'testNumber',
 91:         label: 'Test Number',
 92:         type: 'number',
 93:       }),
 94:       {}
 95:     );
 96:     expect(screen.getByTestId('InputField')).toBeInTheDocument();
 97:   });
 98: 
 99:   it('renders SelectField for select type', () => {
100:     const field = { name: 'testSelect', label: 'Test Select', type: 'select', options: ['option1', 'option2'] };
101:     render(
102:       <Wrapper>
103:         <FieldRegistry field={field} formMethods={useForm()} />
104:       </Wrapper>
105:     );
106:     expect(SelectField).toHaveBeenCalledWith(
107:       expect.objectContaining({
108:         name: 'testSelect',
109:         label: 'Test Select',
110:         options: ['option1', 'option2'],
111:       }),
112:       {}
113:     );
114:     expect(screen.getByTestId('SelectField')).toBeInTheDocument();
115:   });
116: 
117:   it('renders message for unknown field type', () => {
118:     const field = { name: 'unknown', label: 'Unknown Field', type: 'unsupported' };
119:     render(
120:       <Wrapper>
121:         <FieldRegistry field={field} formMethods={useForm()} />
122:       </Wrapper>
123:     );
124:     expect(screen.getByText('Unknown or unsupported field type: unsupported')).toBeInTheDocument();
125:   });
126: });
</file>

<file path="src/app/(frontend)/components/forms/InputField.tsx">
 1: 'use client';
 2: 
 3: import React from 'react';
 4: import { useFormContext } from 'react-hook-form';
 5: import { Input } from '@/components/ui/input';
 6: import { Label } from '@/components/ui/label';
 7: import { cn } from '@/lib/utils';
 8: 
 9: interface InputFieldProps extends React.InputHTMLAttributes<HTMLInputElement> {
10:   name: string;
11:   label?: string;
12:   type?: string;
13:   placeholder?: string;
14:   className?: string;
15:   labelClassName?: string;
16: }
17: 
18: /**
19:  * @description A reusable input field component that integrates with react-hook-form.
20:  * @param {InputFieldProps} props
21:  * @returns {React.ReactElement}
22:  */
23: export const InputField = ({
24:   name,
25:   label,
26:   type = 'text',
27:   placeholder,
28:   className,
29:   labelClassName,
30:   ...props
31: }: InputFieldProps) => {
32:   const { register, formState: { errors } } = useFormContext();
33:   const errorMessage = errors[name]?.message as string | undefined;
34: 
35:   return (
36:     <div className={cn('space-y-2', className)}>
37:       {label && (
38:         <Label htmlFor={name} className={labelClassName}>
39:           {label}
40:         </Label>
41:       )}
42:       <Input
43:         id={name}
44:         type={type}
45:         placeholder={placeholder}
46:         {...register(name)}
47:         {...props}
48:       />
49:       {errorMessage && (
50:         <p className="text-sm font-medium text-destructive">{errorMessage}</p>
51:       )}
52:     </div>
53:   );
54: };
</file>

<file path="src/app/(frontend)/components/forms/LoginForm.tsx">
  1: 'use client'
  2: 
  3: import React from 'react'
  4: import { useForm } from 'react-hook-form'
  5: import { zodResolver } from '@hookform/resolvers/zod'
  6: import * as z from 'zod'
  7: import { Input } from '../ui/input'
  8: import { Button } from '../ui/button'
  9: import { useToast } from '../ui/use-toast'
 10: 
 11: const loginSchema = z.object({
 12:   email: z.string().email('Invalid email address'),
 13:   password: z.string().min(8, 'Password must be at least 8 characters'),
 14: })
 15: 
 16: type LoginFormData = z.infer<typeof loginSchema>
 17: 
 18: export function LoginForm() {
 19:   const { toast } = useToast()
 20:   const {
 21:     register,
 22:     handleSubmit,
 23:     formState: { errors, isSubmitting },
 24:   } = useForm<LoginFormData>({
 25:     resolver: zodResolver(loginSchema),
 26:   })
 27: 
 28:   async function onSubmit(data: LoginFormData) {
 29:     try {
 30:       const response = await fetch('/api/auth/login', {
 31:         method: 'POST',
 32:         headers: { 'Content-Type': 'application/json' },
 33:         body: JSON.stringify(data),
 34:       })
 35: 
 36:       const result = await response.json()
 37: 
 38:       if (response.ok) {
 39:         toast({
 40:           title: 'Success',
 41:           description: 'Logged in successfully.',
 42:         })
 43:         // Optionally redirect or update UI here
 44:       } else {
 45:         toast({
 46:           variant: 'destructive',
 47:           title: 'Error',
 48:           description: result.error || 'Login failed',
 49:         })
 50:       }
 51:     } catch (error) {
 52:       toast({
 53:         variant: 'destructive',
 54:         title: 'Error',
 55:         description: 'An unexpected error occurred',
 56:       })
 57:     }
 58:   }
 59: 
 60:   return (
 61:     <form onSubmit={handleSubmit(onSubmit)} className="space-y-4">
 62:       <div>
 63:         <label htmlFor="email" className="block text-sm font-medium text-gray-700">
 64:           Email address
 65:         </label>
 66:         <Input
 67:           id="email"
 68:           type="email"
 69:           autoComplete="email"
 70:           {...register('email')}
 71:           aria-invalid={errors.email ? 'true' : 'false'}
 72:           aria-describedby="email-error"
 73:           className="mt-1 block w-full"
 74:         />
 75:         {errors.email && (
 76:           <p id="email-error" className="mt-1 text-sm text-red-600">
 77:             {errors.email.message}
 78:           </p>
 79:         )}
 80:       </div>
 81:       <div>
 82:         <label htmlFor="password" className="block text-sm font-medium text-gray-700">
 83:           Password
 84:         </label>
 85:         <Input
 86:           id="password"
 87:           type="password"
 88:           autoComplete="current-password"
 89:           {...register('password')}
 90:           aria-invalid={errors.password ? 'true' : 'false'}
 91:           aria-describedby="password-error"
 92:           className="mt-1 block w-full"
 93:         />
 94:         {errors.password && (
 95:           <p id="password-error" className="mt-1 text-sm text-red-600">
 96:             {errors.password.message}
 97:           </p>
 98:         )}
 99:       </div>
100:       <Button type="submit" disabled={isSubmitting}>
101:         Log In
102:       </Button>
103:     </form>
104:   )
105: }
</file>

<file path="src/app/(frontend)/components/forms/PasswordResetForm.tsx">
  1: 'use client'
  2: 
  3: import React from 'react'
  4: import { useForm } from 'react-hook-form'
  5: import { zodResolver } from '@hookform/resolvers/zod'
  6: import * as z from 'zod'
  7: import { Input } from '../ui/input'
  8: import { Button } from '../ui/button'
  9: import { useToast } from '../ui/use-toast'
 10: import { useSearchParams } from 'next/navigation'
 11: 
 12: const passwordResetSchema = z
 13:   .object({
 14:     token: z.string().min(1, 'Token is required'),
 15:     newPassword: z.string().min(8, 'Password must be at least 8 characters'),
 16:     confirmPassword: z.string().min(8, 'Confirm password must be at least 8 characters'),
 17:   })
 18:   .refine((data) => data.newPassword === data.confirmPassword, {
 19:     message: "Passwords don't match",
 20:     path: ['confirmPassword'],
 21:   })
 22: 
 23: type PasswordResetFormData = z.infer<typeof passwordResetSchema>
 24: 
 25: export function PasswordResetForm() {
 26:   const { toast } = useToast()
 27:   const searchParams = useSearchParams()
 28:   const tokenFromUrl = searchParams.get('token') || ''
 29: 
 30:   const {
 31:     register,
 32:     handleSubmit,
 33:     formState: { errors, isSubmitting },
 34:   } = useForm<PasswordResetFormData>({
 35:     resolver: zodResolver(passwordResetSchema),
 36:     defaultValues: {
 37:       token: tokenFromUrl,
 38:     },
 39:   })
 40: 
 41:   async function onSubmit(data: PasswordResetFormData) {
 42:     try {
 43:       const response = await fetch('/api/auth/password-reset', {
 44:         method: 'POST',
 45:         headers: { 'Content-Type': 'application/json' },
 46:         body: JSON.stringify({ token: data.token, newPassword: data.newPassword }),
 47:       })
 48: 
 49:       const result = await response.json()
 50: 
 51:       if (response.ok) {
 52:         toast({
 53:           title: 'Success',
 54:           description: 'Your password has been reset successfully.',
 55:         })
 56:       } else {
 57:         toast({
 58:           variant: 'destructive',
 59:           title: 'Error',
 60:           description: result.error || 'Failed to reset password',
 61:         })
 62:       }
 63:     } catch (error) {
 64:       toast({
 65:         variant: 'destructive',
 66:         title: 'Error',
 67:         description: 'An unexpected error occurred',
 68:       })
 69:     }
 70:   }
 71: 
 72:   return (
 73:     <form onSubmit={handleSubmit(onSubmit)} className="space-y-4">
 74:       <input type="hidden" {...register('token')} />
 75:       <div>
 76:         <label htmlFor="newPassword" className="block text-sm font-medium text-gray-700">
 77:           New Password
 78:         </label>
 79:         <Input
 80:           id="newPassword"
 81:           type="password"
 82:           {...register('newPassword')}
 83:           aria-invalid={errors.newPassword ? 'true' : 'false'}
 84:           aria-describedby="newPassword-error"
 85:           className="mt-1 block w-full"
 86:         />
 87:         {errors.newPassword && (
 88:           <p id="newPassword-error" className="mt-1 text-sm text-red-600">
 89:             {errors.newPassword.message}
 90:           </p>
 91:         )}
 92:       </div>
 93:       <div>
 94:         <label htmlFor="confirmPassword" className="block text-sm font-medium text-gray-700">
 95:           Confirm Password
 96:         </label>
 97:         <Input
 98:           id="confirmPassword"
 99:           type="password"
100:           {...register('confirmPassword')}
101:           aria-invalid={errors.confirmPassword ? 'true' : 'false'}
102:           aria-describedby="confirmPassword-error"
103:           className="mt-1 block w-full"
104:         />
105:         {errors.confirmPassword && (
106:           <p id="confirmPassword-error" className="mt-1 text-sm text-red-600">
107:             {errors.confirmPassword.message}
108:           </p>
109:         )}
110:       </div>
111:       <Button type="submit" disabled={isSubmitting}>
112:         Reset Password
113:       </Button>
114:     </form>
115:   )
116: }
</file>

<file path="src/app/(frontend)/components/forms/PasswordResetRequestForm.tsx">
 1: 'use client'
 2: 
 3: import React from 'react'
 4: import { useForm } from 'react-hook-form'
 5: import { zodResolver } from '@hookform/resolvers/zod'
 6: import * as z from 'zod'
 7: import { Input } from '../ui/input'
 8: import { Button } from '../ui/button'
 9: import { useToast } from '../ui/use-toast'
10: 
11: const passwordResetRequestSchema = z.object({
12:   email: z.string().email('Invalid email address'),
13: })
14: 
15: type PasswordResetRequestFormData = z.infer<typeof passwordResetRequestSchema>
16: 
17: export function PasswordResetRequestForm() {
18:   const { toast } = useToast()
19:   const {
20:     register,
21:     handleSubmit,
22:     formState: { errors, isSubmitting },
23:   } = useForm<PasswordResetRequestFormData>({
24:     resolver: zodResolver(passwordResetRequestSchema),
25:   })
26: 
27:   async function onSubmit(data: PasswordResetRequestFormData) {
28:     try {
29:       const response = await fetch('/api/auth/password-reset-request', {
30:         method: 'POST',
31:         headers: { 'Content-Type': 'application/json' },
32:         body: JSON.stringify({ email: data.email }),
33:       })
34: 
35:       const result = await response.json()
36: 
37:       if (response.ok) {
38:         toast({
39:           title: 'Success',
40:           description: 'If the email exists, a reset link has been sent.',
41:         })
42:       } else {
43:         toast({
44:           variant: 'destructive',
45:           title: 'Error',
46:           description: result.error || 'Failed to send reset link',
47:         })
48:       }
49:     } catch (error) {
50:       toast({
51:         variant: 'destructive',
52:         title: 'Error',
53:         description: 'An unexpected error occurred',
54:       })
55:     }
56:   }
57: 
58:   return (
59:     <form onSubmit={handleSubmit(onSubmit)} className="space-y-4">
60:       <div>
61:         <label htmlFor="email" className="block text-sm font-medium text-gray-700">
62:           Email address
63:         </label>
64:         <Input
65:           id="email"
66:           type="email"
67:           autoComplete="email"
68:           {...register('email')}
69:           aria-invalid={errors.email ? 'true' : 'false'}
70:           aria-describedby="email-error"
71:           className="mt-1 block w-full"
72:         />
73:         {errors.email && (
74:           <p id="email-error" className="mt-1 text-sm text-red-600">
75:             {errors.email.message}
76:           </p>
77:         )}
78:       </div>
79:       <Button type="submit" disabled={isSubmitting}>
80:         Send Reset Link
81:       </Button>
82:     </form>
83:   )
84: }
</file>

<file path="src/app/(frontend)/components/forms/SelectField.tsx">
 1: 'use client';
 2: 
 3: import React from 'react';
 4: import { useFormContext } from 'react-hook-form';
 5: import { Label } from '@/components/ui/label';
 6: import { Select, SelectContent, SelectItem, SelectTrigger, SelectValue } from '@/components/ui/select';
 7: import { cn } from '@/lib/utils';
 8: 
 9: interface SelectFieldProps extends React.SelectHTMLAttributes<HTMLSelectElement> {
10:   name: string;
11:   label?: string;
12:   options: { label: string; value: string }[];
13:   placeholder?: string;
14:   className?: string;
15:   labelClassName?: string;
16: }
17: 
18: /**
19:  * @description A reusable select field component that integrates with react-hook-form.
20:  * @param {SelectFieldProps} props
21:  * @returns {React.ReactElement}
22:  */
23: export const SelectField = ({
24:   name,
25:   label,
26:   options,
27:   placeholder,
28:   className,
29:   labelClassName,
30:   ...props
31: }: SelectFieldProps) => {
32:   const { setValue, formState: { errors }, watch } = useFormContext();
33:   const errorMessage = errors[name]?.message as string | undefined;
34:   const selectedValue = watch(name);
35: 
36:   return (
37:     <div className={cn('space-y-2', className)}>
38:       {label && (
39:         <Label htmlFor={name} className={labelClassName}>
40:           {label}
41:         </Label>
42:       )}
43:       <Select
44:         onValueChange={(value) => setValue(name, value, { shouldValidate: true })}
45:         value={selectedValue}
46:       >
47:         <SelectTrigger className="w-full">
48:           <SelectValue placeholder={placeholder || label} />
49:         </SelectTrigger>
50:         <SelectContent>
51:           {options.map((option) => (
52:             <SelectItem key={option.value} value={option.value}>
53:               {option.label}
54:             </SelectItem>
55:           ))}
56:         </SelectContent>
57:       </Select>
58:       {errorMessage && (
59:         <p className="text-sm font-medium text-destructive">{errorMessage}</p>
60:       )}
61:     </div>
62:   );
63: };
</file>

<file path="src/app/(frontend)/components/forms/TabbedField.tsx">
 1: import React, { useState } from 'react'
 2: import { FieldValues, UseFormReturn } from 'react-hook-form'
 3: import { PayloadField } from '@/app/(frontend)/hooks/useCollectionSchema'
 4: import FieldRegistry from './FieldRegistry'
 5: 
 6: interface TabbedFieldProps<TFormValues extends FieldValues> {
 7:   field: PayloadField
 8:   formMethods: UseFormReturn<TFormValues>
 9: }
10: 
11: export const TabbedField = <TFormValues extends FieldValues>({
12:   field,
13:   formMethods,
14: }: TabbedFieldProps<TFormValues>) => {
15:   const [activeTab, setActiveTab] = useState(0)
16: 
17:   if (field.type !== 'tabs' || !field.tabs) {
18:     return null
19:   }
20: 
21:   const handleTabClick = (index: number) => {
22:     setActiveTab(index)
23:   }
24: 
25:   const handleKeyDown = (event: React.KeyboardEvent<HTMLButtonElement>, index: number) => {
26:     if (event.key === 'ArrowRight') {
27:       const nextTab = (index + 1) % field.tabs.length
28:       setActiveTab(nextTab)
29:       const nextTabElement = document.getElementById(`tab-${nextTab}`)
30:       nextTabElement?.focus()
31:     } else if (event.key === 'ArrowLeft') {
32:       const prevTab = (index - 1 + field.tabs.length) % field.tabs.length
33:       setActiveTab(prevTab)
34:       const prevTabElement = document.getElementById(`tab-${prevTab}`)
35:       prevTabElement?.focus()
36:     }
37:   }
38: 
39:   const progress = ((activeTab + 1) / field.tabs.length) * 100
40: 
41:   return (
42:     <div>
43:       <div style={{ marginBottom: '1rem' }}>
44:         <div style={{ width: '100%', backgroundColor: '#e0e0e0', borderRadius: '4px' }}>
45:           <div
46:             style={{
47:               width: `${progress}%`,
48:               backgroundColor: '#76c7c0',
49:               height: '10px',
50:               borderRadius: '4px',
51:               transition: 'width 0.3s ease-in-out',
52:             }}
53:           />
54:         </div>
55:         <span style={{ marginTop: '0.5rem', display: 'block' }}>
56:           Step {activeTab + 1} of {field.tabs.length}
57:         </span>
58:       </div>
59:       <div role="tablist">
60:         {field.tabs.map((tab, index) => (
61:           <button
62:             key={tab.label}
63:             id={`tab-${index}`}
64:             type="button"
65:             role="tab"
66:             aria-selected={activeTab === index}
67:             onClick={() => handleTabClick(index)}
68:             onKeyDown={(e) => handleKeyDown(e, index)}
69:             tabIndex={activeTab === index ? 0 : -1}
70:           >
71:             {tab.label}
72:           </button>
73:         ))}
74:       </div>
75:       <div role="tabpanel">
76:         {field.tabs[activeTab].fields.map((tabField) => (
77:           <FieldRegistry key={tabField.name} field={tabField} formMethods={formMethods} />
78:         ))}
79:       </div>
80:     </div>
81:   )
82: }
</file>

<file path="src/app/(frontend)/components/ErrorBoundary.tsx">
 1: 'use client';
 2: 
 3: import React, { Component, ErrorInfo, ReactNode } from 'react';
 4: 
 5: interface Props {
 6:   children?: ReactNode;
 7:   fallback?: ReactNode;
 8: }
 9: 
10: interface State {
11:   hasError: boolean;
12: }
13: 
14: /**
15:  * @description ErrorBoundary component to catch and display UI errors.
16:  * @augments {React.Component<Props, State>}
17:  */
18: class ErrorBoundary extends Component<Props, State> {
19:   public state: State = {
20:     hasError: false,
21:   };
22: 
23:   /**
24:    * @description Derives state from an error. Used to update the state so the next render will show the fallback UI.
25:    * @param {Error} _error - The error that was thrown.
26:    * @returns {State} The new state.
27:    */
28:   public static getDerivedStateFromError(_: Error): State {
29:     // Update state so the next render will show the fallback UI.
30:     return { hasError: true };
31:   }
32: 
33:   /**
34:    * @description Catches uncaught errors and logs them.
35:    * @param {Error} error - The error that was thrown.
36:    * @param {ErrorInfo} errorInfo - Information about the error.
37:    * @returns {void}
38:    */
39:   public componentDidCatch(error: Error, errorInfo: ErrorInfo) {
40:     console.error("Uncaught error:", error, errorInfo);
41:   }
42: 
43:   /**
44:    * @description Renders the component or the fallback UI if an error occurred.
45:    * @returns {ReactNode}
46:    */
47:   public render() {
48:     if (this.state.hasError) {
49:       if (this.props.fallback) {
50:         return this.props.fallback;
51:       }
52:       return (
53:         <div className="flex items-center justify-center min-h-screen bg-red-100 text-red-800">
54:           <h1 className="text-2xl font-bold">Something went wrong.</h1>
55:         </div>
56:       );
57:     }
58: 
59:     return this.props.children;
60:   }
61: }
62: 
63: export default ErrorBoundary;
</file>

<file path="src/app/(frontend)/components/LoadingSpinner.tsx">
 1: 'use client';
 2: 
 3: import React from 'react';
 4: 
 5: /**
 6:  * @description A simple loading spinner component.
 7:  * @returns {React.ReactElement}
 8:  */
 9: export const LoadingSpinner: React.FC = () => {
10:   return (
11:     <div className="flex items-center justify-center h-full">
12:       <div className="animate-spin rounded-full h-16 w-16 border-t-2 border-b-2 border-gray-900"></div>
13:     </div>
14:   );
15: };
</file>

<file path="src/app/(frontend)/components/PermissionGate.tsx">
 1: 'use client'
 2: 
 3: import React from 'react'
 4: import { useAuth } from '@/app/(frontend)/hooks/useAuth'
 5: 
 6: type PermissionGateProps = {
 7:   requiredRoles: string[]
 8:   children: React.ReactNode
 9:   fallback?: React.ReactNode
10: }
11: 
12: export function PermissionGate({ requiredRoles, children, fallback = null }: PermissionGateProps) {
13:   const { user, isLoading } = useAuth()
14: 
15:   if (isLoading) {
16:     return <div>Loading...</div>
17:   }
18: 
19:   if (!user) {
20:     return fallback
21:   }
22: 
23:   const hasPermission = requiredRoles.some((role) => user.roles.includes(role))
24: 
25:   if (!hasPermission) {
26:     return fallback
27:   }
28: 
29:   return <>{children}</>
30: }
</file>

<file path="src/app/(frontend)/context/AuthContext.tsx">
 1: 'use client'
 2: 
 3: import React, { createContext, useContext, ReactNode } from 'react'
 4: import create from 'zustand'
 5: import { useQuery, useQueryClient } from '@tanstack/react-query'
 6: import { getUser } from '@/lib/api' // Assume this fetches current user info
 7: 
 8: type User = {
 9:   id: string
10:   email: string
11:   roles: string[]
12:   // Add other user fields as needed
13: }
14: 
15: type AuthState = {
16:   user: User | null
17:   setUser: (user: User | null) => void
18:   login: (email: string, password: string) => Promise<void>
19:   logout: () => Promise<void>
20:   loading: boolean
21: }
22: 
23: const useAuthStore = create<AuthState>((set) => ({
24:   user: null,
25:   setUser: (user) => set({ user }),
26:   login: async (email, password) => {
27:     // Implement login logic calling /api/auth/login
28:     const response = await fetch('/api/auth/login', {
29:       method: 'POST',
30:       headers: { 'Content-Type': 'application/json' },
31:       body: JSON.stringify({ email, password }),
32:     })
33:     if (!response.ok) {
34:       throw new Error('Login failed')
35:     }
36:     // On success, refetch user data
37:     const user = await getUser()
38:     set({ user })
39:   },
40:   logout: async () => {
41:     // Implement logout logic calling /api/auth/logout or clearing cookies
42:     await fetch('/api/auth/logout', { method: 'POST' })
43:     set({ user: null })
44:   },
45:   loading: false,
46: }))
47: 
48: const AuthContext = createContext<AuthState | undefined>(undefined)
49: 
50: export function AuthProvider({ children }: { children: ReactNode }) {
51:   const auth = useAuthStore()
52:   const queryClient = useQueryClient()
53: 
54:   // Fetch user data on mount or when needed
55:   const { data, isLoading } = useQuery<User | null>(['currentUser'], getUser, {
56:     onSuccess: (user) => auth.setUser(user),
57:     staleTime: 1000 * 60 * 5, // 5 minutes
58:   })
59: 
60:   React.useEffect(() => {
61:     auth.setUser(data || null)
62:   }, [data])
63: 
64:   return (
65:     <AuthContext.Provider value={{ ...auth, loading: isLoading }}>{children}</AuthContext.Provider>
66:   )
67: }
68: 
69: export function useAuth() {
70:   const context = useContext(AuthContext)
71:   if (!context) {
72:     throw new Error('useAuth must be used within an AuthProvider')
73:   }
74:   return context
75: }
</file>

<file path="src/app/(frontend)/hooks/useAuth.ts">
 1: import { useQuery, useQueryClient } from '@tanstack/react-query'
 2: import { useCallback } from 'react'
 3: 
 4: type User = {
 5:   id: string
 6:   email: string
 7:   roles: string[]
 8:   // Add other user fields as needed
 9: }
10: 
11: async function fetchCurrentUser(): Promise<User | null> {
12:   const res = await fetch('/api/users/me', { credentials: 'include' })
13:   if (!res.ok) return null
14:   return res.json()
15: }
16: 
17: export function useAuth() {
18:   const queryClient = useQueryClient()
19: 
20:   const {
21:     data: user,
22:     isLoading,
23:     refetch,
24:   } = useQuery<User | null>(['currentUser'], fetchCurrentUser, {
25:     staleTime: 1000 * 60 * 5, // 5 minutes
26:     refetchOnWindowFocus: true,
27:   })
28: 
29:   const login = useCallback(
30:     async (email: string, password: string) => {
31:       const res = await fetch('/api/auth/login', {
32:         method: 'POST',
33:         headers: { 'Content-Type': 'application/json' },
34:         body: JSON.stringify({ email, password }),
35:         credentials: 'include',
36:       })
37:       if (!res.ok) {
38:         throw new Error('Login failed')
39:       }
40:       await refetch()
41:     },
42:     [refetch],
43:   )
44: 
45:   const logout = useCallback(async () => {
46:     await fetch('/api/auth/logout', { method: 'POST', credentials: 'include' })
47:     queryClient.clear()
48:   }, [queryClient])
49: 
50:   return {
51:     user,
52:     isLoading,
53:     login,
54:     logout,
55:   }
56: }
</file>

<file path="src/app/(frontend)/hooks/useAuthQuery.ts">
 1: 'use client';
 2: 
 3: import { QueryKey, useQuery, UseQueryOptions } from '@tanstack/react-query';
 4: import Cookies from 'js-cookie';
 5: import { createQuery } from '@/app/(frontend)/lib/queryFactories';
 6: 
 7: /**
 8:  * @description Options for the useAuthQuery hook.
 9:  * @template TQueryFnData
10:  * @template TError
11:  * @template TData
12:  * @template TQueryKey
13:  * @augments UseQueryOptions<TQueryFnData, TError, TData, TQueryKey>
14:  */
15: interface UseAuthQueryOptions<TQueryFnData, TError, TData, TQueryKey extends QueryKey> extends UseQueryOptions<TQueryFnData, TError, TData, TQueryKey> {
16:   requireAuth?: boolean; // Whether the query requires authentication
17: }
18: 
19: /**
20:  * @description A custom hook for authenticated data fetching with TanStack Query.
21:  * It automatically includes the authentication token from cookies and handles unauthorized responses.
22:  * @template TQueryFnData
23:  * @template TError
24:  * @template TData
25:  * @template TQueryKey
26:  * @param {TQueryKey} queryKey - The query key for TanStack Query.
27:  * @param {(context: { queryKey: TQueryKey; signal?: AbortSignal }) => Promise<TQueryFnData>} queryFn - The function that fetches the data.
28:  * @param {UseAuthQueryOptions<TQueryFnData, TError, TData, TQueryKey>} [options] - Options for the query.
29:  * @returns {import('@tanstack/react-query').UseQueryResult<TData, TError>}
30:  */
31: export const useAuthQuery = <TQueryFnData = unknown, TError = unknown, TData = TQueryFnData, TQueryKey extends QueryKey = QueryKey>(
32:   queryKey: TQueryKey,
33:   queryFn: (context: { queryKey: TQueryKey; signal?: AbortSignal }) => Promise<TQueryFnData>,
34:   options?: UseAuthQueryOptions<TQueryFnData, TError, TData, TQueryKey>,
35: ) => {
36:   const token = Cookies.get('payload-token'); // Assuming the token is stored in a cookie named 'payload-token'
37:   const isAuthenticated = !!token;
38: 
39:   /**
40:    * @description Authenticated query function that adds authorization headers.
41:    * @param {{ queryKey: TQueryKey; signal?: AbortSignal }} context
42:    * @returns {Promise<TQueryFnData>}
43:    */
44:   const authenticatedQueryFn: typeof queryFn = async (context) => {
45:     const headers: HeadersInit = {};
46:     if (token) {
47:       headers['Authorization'] = `Bearer ${token}`;
48:     }
49:     // Modify the original queryFn to include headers if it's a fetch request
50:     // This is a simplified example and might need more robust handling for different queryFn types
51:     if (context.queryKey[0] && typeof context.queryKey[0] === 'string' && context.queryKey[0].startsWith('/')) {
52:       const response = await fetch(context.queryKey[0], {
53:         headers,
54:         signal: context.signal,
55:       });
56:       if (!response.ok) {
57:         // Handle unauthorized or forbidden responses
58:         if (response.status === 401 || response.status === 403) {
59:           // Redirect to login or show an error
60:           console.error('Authentication error', response.status);
61:           // Example: window.location.href = '/login';
62:         }
63:         throw new Error(`Request failed with status ${response.status}`);
64:       }
65:       return response.json();
66:     }
67:     return queryFn(context);
68:   };
69: 
70:   return createQuery<TQueryFnData, TError, TData, TQueryKey>(
71:     queryKey,
72:     authenticatedQueryFn,
73:     {
74:       enabled: options?.requireAuth ? isAuthenticated : true, // Only enable if authenticated and required
75:       ...options,
76:     }
77:   )();
78: };
</file>

<file path="src/app/(frontend)/hooks/useCollectionSchema.ts">
 1: import { useQuery } from '@tanstack/react-query';
 2: 
 3: /**
 4:  * @description Interface for a Payload field, defining its properties and admin configurations.
 5:  */
 6: export interface PayloadField {
 7:   name: string;
 8:   type: string;
 9:   label?: string;
10:   required?: boolean;
11:   unique?: boolean;
12:   maxLength?: number;
13:   min?: number;
14:   max?: number;
15:   options?: { label: string; value: string }[];
16:   relationTo?: string;
17:   hasMany?: boolean;
18:   admin?: {
19:     readOnly?: boolean;
20:     disabled?: boolean;
21:     hidden?: boolean;
22:     description?: string;
23:     position?: 'sidebar' | 'main';
24:     width?: string;
25:     condition?: (data: Record<string, any>, siblingData: Record<string, any>, args: Record<string, any>) => boolean;
26:   };
27:   fields?: PayloadField[]; // For group or array types
28: }
29: 
30: interface CollectionSchema {
31:   slug: string;
32:   fields: PayloadField[];
33: }
34: 
35: /**
36:  * @description Fetches the schema for a given Payload collection.
37:  * @param {string} collectionSlug - The slug of the collection to fetch.
38:  * @returns {Promise<CollectionSchema>} The collection schema.
39:  */
40: const fetchCollectionSchema = async (collectionSlug: string): Promise<CollectionSchema> => {
41:   // In a real application, you would fetch this from your Payload API
42:   // For now, we'll simulate fetching a schema.
43:   // This would typically be an endpoint like /api/payload/schema?collection=users
44:   // or a direct import if the schema is static and available on the frontend.
45:   // For this task, we'll assume a simplified structure for demonstration.
46: 
47:   // Example: Fetching a simplified 'users' schema
48:   if (collectionSlug === 'users') {
49:     return {
50:       slug: 'users',
51:       fields: [
52:         { name: 'first_name', type: 'text', label: 'First Name', required: true, maxLength: 50 },
53:         { name: 'last_name', type: 'text', label: 'Last Name', required: true, maxLength: 50 },
54:         { name: 'email', type: 'email', label: 'Email', required: true, unique: true },
55:         { name: 'password', type: 'password', label: 'Password', required: true },
56:         { name: 'roles', type: 'select', label: 'Roles', hasMany: true, options: [{ label: 'Admin', value: 'admin' }, { label: 'User', value: 'user' }] },
57:         { name: 'locations', type: 'relationship', label: 'Locations', relationTo: 'locations', hasMany: true },
58:       ],
59:     };
60:   } else if (collectionSlug === 'contacts') {
61:     return {
62:       slug: 'contacts',
63:       fields: [
64:         { name: 'first_name', type: 'text', label: 'First Name', required: true, maxLength: 50 },
65:         { name: 'last_name', type: 'text', label: 'Last Name', required: true, maxLength: 50 },
66:         { name: 'email', type: 'email', label: 'Email', required: true, unique: true },
67:         { name: 'phone', type: 'text', label: 'Phone', maxLength: 20 },
68:         { name: 'contact_type', type: 'select', label: 'Contact Type', options: [{ label: 'Customer', value: 'customer' }, { label: 'Vendor', value: 'vendor' }] },
69:       ],
70:     };
71:   }
72:   // Return an empty schema for unknown collections
73:   return { slug: collectionSlug, fields: [] };
74: };
75: 
76: /**
77:  * @description A custom hook to fetch and cache a Payload collection schema.
78:  * @param {string} collectionSlug - The slug of the collection to fetch.
79:  * @returns {import('@tanstack/react-query').UseQueryResult<CollectionSchema, Error>}
80:  */
81: export const useCollectionSchema = (collectionSlug: string) => {
82:   return useQuery<CollectionSchema, Error>({
83:     queryKey: ['collectionSchema', collectionSlug],
84:     queryFn: () => fetchCollectionSchema(collectionSlug),
85:     staleTime: Infinity, // Schemas don't change often
86:   });
87: };
</file>

<file path="src/app/(frontend)/hooks/useCrudMutation.ts">
 1: 'use client';
 2: 
 3: import { useMutation, UseMutationOptions, useQueryClient } from '@tanstack/react-query';
 4: import { createMutation } from '@/app/(frontend)/lib/queryFactories';
 5: 
 6: interface UseCrudMutationOptions<TData, TError, TVariables, TContext> extends UseMutationOptions<TData, TError, TVariables, TContext> {
 7:   invalidateQueryKeys?: string[][];
 8: }
 9: 
10: /**
11:  * @description A custom hook for performing CRUD mutations with TanStack Query, including automatic query invalidation.
12:  * @template TData
13:  * @template TError
14:  * @template TVariables
15:  * @template TContext
16:  * @param {(variables: TVariables) => Promise<TData>} mutationFn - The function that performs the mutation.
17:  * @param {UseCrudMutationOptions<TData, TError, TVariables, TContext>} [options] - Options for the mutation, including query invalidation keys.
18:  * @returns {import('@tanstack/react-query').UseMutationResult<TData, TError, TVariables, TContext>}
19:  */
20: export const useCrudMutation = <TData, TError, TVariables, TContext = unknown>(
21:   mutationFn: (variables: TVariables) => Promise<TData>,
22:   options?: UseCrudMutationOptions<TData, TError, TVariables, TContext>,
23: ) => {
24:   const queryClient = useQueryClient();
25: 
26:   return createMutation<TData, TError, TVariables, TContext>(
27:     mutationFn,
28:     {
29:       onMutate: async (variables) => {
30:         // Cancel any outgoing refetches (so they don't overwrite our optimistic update)
31:         if (options?.invalidateQueryKeys) {
32:           for (const key of options.invalidateQueryKeys) {
33:             await queryClient.cancelQueries({ queryKey: key });
34:           }
35:         }
36: 
37:         // Snapshot the previous value
38:         const previousData = options?.invalidateQueryKeys ? 
39:           queryClient.getQueryData(options.invalidateQueryKeys[0]) : undefined;
40: 
41:         // Optimistically update to the new value (if an optimistic update function is provided)
42:         if (options?.onMutate) {
43:           options.onMutate(variables);
44:         }
45: 
46:         return { previousData };
47:       },
48:       onError: (error, variables, context) => {
49:         // Rollback on failure
50:         if (context?.previousData) {
51:           queryClient.setQueryData(options?.invalidateQueryKeys?.[0] || [], context.previousData);
52:         }
53:         options?.onError?.(error, variables, context);
54:       },
55:       onSettled: (data, error, variables, context) => {
56:         // Always refetch after error or success:
57:         if (options?.invalidateQueryKeys) {
58:           options.invalidateQueryKeys.forEach(key => {
59:             queryClient.invalidateQueries({ queryKey: key });
60:           });
61:         }
62:         options?.onSettled?.(data, error, variables, context);
63:       },
64:       onSuccess: (data, variables, context) => {
65:         options?.onSuccess?.(data, variables, context);
66:       },
67:       ...options,
68:     }
69:   )();
70: };
</file>

<file path="src/app/(frontend)/hooks/useFormState.ts">
 1: 'use client';
 2: 
 3: import { useState, useCallback } from 'react';
 4: import { FieldValues, UseFormReturn } from 'react-hook-form';
 5: 
 6: interface FormStateOptions<TFormValues extends FieldValues> {
 7:   form: UseFormReturn<TFormValues>;
 8:   initialState?: Partial<TFormValues>;
 9: }
10: 
11: /**
12:  * @description A custom hook to manage form state, including dirty status, submission status, and submit count.
13:  * @template TFormValues
14:  * @param {FormStateOptions<TFormValues>} props
15:  * @returns {object}
16:  */
17: export const useFormState = <TFormValues extends FieldValues>({
18:   form,
19:   initialState,
20: }: FormStateOptions<TFormValues>) => {
21:   const [isDirty, setIsDirty] = useState(false);
22:   const [isSubmitting, setIsSubmitting] = useState(false);
23:   const [submitCount, setSubmitCount] = useState(0);
24: 
25:   // Track if any field has been changed from its initial state
26:   const watchAllFields = form.watch();
27:   useCallback(() => {
28:     if (initialState) {
29:       const dirtyFields = form.formState.dirtyFields;
30:       setIsDirty(Object.keys(dirtyFields).length > 0);
31:     } else {
32:       setIsDirty(Object.keys(watchAllFields).length > 0);
33:     }
34:   }, [watchAllFields, form.formState.dirtyFields, initialState, form]);
35: 
36:   const setSubmitting = useCallback((value: boolean) => {
37:     setIsSubmitting(value);
38:   }, []);
39: 
40:   const incrementSubmitCount = useCallback(() => {
41:     setSubmitCount((prev) => prev + 1);
42:   }, []);
43: 
44:   return {
45:     isDirty,
46:     isSubmitting,
47:     submitCount,
48:     setSubmitting,
49:     incrementSubmitCount,
50:     formState: form.formState,
51:     control: form.control,
52:     watch: form.watch,
53:     getValues: form.getValues,
54:     setValue: form.setValue,
55:     reset: form.reset,
56:   };
57: };
</file>

<file path="src/app/(frontend)/hooks/useFormSubmission.ts">
 1: 'use client';
 2: 
 3: import { useMutation, UseMutationOptions } from '@tanstack/react-query';
 4: import { FieldValues } from 'react-hook-form';
 5: 
 6: interface UseFormSubmissionOptions<TData, TError, TVariables extends FieldValues, TContext>
 7:   extends UseMutationOptions<TData, TError, TVariables, TContext> {
 8:   onSuccess?: (data: TData, variables: TVariables, context: TContext | undefined) => Promise<unknown> | void;
 9:   onError?: (error: TError, variables: TVariables, context: TContext | undefined) => Promise<unknown> | void;
10: }
11: 
12: /**
13:  * @description A custom hook for handling form submissions with TanStack Query.
14:  * @template TData
15:  * @template TError
16:  * @template TVariables
17:  * @template TContext
18:  * @param {(variables: TVariables) => Promise<TData>} mutationFn
19:  * @param {UseFormSubmissionOptions<TData, TError, TVariables, TContext>} [options]
20:  * @returns {import('@tanstack/react-query').UseMutationResult<TData, TError, TVariables, TContext>}
21:  */
22: export const useFormSubmission = <TData, TError, TVariables extends FieldValues, TContext = unknown>(
23:   mutationFn: (variables: TVariables) => Promise<TData>,
24:   options?: UseFormSubmissionOptions<TData, TError, TVariables, TContext>,
25: ) => {
26:   return useMutation<TData, TError, TVariables, TContext>({
27:     mutationFn,
28:     ...options,
29:   });
30: };
</file>

<file path="src/app/(frontend)/lib/HydrationProvider.tsx">
 1: 'use client';
 2: 
 3: import { HydrationBoundary, QueryClient, QueryClientProvider } from '@tanstack/react-query';
 4: import { useState } from 'react';
 5: 
 6: interface HydrationProviderProps {
 7:   children: React.ReactNode;
 8:   state: unknown;
 9: }
10: 
11: /**
12:  * @description Provides hydration for TanStack Query state.
13:  * @param {HydrationProviderProps} { children, state }
14:  * @returns {React.ReactElement}
15:  */
16: export const HydrationProvider: React.FC<HydrationProviderProps> = ({
17:   children,
18:   state,
19: }) => {
20:   const [queryClient] = useState(() => new QueryClient());
21: 
22:   return (
23:     <QueryClientProvider client={queryClient}>
24:       <HydrationBoundary state={state}>
25:         {children}
26:       </HydrationBoundary>
27:     </QueryClientProvider>
28:   );
29: };
</file>

<file path="src/app/(frontend)/lib/queryClient.ts">
 1: 'use client';
 2: 
 3: import { QueryClient } from '@tanstack/react-query';
 4: 
 5: export const queryClient = new QueryClient({
 6:   defaultOptions: {
 7:     queries: {
 8:       staleTime: 1000 * 60 * 5, // 5 minutes
 9:       gcTime: 1000 * 60 * 60 * 24, // 24 hours
10:       refetchOnWindowFocus: false,
11:       retry: 3,
12:     },
13:     mutations: {
14:       retry: 0,
15:     },
16:   },
17: });
</file>

<file path="src/app/(frontend)/lib/queryFactories.ts">
 1: import { QueryKey, useQuery, UseQueryOptions, useMutation, UseMutationOptions } from '@tanstack/react-query';
 2: 
 3: interface QueryFactoryOptions<TQueryFnData, TError, TData, TQueryKey extends QueryKey> extends UseQueryOptions<TQueryFnData, TError, TData, TQueryKey> {}
 4: 
 5: interface MutationFactoryOptions<TData, TError, TVariables, TContext> extends UseMutationOptions<TData, TError, TVariables, TContext> {}
 6: 
 7: /**
 8:  * @description Creates a reusable query hook with a predefined query key and function.
 9:  * @template TQueryFnData
10:  * @template TError
11:  * @template TData
12:  * @template TQueryKey
13:  * @param {TQueryKey} queryKey - The query key for TanStack Query.
14:  * @param {(context: { queryKey: TQueryKey; signal?: AbortSignal }) => Promise<TQueryFnData>} queryFn - The function that fetches the data.
15:  * @param {QueryFactoryOptions<TQueryFnData, TError, TData, TQueryKey>} [options] - Options for the query.
16:  * @returns {() => import('@tanstack/react-query').UseQueryResult<TData, TError>}
17:  */
18: export const createQuery = <TQueryFnData = unknown, TError = unknown, TData = TQueryFnData, TQueryKey extends QueryKey = QueryKey>(
19:   queryKey: TQueryKey,
20:   queryFn: (context: { queryKey: TQueryKey; signal?: AbortSignal }) => Promise<TQueryFnData>,
21:   options?: QueryFactoryOptions<TQueryFnData, TError, TData, TQueryKey>,
22: ) => {
23:   return () => useQuery<TQueryFnData, TError, TData, TQueryKey>({
24:     queryKey,
25:     queryFn,
26:     ...options,
27:   });
28: };
29: 
30: /**
31:  * @description Creates a reusable mutation hook with a predefined mutation function.
32:  * @template TData
33:  * @template TError
34:  * @template TVariables
35:  * @template TContext
36:  * @param {(variables: TVariables) => Promise<TData>} mutationFn - The function that performs the mutation.
37:  * @param {MutationFactoryOptions<TData, TError, TVariables, TContext>} [options] - Options for the mutation.
38:  * @returns {() => import('@tanstack/react-query').UseMutationResult<TData, TError, TVariables, TContext>}
39:  */
40: export const createMutation = <TData = unknown, TError = unknown, TVariables = void, TContext = unknown>(
41:   mutationFn: (variables: TVariables) => Promise<TData>,
42:   options?: MutationFactoryOptions<TData, TError, TVariables, TContext>,
43: ) => {
44:   return () => useMutation<TData, TError, TVariables, TContext>({
45:     mutationFn,
46:     ...options,
47:   });
48: };
</file>

<file path="src/app/(frontend)/register/page.tsx">
 1: 'use client'
 2: 
 3: import React from 'react'
 4: import { toast } from '@/components/ui/use-toast'
 5: import DynamicForm from '@/app/(frontend)/components/forms/DynamicForm'
 6: import { registerSchema } from '@/schemas/registerSchema'
 7: import { registerUserAction } from './actions';
 8: import { useCrudMutation } from '@/app/(frontend)/hooks/useCrudMutation';
 9: 
10: /**
11:  * @description The user registration page.
12:  * @returns {React.ReactElement}
13:  */
14: /**
15:  * @description The user registration page.
16:  * @returns {React.ReactElement}
17:  */
18: export default function RegisterPage() {
19:   const { mutate, isPending } = useCrudMutation(registerUserAction, {
20:     onSuccess: (data) => {
21:       if (data.success) {
22:         toast({
23:           title: 'Registration successful!',
24:           description: 'You can now log in with your new account.',
25:         });
26:       } else {
27:         toast({
28:           title: 'Registration failed',
29:           description: data.error || 'An error occurred during registration.',
30:           variant: 'destructive',
31:         });
32:       }
33:     },
34:     onError: (error: Error) => {
35:       toast({
36:         title: 'Registration failed',
37:         description: error.message || 'An error occurred during registration.',
38:         variant: 'destructive',
39:       });
40:     },
41:   });
42: 
43:   /**
44:    * @description Handles the form submission for user registration.
45:    * @param {FieldValues} data - The form data.
46:    * @returns {Promise<void>}
47:    */
48:   const onSubmit = async (data: FieldValues) => {
49:     const formData = new FormData();
50:     for (const key in data) {
51:       formData.append(key, data[key]);
52:     }
53:     mutate(formData);
54:   };
55: 
56:   return (
57:     <div className="flex items-center justify-center min-h-screen">
58:       <div className="w-full max-w-md p-8 space-y-8 bg-white rounded-lg shadow-md">
59:         <div className="text-center">
60:           <h1 className="text-3xl font-bold">Register</h1>
61:           <p className="mt-2 text-sm text-gray-600">Create your account</p>
62:         </div>
63:         <DynamicForm
64:           collectionSlug="users"
65:           onSubmit={onSubmit}
66:           className="space-y-6"
67:         />
68:       </div>
69:     </div>
70:   );
71: }
</file>

<file path="src/app/(frontend)/actions.ts">
 1: 'use server';
 2: 
 3: import { getPayload } from 'payload';
 4: import configPromise from '@payload-config';
 5: import { registerSchema } from '@/schemas/registerSchema';
 6: 
 7: /**
 8:  * @description Registers a new user via a server action.
 9:  * @param {FormData} formData - The form data containing user registration details.
10:  * @returns {Promise<{ success: boolean; user?: any; error?: string }>}
11:  */
12: export async function registerUserAction(formData: FormData) {
13:   const data = Object.fromEntries(formData);
14:   const parsedData = registerSchema.parse(data);
15: 
16:   const payload = await getPayload({
17:     config: configPromise,
18:   });
19: 
20:   try {
21:     const newUser = await payload.create({
22:       collection: 'users',
23:       data: {
24:         email: parsedData.email,
25:         password: parsedData.password,
26:         first_name: parsedData.first_name,
27:         last_name: parsedData.last_name,
28:       },
29:     });
30:     return { success: true, user: newUser };
31:   } catch (error: any) {
32:     return { success: false, error: error.message };
33:   }
34: }
</file>

<file path="src/app/(frontend)/layout.tsx">
 1: import React, { Suspense } from 'react'
 2: import './styles.css'
 3: import { QueryClientProviderWrapper } from './lib/QueryClientProviderWrapper'
 4: import ErrorBoundary from './components/ErrorBoundary'
 5: import { LoadingSpinner } from './components/LoadingSpinner'
 6: 
 7: export const metadata = {
 8:   description: 'A blank template using Payload in a Next.js app.',
 9:   title: 'Payload Blank Template',
10: }
11: 
12: /**
13:  * @description The root layout for the frontend application.
14:  * @param {{ children: React.ReactNode }} props
15:  * @returns {Promise<React.ReactElement>}
16:  */
17: export default async function RootLayout(props: { children: React.ReactNode }) {
18:   const { children } = props
19: 
20:   return (
21:     <html lang="en">
22:       <body>
23:         <QueryClientProviderWrapper>
24:           <ErrorBoundary fallback={<div>Something went wrong in the app!</div>}>
25:             <Suspense fallback={<LoadingSpinner />}>
26:               <main>{children}</main>
27:             </Suspense>
28:           </ErrorBoundary>
29:         </QueryClientProviderWrapper>
30:       </body>
31:     </html>
32:   )
33: }
</file>

<file path="src/app/(payload)/admin/[[...segments]]/not-found.tsx">
 1: /* THIS FILE WAS GENERATED AUTOMATICALLY BY PAYLOAD. */
 2: /* DO NOT MODIFY IT BECAUSE IT COULD BE REWRITTEN AT ANY TIME. */
 3: import type { Metadata } from 'next'
 4: 
 5: import config from '@payload-config'
 6: import { NotFoundPage, generatePageMetadata } from '@payloadcms/next/views'
 7: import { importMap } from '../importMap'
 8: 
 9: type Args = {
10:   params: Promise<{
11:     segments: string[]
12:   }>
13:   searchParams: Promise<{
14:     [key: string]: string | string[]
15:   }>
16: }
17: 
18: /**
19:  * @description Generates metadata for the not found page.
20:  * @param {Args} { params, searchParams }
21:  * @returns {Promise<Metadata>}
22:  */
23: export const generateMetadata = ({ params, searchParams }: Args): Promise<Metadata> =>
24:   generatePageMetadata({ config, params, searchParams })
25: 
26: /**
27:  * @description The not found page component.
28:  * @param {Args} { params, searchParams }
29:  * @returns {React.ReactElement}
30:  */
31: const NotFound = ({ params, searchParams }: Args) =>
32:   NotFoundPage({ config, params, searchParams, importMap })
33: 
34: export default NotFound
</file>

<file path="src/app/(payload)/admin/[[...segments]]/page.tsx">
 1: /* THIS FILE WAS GENERATED AUTOMATICALLY BY PAYLOAD. */
 2: /* DO NOT MODIFY IT BECAUSE IT COULD BE REWRITTEN AT ANY TIME. */
 3: import type { Metadata } from 'next'
 4: 
 5: import config from '@payload-config'
 6: import { RootPage, generatePageMetadata } from '@payloadcms/next/views'
 7: import { importMap } from '../importMap'
 8: 
 9: type Args = {
10:   params: Promise<{
11:     segments: string[]
12:   }>
13:   searchParams: Promise<{
14:     [key: string]: string | string[]
15:   }>
16: }
17: 
18: /**
19:  * @description Generates metadata for the admin page.
20:  * @param {Args} { params, searchParams }
21:  * @returns {Promise<Metadata>}
22:  */
23: export const generateMetadata = ({ params, searchParams }: Args): Promise<Metadata> =>
24:   generatePageMetadata({ config, params, searchParams })
25: 
26: /**
27:  * @description The admin page component.
28:  * @param {Args} { params, searchParams }
29:  * @returns {React.ReactElement}
30:  */
31: const Page = ({ params, searchParams }: Args) =>
32:   RootPage({ config, params, searchParams, importMap })
33: 
34: export default Page
</file>

<file path="src/app/(payload)/admin/importMap.js">
 1: import { RscEntryLexicalCell as RscEntryLexicalCell_44fe37237e0ebf4470c9990d8cb7b07e } from '@payloadcms/richtext-lexical/rsc'
 2: import { RscEntryLexicalField as RscEntryLexicalField_44fe37237e0ebf4470c9990d8cb7b07e } from '@payloadcms/richtext-lexical/rsc'
 3: import { LexicalDiffComponent as LexicalDiffComponent_44fe37237e0ebf4470c9990d8cb7b07e } from '@payloadcms/richtext-lexical/rsc'
 4: import { InlineToolbarFeatureClient as InlineToolbarFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
 5: import { HorizontalRuleFeatureClient as HorizontalRuleFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
 6: import { UploadFeatureClient as UploadFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
 7: import { BlockquoteFeatureClient as BlockquoteFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
 8: import { RelationshipFeatureClient as RelationshipFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
 9: import { LinkFeatureClient as LinkFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
10: import { ChecklistFeatureClient as ChecklistFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
11: import { OrderedListFeatureClient as OrderedListFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
12: import { UnorderedListFeatureClient as UnorderedListFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
13: import { IndentFeatureClient as IndentFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
14: import { AlignFeatureClient as AlignFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
15: import { HeadingFeatureClient as HeadingFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
16: import { ParagraphFeatureClient as ParagraphFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
17: import { InlineCodeFeatureClient as InlineCodeFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
18: import { SuperscriptFeatureClient as SuperscriptFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
19: import { SubscriptFeatureClient as SubscriptFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
20: import { StrikethroughFeatureClient as StrikethroughFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
21: import { UnderlineFeatureClient as UnderlineFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
22: import { BoldFeatureClient as BoldFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
23: import { ItalicFeatureClient as ItalicFeatureClient_e70f5e05f09f93e00b997edb1ef0c864 } from '@payloadcms/richtext-lexical/client'
24: import { S3ClientUploadHandler as S3ClientUploadHandler_f97aa6c64367fa259c5bc0567239ef24 } from '@payloadcms/storage-s3/client'
25: 
26: export const importMap = {
27:   "@payloadcms/richtext-lexical/rsc#RscEntryLexicalCell": RscEntryLexicalCell_44fe37237e0ebf4470c9990d8cb7b07e,
28:   "@payloadcms/richtext-lexical/rsc#RscEntryLexicalField": RscEntryLexicalField_44fe37237e0ebf4470c9990d8cb7b07e,
29:   "@payloadcms/richtext-lexical/rsc#LexicalDiffComponent": LexicalDiffComponent_44fe37237e0ebf4470c9990d8cb7b07e,
30:   "@payloadcms/richtext-lexical/client#InlineToolbarFeatureClient": InlineToolbarFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
31:   "@payloadcms/richtext-lexical/client#HorizontalRuleFeatureClient": HorizontalRuleFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
32:   "@payloadcms/richtext-lexical/client#UploadFeatureClient": UploadFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
33:   "@payloadcms/richtext-lexical/client#BlockquoteFeatureClient": BlockquoteFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
34:   "@payloadcms/richtext-lexical/client#RelationshipFeatureClient": RelationshipFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
35:   "@payloadcms/richtext-lexical/client#LinkFeatureClient": LinkFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
36:   "@payloadcms/richtext-lexical/client#ChecklistFeatureClient": ChecklistFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
37:   "@payloadcms/richtext-lexical/client#OrderedListFeatureClient": OrderedListFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
38:   "@payloadcms/richtext-lexical/client#UnorderedListFeatureClient": UnorderedListFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
39:   "@payloadcms/richtext-lexical/client#IndentFeatureClient": IndentFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
40:   "@payloadcms/richtext-lexical/client#AlignFeatureClient": AlignFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
41:   "@payloadcms/richtext-lexical/client#HeadingFeatureClient": HeadingFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
42:   "@payloadcms/richtext-lexical/client#ParagraphFeatureClient": ParagraphFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
43:   "@payloadcms/richtext-lexical/client#InlineCodeFeatureClient": InlineCodeFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
44:   "@payloadcms/richtext-lexical/client#SuperscriptFeatureClient": SuperscriptFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
45:   "@payloadcms/richtext-lexical/client#SubscriptFeatureClient": SubscriptFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
46:   "@payloadcms/richtext-lexical/client#StrikethroughFeatureClient": StrikethroughFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
47:   "@payloadcms/richtext-lexical/client#UnderlineFeatureClient": UnderlineFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
48:   "@payloadcms/richtext-lexical/client#BoldFeatureClient": BoldFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
49:   "@payloadcms/richtext-lexical/client#ItalicFeatureClient": ItalicFeatureClient_e70f5e05f09f93e00b997edb1ef0c864,
50:   "@payloadcms/storage-s3/client#S3ClientUploadHandler": S3ClientUploadHandler_f97aa6c64367fa259c5bc0567239ef24
51: }
</file>

<file path="src/app/(payload)/api/auth/login/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import bcrypt from 'bcrypt'
 3: import { getPayloadClient } from '@/lib/payloadClient'
 4: 
 5: export async function POST(request: NextRequest) {
 6:   try {
 7:     const { email, password } = await request.json()
 8: 
 9:     if (!email || typeof email !== 'string' || !password || typeof password !== 'string') {
10:       return NextResponse.json({ error: 'Invalid email or password' }, { status: 400 })
11:     }
12: 
13:     const payload = getPayloadClient()
14: 
15:     // Find user by email
16:     const users = await payload.find({
17:       collection: 'users',
18:       where: {
19:         email: {
20:           equals: email.toLowerCase(),
21:         },
22:       },
23:       limit: 1,
24:     })
25: 
26:     if (!users.docs.length) {
27:       return NextResponse.json({ error: 'Invalid credentials' }, { status: 401 })
28:     }
29: 
30:     const user = users.docs[0]
31: 
32:     // Verify password
33:     const passwordMatch = await bcrypt.compare(password, user.password)
34:     if (!passwordMatch) {
35:       return NextResponse.json({ error: 'Invalid credentials' }, { status: 401 })
36:     }
37: 
38:     // Generate JWT token or use Payload session (depending on auth strategy)
39:     // For this example, assume JWT token generation here
40:     const token = await payload.createJWT(user.id)
41: 
42:     // Set HttpOnly cookie with token
43:     const response = NextResponse.json({ message: 'Login successful' })
44:     response.cookies.set('token', token, {
45:       httpOnly: true,
46:       secure: process.env.NODE_ENV === 'production',
47:       sameSite: 'strict',
48:       path: '/',
49:       maxAge: 60 * 60 * 24 * 7, // 7 days
50:     })
51: 
52:     return response
53:   } catch (error) {
54:     console.error('Login error:', error)
55:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
56:   }
57: }
</file>

<file path="src/app/(payload)/api/auth/logout/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: 
 3: const TOKEN_COOKIE_NAME = 'token'
 4: const REFRESH_TOKEN_COOKIE = 'refreshToken'
 5: 
 6: export async function POST(request: NextRequest) {
 7:   try {
 8:     // Clear authentication cookies
 9:     const response = NextResponse.json({ message: 'Logged out successfully' })
10:     response.cookies.set(TOKEN_COOKIE_NAME, '', {
11:       httpOnly: true,
12:       secure: process.env.NODE_ENV === 'production',
13:       sameSite: 'strict',
14:       path: '/',
15:       maxAge: 0,
16:     })
17:     response.cookies.set(REFRESH_TOKEN_COOKIE, '', {
18:       httpOnly: true,
19:       secure: process.env.NODE_ENV === 'production',
20:       sameSite: 'strict',
21:       path: '/',
22:       maxAge: 0,
23:     })
24: 
25:     // Optionally revoke tokens in backend store (e.g., Redis blacklist)
26: 
27:     return response
28:   } catch (error) {
29:     console.error('Logout error:', error)
30:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
31:   }
32: }
</file>

<file path="src/app/(payload)/api/auth/password-reset/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import bcrypt from 'bcrypt'
 3: import { getPayloadClient } from '@/lib/payloadClient'
 4: 
 5: export async function POST(request: NextRequest) {
 6:   try {
 7:     const { token, newPassword } = await request.json()
 8: 
 9:     if (!token || typeof token !== 'string') {
10:       return NextResponse.json({ error: 'Invalid or missing token' }, { status: 400 })
11:     }
12:     if (!newPassword || typeof newPassword !== 'string' || newPassword.length < 8) {
13:       return NextResponse.json({ error: 'Invalid or missing new password' }, { status: 400 })
14:     }
15: 
16:     const payload = getPayloadClient()
17: 
18:     // Find user by reset token and check expiration
19:     const users = await payload.find({
20:       collection: 'users',
21:       where: {
22:         resetPasswordToken: {
23:           equals: token,
24:         },
25:         resetPasswordExpires: {
26:           greater_than: new Date().toISOString(),
27:         },
28:       },
29:       limit: 1,
30:     })
31: 
32:     if (!users.docs.length) {
33:       return NextResponse.json({ error: 'Invalid or expired token' }, { status: 400 })
34:     }
35: 
36:     const user = users.docs[0]
37: 
38:     // Hash new password
39:     const hashedPassword = await bcrypt.hash(newPassword, 12)
40: 
41:     // Update user password and clear reset token fields
42:     await payload.update({
43:       collection: 'users',
44:       id: user.id,
45:       data: {
46:         password: hashedPassword,
47:         resetPasswordToken: null,
48:         resetPasswordExpires: null,
49:       },
50:     })
51: 
52:     return NextResponse.json({ message: 'Password has been reset successfully' })
53:   } catch (error) {
54:     console.error('Password reset error:', error)
55:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
56:   }
57: }
</file>

<file path="src/app/(payload)/api/auth/password-reset-request/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import crypto from 'crypto'
 3: import { sendPasswordResetEmail } from '@/lib/email'
 4: import { getPayloadClient } from '@/lib/payloadClient'
 5: import { addMinutes, isAfter } from 'date-fns'
 6: 
 7: const TOKEN_EXPIRATION_MINUTES = 60 // 1 hour expiration
 8: 
 9: export async function POST(request: NextRequest) {
10:   try {
11:     const { email } = await request.json()
12: 
13:     if (!email || typeof email !== 'string') {
14:       return NextResponse.json({ error: 'Invalid email' }, { status: 400 })
15:     }
16: 
17:     const payload = getPayloadClient()
18: 
19:     // Find user by email
20:     const users = await payload.find({
21:       collection: 'users',
22:       where: {
23:         email: {
24:           equals: email.toLowerCase(),
25:         },
26:       },
27:       limit: 1,
28:     })
29: 
30:     if (!users.docs.length) {
31:       // To prevent user enumeration, respond with success even if user not found
32:       return NextResponse.json({ message: 'If the email exists, a reset link has been sent.' })
33:     }
34: 
35:     const user = users.docs[0]
36: 
37:     // Generate secure token
38:     const token = crypto.randomBytes(32).toString('hex')
39:     const expiresAt = addMinutes(new Date(), TOKEN_EXPIRATION_MINUTES)
40: 
41:     // Store token and expiration in user's metadata or a dedicated collection
42:     await payload.update({
43:       collection: 'users',
44:       id: user.id,
45:       data: {
46:         resetPasswordToken: token,
47:         resetPasswordExpires: expiresAt.toISOString(),
48:       },
49:     })
50: 
51:     // Send password reset email with token link
52:     const resetUrl = `${process.env.NEXT_PUBLIC_FRONTEND_URL}/reset-password?token=${token}`
53: 
54:     await sendPasswordResetEmail(email, resetUrl)
55: 
56:     return NextResponse.json({ message: 'If the email exists, a reset link has been sent.' })
57:   } catch (error) {
58:     console.error('Password reset request error:', error)
59:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
60:   }
61: }
</file>

<file path="src/app/(payload)/api/auth/refresh-token/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import { getPayloadClient } from '@/lib/payloadClient'
 3: 
 4: const REFRESH_TOKEN_COOKIE = 'refreshToken'
 5: 
 6: export async function POST(request: NextRequest) {
 7:   try {
 8:     const refreshToken = request.cookies.get(REFRESH_TOKEN_COOKIE)?.value
 9: 
10:     if (!refreshToken) {
11:       return NextResponse.json({ error: 'No refresh token provided' }, { status: 401 })
12:     }
13: 
14:     const payload = getPayloadClient()
15: 
16:     // Verify refresh token and get user ID
17:     const decoded = await payload.verifyJWT(refreshToken).catch(() => null)
18:     if (!decoded || !decoded.sub) {
19:       return NextResponse.json({ error: 'Invalid refresh token' }, { status: 401 })
20:     }
21: 
22:     const userId = decoded.sub
23: 
24:     // Optionally check token revocation status here (e.g., Redis blacklist)
25: 
26:     // Generate new access token
27:     const newAccessToken = await payload.createJWT(userId)
28: 
29:     // Return new access token in response body or set cookie as needed
30:     return NextResponse.json({ accessToken: newAccessToken })
31:   } catch (error) {
32:     console.error('Refresh token error:', error)
33:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
34:   }
35: }
</file>

<file path="src/app/(payload)/api/graphql/route.ts">
1: /* THIS FILE WAS GENERATED AUTOMATICALLY BY PAYLOAD. */
2: /* DO NOT MODIFY IT BECAUSE IT COULD BE REWRITTEN AT ANY TIME. */
3: import config from '@payload-config'
4: import { GRAPHQL_POST, REST_OPTIONS } from '@payloadcms/next/routes'
5: 
6: export const POST = GRAPHQL_POST(config)
7: 
8: export const OPTIONS = REST_OPTIONS(config)
</file>

<file path="src/app/(payload)/api/graphql-playground/route.ts">
1: /* THIS FILE WAS GENERATED AUTOMATICALLY BY PAYLOAD. */
2: /* DO NOT MODIFY IT BECAUSE IT COULD BE REWRITTEN AT ANY TIME. */
3: import config from '@payload-config'
4: import '@payloadcms/next/css'
5: import { GRAPHQL_PLAYGROUND_GET } from '@payloadcms/next/routes'
6: 
7: export const GET = GRAPHQL_PLAYGROUND_GET(config)
</file>

<file path="src/app/(payload)/api/media/upload/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import { getPayloadClient } from '@/lib/payloadClient'
 3: import formidable from 'formidable'
 4: import fs from 'fs'
 5: import path from 'path'
 6: 
 7: // Disable Next.js default body parser to handle multipart/form-data
 8: export const config = {
 9:   api: {
10:     bodyParser: false,
11:   },
12: }
13: 
14: const MAX_FILE_SIZE = 5 * 1024 * 1024 // 5MB
15: const ALLOWED_MIME_TYPES = ['image/jpeg', 'image/png', 'image/webp']
16: 
17: export async function POST(request: NextRequest) {
18:   try {
19:     const payload = getPayloadClient()
20: 
21:     const form = new formidable.IncomingForm({
22:       maxFileSize: MAX_FILE_SIZE,
23:       multiples: false,
24:       keepExtensions: true,
25:     })
26: 
27:     const data = await new Promise<{ files: formidable.File[] }>((resolve, reject) => {
28:       form.parse(request, (err, fields, files) => {
29:         if (err) {
30:           reject(err)
31:           return
32:         }
33:         // formidable returns files as object, convert to array
34:         const fileArray = Array.isArray(files.file) ? files.file : [files.file]
35:         resolve({ files: fileArray })
36:       })
37:     })
38: 
39:     if (!data.files || data.files.length === 0) {
40:       return NextResponse.json({ error: 'No file uploaded' }, { status: 400 })
41:     }
42: 
43:     const file = data.files[0]
44: 
45:     if (!ALLOWED_MIME_TYPES.includes(file.mimetype || '')) {
46:       return NextResponse.json({ error: 'Invalid file type' }, { status: 400 })
47:     }
48: 
49:     if (file.size > MAX_FILE_SIZE) {
50:       return NextResponse.json({ error: 'File size exceeds limit' }, { status: 400 })
51:     }
52: 
53:     // Read file buffer
54:     const fileBuffer = fs.readFileSync(file.filepath)
55: 
56:     // Create media document in Payload CMS
57:     const mediaDoc = await payload.create({
58:       collection: 'media',
59:       data: {
60:         filename: file.originalFilename,
61:         mimeType: file.mimetype,
62:         filesize: file.size,
63:       },
64:       file: {
65:         data: fileBuffer,
66:         filename: file.originalFilename || 'upload',
67:         mimetype: file.mimetype || 'application/octet-stream',
68:       },
69:     })
70: 
71:     return NextResponse.json({ media: mediaDoc })
72:   } catch (error) {
73:     console.error('File upload error:', error)
74:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
75:   }
76: }
</file>

<file path="src/app/(payload)/api/users/me/route.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import { getPayloadClient } from '@/lib/payloadClient'
 3: 
 4: export async function GET(request: NextRequest) {
 5:   try {
 6:     const token = request.cookies.get('token')?.value
 7: 
 8:     if (!token) {
 9:       return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
10:     }
11: 
12:     const payload = getPayloadClient()
13: 
14:     // Verify token and get user ID
15:     const decoded = await payload.verifyJWT(token).catch(() => null)
16:     if (!decoded || !decoded.sub) {
17:       return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
18:     }
19: 
20:     const userId = decoded.sub
21: 
22:     // Fetch user data from Payload CMS
23:     const user = await payload.findByID({
24:       collection: 'users',
25:       id: userId,
26:       depth: 0,
27:     })
28: 
29:     if (!user) {
30:       return NextResponse.json({ error: 'User not found' }, { status: 404 })
31:     }
32: 
33:     // Remove sensitive fields
34:     const { password, resetPasswordToken, resetPasswordExpires, ...safeUser } = user
35: 
36:     return NextResponse.json(safeUser)
37:   } catch (error) {
38:     console.error('Error fetching current user:', error)
39:     return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
40:   }
41: }
</file>

<file path="src/app/(payload)/api/v1/[...slug]/route.ts">
 1: /* THIS FILE WAS GENERATED AUTOMATICALLY BY PAYLOAD. */
 2: /* DO NOT MODIFY IT BECAUSE IT COULD BE REWRITTEN AT ANY TIME. */
 3: import config from '@payload-config'
 4: import '@payloadcms/next/css'
 5: import {
 6:   REST_DELETE,
 7:   REST_GET,
 8:   REST_OPTIONS,
 9:   REST_PATCH,
10:   REST_POST,
11:   REST_PUT,
12: } from '@payloadcms/next/routes'
13: 
14: export const GET = REST_GET(config)
15: export const POST = REST_POST(config)
16: export const DELETE = REST_DELETE(config)
17: export const PATCH = REST_PATCH(config)
18: export const PUT = REST_PUT(config)
19: export const OPTIONS = REST_OPTIONS(config)
</file>

<file path="src/app/(payload)/layout.tsx">
 1: /* THIS FILE WAS GENERATED AUTOMATICALLY BY PAYLOAD. */
 2: /* DO NOT MODIFY IT BECAUSE IT COULD BE REWRITTEN AT ANY TIME. */
 3: import config from '@payload-config'
 4: import '@payloadcms/next/css'
 5: import type { ServerFunctionClient } from 'payload'
 6: import { handleServerFunctions, RootLayout } from '@payloadcms/next/layouts'
 7: import React from 'react'
 8: 
 9: import { importMap } from './admin/importMap.js'
10: import './custom.scss'
11: 
12: type Args = {
13:   children: React.ReactNode
14: }
15: 
16: /**
17:  * @description Handles server functions for Payload CMS.
18:  * @param {ServerFunctionClient} args
19:  * @returns {Promise<any>}
20:  */
21: const serverFunction: ServerFunctionClient = async function (args) {
22:   'use server'
23:   return handleServerFunctions({
24:     ...args,
25:     config,
26:     importMap,
27:   })
28: }
29: 
30: /**
31:  * @description The root layout for the Payload admin panel.
32:  * @param {Args} { children }
33:  * @returns {React.ReactElement}
34:  */
35: const Layout = ({ children }: Args) => (
36:   <RootLayout config={config} importMap={importMap} serverFunction={serverFunction}>
37:     {children}
38:   </RootLayout>
39: )
40: 
41: export default Layout
</file>

<file path="src/app/api/v1/my-route/route.ts">
 1: import configPromise from '@payload-config'
 2: import { getPayload } from 'payload'
 3: 
 4: /**
 5:  * @description Handles GET requests for the custom route.
 6:  * @param {Request} request
 7:  * @returns {Promise<Response>}
 8:  */
 9: export const GET = async (request: Request) => {
10:   const payload = await getPayload({
11:     config: configPromise,
12:   })
13: 
14:   return Response.json({
15:     message: 'This is an example of a custom route.',
16:   })
17: }
</file>

<file path="src/collections/Contacts.ts">
  1: import { CollectionConfig } from 'payload';
  2: import { isAdmin, isStoreManager, isShiftManager, isFohEmployee, isAuthenticated } from '../access';
  3: 
  4: /**
  5:  * @description Contacts collection configuration.
  6:  */
  7: export const Contacts: CollectionConfig = {
  8:   slug: 'contacts',
  9:   admin: {
 10:     useAsTitle: 'first_name',
 11:     defaultColumns: ['first_name', 'last_name', 'email', 'phone', 'visit_frequency'],
 12:   },
 13:   access: {
 14:     create: isAuthenticated, // Any authenticated user can create contacts
 15:     read: isAuthenticated, // Any authenticated user can read contacts (as per current effective logic)
 16:     update: ({ req: { user } }) => isAdmin({ req: { user } }) || isStoreManager({ req: { user } }) || isShiftManager({ req: { user } }) || isFohEmployee({ req: { user } }),
 17:     delete: ({ req: { user } }) => isAdmin({ req: { user } }) || isStoreManager({ req: { user } }) || isShiftManager({ req: { user } }),
 18:   },
 19:   fields: [
 20:     {
 21:       name: 'first_name',
 22:       type: 'text',
 23:       required: true,
 24:       maxLength: 50,
 25:     },
 26:     {
 27:       name: 'last_name',
 28:       type: 'text',
 29:       required: true,
 30:       maxLength: 50,
 31:     },
 32:     {
 33:       name: 'email',
 34:       type: 'email',
 35:       unique: true,
 36:       index: true,
 37:     },
 38:     {
 39:       name: 'phone',
 40:       type: 'text',
 41:       maxLength: 20,
 42:     },
 43:     {
 44:       name: 'company',
 45:       type: 'text',
 46:       maxLength: 100,
 47:     },
 48:     {
 49:       name: 'contact_type',
 50:       type: 'select',
 51:       options: [
 52:         { label: 'Customer', value: 'customer' },
 53:         { label: 'Vendor', value: 'vendor' },
 54:         { label: 'Contractor', value: 'contractor' },
 55:         { label: 'Other', value: 'other' },
 56:       ],
 57:       defaultValue: 'customer',
 58:       required: true,
 59:     },
 60:     {
 61:       name: 'toast_id',
 62:       type: 'text',
 63:       maxLength: 50,
 64:       admin: {
 65:         position: 'sidebar',
 66:       },
 67:     },
 68:     {
 69:       name: 'brevo_id',
 70:       type: 'text',
 71:       maxLength: 50,
 72:       admin: {
 73:         position: 'sidebar',
 74:       },
 75:     },
 76:     {
 77:       name: 'vip_id',
 78:       type: 'number',
 79:       unique: true,
 80:       admin: {
 81:         position: 'sidebar',
 82:       },
 83:     },
 84:     {
 85:       name: 'associated_locations',
 86:       type: 'relationship',
 87:       relationTo: 'locations',
 88:       hasMany: true,
 89:       admin: {
 90:         position: 'sidebar',
 91:       },
 92:     },
 93:     {
 94:       name: 'associated_messages',
 95:       type: 'relationship',
 96:       relationTo: 'messages',
 97:       hasMany: true,
 98:       admin: {
 99:         position: 'sidebar',
100:       },
101:     },
102:     {
103:       name: 'visit_frequency',
104:       type: 'select',
105:       options: [
106:         {
107:           label: 'First Time',
108:           value: 'first_time',
109:         },
110:         {
111:           label: 'Occasional',
112:           value: 'occasional',
113:         },
114:         {
115:           label: 'Regular',
116:           value: 'regular',
117:         },
118:         {
119:           label: 'VIP',
120:           value: 'vip',
121:         },
122:       ],
123:       admin: {
124:         position: 'sidebar',
125:       },
126:     },
127:     {
128:       name: 'last_visit',
129:       type: 'date',
130:       admin: {
131:         position: 'sidebar',
132:       },
133:     },
134:     {
135:       name: 'total_visits',
136:       type: 'number',
137:       min: 0,
138:       defaultValue: 0,
139:       admin: {
140:         position: 'sidebar',
141:       },
142:     },
143:     {
144:       name: 'average_spend',
145:       type: 'number',
146:       min: 0,
147:       admin: {
148:         step: 0.01,
149:         position: 'sidebar',
150:       },
151:     },
152:     {
153:       name: 'preferred_location',
154:       type: 'relationship',
155:       relationTo: 'locations',
156:       admin: {
157:         position: 'sidebar',
158:       },
159:     },
160:     {
161:       name: 'notes',
162:       type: 'textarea',
163:       maxLength: 1000,
164:     },
165:     {
166:       name: 'marketing_consent',
167:       type: 'checkbox',
168:       defaultValue: false,
169:       admin: {
170:         position: 'sidebar',
171:       },
172:     },
173:     {
174:       name: 'birthday',
175:       type: 'date',
176:       admin: {
177:         position: 'sidebar',
178:       },
179:     },
180:     {
181:       name: 'anniversary',
182:       type: 'date',
183:       admin: {
184:         position: 'sidebar',
185:       },
186:     },
187:   ],
188:   hooks: {
189:     beforeChange: [
190:       /**
191:        * @description Hook to set default values and generate VIP ID for new contacts.
192:        * @param {object} args
193:        * @param {object} args.data - The data being saved.
194:        * @param {string} args.operation - The operation being performed (e.g., 'create', 'update').
195:        * @param {object} args.req - The Payload request object.
196:        * @returns {Promise<object>} The modified data.
197:        */
198:       async ({ data, operation, req }) => {
199:         if (operation === 'create') {
200:           // Set default values for new contacts
201:           if (data.total_visits === undefined) {
202:             data.total_visits = 1; // First visit
203:           }
204:           if (!data.visit_frequency) {
205:             data.visit_frequency = 'first_time';
206:           }
207: 
208:           // Generate vip_id if not provided
209:           if (!data.vip_id) {
210:             const contacts = await req.payload.find({
211:               collection: 'contacts',
212:               sort: '-vip_id',
213:               limit: 1,
214:             });
215:             const maxVipId = contacts.docs.length > 0 ? (contacts.docs[0].vip_id as number) : 9999;
216:             data.vip_id = maxVipId + 1;
217:           }
218:         }
219:         return data;
220:       },
221:     ],
222:     afterChange: [
223:       /**
224:        * @description Hook to log contact creation/updates.
225:        * @param {object} args
226:        * @param {object} args.doc - The document after the change.
227:        * @param {string} args.operation - The operation being performed (e.g., 'create', 'update').
228:        * @returns {void}
229:        */
230:       ({ doc, operation }) => {
231:         // Log contact creation/updates for analytics
232:         if (operation === 'create') {
233:           console.log(`New contact created: ${doc.first_name} ${doc.last_name}`);
234:         }
235:       },
236:     ],
237:   },
238: };
</file>

<file path="src/collections/EmployeeRatings.ts">
  1: import type { CollectionConfig } from 'payload'
  2: import { isAdmin, isAdminOrManager, canReadEmployeeRatings } from '../access';
  3: 
  4: /**
  5:  * @description Employee Ratings collection configuration.
  6:  */
  7: export const EmployeeRatings: CollectionConfig = {
  8:   slug: 'employee-ratings',
  9:   admin: {
 10:     useAsTitle: 'employee_id',
 11:     defaultColumns: ['employee_id', 'location_id', 'data_date', 'rating'],
 12:     group: 'Reports',
 13:     description: 'Employee performance ratings from managers'
 14:   },
 15:   access: {
 16:     read: canReadEmployeeRatings,
 17:     create: isAdminOrManager,
 18:     update: isAdminOrManager,
 19:     delete: isAdmin,
 20:   },
 21:   fields: [
 22:     {
 23:       name: 'employee_id',
 24:       type: 'relationship',
 25:       relationTo: 'users',
 26:       required: true,
 27:       admin: {
 28:         description: 'Employee being rated'
 29:       }
 30:     },
 31:     {
 32:       name: 'location_id',
 33:       type: 'relationship',
 34:       relationTo: 'locations',
 35:       required: true,
 36:       admin: {
 37:         position: 'sidebar'
 38:       }
 39:     },
 40:     {
 41:       name: 'data_date',
 42:       type: 'date',
 43:       required: true,
 44:       admin: {
 45:         date: {
 46:           pickerAppearance: 'dayOnly',
 47:           displayFormat: 'MMM d, yyyy'
 48:         }
 49:       }
 50:     },
 51:     {
 52:       name: 'rating',
 53:       type: 'number',
 54:       min: 1,
 55:       max: 5,
 56:       required: true,
 57:       admin: {
 58:         description: 'Rating from 1-5 stars',
 59:         step: 1
 60:       }
 61:     },
 62:     {
 63:       name: 'manager_report_id',
 64:       type: 'relationship',
 65:       relationTo: 'managerReports',
 66:       admin: {
 67:         description: 'Associated manager report (if applicable)'
 68:       }
 69:     },
 70:     {
 71:       name: 'employee_notes',
 72:       type: 'richText',
 73:       admin: {
 74:         description: 'Notes about employee performance'
 75:       }
 76:     },
 77:     {
 78:       name: 'internal_notes',
 79:       type: 'textarea',
 80:       admin: {
 81:         description: 'Internal management notes (not visible to employee)'
 82:       }
 83:     }
 84:   ],
 85:   timestamps: true,
 86:   hooks: {
 87:     beforeChange: [
 88:       /**
 89:        * @description Hook to validate rating range before changing an employee rating.
 90:        * @param {object} args
 91:        * @param {object} args.data - The data being saved.
 92:        * @param {object} args.req - The Payload request object.
 93:        * @returns {object} The modified data.
 94:        */
 95:       ({ data, req }) => {
 96:         // Ensure rating is within valid range
 97:         if (data.rating && (data.rating < 1 || data.rating > 5)) {
 98:           throw new Error('Rating must be between 1 and 5')
 99:         }
100:         return data
101:       }
102:     ]
103:   }
104: }
</file>

<file path="src/collections/HotspotLogins.ts">
 1: import type { CollectionConfig } from 'payload'
 2: import { isAdmin, isAdminOrManager, isAdminOrHasLocationAccess } from '../access';
 3: 
 4: /**
 5:  * @description Hotspot Logins collection configuration.
 6:  */
 7: export const HotspotLogins: CollectionConfig = {
 8:   slug: 'hotspot-logins',
 9:   admin: {
10:     useAsTitle: 'customer_name',
11:     defaultColumns: ['customer_name', 'customer_email', 'location', 'date_created'],
12:     group: 'Data',
13:     description: 'WiFi hotspot login data and customer information'
14:   },
15:   access: {
16:     read: isAdminOrHasLocationAccess,
17:     create: () => true, // Public creation for hotspot logins
18:     update: isAdminOrManager,
19:     delete: isAdmin,
20:   },
21:   fields: [
22:     {
23:       name: 'location',
24:       type: 'relationship',
25:       relationTo: 'locations',
26:       required: true,
27:       admin: {
28:         position: 'sidebar',
29:         description: 'Location where the login occurred'
30:       }
31:     },
32:     {
33:       name: 'customer_name',
34:       type: 'text',
35:       required: false,
36:       admin: {
37:         description: 'Customer name provided during login (optional)'
38:       }
39:     },
40:     {
41:       name: 'customer_email',
42:       type: 'email',
43:       required: false,
44:       admin: {
45:         description: 'Customer email provided during login (optional)'
46:       }
47:     },
48:     {
49:       name: 'marketing_consent',
50:       type: 'checkbox',
51:       defaultValue: false,
52:       admin: {
53:         position: 'sidebar',
54:         description: 'Customer consented to marketing communications'
55:       }
56:     }
57:   ],
58:   timestamps: true,
59:   hooks: {
60:     beforeChange: [
61:       /**
62:        * @description Hook to validate email format before changing a hotspot login.
63:        * @param {object} args
64:        * @param {object} args.data - The data being saved.
65:        * @returns {object} The modified data.
66:        */
67:       ({ data }) => {
68:         // Validate email format if provided
69:         if (data.customer_email && !data.customer_email.includes('@')) {
70:           throw new Error('Invalid email format')
71:         }
72:         
73:         return data
74:       }
75:     ]
76:   }
77: }
</file>

<file path="src/collections/Incidents.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager } from '../access';
 3: 
 4: export const Incidents: CollectionConfig = {
 5:   slug: 'incidents',
 6:   admin: {
 7:     useAsTitle: 'title',
 8:   },
 9:   access: {
10:     create: isAdminOrManager,
11:     read: isAdminOrManager,
12:     update: isAdminOrManager,
13:     delete: isAdmin,
14:   },
15:   fields: [
16:     {
17:       name: 'title',
18:       type: 'text',
19:       required: true,
20:     },
21:     {
22:       name: 'description',
23:       type: 'textarea',
24:     },
25:     {
26:       name: 'date',
27:       type: 'date',
28:       required: true,
29:     },
30:     {
31:       name: 'location',
32:       type: 'relationship',
33:       relationTo: 'locations',
34:       required: true,
35:     },
36:     {
37:       name: 'reportedBy',
38:       type: 'relationship',
39:       relationTo: 'users',
40:       required: true,
41:     },
42:     {
43:       name: 'status',
44:       type: 'select',
45:       options: [
46:         { label: 'Open', value: 'open' },
47:         { label: 'In Progress', value: 'in_progress' },
48:         { label: 'Closed', value: 'closed' },
49:       ],
50:       defaultValue: 'open',
51:     },
52:   ],
53: };
</file>

<file path="src/collections/ManagerReports.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager } from '../access';
 3: 
 4: export const ManagerReports: CollectionConfig = {
 5:   slug: 'managerReports',
 6:   admin: {
 7:     useAsTitle: 'title',
 8:   },
 9:   access: {
10:     create: isAdminOrManager,
11:     read: isAdminOrManager,
12:     update: isAdminOrManager,
13:     delete: isAdmin,
14:   },
15:   fields: [
16:     {
17:       name: 'title',
18:       type: 'text',
19:       required: true,
20:     },
21:     {
22:       name: 'date',
23:       type: 'date',
24:       required: true,
25:     },
26:     {
27:       name: 'manager',
28:       type: 'relationship',
29:       relationTo: 'users',
30:       required: true,
31:     },
32:     {
33:       name: 'location',
34:       type: 'relationship',
35:       relationTo: 'locations',
36:       required: true,
37:     },
38:     {
39:       name: 'notes',
40:       type: 'textarea',
41:     },
42:   ],
43: };
</file>

<file path="src/collections/QrFeedback.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager } from '../access';
 3: 
 4: /**
 5:  * @description QR Feedback collection configuration.
 6:  */
 7: export const QrFeedback: CollectionConfig = {
 8:   slug: 'qrFeedback',
 9:   admin: {
10:     useAsTitle: 'id',
11:   },
12:   access: {
13:     create: () => true,
14:     read: isAdminOrManager,
15:     update: isAdminOrManager,
16:     delete: isAdmin,
17:   },
18:   fields: [
19:     /**
20:      * @description The rating given by the user (1-5).
21:      */
22:     {
23:       name: 'rating',
24:       type: 'number',
25:       min: 1,
26:       max: 5,
27:       required: true,
28:     },
29:     /**
30:      * @description Optional comment from the user.
31:      */
32:     {
33:       name: 'comment',
34:       type: 'textarea',
35:     },
36:     /**
37:      * @description The location where the feedback was given.
38:      */
39:     {
40:       name: 'location',
41:       type: 'relationship',
42:       relationTo: 'locations',
43:       required: true,
44:     },
45:     /**
46:      * @description The user who provided the feedback.
47:      */
48:     {
49:       name: 'user',
50:       type: 'relationship',
51:       relationTo: 'users',
52:     },
53:   ],
54: };
</file>

<file path="src/collections/Questions.ts">
  1: import type { CollectionConfig } from 'payload'
  2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
  3: 
  4: export const Questions: CollectionConfig = {
  5:   slug: 'questions',
  6:   labels: {
  7:     singular: 'Custom Question',
  8:     plural: 'Custom Questions'
  9:   },
 10:   admin: {
 11:     useAsTitle: 'question',
 12:     defaultColumns: ['question', 'shift_timing', 'shift_selection', 'status', 'sort'],
 13:     group: 'Reports',
 14:     description: 'Custom questions to be displayed on server and manager reports'
 15:   },
 16:   access: {
 17:     read: isAuthenticated,
 18:     create: isAdminOrManager,
 19:     update: isAdminOrManager,
 20:     delete: isAdmin,
 21:   },
 22:   fields: [
 23:     {
 24:       name: 'status',
 25:       type: 'select',
 26:       options: [
 27:         { label: 'Active', value: 'active' },
 28:         { label: 'Inactive', value: 'inactive' },
 29:         { label: 'Archived', value: 'archived' }
 30:       ],
 31:       defaultValue: 'active',
 32:       admin: {
 33:         position: 'sidebar'
 34:       }
 35:     },
 36:     {
 37:       name: 'sort',
 38:       type: 'number',
 39:       admin: {
 40:         position: 'sidebar',
 41:         description: 'Sort order for display'
 42:       }
 43:     },
 44:     {
 45:       name: 'question',
 46:       type: 'text',
 47:       required: true,
 48:       admin: {
 49:         description: 'The question text to display'
 50:       }
 51:     },
 52:     {
 53:       name: 'shift_timing',
 54:       type: 'select',
 55:       options: [
 56:         { label: 'AM Only', value: 'am' },
 57:         { label: 'PM Only', value: 'pm' },
 58:         { label: 'Any Shift Time', value: 'any' }
 59:       ],
 60:       defaultValue: 'any',
 61:       admin: {
 62:         description: 'When this question should be displayed'
 63:       }
 64:     },
 65:     {
 66:       name: 'shift_selection',
 67:       type: 'select',
 68:       hasMany: true,
 69:       options: [
 70:         { label: 'Bartender', value: 'bartender' },
 71:         { label: 'Server', value: 'server' },
 72:         { label: 'FOH Support', value: 'foh_support' },
 73:         { label: 'Shift Manager', value: 'shift_manager' },
 74:         { label: 'Store Manager', value: 'store_manager' }
 75:       ],
 76:       admin: {
 77:         description: 'Which roles should see this question'
 78:       }
 79:     },
 80:     {
 81:       name: 'min_characters',
 82:       type: 'number',
 83:       min: 0,
 84:       admin: {
 85:         description: 'Minimum character count for answers'
 86:       }
 87:     },
 88:     {
 89:       name: 'locations',
 90:       type: 'relationship',
 91:       relationTo: 'locations',
 92:       hasMany: true,
 93:       admin: {
 94:         description: 'Locations where this question should appear (leave empty for all locations)'
 95:       }
 96:     }
 97:   ],
 98:   timestamps: true,
 99:   hooks: {
100:     beforeChange: [
101:       ({ data }) => {
102:         // Validate minimum characters
103:         if (data.min_characters && data.min_characters < 0) {
104:           throw new Error('Minimum characters cannot be negative')
105:         }
106:         
107:         return data
108:       }
109:     ]
110:   }
111: }
</file>

<file path="src/collections/ServerReports.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isFohEmployee } from '../access';
 3: 
 4: /**
 5:  * @description Server Reports collection configuration.
 6:  */
 7: export const ServerReports: CollectionConfig = {
 8:   slug: 'serverReports',
 9:   admin: {
10:     useAsTitle: 'title',
11:   },
12:   access: {
13:     create: ({ req: { user } }) => isAdminOrManager({ req: { user } }) || isFohEmployee({ req: { user } }),
14:     read: ({ req: { user } }) => isAdminOrManager({ req: { user } }) || isFohEmployee({ req: { user } }),
15:     update: ({ req: { user } }) => isAdminOrManager({ req: { user } }) || isFohEmployee({ req: { user } }),
16:     delete: isAdmin,
17:   },
18:   fields: [
19:     /**
20:      * @description The title of the server report.
21:      */
22:     {
23:       name: 'title',
24:       type: 'text',
25:       required: true,
26:     },
27:     /**
28:      * @description The date of the server report.
29:      */
30:     {
31:       name: 'date',
32:       type: 'date',
33:       required: true,
34:     },
35:     /**
36:      * @description The server who submitted the report.
37:      */
38:     {
39:       name: 'server',
40:       type: 'relationship',
41:       relationTo: 'users',
42:       required: true,
43:     },
44:     /**
45:      * @description The location where the report was submitted.
46:      */
47:     {
48:       name: 'location',
49:       type: 'relationship',
50:       relationTo: 'locations',
51:       required: true,
52:     },
53:     {
54:       name: 'notes',
55:       type: 'textarea',
56:     },
57:   ],
58: };
</file>

<file path="src/collections/ShiftTypes.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager } from '../access';
 3: 
 4: /**
 5:  * @description Shift Types collection configuration.
 6:  */
 7: export const ShiftTypes: CollectionConfig = {
 8:   slug: 'shiftTypes',
 9:   admin: {
10:     useAsTitle: 'name',
11:   },
12:   access: {
13:     read: () => true,
14:   },
15:   fields: [
16:     /**
17:      * @description The name of the shift type.
18:      */
19:     {
20:       name: 'name',
21:       type: 'text',
22:       required: true,
23:       unique: true,
24:     },
25:   ],
26: };
</file>

<file path="src/collections/Users.ts">
  1: import { CollectionConfig } from 'payload';
  2: import { Access, PayloadRequest } from 'payload';
  3: import { User } from '../payload-types';
  4: import { isAdmin, isAdminOrSelf, canManageUsers } from '../access';
  5: 
  6: /**
  7:  * @description Users collection configuration.
  8:  */
  9: const Users: CollectionConfig = {
 10:   slug: 'users',
 11:   auth: {
 12:     tokenExpiration: 7200, // 2 hours
 13:     verify: false,
 14:     maxLoginAttempts: 5,
 15:     lockTime: 600 * 1000, // 10 minutes
 16:     cookies: {
 17:       secure: process.env.NODE_ENV === 'production',
 18:       sameSite: 'Strict',
 19:     },
 20:   },
 21:   admin: {
 22:     useAsTitle: 'email',
 23:     defaultColumns: ['email', 'first_name', 'last_name', 'roles'],
 24:   },
 25:   access: {
 26:     create: isAdmin, // Only admins can create users
 27:     read: isAdminOrSelf,
 28:     update: isAdminOrSelf, // Simplified for now, managers can update all users except admins would need custom logic
 29:     delete: isAdmin,
 30:   },
 31:   fields: [
 32:     {
 33:       name: 'first_name',
 34:       type: 'text',
 35:       required: true,
 36:       maxLength: 50,
 37:     },
 38:     {
 39:       name: 'last_name',
 40:       type: 'text',
 41:       required: true,
 42:       maxLength: 50,
 43:     },
 44:     {
 45:       name: 'phone',
 46:       type: 'text',
 47:       required: false,
 48:       maxLength: 20,
 49:     },
 50:     {
 51:       name: 'employee_id',
 52:       type: 'text',
 53:       required: false,
 54:       unique: true,
 55:       maxLength: 20,
 56:     },
 57:     {
 58:       name: 'roles',
 59:       type: 'select',
 60:       hasMany: true,
 61:       defaultValue: ['user'],
 62:       options: [
 63:         {
 64:           label: 'Admin',
 65:           value: 'admin',
 66:         },
 67:         {
 68:           label: 'Store Manager',
 69:           value: 'store_manager',
 70:         },
 71:         {
 72:           label: 'Shift Manager',
 73:           value: 'shift_manager',
 74:         },
 75:         {
 76:           label: 'FOH Employee',
 77:           value: 'foh_employee',
 78:         },
 79:         {
 80:           label: 'BOH Employee',
 81:           value: 'boh_employee',
 82:         },
 83:         {
 84:           label: 'User',
 85:           value: 'user',
 86:         },
 87:       ],
 88:       access: {
 89:         create: canManageUsers,
 90:         update: canManageUsers,
 91:       },
 92:     },
 93:     {
 94:       name: 'status',
 95:       type: 'select',
 96:       defaultValue: 'active',
 97:       options: [
 98:         {
 99:           label: 'Active',
100:           value: 'active',
101:         },
102:         {
103:           label: 'Inactive',
104:           value: 'inactive',
105:         },
106:         {
107:           label: 'On Leave',
108:           value: 'on_leave',
109:         },
110:         {
111:           label: 'Terminated',
112:           value: 'terminated',
113:         },
114:       ],
115:       access: {
116:         create: canManageUsers,
117:         update: canManageUsers,
118:       },
119:     },
120:     {
121:       name: 'locations',
122:       type: 'relationship',
123:       relationTo: 'locations',
124:       hasMany: true,
125:       admin: {
126:         position: 'sidebar',
127:       },
128:     },
129:     {
130:       name: 'primary_location',
131:       type: 'relationship',
132:       relationTo: 'locations',
133:       admin: {
134:         position: 'sidebar',
135:       },
136:     },
137:     {
138:       name: 'employment_details',
139:       type: 'group',
140:       fields: [
141:         {
142:           name: 'hire_date',
143:           type: 'date',
144:         },
145:         {
146:           name: 'termination_date',
147:           type: 'date',
148:         },
149:         {
150:           name: 'employment_type',
151:           type: 'select',
152:           options: [
153:             { label: 'Full Time', value: 'full_time' },
154:             { label: 'Part Time', value: 'part_time' },
155:             { label: 'Seasonal', value: 'seasonal' },
156:             { label: 'Contract', value: 'contract' },
157:           ],
158:         },
159:         {
160:           name: 'hourly_rate',
161:           type: 'number',
162:           min: 0,
163:           admin: {
164:             step: 0.01,
165:           },
166:         },
167:       ],
168:       admin: {
169:         condition: (data, siblingData, { user }) => {
170:           return (user?.roles as string[])?.includes('admin') || (user?.roles as string[])?.includes('store_manager') || (user?.roles as string[])?.includes('shift_manager');
171:         },
172:       },
173:     },
174:     {
175:       name: 'profile_photo',
176:       type: 'relationship',
177:       relationTo: 'media',
178:       admin: {
179:         position: 'sidebar',
180:       },
181:     },
182:     {
183:       name: 'jobs',
184:       type: 'relationship',
185:       relationTo: 'jobs',
186:       hasMany: true,
187:       admin: {
188:         position: 'sidebar',
189:       },
190:     },
191:   ],
192:   hooks: {
193:     beforeChange: [
194:       /**
195:        * @description Hook to set default role for new users.
196:        * @param {object} args
197:        * @param {object} args.data - The data being saved.
198:        * @param {object} args.req - The Payload request object.
199:        * @param {string} args.operation - The operation being performed (e.g., 'create', 'update').
200:        * @returns {object} The modified data.
201:        */
202:       ({ data, req, operation }) => {
203:         if (operation === 'create') {
204:           // Set default role for new users
205:           if (!data.roles || data.roles.length === 0) {
206:             data.roles = ['user'];
207:           }
208:         }
209:         return data;
210:       },
211:     ],
212:   },
213: };
214: 
215: export default Users;
</file>

<file path="src/components/ui/button.tsx">
 1: import * as React from 'react'
 2: import { Slot } from '@radix-ui/react-slot'
 3: import { cva, type VariantProps } from 'class-variance-authority'
 4: 
 5: import { cn } from '@/lib/utils'
 6: 
 7: const buttonVariants = cva(
 8:   'inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50',
 9:   {
10:     variants: {
11:       variant: {
12:         default: 'bg-primary text-primary-foreground hover:bg-primary/90',
13:         destructive: 'bg-destructive text-destructive-foreground hover:bg-destructive/90',
14:         outline: 'border border-input bg-background hover:bg-accent hover:text-accent-foreground',
15:         secondary: 'bg-secondary text-secondary-foreground hover:bg-secondary/80',
16:         ghost: 'hover:bg-accent hover:text-accent-foreground',
17:         link: 'text-primary underline-offset-4 hover:underline',
18:       },
19:       size: {
20:         default: 'h-10 px-4 py-2',
21:         sm: 'h-9 rounded-md px-3',
22:         lg: 'h-11 rounded-md px-8',
23:         icon: 'h-10 w-10',
24:       },
25:     },
26:     defaultVariants: {
27:       variant: 'default',
28:       size: 'default',
29:     },
30:   },
31: )
32: 
33: export interface ButtonProps
34:   extends React.ButtonHTMLAttributes<HTMLButtonElement>,
35:     VariantProps<typeof buttonVariants> {
36:   asChild?: boolean
37: }
38: 
39: const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
40:   ({ className, variant, size, asChild = false, ...props }, ref) => {
41:     const Comp = asChild ? Slot : 'button'
42:     return (
43:       <Comp className={cn(buttonVariants({ variant, size, className }))} ref={ref} {...props} />
44:     )
45:   },
46: )
47: Button.displayName = 'Button'
48: 
49: export { Button, buttonVariants }
</file>

<file path="src/components/ui/form.tsx">
  1: import * as React from 'react'
  2: import {
  3:   Controller,
  4:   ControllerProps,
  5:   FieldPath,
  6:   FieldValues,
  7:   FormProvider,
  8:   useFormContext,
  9: } from 'react-hook-form'
 10: 
 11: import { Label } from '@/components/ui/label'
 12: import { cn } from '@/lib/utils'
 13: 
 14: const Form = FormProvider
 15: 
 16: type FormFieldContextValue<
 17:   TFieldValues extends FieldValues = FieldValues,
 18:   TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>,
 19: > = {
 20:   name: TName
 21: }
 22: 
 23: const FormFieldContext = React.createContext<FormFieldContextValue>({} as FormFieldContextValue)
 24: 
 25: /**
 26:  * @description Renders a form field with a controller for react-hook-form.
 27:  * @template TFieldValues
 28:  * @template TName
 29:  * @param {ControllerProps<TFieldValues, TName>} props
 30:  * @returns {React.ReactElement}
 31:  */
 32: const FormField = <
 33:   TFieldValues extends FieldValues = FieldValues,
 34:   TName extends FieldPath<TFieldValues> = FieldPath<TFieldValues>,
 35: >({
 36:   ...props
 37: }: ControllerProps<TFieldValues, TName>) => {
 38:   return (
 39:     <FormFieldContext.Provider value={{ name: props.name }}>
 40:       <Controller {...props} />
 41:     </FormFieldContext.Provider>
 42:   )
 43: }
 44: 
 45: /**
 46:  * @description A hook to access form field context and state.
 47:  * @returns {object}
 48:  */
 49: const useFormField = () => {
 50:   const fieldContext = React.useContext(FormFieldContext)
 51:   const itemContext = React.useContext(FormItemContext)
 52:   const { getFieldState, formState } = useFormContext()
 53: 
 54:   const fieldState = getFieldState(fieldContext.name, formState)
 55: 
 56:   if (!fieldContext) {
 57:     throw new Error('useFormField should be used within <FormField>')
 58:   }
 59: 
 60:   const { id } = itemContext
 61: 
 62:   return {
 63:     id,
 64:     name: fieldContext.name,
 65:     formItemId: `${id}-form-item`,
 66:     formDescriptionId: `${id}-form-item-description`,
 67:     formMessageId: `${id}-form-item-message`,
 68:     ...fieldState,
 69:   }
 70: }
 71: 
 72: type FormItemContextValue = {
 73:   id: string
 74: }
 75: 
 76: const FormItemContext = React.createContext<FormItemContextValue>({} as FormItemContextValue)
 77: 
 78: /**
 79:  * @description Renders a form item container.
 80:  * @param {React.HTMLAttributes<HTMLDivElement>} props
 81:  * @param {React.Ref<HTMLDivElement>} ref
 82:  * @returns {React.ReactElement}
 83:  */
 84: const FormItem = React.forwardRef<HTMLDivElement, React.HTMLAttributes<HTMLDivElement>>(
 85:   ({ className, ...props }, ref) => {
 86:     const id = React.useId()
 87: 
 88:     return (
 89:       <FormItemContext.Provider value={{ id }}>
 90:         <div ref={ref} className={cn('space-y-2', className)} {...props} />
 91:       </FormItemContext.Provider>
 92:     )
 93:   },
 94: )
 95: FormItem.displayName = 'FormItem'
 96: 
 97: /**
 98:  * @description Renders a form label.
 99:  * @param {React.ComponentPropsWithoutRef<typeof Label>} props
100:  * @param {React.Ref<React.ElementRef<typeof Label>>} ref
101:  * @returns {React.ReactElement}
102:  */
103: const FormLabel = React.forwardRef<
104:   React.ElementRef<typeof Label>,
105:   React.ComponentPropsWithoutRef<typeof Label>
106: >(({ className, ...props }, ref) => {
107:   const { error, formItemId } = useFormField()
108: 
109:   return (
110:     <Label
111:       ref={ref}
112:       className={cn(error && 'text-destructive', className)}
113:       htmlFor={formItemId}
114:       {...props}
115:     />
116:   )
117: })
118: FormLabel.displayName = 'FormLabel'
119: 
120: /**
121:  * @description Renders a form control.
122:  * @param {React.ComponentPropsWithoutRef<"div">} props
123:  * @param {React.Ref<HTMLDivElement>} ref
124:  * @returns {React.ReactElement}
125:  */
126: const FormControl = React.forwardRef<
127:   React.ElementRef<'div'>,
128:   React.ComponentPropsWithoutRef<'div'>
129: >(({ ...props }, ref) => {
130:   const { error, formItemId, formDescriptionId, formMessageId } = useFormField()
131: 
132:   return (
133:     <div
134:       ref={ref}
135:       id={formItemId}
136:       aria-describedby={!error ? `${formDescriptionId}` : `${formDescriptionId} ${formMessageId}`}
137:       aria-invalid={!!error}
138:       {...props}
139:     />
140:   )
141: })
142: FormControl.displayName = 'FormControl'
143: 
144: /**
145:  * @description Renders a form description.
146:  * @param {React.HTMLAttributes<HTMLParagraphElement>} props
147:  * @param {React.Ref<HTMLParagraphElement>} ref
148:  * @returns {React.ReactElement}
149:  */
150: const FormDescription = React.forwardRef<
151:   HTMLParagraphElement,
152:   React.HTMLAttributes<HTMLParagraphElement>
153: >(({ className, ...props }, ref) => {
154:   const { formDescriptionId } = useFormField()
155: 
156:   return (
157:     <p
158:       ref={ref}
159:       id={formDescriptionId}
160:       className={cn('text-sm text-muted-foreground', className)}
161:       {...props}
162:     />
163:   )
164: })
165: FormDescription.displayName = 'FormDescription'
166: 
167: /**
168:  * @description Renders a form message.
169:  * @param {React.HTMLAttributes<HTMLParagraphElement>} props
170:  * @param {React.Ref<HTMLParagraphElement>} ref
171:  * @returns {React.ReactElement | null}
172:  */
173: const FormMessage = React.forwardRef<
174:   HTMLParagraphElement,
175:   React.HTMLAttributes<HTMLParagraphElement>
176: >(({ className, children, ...props }, ref) => {
177:   const { error, formMessageId } = useFormField()
178:   const body = error ? String(error?.message) : children
179: 
180:   if (!body) {
181:     return null
182:   }
183: 
184:   return (
185:     <p
186:       ref={ref}
187:       id={formMessageId}
188:       className={cn('text-sm font-medium text-destructive', className)}
189:       {...props}
190:     >
191:       {body}
192:     </p>
193:   )
194: })
195: FormMessage.displayName = 'FormMessage'
196: 
197: export {
198:   useFormField,
199:   Form,
200:   FormItem,
201:   FormLabel,
202:   FormControl,
203:   FormDescription,
204:   FormMessage,
205:   FormField,
206: }
</file>

<file path="src/components/ui/input.tsx">
 1: import * as React from 'react'
 2: 
 3: import { cn } from '@/lib/utils'
 4: 
 5: export interface InputProps extends React.InputHTMLAttributes<HTMLInputElement> {}
 6: 
 7: /**
 8:  * @description Renders an input element with a customizable className and type.
 9:  * @param {InputProps} props
10:  * @param {React.Ref<HTMLInputElement>} ref
11:  * @returns {React.ReactElement}
12:  */
13: const Input = React.forwardRef<HTMLInputElement, InputProps>(
14:   ({ className, type, ...props }, ref) => {
15:     return (
16:       <input
17:         type={type}
18:         className={cn(
19:           'flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50',
20:           className,
21:         )}
22:         ref={ref}
23:         {...props}
24:       />
25:     )
26:   },
27: )
28: Input.displayName = 'Input'
29: 
30: export { Input }
</file>

<file path="src/components/ui/label.tsx">
 1: 'use client'
 2: 
 3: import * as React from 'react'
 4: import * as LabelPrimitive from '@radix-ui/react-label'
 5: import { cva, type VariantProps } from 'class-variance-authority'
 6: 
 7: import { cn } from '@/lib/utils'
 8: 
 9: const labelVariants = cva(
10:   'text-sm font-medium leading-none peer-disabled:cursor-not-allowed peer-disabled:opacity-70',
11: )
12: 
13: const Label = React.forwardRef<
14:   React.ElementRef<typeof LabelPrimitive.Root>,
15:   React.ComponentPropsWithoutRef<typeof LabelPrimitive.Root> & VariantProps<typeof labelVariants>
16: >(({ className, ...props }, ref) => (
17:   <LabelPrimitive.Root ref={ref} className={cn(labelVariants(), className)} {...props} />
18: ))
19: Label.displayName = LabelPrimitive.Root.displayName
20: 
21: export { Label }
</file>

<file path="src/components/ui/select.tsx">
  1: 'use client'
  2: 
  3: import * as React from 'react'
  4: import * as SelectPrimitive from '@radix-ui/react-select'
  5: import { Check, ChevronDown } from 'lucide-react'
  6: 
  7: import { cn } from '@/lib/utils'
  8: 
  9: const Select = SelectPrimitive.Root
 10: 
 11: const SelectGroup = SelectPrimitive.Group
 12: 
 13: const SelectValue = SelectPrimitive.Value
 14: 
 15: const SelectTrigger = React.forwardRef<
 16:   React.ElementRef<typeof SelectPrimitive.Trigger>,
 17:   React.ComponentPropsWithoutRef<typeof SelectPrimitive.Trigger>
 18: >(({ className, children, ...props }, ref) => (
 19:   <SelectPrimitive.Trigger
 20:     ref={ref}
 21:     className={cn(
 22:       'flex h-10 w-full items-center justify-between rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 [&>span]:line-clamp-1',
 23:       className,
 24:     )}
 25:     {...props}
 26:   >
 27:     {children}
 28:     <SelectPrimitive.Icon asChild>
 29:       <ChevronDown className="h-4 w-4 opacity-50" />
 30:     </SelectPrimitive.Icon>
 31:   </SelectPrimitive.Trigger>
 32: ))
 33: SelectTrigger.displayName = SelectPrimitive.Trigger.displayName
 34: 
 35: const SelectContent = React.forwardRef< 
 36:   React.ElementRef<typeof SelectPrimitive.Content>,
 37:   React.ComponentPropsWithoutRef<typeof SelectPrimitive.Content>
 38: >(({ className, children, position = 'popper', ...props }, ref) => (
 39:   <SelectPrimitive.Portal>
 40:     <SelectPrimitive.Content
 41:       ref={ref}
 42:       className={cn(
 43:         'relative z-50 max-h-96 min-w-[8rem] overflow-hidden rounded-md border bg-popover text-popover-foreground shadow-md data-[state=open]:animate-in data-[state=closed]:animate-out data-[state=closed]:fade-out-0 data-[state=open]:fade-in-0 data-[state=closed]:zoom-out-95 data-[state=open]:zoom-in-95 data-[side=bottom]:slide-in-from-top-2 data-[side=left]:slide-in-from-right-2 data-[side=right]:slide-in-from-left-2 data-[side=top]:slide-in-from-bottom-2',
 44:         position === 'popper' &&
 45:           'data-[side=bottom]:translate-y-1 data-[side=left]:-translate-x-1 data-[side=right]:translate-x-1 data-[side=top]:-translate-y-1',
 46:         className,
 47:       )}
 48:       position={position}
 49:       {...props}
 50:     >
 51:       <SelectPrimitive.Viewport
 52:         className={cn(
 53:           'p-1',
 54:           position === 'popper' &&
 55:             'h-[var(--radix-select-trigger-height)] w-full min-w-[var(--radix-select-trigger-width)]',
 56:         )}
 57:       >
 58:         {children}
 59:       </SelectPrimitive.Viewport>
 60:     </SelectPrimitive.Content>
 61:   </SelectPrimitive.Portal>
 62: ))
 63: SelectContent.displayName = SelectPrimitive.Content.displayName
 64: 
 65: const SelectLabel = React.forwardRef< 
 66:   React.ElementRef<typeof SelectPrimitive.Label>,
 67:   React.ComponentPropsWithoutRef<typeof SelectPrimitive.Label>
 68: >(({ className, ...props }, ref) => (
 69:   <SelectPrimitive.Label
 70:     ref={ref}
 71:     className={cn('py-1.5 pl-8 pr-2 text-sm font-semibold', className)}
 72:     {...props}
 73:   />
 74: ))
 75: SelectLabel.displayName = SelectPrimitive.Label.displayName
 76: 
 77: const SelectItem = React.forwardRef< 
 78:   React.ElementRef<typeof SelectPrimitive.Item>,
 79:   React.ComponentPropsWithoutRef<typeof SelectPrimitive.Item>
 80: >(({ className, children, ...props }, ref) => (
 81:   <SelectPrimitive.Item
 82:     ref={ref}
 83:     className={cn(
 84:       'relative flex w-full cursor-default select-none items-center rounded-sm py-1.5 pl-8 pr-2 text-sm outline-none focus:bg-accent focus:text-accent-foreground data-[disabled]:pointer-events-none data-[disabled]:opacity-50',
 85:       className,
 86:     )}
 87:     {...props}
 88:   >
 89:     <span className="absolute left-2 flex h-3.5 w-3.5 items-center justify-center">
 90:       <SelectPrimitive.ItemIndicator>
 91:         <Check className="h-4 w-4" />
 92:       </SelectPrimitive.ItemIndicator>
 93:     </span>
 94: 
 95:     <SelectPrimitive.ItemText>{children}</SelectPrimitive.ItemText>
 96:   </SelectPrimitive.Item>
 97: ))
 98: SelectItem.displayName = SelectPrimitive.Item.displayName
 99: 
100: const SelectSeparator = React.forwardRef< 
101:   React.ElementRef<typeof SelectPrimitive.Separator>,
102:   React.ComponentPropsWithoutRef<typeof SelectPrimitive.Separator>
103: >(({ className, ...props }, ref) => (
104:   <SelectPrimitive.Separator
105:     ref={ref}
106:     className={cn('-mx-1 my-1 h-px bg-muted', className)}
107:     {...props}
108:   />
109: ))
110: SelectSeparator.displayName = SelectPrimitive.Separator.displayName
111: 
112: export {
113:   Select,
114:   SelectGroup,
115:   SelectValue,
116:   SelectTrigger,
117:   SelectContent,
118:   SelectLabel,
119:   SelectItem,
120:   SelectSeparator,
121: }
</file>

<file path="src/components/ui/toaster.tsx">
 1: 'use client'
 2: 
 3: import {
 4:   Toast,
 5:   ToastClose,
 6:   ToastDescription,
 7:   ToastProvider,
 8:   ToastTitle,
 9:   ToastViewport,
10: } from '@/components/ui/toast'
11: import { useToast } from '@/components/ui/use-toast'
12: 
13: /**
14:  * @description Renders a toaster component to display toasts.
15:  * @returns {React.ReactElement}
16:  */
17: export function Toaster() {
18:   const { toasts } = useToast()
19: 
20:   return (
21:     <ToastProvider>
22:       {toasts.map(function ({ id, title, description, action, ...props }) {
23:         return (
24:           <Toast key={id} {...props}>
25:             <div className="grid gap-1">
26:               {title && <ToastTitle>{title}</ToastTitle>}
27:               {description && <ToastDescription>{description}</ToastDescription>}
28:             </div>
29:             {action}
30:             <ToastClose />
31:           </Toast>
32:         )
33:       })}
34:       <ToastViewport />
35:     </ToastProvider>
36:   )
37: }
</file>

<file path="src/components/ui/use-toast.ts">
  1: // Inspired by react-hot-toast library
  2: import * as React from 'react'
  3: 
  4: type ToasterToast = ToastProps & {
  5:   id: string
  6:   title?: React.ReactNode
  7:   description?: React.ReactNode
  8:   action?: React.ReactNode
  9:   open?: boolean
 10:   onOpenChange?: (open: boolean) => void
 11: }
 12: 
 13: const TOAST_LIMIT = 1
 14: const TOAST_REMOVE_DELAY = 1000000
 15: 
 16: type ToastProps = {
 17:   // props
 18: }
 19: 
 20: /**
 21:  * @description Defines the types of actions that can be performed on toasts.
 22:  */
 23: const actionTypes = {
 24:   ADD_TOAST: 'ADD_TOAST',
 25:   UPDATE_TOAST: 'UPDATE_TOAST',
 26:   DISMISS_TOAST: 'DISMISS_TOAST',
 27:   REMOVE_TOAST: 'REMOVE_TOAST',
 28: } as const
 29: 
 30: let count = 0
 31: 
 32: /**
 33:  * @description Generates a unique ID for a toast.
 34:  * @returns {string}
 35:  */
 36: function genId() {
 37:   count = (count + 1) % 100
 38:   return count.toString()
 39: }
 40: 
 41: type ActionType = typeof actionTypes
 42: 
 43: type Action =
 44:   | {
 45:       type: ActionType['ADD_TOAST']
 46:       toast: ToasterToast
 47:     }
 48:   | {
 49:       type: ActionType['UPDATE_TOAST']
 50:       toast: Partial<ToasterToast>
 51:     }
 52:   | {
 53:       type: ActionType['DISMISS_TOAST']
 54:       toastId?: ToasterToast['id']
 55:     }
 56:   | {
 57:       type: ActionType['REMOVE_TOAST']
 58:       toastId?: ToasterToast['id']
 59:     }
 60: 
 61: interface State {
 62:   toasts: ToasterToast[]
 63: }
 64: 
 65: const toastTimeouts = new Map<string, ReturnType<typeof setTimeout>>()
 66: 
 67: /**
 68:  * @description Adds a toast to the remove queue after a delay.
 69:  * @param {string} toastId
 70:  * @returns {void}
 71:  */
 72: const addToRemoveQueue = (toastId: string) => {
 73:   if (toastTimeouts.has(toastId)) {
 74:     return
 75:   }
 76: 
 77:   const timeout = setTimeout(() => {
 78:     toastTimeouts.delete(toastId)
 79:     dispatch({
 80:       type: 'REMOVE_TOAST',
 81:       toastId: toastId,
 82:     })
 83:   }, TOAST_REMOVE_DELAY)
 84: 
 85:   toastTimeouts.set(toastId, timeout)
 86: }
 87: 
 88: /**
 89:  * @description Reducer function for managing toast state.
 90:  * @param {State} state
 91:  * @param {Action} action
 92:  * @returns {State}
 93:  */
 94: export const reducer = (state: State, action: Action): State => {
 95:   switch (action.type) {
 96:     case 'ADD_TOAST':
 97:       return {
 98:         ...state,
 99:         toasts: [action.toast, ...state.toasts].slice(0, TOAST_LIMIT),
100:       }
101: 
102:     case 'UPDATE_TOAST':
103:       return {
104:         ...state,
105:         toasts: state.toasts.map(t =>
106:           t.id === action.toast.id ? { ...t, ...action.toast } : t,
107:         ),
108:       }
109: 
110:     case 'DISMISS_TOAST': {
111:       const { toastId } = action
112: 
113:       // ! Side effects ! - This could be extracted into a dismissToast() action,
114:       // but I'll keep it here for simplicity
115:       if (toastId) {
116:         addToRemoveQueue(toastId)
117:       } else {
118:         state.toasts.forEach(toast => {
119:           addToRemoveQueue(toast.id)
120:         })
121:       }
122: 
123:       return {
124:         ...state,
125:         toasts: state.toasts.map(t =>
126:           t.id === toastId || toastId === undefined
127:             ? {
128:                 ...t,
129:                 open: false,
130:               }
131:             : t,
132:         ),
133:       }
134:     }
135:     case 'REMOVE_TOAST':
136:       if (action.toastId === undefined) {
137:         return {
138:           ...state,
139:           toasts: [],
140:         }
141:       }
142:       return {
143:         ...state,
144:         toasts: state.toasts.filter(t => t.id !== action.toastId),
145:       }
146:   }
147: }
148: 
149: const listeners: Array<(state: State) => void> = []
150: 
151: let memoryState: State = { toasts: [] }
152: 
153: /**
154:  * @description Dispatches an action to update the toast state.
155:  * @param {Action} action
156:  * @returns {void}
157:  */
158: function dispatch(action: Action) {
159:   memoryState = reducer(memoryState, action)
160:   listeners.forEach(listener => {
161:     listener(memoryState)
162:   })
163: }
164: 
165: type Toast = Omit<ToasterToast, 'id'>
166: 
167: /**
168:  * @description Displays a toast notification.
169:  * @param {Toast} props
170:  * @returns {{ id: string; dismiss: () => void; update: (props: ToasterToast) => void }}
171:  */
172: function toast(props: Toast) {
173:   const id = genId()
174: 
175:   const update = (props: ToasterToast) =>
176:     dispatch({
177:       type: 'UPDATE_TOAST',
178:       toast: { ...props, id },
179:     })
180:   const dismiss = () => dispatch({ type: 'DISMISS_TOAST', toastId: id })
181: 
182:   dispatch({
183:     type: 'ADD_TOAST',
184:     toast: {
185:       ...props,
186:       id,
187:       open: true,
188:       onOpenChange: (open: boolean) => {
189:         if (!open) dismiss()
190:       },
191:     },
192:   })
193: 
194:   return {
195:     id: id,
196:     dismiss,
197:     update,
198:   }
199: }
200: 
201: /**
202:  * @description A hook to access and manage toast notifications.
203:  * @returns {State & { toast: (props: Toast) => { id: string; dismiss: () => void; update: (props: ToasterToast) => void }; dismiss: (toastId?: string) => void }}
204:  */
205: function useToast() {
206:   const [state, setState] = React.useState<State>(memoryState)
207: 
208:   React.useEffect(() => {
209:     listeners.push(setState)
210:     return () => {
211:       const index = listeners.indexOf(setState)
212:       if (index > -1) {
213:         listeners.splice(index, 1)
214:       }
215:     }
216:   }, [state])
217: 
218:   return {
219:     ...state,
220:     toast,
221:     dismiss: (toastId?: string) => dispatch({ type: 'DISMISS_TOAST', toastId }),
222:   }
223: }
224: 
225: export { useToast, toast }
</file>

<file path="src/lib/utils.ts">
 1: import { type ClassValue, clsx } from 'clsx'
 2: import { twMerge } from 'tailwind-merge'
 3: 
 4: /**
 5:  * @description Combines Tailwind CSS classes and other class values into a single string.
 6:  * @param {ClassValue[]} inputs
 7:  * @returns {string}
 8:  */
 9: export function cn(...inputs: ClassValue[]) {
10:   return twMerge(clsx(inputs))
11: }
</file>

<file path="src/middleware/cors.ts">
 1: import { NextRequest, NextResponse } from 'next/server';
 2: 
 3: /**
 4:  * @description Sets CORS headers for API routes.
 5:  * @param {NextRequest} request
 6:  * @param {NextResponse} response
 7:  * @returns {NextResponse}
 8:  */
 9: export function setCorsHeaders(request: NextRequest, response: NextResponse) {
10:   if (request.nextUrl.pathname.startsWith('/api/')) {
11:     response.headers.set('Access-Control-Allow-Origin', process.env.PAYLOAD_PUBLIC_SERVER_URL || '*');
12:     response.headers.set('Access-Control-Allow-Methods', 'GET, POST, PUT, DELETE, OPTIONS');
13:     response.headers.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
14:     response.headers.set('Access-Control-Allow-Credentials', 'true');
15:   }
16: 
17:   if (request.method === 'OPTIONS') {
18:     return new Response(null, { status: 200, headers: response.headers });
19:   }
20:   return response;
21: }
</file>

<file path="src/middleware/csrfProtection.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import crypto from 'crypto'
 3: 
 4: const CSRF_TOKEN_HEADER = 'x-csrf-token'
 5: const CSRF_COOKIE_NAME = 'csrf-token'
 6: 
 7: function generateCsrfToken() {
 8:   return crypto.randomBytes(32).toString('hex')
 9: }
10: 
11: export function csrfProtection(request: NextRequest) {
12:   const method = request.method.toUpperCase()
13:   const safeMethods = ['GET', 'HEAD', 'OPTIONS', 'TRACE']
14: 
15:   // For safe methods, generate and set CSRF token cookie if not present
16:   if (safeMethods.includes(method)) {
17:     const csrfToken = request.cookies.get(CSRF_COOKIE_NAME)?.value || generateCsrfToken()
18:     const response = NextResponse.next()
19:     response.cookies.set(CSRF_COOKIE_NAME, csrfToken, {
20:       httpOnly: false,
21:       secure: process.env.NODE_ENV === 'production',
22:       sameSite: 'strict',
23:       path: '/',
24:       maxAge: 60 * 60 * 24, // 1 day
25:     })
26:     return response
27:   }
28: 
29:   // For unsafe methods, validate CSRF token header matches cookie
30:   const csrfCookie = request.cookies.get(CSRF_COOKIE_NAME)?.value
31:   const csrfHeader = request.headers.get(CSRF_TOKEN_HEADER)
32: 
33:   if (!csrfCookie || !csrfHeader || csrfCookie !== csrfHeader) {
34:     return new NextResponse('Invalid CSRF token', { status: 403 })
35:   }
36: 
37:   return NextResponse.next()
38: }
</file>

<file path="src/middleware/securityHeaders.ts">
 1: import { NextRequest, NextResponse } from 'next/server';
 2: 
 3: /**
 4:  * @description Sets security headers for the response.
 5:  * @param {NextResponse} response
 6:  * @returns {void}
 7:  */
 8: export function setSecurityHeaders(response: NextResponse) {
 9:   response.headers.set('X-Frame-Options', 'DENY');
10:   response.headers.set('X-Content-Type-Options', 'nosniff');
11:   response.headers.set('Referrer-Policy', 'origin-when-cross-origin');
12:   response.headers.set('X-XSS-Protection', '1; mode=block');
13: }
</file>

<file path="src/migrations/20250702_042115_initial_schema.json">
   1: {
   2:   "id": "727476b3-6a7a-4b93-a215-0d1782abad0b",
   3:   "prevId": "00000000-0000-0000-0000-000000000000",
   4:   "version": "7",
   5:   "dialect": "postgresql",
   6:   "tables": {
   7:     "public.users_roles": {
   8:       "name": "users_roles",
   9:       "schema": "",
  10:       "columns": {
  11:         "order": {
  12:           "name": "order",
  13:           "type": "integer",
  14:           "primaryKey": false,
  15:           "notNull": true
  16:         },
  17:         "parent_id": {
  18:           "name": "parent_id",
  19:           "type": "integer",
  20:           "primaryKey": false,
  21:           "notNull": true
  22:         },
  23:         "value": {
  24:           "name": "value",
  25:           "type": "enum_users_roles",
  26:           "typeSchema": "public",
  27:           "primaryKey": false,
  28:           "notNull": false
  29:         },
  30:         "id": {
  31:           "name": "id",
  32:           "type": "serial",
  33:           "primaryKey": true,
  34:           "notNull": true
  35:         }
  36:       },
  37:       "indexes": {
  38:         "users_roles_order_idx": {
  39:           "name": "users_roles_order_idx",
  40:           "columns": [
  41:             {
  42:               "expression": "order",
  43:               "isExpression": false,
  44:               "asc": true,
  45:               "nulls": "last"
  46:             }
  47:           ],
  48:           "isUnique": false,
  49:           "concurrently": false,
  50:           "method": "btree",
  51:           "with": {}
  52:         },
  53:         "users_roles_parent_idx": {
  54:           "name": "users_roles_parent_idx",
  55:           "columns": [
  56:             {
  57:               "expression": "parent_id",
  58:               "isExpression": false,
  59:               "asc": true,
  60:               "nulls": "last"
  61:             }
  62:           ],
  63:           "isUnique": false,
  64:           "concurrently": false,
  65:           "method": "btree",
  66:           "with": {}
  67:         }
  68:       },
  69:       "foreignKeys": {
  70:         "users_roles_parent_fk": {
  71:           "name": "users_roles_parent_fk",
  72:           "tableFrom": "users_roles",
  73:           "tableTo": "users",
  74:           "columnsFrom": [
  75:             "parent_id"
  76:           ],
  77:           "columnsTo": [
  78:             "id"
  79:           ],
  80:           "onDelete": "cascade",
  81:           "onUpdate": "no action"
  82:         }
  83:       },
  84:       "compositePrimaryKeys": {},
  85:       "uniqueConstraints": {},
  86:       "policies": {},
  87:       "checkConstraints": {},
  88:       "isRLSEnabled": false
  89:     },
  90:     "public.users_sessions": {
  91:       "name": "users_sessions",
  92:       "schema": "",
  93:       "columns": {
  94:         "_order": {
  95:           "name": "_order",
  96:           "type": "integer",
  97:           "primaryKey": false,
  98:           "notNull": true
  99:         },
 100:         "_parent_id": {
 101:           "name": "_parent_id",
 102:           "type": "integer",
 103:           "primaryKey": false,
 104:           "notNull": true
 105:         },
 106:         "id": {
 107:           "name": "id",
 108:           "type": "varchar",
 109:           "primaryKey": true,
 110:           "notNull": true
 111:         },
 112:         "created_at": {
 113:           "name": "created_at",
 114:           "type": "timestamp(3) with time zone",
 115:           "primaryKey": false,
 116:           "notNull": false
 117:         },
 118:         "expires_at": {
 119:           "name": "expires_at",
 120:           "type": "timestamp(3) with time zone",
 121:           "primaryKey": false,
 122:           "notNull": true
 123:         }
 124:       },
 125:       "indexes": {
 126:         "users_sessions_order_idx": {
 127:           "name": "users_sessions_order_idx",
 128:           "columns": [
 129:             {
 130:               "expression": "_order",
 131:               "isExpression": false,
 132:               "asc": true,
 133:               "nulls": "last"
 134:             }
 135:           ],
 136:           "isUnique": false,
 137:           "concurrently": false,
 138:           "method": "btree",
 139:           "with": {}
 140:         },
 141:         "users_sessions_parent_id_idx": {
 142:           "name": "users_sessions_parent_id_idx",
 143:           "columns": [
 144:             {
 145:               "expression": "_parent_id",
 146:               "isExpression": false,
 147:               "asc": true,
 148:               "nulls": "last"
 149:             }
 150:           ],
 151:           "isUnique": false,
 152:           "concurrently": false,
 153:           "method": "btree",
 154:           "with": {}
 155:         }
 156:       },
 157:       "foreignKeys": {
 158:         "users_sessions_parent_id_fk": {
 159:           "name": "users_sessions_parent_id_fk",
 160:           "tableFrom": "users_sessions",
 161:           "tableTo": "users",
 162:           "columnsFrom": [
 163:             "_parent_id"
 164:           ],
 165:           "columnsTo": [
 166:             "id"
 167:           ],
 168:           "onDelete": "cascade",
 169:           "onUpdate": "no action"
 170:         }
 171:       },
 172:       "compositePrimaryKeys": {},
 173:       "uniqueConstraints": {},
 174:       "policies": {},
 175:       "checkConstraints": {},
 176:       "isRLSEnabled": false
 177:     },
 178:     "public.users": {
 179:       "name": "users",
 180:       "schema": "",
 181:       "columns": {
 182:         "id": {
 183:           "name": "id",
 184:           "type": "serial",
 185:           "primaryKey": true,
 186:           "notNull": true
 187:         },
 188:         "first_name": {
 189:           "name": "first_name",
 190:           "type": "varchar",
 191:           "primaryKey": false,
 192:           "notNull": true
 193:         },
 194:         "last_name": {
 195:           "name": "last_name",
 196:           "type": "varchar",
 197:           "primaryKey": false,
 198:           "notNull": true
 199:         },
 200:         "phone": {
 201:           "name": "phone",
 202:           "type": "varchar",
 203:           "primaryKey": false,
 204:           "notNull": false
 205:         },
 206:         "employee_id": {
 207:           "name": "employee_id",
 208:           "type": "varchar",
 209:           "primaryKey": false,
 210:           "notNull": false
 211:         },
 212:         "status": {
 213:           "name": "status",
 214:           "type": "enum_users_status",
 215:           "typeSchema": "public",
 216:           "primaryKey": false,
 217:           "notNull": false,
 218:           "default": "'active'"
 219:         },
 220:         "primary_location_id": {
 221:           "name": "primary_location_id",
 222:           "type": "integer",
 223:           "primaryKey": false,
 224:           "notNull": false
 225:         },
 226:         "employment_details_hire_date": {
 227:           "name": "employment_details_hire_date",
 228:           "type": "timestamp(3) with time zone",
 229:           "primaryKey": false,
 230:           "notNull": false
 231:         },
 232:         "employment_details_termination_date": {
 233:           "name": "employment_details_termination_date",
 234:           "type": "timestamp(3) with time zone",
 235:           "primaryKey": false,
 236:           "notNull": false
 237:         },
 238:         "employment_details_employment_type": {
 239:           "name": "employment_details_employment_type",
 240:           "type": "enum_users_employment_details_employment_type",
 241:           "typeSchema": "public",
 242:           "primaryKey": false,
 243:           "notNull": false
 244:         },
 245:         "employment_details_hourly_rate": {
 246:           "name": "employment_details_hourly_rate",
 247:           "type": "numeric",
 248:           "primaryKey": false,
 249:           "notNull": false
 250:         },
 251:         "profile_photo_id": {
 252:           "name": "profile_photo_id",
 253:           "type": "integer",
 254:           "primaryKey": false,
 255:           "notNull": false
 256:         },
 257:         "updated_at": {
 258:           "name": "updated_at",
 259:           "type": "timestamp(3) with time zone",
 260:           "primaryKey": false,
 261:           "notNull": true,
 262:           "default": "now()"
 263:         },
 264:         "created_at": {
 265:           "name": "created_at",
 266:           "type": "timestamp(3) with time zone",
 267:           "primaryKey": false,
 268:           "notNull": true,
 269:           "default": "now()"
 270:         },
 271:         "email": {
 272:           "name": "email",
 273:           "type": "varchar",
 274:           "primaryKey": false,
 275:           "notNull": true
 276:         },
 277:         "reset_password_token": {
 278:           "name": "reset_password_token",
 279:           "type": "varchar",
 280:           "primaryKey": false,
 281:           "notNull": false
 282:         },
 283:         "reset_password_expiration": {
 284:           "name": "reset_password_expiration",
 285:           "type": "timestamp(3) with time zone",
 286:           "primaryKey": false,
 287:           "notNull": false
 288:         },
 289:         "salt": {
 290:           "name": "salt",
 291:           "type": "varchar",
 292:           "primaryKey": false,
 293:           "notNull": false
 294:         },
 295:         "hash": {
 296:           "name": "hash",
 297:           "type": "varchar",
 298:           "primaryKey": false,
 299:           "notNull": false
 300:         },
 301:         "login_attempts": {
 302:           "name": "login_attempts",
 303:           "type": "numeric",
 304:           "primaryKey": false,
 305:           "notNull": false,
 306:           "default": 0
 307:         },
 308:         "lock_until": {
 309:           "name": "lock_until",
 310:           "type": "timestamp(3) with time zone",
 311:           "primaryKey": false,
 312:           "notNull": false
 313:         }
 314:       },
 315:       "indexes": {
 316:         "users_employee_id_idx": {
 317:           "name": "users_employee_id_idx",
 318:           "columns": [
 319:             {
 320:               "expression": "employee_id",
 321:               "isExpression": false,
 322:               "asc": true,
 323:               "nulls": "last"
 324:             }
 325:           ],
 326:           "isUnique": true,
 327:           "concurrently": false,
 328:           "method": "btree",
 329:           "with": {}
 330:         },
 331:         "users_primary_location_idx": {
 332:           "name": "users_primary_location_idx",
 333:           "columns": [
 334:             {
 335:               "expression": "primary_location_id",
 336:               "isExpression": false,
 337:               "asc": true,
 338:               "nulls": "last"
 339:             }
 340:           ],
 341:           "isUnique": false,
 342:           "concurrently": false,
 343:           "method": "btree",
 344:           "with": {}
 345:         },
 346:         "users_profile_photo_idx": {
 347:           "name": "users_profile_photo_idx",
 348:           "columns": [
 349:             {
 350:               "expression": "profile_photo_id",
 351:               "isExpression": false,
 352:               "asc": true,
 353:               "nulls": "last"
 354:             }
 355:           ],
 356:           "isUnique": false,
 357:           "concurrently": false,
 358:           "method": "btree",
 359:           "with": {}
 360:         },
 361:         "users_updated_at_idx": {
 362:           "name": "users_updated_at_idx",
 363:           "columns": [
 364:             {
 365:               "expression": "updated_at",
 366:               "isExpression": false,
 367:               "asc": true,
 368:               "nulls": "last"
 369:             }
 370:           ],
 371:           "isUnique": false,
 372:           "concurrently": false,
 373:           "method": "btree",
 374:           "with": {}
 375:         },
 376:         "users_created_at_idx": {
 377:           "name": "users_created_at_idx",
 378:           "columns": [
 379:             {
 380:               "expression": "created_at",
 381:               "isExpression": false,
 382:               "asc": true,
 383:               "nulls": "last"
 384:             }
 385:           ],
 386:           "isUnique": false,
 387:           "concurrently": false,
 388:           "method": "btree",
 389:           "with": {}
 390:         },
 391:         "users_email_idx": {
 392:           "name": "users_email_idx",
 393:           "columns": [
 394:             {
 395:               "expression": "email",
 396:               "isExpression": false,
 397:               "asc": true,
 398:               "nulls": "last"
 399:             }
 400:           ],
 401:           "isUnique": true,
 402:           "concurrently": false,
 403:           "method": "btree",
 404:           "with": {}
 405:         }
 406:       },
 407:       "foreignKeys": {
 408:         "users_primary_location_id_locations_id_fk": {
 409:           "name": "users_primary_location_id_locations_id_fk",
 410:           "tableFrom": "users",
 411:           "tableTo": "locations",
 412:           "columnsFrom": [
 413:             "primary_location_id"
 414:           ],
 415:           "columnsTo": [
 416:             "id"
 417:           ],
 418:           "onDelete": "set null",
 419:           "onUpdate": "no action"
 420:         },
 421:         "users_profile_photo_id_media_id_fk": {
 422:           "name": "users_profile_photo_id_media_id_fk",
 423:           "tableFrom": "users",
 424:           "tableTo": "media",
 425:           "columnsFrom": [
 426:             "profile_photo_id"
 427:           ],
 428:           "columnsTo": [
 429:             "id"
 430:           ],
 431:           "onDelete": "set null",
 432:           "onUpdate": "no action"
 433:         }
 434:       },
 435:       "compositePrimaryKeys": {},
 436:       "uniqueConstraints": {},
 437:       "policies": {},
 438:       "checkConstraints": {},
 439:       "isRLSEnabled": false
 440:     },
 441:     "public.users_rels": {
 442:       "name": "users_rels",
 443:       "schema": "",
 444:       "columns": {
 445:         "id": {
 446:           "name": "id",
 447:           "type": "serial",
 448:           "primaryKey": true,
 449:           "notNull": true
 450:         },
 451:         "order": {
 452:           "name": "order",
 453:           "type": "integer",
 454:           "primaryKey": false,
 455:           "notNull": false
 456:         },
 457:         "parent_id": {
 458:           "name": "parent_id",
 459:           "type": "integer",
 460:           "primaryKey": false,
 461:           "notNull": true
 462:         },
 463:         "path": {
 464:           "name": "path",
 465:           "type": "varchar",
 466:           "primaryKey": false,
 467:           "notNull": true
 468:         },
 469:         "locations_id": {
 470:           "name": "locations_id",
 471:           "type": "integer",
 472:           "primaryKey": false,
 473:           "notNull": false
 474:         },
 475:         "jobs_id": {
 476:           "name": "jobs_id",
 477:           "type": "integer",
 478:           "primaryKey": false,
 479:           "notNull": false
 480:         }
 481:       },
 482:       "indexes": {
 483:         "users_rels_order_idx": {
 484:           "name": "users_rels_order_idx",
 485:           "columns": [
 486:             {
 487:               "expression": "order",
 488:               "isExpression": false,
 489:               "asc": true,
 490:               "nulls": "last"
 491:             }
 492:           ],
 493:           "isUnique": false,
 494:           "concurrently": false,
 495:           "method": "btree",
 496:           "with": {}
 497:         },
 498:         "users_rels_parent_idx": {
 499:           "name": "users_rels_parent_idx",
 500:           "columns": [
 501:             {
 502:               "expression": "parent_id",
 503:               "isExpression": false,
 504:               "asc": true,
 505:               "nulls": "last"
 506:             }
 507:           ],
 508:           "isUnique": false,
 509:           "concurrently": false,
 510:           "method": "btree",
 511:           "with": {}
 512:         },
 513:         "users_rels_path_idx": {
 514:           "name": "users_rels_path_idx",
 515:           "columns": [
 516:             {
 517:               "expression": "path",
 518:               "isExpression": false,
 519:               "asc": true,
 520:               "nulls": "last"
 521:             }
 522:           ],
 523:           "isUnique": false,
 524:           "concurrently": false,
 525:           "method": "btree",
 526:           "with": {}
 527:         },
 528:         "users_rels_locations_id_idx": {
 529:           "name": "users_rels_locations_id_idx",
 530:           "columns": [
 531:             {
 532:               "expression": "locations_id",
 533:               "isExpression": false,
 534:               "asc": true,
 535:               "nulls": "last"
 536:             }
 537:           ],
 538:           "isUnique": false,
 539:           "concurrently": false,
 540:           "method": "btree",
 541:           "with": {}
 542:         },
 543:         "users_rels_jobs_id_idx": {
 544:           "name": "users_rels_jobs_id_idx",
 545:           "columns": [
 546:             {
 547:               "expression": "jobs_id",
 548:               "isExpression": false,
 549:               "asc": true,
 550:               "nulls": "last"
 551:             }
 552:           ],
 553:           "isUnique": false,
 554:           "concurrently": false,
 555:           "method": "btree",
 556:           "with": {}
 557:         }
 558:       },
 559:       "foreignKeys": {
 560:         "users_rels_parent_fk": {
 561:           "name": "users_rels_parent_fk",
 562:           "tableFrom": "users_rels",
 563:           "tableTo": "users",
 564:           "columnsFrom": [
 565:             "parent_id"
 566:           ],
 567:           "columnsTo": [
 568:             "id"
 569:           ],
 570:           "onDelete": "cascade",
 571:           "onUpdate": "no action"
 572:         },
 573:         "users_rels_locations_fk": {
 574:           "name": "users_rels_locations_fk",
 575:           "tableFrom": "users_rels",
 576:           "tableTo": "locations",
 577:           "columnsFrom": [
 578:             "locations_id"
 579:           ],
 580:           "columnsTo": [
 581:             "id"
 582:           ],
 583:           "onDelete": "cascade",
 584:           "onUpdate": "no action"
 585:         },
 586:         "users_rels_jobs_fk": {
 587:           "name": "users_rels_jobs_fk",
 588:           "tableFrom": "users_rels",
 589:           "tableTo": "jobs",
 590:           "columnsFrom": [
 591:             "jobs_id"
 592:           ],
 593:           "columnsTo": [
 594:             "id"
 595:           ],
 596:           "onDelete": "cascade",
 597:           "onUpdate": "no action"
 598:         }
 599:       },
 600:       "compositePrimaryKeys": {},
 601:       "uniqueConstraints": {},
 602:       "policies": {},
 603:       "checkConstraints": {},
 604:       "isRLSEnabled": false
 605:     },
 606:     "public.media": {
 607:       "name": "media",
 608:       "schema": "",
 609:       "columns": {
 610:         "id": {
 611:           "name": "id",
 612:           "type": "serial",
 613:           "primaryKey": true,
 614:           "notNull": true
 615:         },
 616:         "alt": {
 617:           "name": "alt",
 618:           "type": "varchar",
 619:           "primaryKey": false,
 620:           "notNull": false
 621:         },
 622:         "caption": {
 623:           "name": "caption",
 624:           "type": "varchar",
 625:           "primaryKey": false,
 626:           "notNull": false
 627:         },
 628:         "uploaded_by_id": {
 629:           "name": "uploaded_by_id",
 630:           "type": "integer",
 631:           "primaryKey": false,
 632:           "notNull": true
 633:         },
 634:         "updated_at": {
 635:           "name": "updated_at",
 636:           "type": "timestamp(3) with time zone",
 637:           "primaryKey": false,
 638:           "notNull": true,
 639:           "default": "now()"
 640:         },
 641:         "created_at": {
 642:           "name": "created_at",
 643:           "type": "timestamp(3) with time zone",
 644:           "primaryKey": false,
 645:           "notNull": true,
 646:           "default": "now()"
 647:         },
 648:         "url": {
 649:           "name": "url",
 650:           "type": "varchar",
 651:           "primaryKey": false,
 652:           "notNull": false
 653:         },
 654:         "thumbnail_u_r_l": {
 655:           "name": "thumbnail_u_r_l",
 656:           "type": "varchar",
 657:           "primaryKey": false,
 658:           "notNull": false
 659:         },
 660:         "filename": {
 661:           "name": "filename",
 662:           "type": "varchar",
 663:           "primaryKey": false,
 664:           "notNull": false
 665:         },
 666:         "mime_type": {
 667:           "name": "mime_type",
 668:           "type": "varchar",
 669:           "primaryKey": false,
 670:           "notNull": false
 671:         },
 672:         "filesize": {
 673:           "name": "filesize",
 674:           "type": "numeric",
 675:           "primaryKey": false,
 676:           "notNull": false
 677:         },
 678:         "width": {
 679:           "name": "width",
 680:           "type": "numeric",
 681:           "primaryKey": false,
 682:           "notNull": false
 683:         },
 684:         "height": {
 685:           "name": "height",
 686:           "type": "numeric",
 687:           "primaryKey": false,
 688:           "notNull": false
 689:         },
 690:         "focal_x": {
 691:           "name": "focal_x",
 692:           "type": "numeric",
 693:           "primaryKey": false,
 694:           "notNull": false
 695:         },
 696:         "focal_y": {
 697:           "name": "focal_y",
 698:           "type": "numeric",
 699:           "primaryKey": false,
 700:           "notNull": false
 701:         },
 702:         "sizes_thumbnail_url": {
 703:           "name": "sizes_thumbnail_url",
 704:           "type": "varchar",
 705:           "primaryKey": false,
 706:           "notNull": false
 707:         },
 708:         "sizes_thumbnail_width": {
 709:           "name": "sizes_thumbnail_width",
 710:           "type": "numeric",
 711:           "primaryKey": false,
 712:           "notNull": false
 713:         },
 714:         "sizes_thumbnail_height": {
 715:           "name": "sizes_thumbnail_height",
 716:           "type": "numeric",
 717:           "primaryKey": false,
 718:           "notNull": false
 719:         },
 720:         "sizes_thumbnail_mime_type": {
 721:           "name": "sizes_thumbnail_mime_type",
 722:           "type": "varchar",
 723:           "primaryKey": false,
 724:           "notNull": false
 725:         },
 726:         "sizes_thumbnail_filesize": {
 727:           "name": "sizes_thumbnail_filesize",
 728:           "type": "numeric",
 729:           "primaryKey": false,
 730:           "notNull": false
 731:         },
 732:         "sizes_thumbnail_filename": {
 733:           "name": "sizes_thumbnail_filename",
 734:           "type": "varchar",
 735:           "primaryKey": false,
 736:           "notNull": false
 737:         },
 738:         "sizes_card_url": {
 739:           "name": "sizes_card_url",
 740:           "type": "varchar",
 741:           "primaryKey": false,
 742:           "notNull": false
 743:         },
 744:         "sizes_card_width": {
 745:           "name": "sizes_card_width",
 746:           "type": "numeric",
 747:           "primaryKey": false,
 748:           "notNull": false
 749:         },
 750:         "sizes_card_height": {
 751:           "name": "sizes_card_height",
 752:           "type": "numeric",
 753:           "primaryKey": false,
 754:           "notNull": false
 755:         },
 756:         "sizes_card_mime_type": {
 757:           "name": "sizes_card_mime_type",
 758:           "type": "varchar",
 759:           "primaryKey": false,
 760:           "notNull": false
 761:         },
 762:         "sizes_card_filesize": {
 763:           "name": "sizes_card_filesize",
 764:           "type": "numeric",
 765:           "primaryKey": false,
 766:           "notNull": false
 767:         },
 768:         "sizes_card_filename": {
 769:           "name": "sizes_card_filename",
 770:           "type": "varchar",
 771:           "primaryKey": false,
 772:           "notNull": false
 773:         },
 774:         "sizes_tablet_url": {
 775:           "name": "sizes_tablet_url",
 776:           "type": "varchar",
 777:           "primaryKey": false,
 778:           "notNull": false
 779:         },
 780:         "sizes_tablet_width": {
 781:           "name": "sizes_tablet_width",
 782:           "type": "numeric",
 783:           "primaryKey": false,
 784:           "notNull": false
 785:         },
 786:         "sizes_tablet_height": {
 787:           "name": "sizes_tablet_height",
 788:           "type": "numeric",
 789:           "primaryKey": false,
 790:           "notNull": false
 791:         },
 792:         "sizes_tablet_mime_type": {
 793:           "name": "sizes_tablet_mime_type",
 794:           "type": "varchar",
 795:           "primaryKey": false,
 796:           "notNull": false
 797:         },
 798:         "sizes_tablet_filesize": {
 799:           "name": "sizes_tablet_filesize",
 800:           "type": "numeric",
 801:           "primaryKey": false,
 802:           "notNull": false
 803:         },
 804:         "sizes_tablet_filename": {
 805:           "name": "sizes_tablet_filename",
 806:           "type": "varchar",
 807:           "primaryKey": false,
 808:           "notNull": false
 809:         }
 810:       },
 811:       "indexes": {
 812:         "media_uploaded_by_idx": {
 813:           "name": "media_uploaded_by_idx",
 814:           "columns": [
 815:             {
 816:               "expression": "uploaded_by_id",
 817:               "isExpression": false,
 818:               "asc": true,
 819:               "nulls": "last"
 820:             }
 821:           ],
 822:           "isUnique": false,
 823:           "concurrently": false,
 824:           "method": "btree",
 825:           "with": {}
 826:         },
 827:         "media_updated_at_idx": {
 828:           "name": "media_updated_at_idx",
 829:           "columns": [
 830:             {
 831:               "expression": "updated_at",
 832:               "isExpression": false,
 833:               "asc": true,
 834:               "nulls": "last"
 835:             }
 836:           ],
 837:           "isUnique": false,
 838:           "concurrently": false,
 839:           "method": "btree",
 840:           "with": {}
 841:         },
 842:         "media_created_at_idx": {
 843:           "name": "media_created_at_idx",
 844:           "columns": [
 845:             {
 846:               "expression": "created_at",
 847:               "isExpression": false,
 848:               "asc": true,
 849:               "nulls": "last"
 850:             }
 851:           ],
 852:           "isUnique": false,
 853:           "concurrently": false,
 854:           "method": "btree",
 855:           "with": {}
 856:         },
 857:         "media_filename_idx": {
 858:           "name": "media_filename_idx",
 859:           "columns": [
 860:             {
 861:               "expression": "filename",
 862:               "isExpression": false,
 863:               "asc": true,
 864:               "nulls": "last"
 865:             }
 866:           ],
 867:           "isUnique": true,
 868:           "concurrently": false,
 869:           "method": "btree",
 870:           "with": {}
 871:         },
 872:         "media_sizes_thumbnail_sizes_thumbnail_filename_idx": {
 873:           "name": "media_sizes_thumbnail_sizes_thumbnail_filename_idx",
 874:           "columns": [
 875:             {
 876:               "expression": "sizes_thumbnail_filename",
 877:               "isExpression": false,
 878:               "asc": true,
 879:               "nulls": "last"
 880:             }
 881:           ],
 882:           "isUnique": false,
 883:           "concurrently": false,
 884:           "method": "btree",
 885:           "with": {}
 886:         },
 887:         "media_sizes_card_sizes_card_filename_idx": {
 888:           "name": "media_sizes_card_sizes_card_filename_idx",
 889:           "columns": [
 890:             {
 891:               "expression": "sizes_card_filename",
 892:               "isExpression": false,
 893:               "asc": true,
 894:               "nulls": "last"
 895:             }
 896:           ],
 897:           "isUnique": false,
 898:           "concurrently": false,
 899:           "method": "btree",
 900:           "with": {}
 901:         },
 902:         "media_sizes_tablet_sizes_tablet_filename_idx": {
 903:           "name": "media_sizes_tablet_sizes_tablet_filename_idx",
 904:           "columns": [
 905:             {
 906:               "expression": "sizes_tablet_filename",
 907:               "isExpression": false,
 908:               "asc": true,
 909:               "nulls": "last"
 910:             }
 911:           ],
 912:           "isUnique": false,
 913:           "concurrently": false,
 914:           "method": "btree",
 915:           "with": {}
 916:         }
 917:       },
 918:       "foreignKeys": {
 919:         "media_uploaded_by_id_users_id_fk": {
 920:           "name": "media_uploaded_by_id_users_id_fk",
 921:           "tableFrom": "media",
 922:           "tableTo": "users",
 923:           "columnsFrom": [
 924:             "uploaded_by_id"
 925:           ],
 926:           "columnsTo": [
 927:             "id"
 928:           ],
 929:           "onDelete": "set null",
 930:           "onUpdate": "no action"
 931:         }
 932:       },
 933:       "compositePrimaryKeys": {},
 934:       "uniqueConstraints": {},
 935:       "policies": {},
 936:       "checkConstraints": {},
 937:       "isRLSEnabled": false
 938:     },
 939:     "public.contacts": {
 940:       "name": "contacts",
 941:       "schema": "",
 942:       "columns": {
 943:         "id": {
 944:           "name": "id",
 945:           "type": "serial",
 946:           "primaryKey": true,
 947:           "notNull": true
 948:         },
 949:         "first_name": {
 950:           "name": "first_name",
 951:           "type": "varchar",
 952:           "primaryKey": false,
 953:           "notNull": true
 954:         },
 955:         "last_name": {
 956:           "name": "last_name",
 957:           "type": "varchar",
 958:           "primaryKey": false,
 959:           "notNull": true
 960:         },
 961:         "email": {
 962:           "name": "email",
 963:           "type": "varchar",
 964:           "primaryKey": false,
 965:           "notNull": false
 966:         },
 967:         "phone": {
 968:           "name": "phone",
 969:           "type": "varchar",
 970:           "primaryKey": false,
 971:           "notNull": false
 972:         },
 973:         "company": {
 974:           "name": "company",
 975:           "type": "varchar",
 976:           "primaryKey": false,
 977:           "notNull": false
 978:         },
 979:         "contact_type": {
 980:           "name": "contact_type",
 981:           "type": "enum_contacts_contact_type",
 982:           "typeSchema": "public",
 983:           "primaryKey": false,
 984:           "notNull": true,
 985:           "default": "'customer'"
 986:         },
 987:         "toast_id": {
 988:           "name": "toast_id",
 989:           "type": "varchar",
 990:           "primaryKey": false,
 991:           "notNull": false
 992:         },
 993:         "brevo_id": {
 994:           "name": "brevo_id",
 995:           "type": "varchar",
 996:           "primaryKey": false,
 997:           "notNull": false
 998:         },
 999:         "vip_id": {
1000:           "name": "vip_id",
1001:           "type": "numeric",
1002:           "primaryKey": false,
1003:           "notNull": false
1004:         },
1005:         "visit_frequency": {
1006:           "name": "visit_frequency",
1007:           "type": "enum_contacts_visit_frequency",
1008:           "typeSchema": "public",
1009:           "primaryKey": false,
1010:           "notNull": false
1011:         },
1012:         "last_visit": {
1013:           "name": "last_visit",
1014:           "type": "timestamp(3) with time zone",
1015:           "primaryKey": false,
1016:           "notNull": false
1017:         },
1018:         "total_visits": {
1019:           "name": "total_visits",
1020:           "type": "numeric",
1021:           "primaryKey": false,
1022:           "notNull": false,
1023:           "default": 0
1024:         },
1025:         "average_spend": {
1026:           "name": "average_spend",
1027:           "type": "numeric",
1028:           "primaryKey": false,
1029:           "notNull": false
1030:         },
1031:         "preferred_location_id": {
1032:           "name": "preferred_location_id",
1033:           "type": "integer",
1034:           "primaryKey": false,
1035:           "notNull": false
1036:         },
1037:         "notes": {
1038:           "name": "notes",
1039:           "type": "varchar",
1040:           "primaryKey": false,
1041:           "notNull": false
1042:         },
1043:         "marketing_consent": {
1044:           "name": "marketing_consent",
1045:           "type": "boolean",
1046:           "primaryKey": false,
1047:           "notNull": false,
1048:           "default": false
1049:         },
1050:         "birthday": {
1051:           "name": "birthday",
1052:           "type": "timestamp(3) with time zone",
1053:           "primaryKey": false,
1054:           "notNull": false
1055:         },
1056:         "anniversary": {
1057:           "name": "anniversary",
1058:           "type": "timestamp(3) with time zone",
1059:           "primaryKey": false,
1060:           "notNull": false
1061:         },
1062:         "updated_at": {
1063:           "name": "updated_at",
1064:           "type": "timestamp(3) with time zone",
1065:           "primaryKey": false,
1066:           "notNull": true,
1067:           "default": "now()"
1068:         },
1069:         "created_at": {
1070:           "name": "created_at",
1071:           "type": "timestamp(3) with time zone",
1072:           "primaryKey": false,
1073:           "notNull": true,
1074:           "default": "now()"
1075:         }
1076:       },
1077:       "indexes": {
1078:         "contacts_email_idx": {
1079:           "name": "contacts_email_idx",
1080:           "columns": [
1081:             {
1082:               "expression": "email",
1083:               "isExpression": false,
1084:               "asc": true,
1085:               "nulls": "last"
1086:             }
1087:           ],
1088:           "isUnique": true,
1089:           "concurrently": false,
1090:           "method": "btree",
1091:           "with": {}
1092:         },
1093:         "contacts_vip_id_idx": {
1094:           "name": "contacts_vip_id_idx",
1095:           "columns": [
1096:             {
1097:               "expression": "vip_id",
1098:               "isExpression": false,
1099:               "asc": true,
1100:               "nulls": "last"
1101:             }
1102:           ],
1103:           "isUnique": true,
1104:           "concurrently": false,
1105:           "method": "btree",
1106:           "with": {}
1107:         },
1108:         "contacts_preferred_location_idx": {
1109:           "name": "contacts_preferred_location_idx",
1110:           "columns": [
1111:             {
1112:               "expression": "preferred_location_id",
1113:               "isExpression": false,
1114:               "asc": true,
1115:               "nulls": "last"
1116:             }
1117:           ],
1118:           "isUnique": false,
1119:           "concurrently": false,
1120:           "method": "btree",
1121:           "with": {}
1122:         },
1123:         "contacts_updated_at_idx": {
1124:           "name": "contacts_updated_at_idx",
1125:           "columns": [
1126:             {
1127:               "expression": "updated_at",
1128:               "isExpression": false,
1129:               "asc": true,
1130:               "nulls": "last"
1131:             }
1132:           ],
1133:           "isUnique": false,
1134:           "concurrently": false,
1135:           "method": "btree",
1136:           "with": {}
1137:         },
1138:         "contacts_created_at_idx": {
1139:           "name": "contacts_created_at_idx",
1140:           "columns": [
1141:             {
1142:               "expression": "created_at",
1143:               "isExpression": false,
1144:               "asc": true,
1145:               "nulls": "last"
1146:             }
1147:           ],
1148:           "isUnique": false,
1149:           "concurrently": false,
1150:           "method": "btree",
1151:           "with": {}
1152:         }
1153:       },
1154:       "foreignKeys": {
1155:         "contacts_preferred_location_id_locations_id_fk": {
1156:           "name": "contacts_preferred_location_id_locations_id_fk",
1157:           "tableFrom": "contacts",
1158:           "tableTo": "locations",
1159:           "columnsFrom": [
1160:             "preferred_location_id"
1161:           ],
1162:           "columnsTo": [
1163:             "id"
1164:           ],
1165:           "onDelete": "set null",
1166:           "onUpdate": "no action"
1167:         }
1168:       },
1169:       "compositePrimaryKeys": {},
1170:       "uniqueConstraints": {},
1171:       "policies": {},
1172:       "checkConstraints": {},
1173:       "isRLSEnabled": false
1174:     },
1175:     "public.contacts_rels": {
1176:       "name": "contacts_rels",
1177:       "schema": "",
1178:       "columns": {
1179:         "id": {
1180:           "name": "id",
1181:           "type": "serial",
1182:           "primaryKey": true,
1183:           "notNull": true
1184:         },
1185:         "order": {
1186:           "name": "order",
1187:           "type": "integer",
1188:           "primaryKey": false,
1189:           "notNull": false
1190:         },
1191:         "parent_id": {
1192:           "name": "parent_id",
1193:           "type": "integer",
1194:           "primaryKey": false,
1195:           "notNull": true
1196:         },
1197:         "path": {
1198:           "name": "path",
1199:           "type": "varchar",
1200:           "primaryKey": false,
1201:           "notNull": true
1202:         },
1203:         "locations_id": {
1204:           "name": "locations_id",
1205:           "type": "integer",
1206:           "primaryKey": false,
1207:           "notNull": false
1208:         },
1209:         "messages_id": {
1210:           "name": "messages_id",
1211:           "type": "integer",
1212:           "primaryKey": false,
1213:           "notNull": false
1214:         }
1215:       },
1216:       "indexes": {
1217:         "contacts_rels_order_idx": {
1218:           "name": "contacts_rels_order_idx",
1219:           "columns": [
1220:             {
1221:               "expression": "order",
1222:               "isExpression": false,
1223:               "asc": true,
1224:               "nulls": "last"
1225:             }
1226:           ],
1227:           "isUnique": false,
1228:           "concurrently": false,
1229:           "method": "btree",
1230:           "with": {}
1231:         },
1232:         "contacts_rels_parent_idx": {
1233:           "name": "contacts_rels_parent_idx",
1234:           "columns": [
1235:             {
1236:               "expression": "parent_id",
1237:               "isExpression": false,
1238:               "asc": true,
1239:               "nulls": "last"
1240:             }
1241:           ],
1242:           "isUnique": false,
1243:           "concurrently": false,
1244:           "method": "btree",
1245:           "with": {}
1246:         },
1247:         "contacts_rels_path_idx": {
1248:           "name": "contacts_rels_path_idx",
1249:           "columns": [
1250:             {
1251:               "expression": "path",
1252:               "isExpression": false,
1253:               "asc": true,
1254:               "nulls": "last"
1255:             }
1256:           ],
1257:           "isUnique": false,
1258:           "concurrently": false,
1259:           "method": "btree",
1260:           "with": {}
1261:         },
1262:         "contacts_rels_locations_id_idx": {
1263:           "name": "contacts_rels_locations_id_idx",
1264:           "columns": [
1265:             {
1266:               "expression": "locations_id",
1267:               "isExpression": false,
1268:               "asc": true,
1269:               "nulls": "last"
1270:             }
1271:           ],
1272:           "isUnique": false,
1273:           "concurrently": false,
1274:           "method": "btree",
1275:           "with": {}
1276:         },
1277:         "contacts_rels_messages_id_idx": {
1278:           "name": "contacts_rels_messages_id_idx",
1279:           "columns": [
1280:             {
1281:               "expression": "messages_id",
1282:               "isExpression": false,
1283:               "asc": true,
1284:               "nulls": "last"
1285:             }
1286:           ],
1287:           "isUnique": false,
1288:           "concurrently": false,
1289:           "method": "btree",
1290:           "with": {}
1291:         }
1292:       },
1293:       "foreignKeys": {
1294:         "contacts_rels_parent_fk": {
1295:           "name": "contacts_rels_parent_fk",
1296:           "tableFrom": "contacts_rels",
1297:           "tableTo": "contacts",
1298:           "columnsFrom": [
1299:             "parent_id"
1300:           ],
1301:           "columnsTo": [
1302:             "id"
1303:           ],
1304:           "onDelete": "cascade",
1305:           "onUpdate": "no action"
1306:         },
1307:         "contacts_rels_locations_fk": {
1308:           "name": "contacts_rels_locations_fk",
1309:           "tableFrom": "contacts_rels",
1310:           "tableTo": "locations",
1311:           "columnsFrom": [
1312:             "locations_id"
1313:           ],
1314:           "columnsTo": [
1315:             "id"
1316:           ],
1317:           "onDelete": "cascade",
1318:           "onUpdate": "no action"
1319:         },
1320:         "contacts_rels_messages_fk": {
1321:           "name": "contacts_rels_messages_fk",
1322:           "tableFrom": "contacts_rels",
1323:           "tableTo": "messages",
1324:           "columnsFrom": [
1325:             "messages_id"
1326:           ],
1327:           "columnsTo": [
1328:             "id"
1329:           ],
1330:           "onDelete": "cascade",
1331:           "onUpdate": "no action"
1332:         }
1333:       },
1334:       "compositePrimaryKeys": {},
1335:       "uniqueConstraints": {},
1336:       "policies": {},
1337:       "checkConstraints": {},
1338:       "isRLSEnabled": false
1339:     },
1340:     "public.dietary_restrictions": {
1341:       "name": "dietary_restrictions",
1342:       "schema": "",
1343:       "columns": {
1344:         "id": {
1345:           "name": "id",
1346:           "type": "serial",
1347:           "primaryKey": true,
1348:           "notNull": true
1349:         },
1350:         "name": {
1351:           "name": "name",
1352:           "type": "varchar",
1353:           "primaryKey": false,
1354:           "notNull": true
1355:         },
1356:         "description": {
1357:           "name": "description",
1358:           "type": "varchar",
1359:           "primaryKey": false,
1360:           "notNull": false
1361:         },
1362:         "updated_at": {
1363:           "name": "updated_at",
1364:           "type": "timestamp(3) with time zone",
1365:           "primaryKey": false,
1366:           "notNull": true,
1367:           "default": "now()"
1368:         },
1369:         "created_at": {
1370:           "name": "created_at",
1371:           "type": "timestamp(3) with time zone",
1372:           "primaryKey": false,
1373:           "notNull": true,
1374:           "default": "now()"
1375:         }
1376:       },
1377:       "indexes": {
1378:         "dietary_restrictions_name_idx": {
1379:           "name": "dietary_restrictions_name_idx",
1380:           "columns": [
1381:             {
1382:               "expression": "name",
1383:               "isExpression": false,
1384:               "asc": true,
1385:               "nulls": "last"
1386:             }
1387:           ],
1388:           "isUnique": true,
1389:           "concurrently": false,
1390:           "method": "btree",
1391:           "with": {}
1392:         },
1393:         "dietary_restrictions_updated_at_idx": {
1394:           "name": "dietary_restrictions_updated_at_idx",
1395:           "columns": [
1396:             {
1397:               "expression": "updated_at",
1398:               "isExpression": false,
1399:               "asc": true,
1400:               "nulls": "last"
1401:             }
1402:           ],
1403:           "isUnique": false,
1404:           "concurrently": false,
1405:           "method": "btree",
1406:           "with": {}
1407:         },
1408:         "dietary_restrictions_created_at_idx": {
1409:           "name": "dietary_restrictions_created_at_idx",
1410:           "columns": [
1411:             {
1412:               "expression": "created_at",
1413:               "isExpression": false,
1414:               "asc": true,
1415:               "nulls": "last"
1416:             }
1417:           ],
1418:           "isUnique": false,
1419:           "concurrently": false,
1420:           "method": "btree",
1421:           "with": {}
1422:         }
1423:       },
1424:       "foreignKeys": {},
1425:       "compositePrimaryKeys": {},
1426:       "uniqueConstraints": {},
1427:       "policies": {},
1428:       "checkConstraints": {},
1429:       "isRLSEnabled": false
1430:     },
1431:     "public.drink_menu_items": {
1432:       "name": "drink_menu_items",
1433:       "schema": "",
1434:       "columns": {
1435:         "id": {
1436:           "name": "id",
1437:           "type": "serial",
1438:           "primaryKey": true,
1439:           "notNull": true
1440:         },
1441:         "name": {
1442:           "name": "name",
1443:           "type": "varchar",
1444:           "primaryKey": false,
1445:           "notNull": true
1446:         },
1447:         "description": {
1448:           "name": "description",
1449:           "type": "varchar",
1450:           "primaryKey": false,
1451:           "notNull": false
1452:         },
1453:         "price": {
1454:           "name": "price",
1455:           "type": "numeric",
1456:           "primaryKey": false,
1457:           "notNull": true
1458:         },
1459:         "category_id": {
1460:           "name": "category_id",
1461:           "type": "integer",
1462:           "primaryKey": false,
1463:           "notNull": true
1464:         },
1465:         "active": {
1466:           "name": "active",
1467:           "type": "boolean",
1468:           "primaryKey": false,
1469:           "notNull": false,
1470:           "default": true
1471:         },
1472:         "updated_at": {
1473:           "name": "updated_at",
1474:           "type": "timestamp(3) with time zone",
1475:           "primaryKey": false,
1476:           "notNull": true,
1477:           "default": "now()"
1478:         },
1479:         "created_at": {
1480:           "name": "created_at",
1481:           "type": "timestamp(3) with time zone",
1482:           "primaryKey": false,
1483:           "notNull": true,
1484:           "default": "now()"
1485:         }
1486:       },
1487:       "indexes": {
1488:         "drink_menu_items_category_idx": {
1489:           "name": "drink_menu_items_category_idx",
1490:           "columns": [
1491:             {
1492:               "expression": "category_id",
1493:               "isExpression": false,
1494:               "asc": true,
1495:               "nulls": "last"
1496:             }
1497:           ],
1498:           "isUnique": false,
1499:           "concurrently": false,
1500:           "method": "btree",
1501:           "with": {}
1502:         },
1503:         "drink_menu_items_updated_at_idx": {
1504:           "name": "drink_menu_items_updated_at_idx",
1505:           "columns": [
1506:             {
1507:               "expression": "updated_at",
1508:               "isExpression": false,
1509:               "asc": true,
1510:               "nulls": "last"
1511:             }
1512:           ],
1513:           "isUnique": false,
1514:           "concurrently": false,
1515:           "method": "btree",
1516:           "with": {}
1517:         },
1518:         "drink_menu_items_created_at_idx": {
1519:           "name": "drink_menu_items_created_at_idx",
1520:           "columns": [
1521:             {
1522:               "expression": "created_at",
1523:               "isExpression": false,
1524:               "asc": true,
1525:               "nulls": "last"
1526:             }
1527:           ],
1528:           "isUnique": false,
1529:           "concurrently": false,
1530:           "method": "btree",
1531:           "with": {}
1532:         }
1533:       },
1534:       "foreignKeys": {
1535:         "drink_menu_items_category_id_drink_subcategories_id_fk": {
1536:           "name": "drink_menu_items_category_id_drink_subcategories_id_fk",
1537:           "tableFrom": "drink_menu_items",
1538:           "tableTo": "drink_subcategories",
1539:           "columnsFrom": [
1540:             "category_id"
1541:           ],
1542:           "columnsTo": [
1543:             "id"
1544:           ],
1545:           "onDelete": "set null",
1546:           "onUpdate": "no action"
1547:         }
1548:       },
1549:       "compositePrimaryKeys": {},
1550:       "uniqueConstraints": {},
1551:       "policies": {},
1552:       "checkConstraints": {},
1553:       "isRLSEnabled": false
1554:     },
1555:     "public.drink_subcategories": {
1556:       "name": "drink_subcategories",
1557:       "schema": "",
1558:       "columns": {
1559:         "id": {
1560:           "name": "id",
1561:           "type": "serial",
1562:           "primaryKey": true,
1563:           "notNull": true
1564:         },
1565:         "name": {
1566:           "name": "name",
1567:           "type": "varchar",
1568:           "primaryKey": false,
1569:           "notNull": true
1570:         },
1571:         "updated_at": {
1572:           "name": "updated_at",
1573:           "type": "timestamp(3) with time zone",
1574:           "primaryKey": false,
1575:           "notNull": true,
1576:           "default": "now()"
1577:         },
1578:         "created_at": {
1579:           "name": "created_at",
1580:           "type": "timestamp(3) with time zone",
1581:           "primaryKey": false,
1582:           "notNull": true,
1583:           "default": "now()"
1584:         }
1585:       },
1586:       "indexes": {
1587:         "drink_subcategories_name_idx": {
1588:           "name": "drink_subcategories_name_idx",
1589:           "columns": [
1590:             {
1591:               "expression": "name",
1592:               "isExpression": false,
1593:               "asc": true,
1594:               "nulls": "last"
1595:             }
1596:           ],
1597:           "isUnique": true,
1598:           "concurrently": false,
1599:           "method": "btree",
1600:           "with": {}
1601:         },
1602:         "drink_subcategories_updated_at_idx": {
1603:           "name": "drink_subcategories_updated_at_idx",
1604:           "columns": [
1605:             {
1606:               "expression": "updated_at",
1607:               "isExpression": false,
1608:               "asc": true,
1609:               "nulls": "last"
1610:             }
1611:           ],
1612:           "isUnique": false,
1613:           "concurrently": false,
1614:           "method": "btree",
1615:           "with": {}
1616:         },
1617:         "drink_subcategories_created_at_idx": {
1618:           "name": "drink_subcategories_created_at_idx",
1619:           "columns": [
1620:             {
1621:               "expression": "created_at",
1622:               "isExpression": false,
1623:               "asc": true,
1624:               "nulls": "last"
1625:             }
1626:           ],
1627:           "isUnique": false,
1628:           "concurrently": false,
1629:           "method": "btree",
1630:           "with": {}
1631:         }
1632:       },
1633:       "foreignKeys": {},
1634:       "compositePrimaryKeys": {},
1635:       "uniqueConstraints": {},
1636:       "policies": {},
1637:       "checkConstraints": {},
1638:       "isRLSEnabled": false
1639:     },
1640:     "public.employee_ratings": {
1641:       "name": "employee_ratings",
1642:       "schema": "",
1643:       "columns": {
1644:         "id": {
1645:           "name": "id",
1646:           "type": "serial",
1647:           "primaryKey": true,
1648:           "notNull": true
1649:         },
1650:         "employee_id_id": {
1651:           "name": "employee_id_id",
1652:           "type": "integer",
1653:           "primaryKey": false,
1654:           "notNull": true
1655:         },
1656:         "location_id_id": {
1657:           "name": "location_id_id",
1658:           "type": "integer",
1659:           "primaryKey": false,
1660:           "notNull": true
1661:         },
1662:         "data_date": {
1663:           "name": "data_date",
1664:           "type": "timestamp(3) with time zone",
1665:           "primaryKey": false,
1666:           "notNull": true
1667:         },
1668:         "rating": {
1669:           "name": "rating",
1670:           "type": "numeric",
1671:           "primaryKey": false,
1672:           "notNull": true
1673:         },
1674:         "manager_report_id_id": {
1675:           "name": "manager_report_id_id",
1676:           "type": "integer",
1677:           "primaryKey": false,
1678:           "notNull": false
1679:         },
1680:         "employee_notes": {
1681:           "name": "employee_notes",
1682:           "type": "jsonb",
1683:           "primaryKey": false,
1684:           "notNull": false
1685:         },
1686:         "internal_notes": {
1687:           "name": "internal_notes",
1688:           "type": "varchar",
1689:           "primaryKey": false,
1690:           "notNull": false
1691:         },
1692:         "updated_at": {
1693:           "name": "updated_at",
1694:           "type": "timestamp(3) with time zone",
1695:           "primaryKey": false,
1696:           "notNull": true,
1697:           "default": "now()"
1698:         },
1699:         "created_at": {
1700:           "name": "created_at",
1701:           "type": "timestamp(3) with time zone",
1702:           "primaryKey": false,
1703:           "notNull": true,
1704:           "default": "now()"
1705:         }
1706:       },
1707:       "indexes": {
1708:         "employee_ratings_employee_id_idx": {
1709:           "name": "employee_ratings_employee_id_idx",
1710:           "columns": [
1711:             {
1712:               "expression": "employee_id_id",
1713:               "isExpression": false,
1714:               "asc": true,
1715:               "nulls": "last"
1716:             }
1717:           ],
1718:           "isUnique": false,
1719:           "concurrently": false,
1720:           "method": "btree",
1721:           "with": {}
1722:         },
1723:         "employee_ratings_location_id_idx": {
1724:           "name": "employee_ratings_location_id_idx",
1725:           "columns": [
1726:             {
1727:               "expression": "location_id_id",
1728:               "isExpression": false,
1729:               "asc": true,
1730:               "nulls": "last"
1731:             }
1732:           ],
1733:           "isUnique": false,
1734:           "concurrently": false,
1735:           "method": "btree",
1736:           "with": {}
1737:         },
1738:         "employee_ratings_manager_report_id_idx": {
1739:           "name": "employee_ratings_manager_report_id_idx",
1740:           "columns": [
1741:             {
1742:               "expression": "manager_report_id_id",
1743:               "isExpression": false,
1744:               "asc": true,
1745:               "nulls": "last"
1746:             }
1747:           ],
1748:           "isUnique": false,
1749:           "concurrently": false,
1750:           "method": "btree",
1751:           "with": {}
1752:         },
1753:         "employee_ratings_updated_at_idx": {
1754:           "name": "employee_ratings_updated_at_idx",
1755:           "columns": [
1756:             {
1757:               "expression": "updated_at",
1758:               "isExpression": false,
1759:               "asc": true,
1760:               "nulls": "last"
1761:             }
1762:           ],
1763:           "isUnique": false,
1764:           "concurrently": false,
1765:           "method": "btree",
1766:           "with": {}
1767:         },
1768:         "employee_ratings_created_at_idx": {
1769:           "name": "employee_ratings_created_at_idx",
1770:           "columns": [
1771:             {
1772:               "expression": "created_at",
1773:               "isExpression": false,
1774:               "asc": true,
1775:               "nulls": "last"
1776:             }
1777:           ],
1778:           "isUnique": false,
1779:           "concurrently": false,
1780:           "method": "btree",
1781:           "with": {}
1782:         }
1783:       },
1784:       "foreignKeys": {
1785:         "employee_ratings_employee_id_id_users_id_fk": {
1786:           "name": "employee_ratings_employee_id_id_users_id_fk",
1787:           "tableFrom": "employee_ratings",
1788:           "tableTo": "users",
1789:           "columnsFrom": [
1790:             "employee_id_id"
1791:           ],
1792:           "columnsTo": [
1793:             "id"
1794:           ],
1795:           "onDelete": "set null",
1796:           "onUpdate": "no action"
1797:         },
1798:         "employee_ratings_location_id_id_locations_id_fk": {
1799:           "name": "employee_ratings_location_id_id_locations_id_fk",
1800:           "tableFrom": "employee_ratings",
1801:           "tableTo": "locations",
1802:           "columnsFrom": [
1803:             "location_id_id"
1804:           ],
1805:           "columnsTo": [
1806:             "id"
1807:           ],
1808:           "onDelete": "set null",
1809:           "onUpdate": "no action"
1810:         },
1811:         "employee_ratings_manager_report_id_id_manager_reports_id_fk": {
1812:           "name": "employee_ratings_manager_report_id_id_manager_reports_id_fk",
1813:           "tableFrom": "employee_ratings",
1814:           "tableTo": "manager_reports",
1815:           "columnsFrom": [
1816:             "manager_report_id_id"
1817:           ],
1818:           "columnsTo": [
1819:             "id"
1820:           ],
1821:           "onDelete": "set null",
1822:           "onUpdate": "no action"
1823:         }
1824:       },
1825:       "compositePrimaryKeys": {},
1826:       "uniqueConstraints": {},
1827:       "policies": {},
1828:       "checkConstraints": {},
1829:       "isRLSEnabled": false
1830:     },
1831:     "public.features": {
1832:       "name": "features",
1833:       "schema": "",
1834:       "columns": {
1835:         "id": {
1836:           "name": "id",
1837:           "type": "serial",
1838:           "primaryKey": true,
1839:           "notNull": true
1840:         },
1841:         "name": {
1842:           "name": "name",
1843:           "type": "varchar",
1844:           "primaryKey": false,
1845:           "notNull": true
1846:         },
1847:         "enabled": {
1848:           "name": "enabled",
1849:           "type": "boolean",
1850:           "primaryKey": false,
1851:           "notNull": false,
1852:           "default": false
1853:         },
1854:         "updated_at": {
1855:           "name": "updated_at",
1856:           "type": "timestamp(3) with time zone",
1857:           "primaryKey": false,
1858:           "notNull": true,
1859:           "default": "now()"
1860:         },
1861:         "created_at": {
1862:           "name": "created_at",
1863:           "type": "timestamp(3) with time zone",
1864:           "primaryKey": false,
1865:           "notNull": true,
1866:           "default": "now()"
1867:         }
1868:       },
1869:       "indexes": {
1870:         "features_name_idx": {
1871:           "name": "features_name_idx",
1872:           "columns": [
1873:             {
1874:               "expression": "name",
1875:               "isExpression": false,
1876:               "asc": true,
1877:               "nulls": "last"
1878:             }
1879:           ],
1880:           "isUnique": true,
1881:           "concurrently": false,
1882:           "method": "btree",
1883:           "with": {}
1884:         },
1885:         "features_updated_at_idx": {
1886:           "name": "features_updated_at_idx",
1887:           "columns": [
1888:             {
1889:               "expression": "updated_at",
1890:               "isExpression": false,
1891:               "asc": true,
1892:               "nulls": "last"
1893:             }
1894:           ],
1895:           "isUnique": false,
1896:           "concurrently": false,
1897:           "method": "btree",
1898:           "with": {}
1899:         },
1900:         "features_created_at_idx": {
1901:           "name": "features_created_at_idx",
1902:           "columns": [
1903:             {
1904:               "expression": "created_at",
1905:               "isExpression": false,
1906:               "asc": true,
1907:               "nulls": "last"
1908:             }
1909:           ],
1910:           "isUnique": false,
1911:           "concurrently": false,
1912:           "method": "btree",
1913:           "with": {}
1914:         }
1915:       },
1916:       "foreignKeys": {},
1917:       "compositePrimaryKeys": {},
1918:       "uniqueConstraints": {},
1919:       "policies": {},
1920:       "checkConstraints": {},
1921:       "isRLSEnabled": false
1922:     },
1923:     "public.hotspot_logins": {
1924:       "name": "hotspot_logins",
1925:       "schema": "",
1926:       "columns": {
1927:         "id": {
1928:           "name": "id",
1929:           "type": "serial",
1930:           "primaryKey": true,
1931:           "notNull": true
1932:         },
1933:         "location_id": {
1934:           "name": "location_id",
1935:           "type": "integer",
1936:           "primaryKey": false,
1937:           "notNull": true
1938:         },
1939:         "customer_name": {
1940:           "name": "customer_name",
1941:           "type": "varchar",
1942:           "primaryKey": false,
1943:           "notNull": false
1944:         },
1945:         "customer_email": {
1946:           "name": "customer_email",
1947:           "type": "varchar",
1948:           "primaryKey": false,
1949:           "notNull": false
1950:         },
1951:         "marketing_consent": {
1952:           "name": "marketing_consent",
1953:           "type": "boolean",
1954:           "primaryKey": false,
1955:           "notNull": false,
1956:           "default": false
1957:         },
1958:         "updated_at": {
1959:           "name": "updated_at",
1960:           "type": "timestamp(3) with time zone",
1961:           "primaryKey": false,
1962:           "notNull": true,
1963:           "default": "now()"
1964:         },
1965:         "created_at": {
1966:           "name": "created_at",
1967:           "type": "timestamp(3) with time zone",
1968:           "primaryKey": false,
1969:           "notNull": true,
1970:           "default": "now()"
1971:         }
1972:       },
1973:       "indexes": {
1974:         "hotspot_logins_location_idx": {
1975:           "name": "hotspot_logins_location_idx",
1976:           "columns": [
1977:             {
1978:               "expression": "location_id",
1979:               "isExpression": false,
1980:               "asc": true,
1981:               "nulls": "last"
1982:             }
1983:           ],
1984:           "isUnique": false,
1985:           "concurrently": false,
1986:           "method": "btree",
1987:           "with": {}
1988:         },
1989:         "hotspot_logins_updated_at_idx": {
1990:           "name": "hotspot_logins_updated_at_idx",
1991:           "columns": [
1992:             {
1993:               "expression": "updated_at",
1994:               "isExpression": false,
1995:               "asc": true,
1996:               "nulls": "last"
1997:             }
1998:           ],
1999:           "isUnique": false,
2000:           "concurrently": false,
2001:           "method": "btree",
2002:           "with": {}
2003:         },
2004:         "hotspot_logins_created_at_idx": {
2005:           "name": "hotspot_logins_created_at_idx",
2006:           "columns": [
2007:             {
2008:               "expression": "created_at",
2009:               "isExpression": false,
2010:               "asc": true,
2011:               "nulls": "last"
2012:             }
2013:           ],
2014:           "isUnique": false,
2015:           "concurrently": false,
2016:           "method": "btree",
2017:           "with": {}
2018:         }
2019:       },
2020:       "foreignKeys": {
2021:         "hotspot_logins_location_id_locations_id_fk": {
2022:           "name": "hotspot_logins_location_id_locations_id_fk",
2023:           "tableFrom": "hotspot_logins",
2024:           "tableTo": "locations",
2025:           "columnsFrom": [
2026:             "location_id"
2027:           ],
2028:           "columnsTo": [
2029:             "id"
2030:           ],
2031:           "onDelete": "set null",
2032:           "onUpdate": "no action"
2033:         }
2034:       },
2035:       "compositePrimaryKeys": {},
2036:       "uniqueConstraints": {},
2037:       "policies": {},
2038:       "checkConstraints": {},
2039:       "isRLSEnabled": false
2040:     },
2041:     "public.incidents": {
2042:       "name": "incidents",
2043:       "schema": "",
2044:       "columns": {
2045:         "id": {
2046:           "name": "id",
2047:           "type": "serial",
2048:           "primaryKey": true,
2049:           "notNull": true
2050:         },
2051:         "title": {
2052:           "name": "title",
2053:           "type": "varchar",
2054:           "primaryKey": false,
2055:           "notNull": true
2056:         },
2057:         "description": {
2058:           "name": "description",
2059:           "type": "varchar",
2060:           "primaryKey": false,
2061:           "notNull": false
2062:         },
2063:         "date": {
2064:           "name": "date",
2065:           "type": "timestamp(3) with time zone",
2066:           "primaryKey": false,
2067:           "notNull": true
2068:         },
2069:         "location_id": {
2070:           "name": "location_id",
2071:           "type": "integer",
2072:           "primaryKey": false,
2073:           "notNull": true
2074:         },
2075:         "reported_by_id": {
2076:           "name": "reported_by_id",
2077:           "type": "integer",
2078:           "primaryKey": false,
2079:           "notNull": true
2080:         },
2081:         "status": {
2082:           "name": "status",
2083:           "type": "enum_incidents_status",
2084:           "typeSchema": "public",
2085:           "primaryKey": false,
2086:           "notNull": false,
2087:           "default": "'open'"
2088:         },
2089:         "updated_at": {
2090:           "name": "updated_at",
2091:           "type": "timestamp(3) with time zone",
2092:           "primaryKey": false,
2093:           "notNull": true,
2094:           "default": "now()"
2095:         },
2096:         "created_at": {
2097:           "name": "created_at",
2098:           "type": "timestamp(3) with time zone",
2099:           "primaryKey": false,
2100:           "notNull": true,
2101:           "default": "now()"
2102:         }
2103:       },
2104:       "indexes": {
2105:         "incidents_location_idx": {
2106:           "name": "incidents_location_idx",
2107:           "columns": [
2108:             {
2109:               "expression": "location_id",
2110:               "isExpression": false,
2111:               "asc": true,
2112:               "nulls": "last"
2113:             }
2114:           ],
2115:           "isUnique": false,
2116:           "concurrently": false,
2117:           "method": "btree",
2118:           "with": {}
2119:         },
2120:         "incidents_reported_by_idx": {
2121:           "name": "incidents_reported_by_idx",
2122:           "columns": [
2123:             {
2124:               "expression": "reported_by_id",
2125:               "isExpression": false,
2126:               "asc": true,
2127:               "nulls": "last"
2128:             }
2129:           ],
2130:           "isUnique": false,
2131:           "concurrently": false,
2132:           "method": "btree",
2133:           "with": {}
2134:         },
2135:         "incidents_updated_at_idx": {
2136:           "name": "incidents_updated_at_idx",
2137:           "columns": [
2138:             {
2139:               "expression": "updated_at",
2140:               "isExpression": false,
2141:               "asc": true,
2142:               "nulls": "last"
2143:             }
2144:           ],
2145:           "isUnique": false,
2146:           "concurrently": false,
2147:           "method": "btree",
2148:           "with": {}
2149:         },
2150:         "incidents_created_at_idx": {
2151:           "name": "incidents_created_at_idx",
2152:           "columns": [
2153:             {
2154:               "expression": "created_at",
2155:               "isExpression": false,
2156:               "asc": true,
2157:               "nulls": "last"
2158:             }
2159:           ],
2160:           "isUnique": false,
2161:           "concurrently": false,
2162:           "method": "btree",
2163:           "with": {}
2164:         }
2165:       },
2166:       "foreignKeys": {
2167:         "incidents_location_id_locations_id_fk": {
2168:           "name": "incidents_location_id_locations_id_fk",
2169:           "tableFrom": "incidents",
2170:           "tableTo": "locations",
2171:           "columnsFrom": [
2172:             "location_id"
2173:           ],
2174:           "columnsTo": [
2175:             "id"
2176:           ],
2177:           "onDelete": "set null",
2178:           "onUpdate": "no action"
2179:         },
2180:         "incidents_reported_by_id_users_id_fk": {
2181:           "name": "incidents_reported_by_id_users_id_fk",
2182:           "tableFrom": "incidents",
2183:           "tableTo": "users",
2184:           "columnsFrom": [
2185:             "reported_by_id"
2186:           ],
2187:           "columnsTo": [
2188:             "id"
2189:           ],
2190:           "onDelete": "set null",
2191:           "onUpdate": "no action"
2192:         }
2193:       },
2194:       "compositePrimaryKeys": {},
2195:       "uniqueConstraints": {},
2196:       "policies": {},
2197:       "checkConstraints": {},
2198:       "isRLSEnabled": false
2199:     },
2200:     "public.jobs": {
2201:       "name": "jobs",
2202:       "schema": "",
2203:       "columns": {
2204:         "id": {
2205:           "name": "id",
2206:           "type": "serial",
2207:           "primaryKey": true,
2208:           "notNull": true
2209:         },
2210:         "name": {
2211:           "name": "name",
2212:           "type": "varchar",
2213:           "primaryKey": false,
2214:           "notNull": true
2215:         },
2216:         "updated_at": {
2217:           "name": "updated_at",
2218:           "type": "timestamp(3) with time zone",
2219:           "primaryKey": false,
2220:           "notNull": true,
2221:           "default": "now()"
2222:         },
2223:         "created_at": {
2224:           "name": "created_at",
2225:           "type": "timestamp(3) with time zone",
2226:           "primaryKey": false,
2227:           "notNull": true,
2228:           "default": "now()"
2229:         }
2230:       },
2231:       "indexes": {
2232:         "jobs_name_idx": {
2233:           "name": "jobs_name_idx",
2234:           "columns": [
2235:             {
2236:               "expression": "name",
2237:               "isExpression": false,
2238:               "asc": true,
2239:               "nulls": "last"
2240:             }
2241:           ],
2242:           "isUnique": true,
2243:           "concurrently": false,
2244:           "method": "btree",
2245:           "with": {}
2246:         },
2247:         "jobs_updated_at_idx": {
2248:           "name": "jobs_updated_at_idx",
2249:           "columns": [
2250:             {
2251:               "expression": "updated_at",
2252:               "isExpression": false,
2253:               "asc": true,
2254:               "nulls": "last"
2255:             }
2256:           ],
2257:           "isUnique": false,
2258:           "concurrently": false,
2259:           "method": "btree",
2260:           "with": {}
2261:         },
2262:         "jobs_created_at_idx": {
2263:           "name": "jobs_created_at_idx",
2264:           "columns": [
2265:             {
2266:               "expression": "created_at",
2267:               "isExpression": false,
2268:               "asc": true,
2269:               "nulls": "last"
2270:             }
2271:           ],
2272:           "isUnique": false,
2273:           "concurrently": false,
2274:           "method": "btree",
2275:           "with": {}
2276:         }
2277:       },
2278:       "foreignKeys": {},
2279:       "compositePrimaryKeys": {},
2280:       "uniqueConstraints": {},
2281:       "policies": {},
2282:       "checkConstraints": {},
2283:       "isRLSEnabled": false
2284:     },
2285:     "public.locations": {
2286:       "name": "locations",
2287:       "schema": "",
2288:       "columns": {
2289:         "id": {
2290:           "name": "id",
2291:           "type": "serial",
2292:           "primaryKey": true,
2293:           "notNull": true
2294:         },
2295:         "name": {
2296:           "name": "name",
2297:           "type": "varchar",
2298:           "primaryKey": false,
2299:           "notNull": true
2300:         },
2301:         "address": {
2302:           "name": "address",
2303:           "type": "varchar",
2304:           "primaryKey": false,
2305:           "notNull": true
2306:         },
2307:         "city": {
2308:           "name": "city",
2309:           "type": "varchar",
2310:           "primaryKey": false,
2311:           "notNull": true
2312:         },
2313:         "state": {
2314:           "name": "state",
2315:           "type": "varchar",
2316:           "primaryKey": false,
2317:           "notNull": true
2318:         },
2319:         "zip": {
2320:           "name": "zip",
2321:           "type": "varchar",
2322:           "primaryKey": false,
2323:           "notNull": true
2324:         },
2325:         "phone": {
2326:           "name": "phone",
2327:           "type": "varchar",
2328:           "primaryKey": false,
2329:           "notNull": false
2330:         },
2331:         "email": {
2332:           "name": "email",
2333:           "type": "varchar",
2334:           "primaryKey": false,
2335:           "notNull": false
2336:         },
2337:         "updated_at": {
2338:           "name": "updated_at",
2339:           "type": "timestamp(3) with time zone",
2340:           "primaryKey": false,
2341:           "notNull": true,
2342:           "default": "now()"
2343:         },
2344:         "created_at": {
2345:           "name": "created_at",
2346:           "type": "timestamp(3) with time zone",
2347:           "primaryKey": false,
2348:           "notNull": true,
2349:           "default": "now()"
2350:         }
2351:       },
2352:       "indexes": {
2353:         "locations_name_idx": {
2354:           "name": "locations_name_idx",
2355:           "columns": [
2356:             {
2357:               "expression": "name",
2358:               "isExpression": false,
2359:               "asc": true,
2360:               "nulls": "last"
2361:             }
2362:           ],
2363:           "isUnique": true,
2364:           "concurrently": false,
2365:           "method": "btree",
2366:           "with": {}
2367:         },
2368:         "locations_updated_at_idx": {
2369:           "name": "locations_updated_at_idx",
2370:           "columns": [
2371:             {
2372:               "expression": "updated_at",
2373:               "isExpression": false,
2374:               "asc": true,
2375:               "nulls": "last"
2376:             }
2377:           ],
2378:           "isUnique": false,
2379:           "concurrently": false,
2380:           "method": "btree",
2381:           "with": {}
2382:         },
2383:         "locations_created_at_idx": {
2384:           "name": "locations_created_at_idx",
2385:           "columns": [
2386:             {
2387:               "expression": "created_at",
2388:               "isExpression": false,
2389:               "asc": true,
2390:               "nulls": "last"
2391:             }
2392:           ],
2393:           "isUnique": false,
2394:           "concurrently": false,
2395:           "method": "btree",
2396:           "with": {}
2397:         }
2398:       },
2399:       "foreignKeys": {},
2400:       "compositePrimaryKeys": {},
2401:       "uniqueConstraints": {},
2402:       "policies": {},
2403:       "checkConstraints": {},
2404:       "isRLSEnabled": false
2405:     },
2406:     "public.manager_reports": {
2407:       "name": "manager_reports",
2408:       "schema": "",
2409:       "columns": {
2410:         "id": {
2411:           "name": "id",
2412:           "type": "serial",
2413:           "primaryKey": true,
2414:           "notNull": true
2415:         },
2416:         "title": {
2417:           "name": "title",
2418:           "type": "varchar",
2419:           "primaryKey": false,
2420:           "notNull": true
2421:         },
2422:         "date": {
2423:           "name": "date",
2424:           "type": "timestamp(3) with time zone",
2425:           "primaryKey": false,
2426:           "notNull": true
2427:         },
2428:         "manager_id": {
2429:           "name": "manager_id",
2430:           "type": "integer",
2431:           "primaryKey": false,
2432:           "notNull": true
2433:         },
2434:         "location_id": {
2435:           "name": "location_id",
2436:           "type": "integer",
2437:           "primaryKey": false,
2438:           "notNull": true
2439:         },
2440:         "notes": {
2441:           "name": "notes",
2442:           "type": "varchar",
2443:           "primaryKey": false,
2444:           "notNull": false
2445:         },
2446:         "updated_at": {
2447:           "name": "updated_at",
2448:           "type": "timestamp(3) with time zone",
2449:           "primaryKey": false,
2450:           "notNull": true,
2451:           "default": "now()"
2452:         },
2453:         "created_at": {
2454:           "name": "created_at",
2455:           "type": "timestamp(3) with time zone",
2456:           "primaryKey": false,
2457:           "notNull": true,
2458:           "default": "now()"
2459:         }
2460:       },
2461:       "indexes": {
2462:         "manager_reports_manager_idx": {
2463:           "name": "manager_reports_manager_idx",
2464:           "columns": [
2465:             {
2466:               "expression": "manager_id",
2467:               "isExpression": false,
2468:               "asc": true,
2469:               "nulls": "last"
2470:             }
2471:           ],
2472:           "isUnique": false,
2473:           "concurrently": false,
2474:           "method": "btree",
2475:           "with": {}
2476:         },
2477:         "manager_reports_location_idx": {
2478:           "name": "manager_reports_location_idx",
2479:           "columns": [
2480:             {
2481:               "expression": "location_id",
2482:               "isExpression": false,
2483:               "asc": true,
2484:               "nulls": "last"
2485:             }
2486:           ],
2487:           "isUnique": false,
2488:           "concurrently": false,
2489:           "method": "btree",
2490:           "with": {}
2491:         },
2492:         "manager_reports_updated_at_idx": {
2493:           "name": "manager_reports_updated_at_idx",
2494:           "columns": [
2495:             {
2496:               "expression": "updated_at",
2497:               "isExpression": false,
2498:               "asc": true,
2499:               "nulls": "last"
2500:             }
2501:           ],
2502:           "isUnique": false,
2503:           "concurrently": false,
2504:           "method": "btree",
2505:           "with": {}
2506:         },
2507:         "manager_reports_created_at_idx": {
2508:           "name": "manager_reports_created_at_idx",
2509:           "columns": [
2510:             {
2511:               "expression": "created_at",
2512:               "isExpression": false,
2513:               "asc": true,
2514:               "nulls": "last"
2515:             }
2516:           ],
2517:           "isUnique": false,
2518:           "concurrently": false,
2519:           "method": "btree",
2520:           "with": {}
2521:         }
2522:       },
2523:       "foreignKeys": {
2524:         "manager_reports_manager_id_users_id_fk": {
2525:           "name": "manager_reports_manager_id_users_id_fk",
2526:           "tableFrom": "manager_reports",
2527:           "tableTo": "users",
2528:           "columnsFrom": [
2529:             "manager_id"
2530:           ],
2531:           "columnsTo": [
2532:             "id"
2533:           ],
2534:           "onDelete": "set null",
2535:           "onUpdate": "no action"
2536:         },
2537:         "manager_reports_location_id_locations_id_fk": {
2538:           "name": "manager_reports_location_id_locations_id_fk",
2539:           "tableFrom": "manager_reports",
2540:           "tableTo": "locations",
2541:           "columnsFrom": [
2542:             "location_id"
2543:           ],
2544:           "columnsTo": [
2545:             "id"
2546:           ],
2547:           "onDelete": "set null",
2548:           "onUpdate": "no action"
2549:         }
2550:       },
2551:       "compositePrimaryKeys": {},
2552:       "uniqueConstraints": {},
2553:       "policies": {},
2554:       "checkConstraints": {},
2555:       "isRLSEnabled": false
2556:     },
2557:     "public.messages": {
2558:       "name": "messages",
2559:       "schema": "",
2560:       "columns": {
2561:         "id": {
2562:           "name": "id",
2563:           "type": "serial",
2564:           "primaryKey": true,
2565:           "notNull": true
2566:         },
2567:         "status": {
2568:           "name": "status",
2569:           "type": "enum_messages_status",
2570:           "typeSchema": "public",
2571:           "primaryKey": false,
2572:           "notNull": false,
2573:           "default": "'new'"
2574:         },
2575:         "priority": {
2576:           "name": "priority",
2577:           "type": "enum_messages_priority",
2578:           "typeSchema": "public",
2579:           "primaryKey": false,
2580:           "notNull": false,
2581:           "default": "'normal'"
2582:         },
2583:         "subject": {
2584:           "name": "subject",
2585:           "type": "varchar",
2586:           "primaryKey": false,
2587:           "notNull": true
2588:         },
2589:         "from_name": {
2590:           "name": "from_name",
2591:           "type": "varchar",
2592:           "primaryKey": false,
2593:           "notNull": true
2594:         },
2595:         "from_email": {
2596:           "name": "from_email",
2597:           "type": "varchar",
2598:           "primaryKey": false,
2599:           "notNull": true
2600:         },
2601:         "from_phone": {
2602:           "name": "from_phone",
2603:           "type": "varchar",
2604:           "primaryKey": false,
2605:           "notNull": false
2606:         },
2607:         "location_id": {
2608:           "name": "location_id",
2609:           "type": "integer",
2610:           "primaryKey": false,
2611:           "notNull": false
2612:         },
2613:         "message_type_id": {
2614:           "name": "message_type_id",
2615:           "type": "integer",
2616:           "primaryKey": false,
2617:           "notNull": true
2618:         },
2619:         "message": {
2620:           "name": "message",
2621:           "type": "jsonb",
2622:           "primaryKey": false,
2623:           "notNull": true
2624:         },
2625:         "internal_notes": {
2626:           "name": "internal_notes",
2627:           "type": "jsonb",
2628:           "primaryKey": false,
2629:           "notNull": false
2630:         },
2631:         "assigned_to_id": {
2632:           "name": "assigned_to_id",
2633:           "type": "integer",
2634:           "primaryKey": false,
2635:           "notNull": false
2636:         },
2637:         "response_sent": {
2638:           "name": "response_sent",
2639:           "type": "boolean",
2640:           "primaryKey": false,
2641:           "notNull": false,
2642:           "default": false
2643:         },
2644:         "response_date": {
2645:           "name": "response_date",
2646:           "type": "timestamp(3) with time zone",
2647:           "primaryKey": false,
2648:           "notNull": false
2649:         },
2650:         "updated_at": {
2651:           "name": "updated_at",
2652:           "type": "timestamp(3) with time zone",
2653:           "primaryKey": false,
2654:           "notNull": true,
2655:           "default": "now()"
2656:         },
2657:         "created_at": {
2658:           "name": "created_at",
2659:           "type": "timestamp(3) with time zone",
2660:           "primaryKey": false,
2661:           "notNull": true,
2662:           "default": "now()"
2663:         }
2664:       },
2665:       "indexes": {
2666:         "messages_location_idx": {
2667:           "name": "messages_location_idx",
2668:           "columns": [
2669:             {
2670:               "expression": "location_id",
2671:               "isExpression": false,
2672:               "asc": true,
2673:               "nulls": "last"
2674:             }
2675:           ],
2676:           "isUnique": false,
2677:           "concurrently": false,
2678:           "method": "btree",
2679:           "with": {}
2680:         },
2681:         "messages_message_type_idx": {
2682:           "name": "messages_message_type_idx",
2683:           "columns": [
2684:             {
2685:               "expression": "message_type_id",
2686:               "isExpression": false,
2687:               "asc": true,
2688:               "nulls": "last"
2689:             }
2690:           ],
2691:           "isUnique": false,
2692:           "concurrently": false,
2693:           "method": "btree",
2694:           "with": {}
2695:         },
2696:         "messages_assigned_to_idx": {
2697:           "name": "messages_assigned_to_idx",
2698:           "columns": [
2699:             {
2700:               "expression": "assigned_to_id",
2701:               "isExpression": false,
2702:               "asc": true,
2703:               "nulls": "last"
2704:             }
2705:           ],
2706:           "isUnique": false,
2707:           "concurrently": false,
2708:           "method": "btree",
2709:           "with": {}
2710:         },
2711:         "messages_updated_at_idx": {
2712:           "name": "messages_updated_at_idx",
2713:           "columns": [
2714:             {
2715:               "expression": "updated_at",
2716:               "isExpression": false,
2717:               "asc": true,
2718:               "nulls": "last"
2719:             }
2720:           ],
2721:           "isUnique": false,
2722:           "concurrently": false,
2723:           "method": "btree",
2724:           "with": {}
2725:         },
2726:         "messages_created_at_idx": {
2727:           "name": "messages_created_at_idx",
2728:           "columns": [
2729:             {
2730:               "expression": "created_at",
2731:               "isExpression": false,
2732:               "asc": true,
2733:               "nulls": "last"
2734:             }
2735:           ],
2736:           "isUnique": false,
2737:           "concurrently": false,
2738:           "method": "btree",
2739:           "with": {}
2740:         }
2741:       },
2742:       "foreignKeys": {
2743:         "messages_location_id_locations_id_fk": {
2744:           "name": "messages_location_id_locations_id_fk",
2745:           "tableFrom": "messages",
2746:           "tableTo": "locations",
2747:           "columnsFrom": [
2748:             "location_id"
2749:           ],
2750:           "columnsTo": [
2751:             "id"
2752:           ],
2753:           "onDelete": "set null",
2754:           "onUpdate": "no action"
2755:         },
2756:         "messages_message_type_id_message_types_id_fk": {
2757:           "name": "messages_message_type_id_message_types_id_fk",
2758:           "tableFrom": "messages",
2759:           "tableTo": "message_types",
2760:           "columnsFrom": [
2761:             "message_type_id"
2762:           ],
2763:           "columnsTo": [
2764:             "id"
2765:           ],
2766:           "onDelete": "set null",
2767:           "onUpdate": "no action"
2768:         },
2769:         "messages_assigned_to_id_users_id_fk": {
2770:           "name": "messages_assigned_to_id_users_id_fk",
2771:           "tableFrom": "messages",
2772:           "tableTo": "users",
2773:           "columnsFrom": [
2774:             "assigned_to_id"
2775:           ],
2776:           "columnsTo": [
2777:             "id"
2778:           ],
2779:           "onDelete": "set null",
2780:           "onUpdate": "no action"
2781:         }
2782:       },
2783:       "compositePrimaryKeys": {},
2784:       "uniqueConstraints": {},
2785:       "policies": {},
2786:       "checkConstraints": {},
2787:       "isRLSEnabled": false
2788:     },
2789:     "public.messages_rels": {
2790:       "name": "messages_rels",
2791:       "schema": "",
2792:       "columns": {
2793:         "id": {
2794:           "name": "id",
2795:           "type": "serial",
2796:           "primaryKey": true,
2797:           "notNull": true
2798:         },
2799:         "order": {
2800:           "name": "order",
2801:           "type": "integer",
2802:           "primaryKey": false,
2803:           "notNull": false
2804:         },
2805:         "parent_id": {
2806:           "name": "parent_id",
2807:           "type": "integer",
2808:           "primaryKey": false,
2809:           "notNull": true
2810:         },
2811:         "path": {
2812:           "name": "path",
2813:           "type": "varchar",
2814:           "primaryKey": false,
2815:           "notNull": true
2816:         },
2817:         "media_id": {
2818:           "name": "media_id",
2819:           "type": "integer",
2820:           "primaryKey": false,
2821:           "notNull": false
2822:         }
2823:       },
2824:       "indexes": {
2825:         "messages_rels_order_idx": {
2826:           "name": "messages_rels_order_idx",
2827:           "columns": [
2828:             {
2829:               "expression": "order",
2830:               "isExpression": false,
2831:               "asc": true,
2832:               "nulls": "last"
2833:             }
2834:           ],
2835:           "isUnique": false,
2836:           "concurrently": false,
2837:           "method": "btree",
2838:           "with": {}
2839:         },
2840:         "messages_rels_parent_idx": {
2841:           "name": "messages_rels_parent_idx",
2842:           "columns": [
2843:             {
2844:               "expression": "parent_id",
2845:               "isExpression": false,
2846:               "asc": true,
2847:               "nulls": "last"
2848:             }
2849:           ],
2850:           "isUnique": false,
2851:           "concurrently": false,
2852:           "method": "btree",
2853:           "with": {}
2854:         },
2855:         "messages_rels_path_idx": {
2856:           "name": "messages_rels_path_idx",
2857:           "columns": [
2858:             {
2859:               "expression": "path",
2860:               "isExpression": false,
2861:               "asc": true,
2862:               "nulls": "last"
2863:             }
2864:           ],
2865:           "isUnique": false,
2866:           "concurrently": false,
2867:           "method": "btree",
2868:           "with": {}
2869:         },
2870:         "messages_rels_media_id_idx": {
2871:           "name": "messages_rels_media_id_idx",
2872:           "columns": [
2873:             {
2874:               "expression": "media_id",
2875:               "isExpression": false,
2876:               "asc": true,
2877:               "nulls": "last"
2878:             }
2879:           ],
2880:           "isUnique": false,
2881:           "concurrently": false,
2882:           "method": "btree",
2883:           "with": {}
2884:         }
2885:       },
2886:       "foreignKeys": {
2887:         "messages_rels_parent_fk": {
2888:           "name": "messages_rels_parent_fk",
2889:           "tableFrom": "messages_rels",
2890:           "tableTo": "messages",
2891:           "columnsFrom": [
2892:             "parent_id"
2893:           ],
2894:           "columnsTo": [
2895:             "id"
2896:           ],
2897:           "onDelete": "cascade",
2898:           "onUpdate": "no action"
2899:         },
2900:         "messages_rels_media_fk": {
2901:           "name": "messages_rels_media_fk",
2902:           "tableFrom": "messages_rels",
2903:           "tableTo": "media",
2904:           "columnsFrom": [
2905:             "media_id"
2906:           ],
2907:           "columnsTo": [
2908:             "id"
2909:           ],
2910:           "onDelete": "cascade",
2911:           "onUpdate": "no action"
2912:         }
2913:       },
2914:       "compositePrimaryKeys": {},
2915:       "uniqueConstraints": {},
2916:       "policies": {},
2917:       "checkConstraints": {},
2918:       "isRLSEnabled": false
2919:     },
2920:     "public.message_types": {
2921:       "name": "message_types",
2922:       "schema": "",
2923:       "columns": {
2924:         "id": {
2925:           "name": "id",
2926:           "type": "serial",
2927:           "primaryKey": true,
2928:           "notNull": true
2929:         },
2930:         "name": {
2931:           "name": "name",
2932:           "type": "varchar",
2933:           "primaryKey": false,
2934:           "notNull": true
2935:         },
2936:         "updated_at": {
2937:           "name": "updated_at",
2938:           "type": "timestamp(3) with time zone",
2939:           "primaryKey": false,
2940:           "notNull": true,
2941:           "default": "now()"
2942:         },
2943:         "created_at": {
2944:           "name": "created_at",
2945:           "type": "timestamp(3) with time zone",
2946:           "primaryKey": false,
2947:           "notNull": true,
2948:           "default": "now()"
2949:         }
2950:       },
2951:       "indexes": {
2952:         "message_types_name_idx": {
2953:           "name": "message_types_name_idx",
2954:           "columns": [
2955:             {
2956:               "expression": "name",
2957:               "isExpression": false,
2958:               "asc": true,
2959:               "nulls": "last"
2960:             }
2961:           ],
2962:           "isUnique": true,
2963:           "concurrently": false,
2964:           "method": "btree",
2965:           "with": {}
2966:         },
2967:         "message_types_updated_at_idx": {
2968:           "name": "message_types_updated_at_idx",
2969:           "columns": [
2970:             {
2971:               "expression": "updated_at",
2972:               "isExpression": false,
2973:               "asc": true,
2974:               "nulls": "last"
2975:             }
2976:           ],
2977:           "isUnique": false,
2978:           "concurrently": false,
2979:           "method": "btree",
2980:           "with": {}
2981:         },
2982:         "message_types_created_at_idx": {
2983:           "name": "message_types_created_at_idx",
2984:           "columns": [
2985:             {
2986:               "expression": "created_at",
2987:               "isExpression": false,
2988:               "asc": true,
2989:               "nulls": "last"
2990:             }
2991:           ],
2992:           "isUnique": false,
2993:           "concurrently": false,
2994:           "method": "btree",
2995:           "with": {}
2996:         }
2997:       },
2998:       "foreignKeys": {},
2999:       "compositePrimaryKeys": {},
3000:       "uniqueConstraints": {},
3001:       "policies": {},
3002:       "checkConstraints": {},
3003:       "isRLSEnabled": false
3004:     },
3005:     "public.qr_feedback": {
3006:       "name": "qr_feedback",
3007:       "schema": "",
3008:       "columns": {
3009:         "id": {
3010:           "name": "id",
3011:           "type": "serial",
3012:           "primaryKey": true,
3013:           "notNull": true
3014:         },
3015:         "rating": {
3016:           "name": "rating",
3017:           "type": "numeric",
3018:           "primaryKey": false,
3019:           "notNull": true
3020:         },
3021:         "comment": {
3022:           "name": "comment",
3023:           "type": "varchar",
3024:           "primaryKey": false,
3025:           "notNull": false
3026:         },
3027:         "location_id": {
3028:           "name": "location_id",
3029:           "type": "integer",
3030:           "primaryKey": false,
3031:           "notNull": true
3032:         },
3033:         "user_id": {
3034:           "name": "user_id",
3035:           "type": "integer",
3036:           "primaryKey": false,
3037:           "notNull": false
3038:         },
3039:         "updated_at": {
3040:           "name": "updated_at",
3041:           "type": "timestamp(3) with time zone",
3042:           "primaryKey": false,
3043:           "notNull": true,
3044:           "default": "now()"
3045:         },
3046:         "created_at": {
3047:           "name": "created_at",
3048:           "type": "timestamp(3) with time zone",
3049:           "primaryKey": false,
3050:           "notNull": true,
3051:           "default": "now()"
3052:         }
3053:       },
3054:       "indexes": {
3055:         "qr_feedback_location_idx": {
3056:           "name": "qr_feedback_location_idx",
3057:           "columns": [
3058:             {
3059:               "expression": "location_id",
3060:               "isExpression": false,
3061:               "asc": true,
3062:               "nulls": "last"
3063:             }
3064:           ],
3065:           "isUnique": false,
3066:           "concurrently": false,
3067:           "method": "btree",
3068:           "with": {}
3069:         },
3070:         "qr_feedback_user_idx": {
3071:           "name": "qr_feedback_user_idx",
3072:           "columns": [
3073:             {
3074:               "expression": "user_id",
3075:               "isExpression": false,
3076:               "asc": true,
3077:               "nulls": "last"
3078:             }
3079:           ],
3080:           "isUnique": false,
3081:           "concurrently": false,
3082:           "method": "btree",
3083:           "with": {}
3084:         },
3085:         "qr_feedback_updated_at_idx": {
3086:           "name": "qr_feedback_updated_at_idx",
3087:           "columns": [
3088:             {
3089:               "expression": "updated_at",
3090:               "isExpression": false,
3091:               "asc": true,
3092:               "nulls": "last"
3093:             }
3094:           ],
3095:           "isUnique": false,
3096:           "concurrently": false,
3097:           "method": "btree",
3098:           "with": {}
3099:         },
3100:         "qr_feedback_created_at_idx": {
3101:           "name": "qr_feedback_created_at_idx",
3102:           "columns": [
3103:             {
3104:               "expression": "created_at",
3105:               "isExpression": false,
3106:               "asc": true,
3107:               "nulls": "last"
3108:             }
3109:           ],
3110:           "isUnique": false,
3111:           "concurrently": false,
3112:           "method": "btree",
3113:           "with": {}
3114:         }
3115:       },
3116:       "foreignKeys": {
3117:         "qr_feedback_location_id_locations_id_fk": {
3118:           "name": "qr_feedback_location_id_locations_id_fk",
3119:           "tableFrom": "qr_feedback",
3120:           "tableTo": "locations",
3121:           "columnsFrom": [
3122:             "location_id"
3123:           ],
3124:           "columnsTo": [
3125:             "id"
3126:           ],
3127:           "onDelete": "set null",
3128:           "onUpdate": "no action"
3129:         },
3130:         "qr_feedback_user_id_users_id_fk": {
3131:           "name": "qr_feedback_user_id_users_id_fk",
3132:           "tableFrom": "qr_feedback",
3133:           "tableTo": "users",
3134:           "columnsFrom": [
3135:             "user_id"
3136:           ],
3137:           "columnsTo": [
3138:             "id"
3139:           ],
3140:           "onDelete": "set null",
3141:           "onUpdate": "no action"
3142:         }
3143:       },
3144:       "compositePrimaryKeys": {},
3145:       "uniqueConstraints": {},
3146:       "policies": {},
3147:       "checkConstraints": {},
3148:       "isRLSEnabled": false
3149:     },
3150:     "public.questions_shift_selection": {
3151:       "name": "questions_shift_selection",
3152:       "schema": "",
3153:       "columns": {
3154:         "order": {
3155:           "name": "order",
3156:           "type": "integer",
3157:           "primaryKey": false,
3158:           "notNull": true
3159:         },
3160:         "parent_id": {
3161:           "name": "parent_id",
3162:           "type": "integer",
3163:           "primaryKey": false,
3164:           "notNull": true
3165:         },
3166:         "value": {
3167:           "name": "value",
3168:           "type": "enum_questions_shift_selection",
3169:           "typeSchema": "public",
3170:           "primaryKey": false,
3171:           "notNull": false
3172:         },
3173:         "id": {
3174:           "name": "id",
3175:           "type": "serial",
3176:           "primaryKey": true,
3177:           "notNull": true
3178:         }
3179:       },
3180:       "indexes": {
3181:         "questions_shift_selection_order_idx": {
3182:           "name": "questions_shift_selection_order_idx",
3183:           "columns": [
3184:             {
3185:               "expression": "order",
3186:               "isExpression": false,
3187:               "asc": true,
3188:               "nulls": "last"
3189:             }
3190:           ],
3191:           "isUnique": false,
3192:           "concurrently": false,
3193:           "method": "btree",
3194:           "with": {}
3195:         },
3196:         "questions_shift_selection_parent_idx": {
3197:           "name": "questions_shift_selection_parent_idx",
3198:           "columns": [
3199:             {
3200:               "expression": "parent_id",
3201:               "isExpression": false,
3202:               "asc": true,
3203:               "nulls": "last"
3204:             }
3205:           ],
3206:           "isUnique": false,
3207:           "concurrently": false,
3208:           "method": "btree",
3209:           "with": {}
3210:         }
3211:       },
3212:       "foreignKeys": {
3213:         "questions_shift_selection_parent_fk": {
3214:           "name": "questions_shift_selection_parent_fk",
3215:           "tableFrom": "questions_shift_selection",
3216:           "tableTo": "questions",
3217:           "columnsFrom": [
3218:             "parent_id"
3219:           ],
3220:           "columnsTo": [
3221:             "id"
3222:           ],
3223:           "onDelete": "cascade",
3224:           "onUpdate": "no action"
3225:         }
3226:       },
3227:       "compositePrimaryKeys": {},
3228:       "uniqueConstraints": {},
3229:       "policies": {},
3230:       "checkConstraints": {},
3231:       "isRLSEnabled": false
3232:     },
3233:     "public.questions": {
3234:       "name": "questions",
3235:       "schema": "",
3236:       "columns": {
3237:         "id": {
3238:           "name": "id",
3239:           "type": "serial",
3240:           "primaryKey": true,
3241:           "notNull": true
3242:         },
3243:         "status": {
3244:           "name": "status",
3245:           "type": "enum_questions_status",
3246:           "typeSchema": "public",
3247:           "primaryKey": false,
3248:           "notNull": false,
3249:           "default": "'active'"
3250:         },
3251:         "sort": {
3252:           "name": "sort",
3253:           "type": "numeric",
3254:           "primaryKey": false,
3255:           "notNull": false
3256:         },
3257:         "question": {
3258:           "name": "question",
3259:           "type": "varchar",
3260:           "primaryKey": false,
3261:           "notNull": true
3262:         },
3263:         "shift_timing": {
3264:           "name": "shift_timing",
3265:           "type": "enum_questions_shift_timing",
3266:           "typeSchema": "public",
3267:           "primaryKey": false,
3268:           "notNull": false,
3269:           "default": "'any'"
3270:         },
3271:         "min_characters": {
3272:           "name": "min_characters",
3273:           "type": "numeric",
3274:           "primaryKey": false,
3275:           "notNull": false
3276:         },
3277:         "updated_at": {
3278:           "name": "updated_at",
3279:           "type": "timestamp(3) with time zone",
3280:           "primaryKey": false,
3281:           "notNull": true,
3282:           "default": "now()"
3283:         },
3284:         "created_at": {
3285:           "name": "created_at",
3286:           "type": "timestamp(3) with time zone",
3287:           "primaryKey": false,
3288:           "notNull": true,
3289:           "default": "now()"
3290:         }
3291:       },
3292:       "indexes": {
3293:         "questions_updated_at_idx": {
3294:           "name": "questions_updated_at_idx",
3295:           "columns": [
3296:             {
3297:               "expression": "updated_at",
3298:               "isExpression": false,
3299:               "asc": true,
3300:               "nulls": "last"
3301:             }
3302:           ],
3303:           "isUnique": false,
3304:           "concurrently": false,
3305:           "method": "btree",
3306:           "with": {}
3307:         },
3308:         "questions_created_at_idx": {
3309:           "name": "questions_created_at_idx",
3310:           "columns": [
3311:             {
3312:               "expression": "created_at",
3313:               "isExpression": false,
3314:               "asc": true,
3315:               "nulls": "last"
3316:             }
3317:           ],
3318:           "isUnique": false,
3319:           "concurrently": false,
3320:           "method": "btree",
3321:           "with": {}
3322:         }
3323:       },
3324:       "foreignKeys": {},
3325:       "compositePrimaryKeys": {},
3326:       "uniqueConstraints": {},
3327:       "policies": {},
3328:       "checkConstraints": {},
3329:       "isRLSEnabled": false
3330:     },
3331:     "public.questions_rels": {
3332:       "name": "questions_rels",
3333:       "schema": "",
3334:       "columns": {
3335:         "id": {
3336:           "name": "id",
3337:           "type": "serial",
3338:           "primaryKey": true,
3339:           "notNull": true
3340:         },
3341:         "order": {
3342:           "name": "order",
3343:           "type": "integer",
3344:           "primaryKey": false,
3345:           "notNull": false
3346:         },
3347:         "parent_id": {
3348:           "name": "parent_id",
3349:           "type": "integer",
3350:           "primaryKey": false,
3351:           "notNull": true
3352:         },
3353:         "path": {
3354:           "name": "path",
3355:           "type": "varchar",
3356:           "primaryKey": false,
3357:           "notNull": true
3358:         },
3359:         "locations_id": {
3360:           "name": "locations_id",
3361:           "type": "integer",
3362:           "primaryKey": false,
3363:           "notNull": false
3364:         }
3365:       },
3366:       "indexes": {
3367:         "questions_rels_order_idx": {
3368:           "name": "questions_rels_order_idx",
3369:           "columns": [
3370:             {
3371:               "expression": "order",
3372:               "isExpression": false,
3373:               "asc": true,
3374:               "nulls": "last"
3375:             }
3376:           ],
3377:           "isUnique": false,
3378:           "concurrently": false,
3379:           "method": "btree",
3380:           "with": {}
3381:         },
3382:         "questions_rels_parent_idx": {
3383:           "name": "questions_rels_parent_idx",
3384:           "columns": [
3385:             {
3386:               "expression": "parent_id",
3387:               "isExpression": false,
3388:               "asc": true,
3389:               "nulls": "last"
3390:             }
3391:           ],
3392:           "isUnique": false,
3393:           "concurrently": false,
3394:           "method": "btree",
3395:           "with": {}
3396:         },
3397:         "questions_rels_path_idx": {
3398:           "name": "questions_rels_path_idx",
3399:           "columns": [
3400:             {
3401:               "expression": "path",
3402:               "isExpression": false,
3403:               "asc": true,
3404:               "nulls": "last"
3405:             }
3406:           ],
3407:           "isUnique": false,
3408:           "concurrently": false,
3409:           "method": "btree",
3410:           "with": {}
3411:         },
3412:         "questions_rels_locations_id_idx": {
3413:           "name": "questions_rels_locations_id_idx",
3414:           "columns": [
3415:             {
3416:               "expression": "locations_id",
3417:               "isExpression": false,
3418:               "asc": true,
3419:               "nulls": "last"
3420:             }
3421:           ],
3422:           "isUnique": false,
3423:           "concurrently": false,
3424:           "method": "btree",
3425:           "with": {}
3426:         }
3427:       },
3428:       "foreignKeys": {
3429:         "questions_rels_parent_fk": {
3430:           "name": "questions_rels_parent_fk",
3431:           "tableFrom": "questions_rels",
3432:           "tableTo": "questions",
3433:           "columnsFrom": [
3434:             "parent_id"
3435:           ],
3436:           "columnsTo": [
3437:             "id"
3438:           ],
3439:           "onDelete": "cascade",
3440:           "onUpdate": "no action"
3441:         },
3442:         "questions_rels_locations_fk": {
3443:           "name": "questions_rels_locations_fk",
3444:           "tableFrom": "questions_rels",
3445:           "tableTo": "locations",
3446:           "columnsFrom": [
3447:             "locations_id"
3448:           ],
3449:           "columnsTo": [
3450:             "id"
3451:           ],
3452:           "onDelete": "cascade",
3453:           "onUpdate": "no action"
3454:         }
3455:       },
3456:       "compositePrimaryKeys": {},
3457:       "uniqueConstraints": {},
3458:       "policies": {},
3459:       "checkConstraints": {},
3460:       "isRLSEnabled": false
3461:     },
3462:     "public.review_keywords": {
3463:       "name": "review_keywords",
3464:       "schema": "",
3465:       "columns": {
3466:         "id": {
3467:           "name": "id",
3468:           "type": "serial",
3469:           "primaryKey": true,
3470:           "notNull": true
3471:         },
3472:         "keyword": {
3473:           "name": "keyword",
3474:           "type": "varchar",
3475:           "primaryKey": false,
3476:           "notNull": true
3477:         },
3478:         "updated_at": {
3479:           "name": "updated_at",
3480:           "type": "timestamp(3) with time zone",
3481:           "primaryKey": false,
3482:           "notNull": true,
3483:           "default": "now()"
3484:         },
3485:         "created_at": {
3486:           "name": "created_at",
3487:           "type": "timestamp(3) with time zone",
3488:           "primaryKey": false,
3489:           "notNull": true,
3490:           "default": "now()"
3491:         }
3492:       },
3493:       "indexes": {
3494:         "review_keywords_keyword_idx": {
3495:           "name": "review_keywords_keyword_idx",
3496:           "columns": [
3497:             {
3498:               "expression": "keyword",
3499:               "isExpression": false,
3500:               "asc": true,
3501:               "nulls": "last"
3502:             }
3503:           ],
3504:           "isUnique": true,
3505:           "concurrently": false,
3506:           "method": "btree",
3507:           "with": {}
3508:         },
3509:         "review_keywords_updated_at_idx": {
3510:           "name": "review_keywords_updated_at_idx",
3511:           "columns": [
3512:             {
3513:               "expression": "updated_at",
3514:               "isExpression": false,
3515:               "asc": true,
3516:               "nulls": "last"
3517:             }
3518:           ],
3519:           "isUnique": false,
3520:           "concurrently": false,
3521:           "method": "btree",
3522:           "with": {}
3523:         },
3524:         "review_keywords_created_at_idx": {
3525:           "name": "review_keywords_created_at_idx",
3526:           "columns": [
3527:             {
3528:               "expression": "created_at",
3529:               "isExpression": false,
3530:               "asc": true,
3531:               "nulls": "last"
3532:             }
3533:           ],
3534:           "isUnique": false,
3535:           "concurrently": false,
3536:           "method": "btree",
3537:           "with": {}
3538:         }
3539:       },
3540:       "foreignKeys": {},
3541:       "compositePrimaryKeys": {},
3542:       "uniqueConstraints": {},
3543:       "policies": {},
3544:       "checkConstraints": {},
3545:       "isRLSEnabled": false
3546:     },
3547:     "public.reviews": {
3548:       "name": "reviews",
3549:       "schema": "",
3550:       "columns": {
3551:         "id": {
3552:           "name": "id",
3553:           "type": "serial",
3554:           "primaryKey": true,
3555:           "notNull": true
3556:         },
3557:         "title": {
3558:           "name": "title",
3559:           "type": "varchar",
3560:           "primaryKey": false,
3561:           "notNull": true
3562:         },
3563:         "rating": {
3564:           "name": "rating",
3565:           "type": "numeric",
3566:           "primaryKey": false,
3567:           "notNull": true
3568:         },
3569:         "comment": {
3570:           "name": "comment",
3571:           "type": "varchar",
3572:           "primaryKey": false,
3573:           "notNull": false
3574:         },
3575:         "user_id": {
3576:           "name": "user_id",
3577:           "type": "integer",
3578:           "primaryKey": false,
3579:           "notNull": true
3580:         },
3581:         "location_id": {
3582:           "name": "location_id",
3583:           "type": "integer",
3584:           "primaryKey": false,
3585:           "notNull": true
3586:         },
3587:         "updated_at": {
3588:           "name": "updated_at",
3589:           "type": "timestamp(3) with time zone",
3590:           "primaryKey": false,
3591:           "notNull": true,
3592:           "default": "now()"
3593:         },
3594:         "created_at": {
3595:           "name": "created_at",
3596:           "type": "timestamp(3) with time zone",
3597:           "primaryKey": false,
3598:           "notNull": true,
3599:           "default": "now()"
3600:         }
3601:       },
3602:       "indexes": {
3603:         "reviews_user_idx": {
3604:           "name": "reviews_user_idx",
3605:           "columns": [
3606:             {
3607:               "expression": "user_id",
3608:               "isExpression": false,
3609:               "asc": true,
3610:               "nulls": "last"
3611:             }
3612:           ],
3613:           "isUnique": false,
3614:           "concurrently": false,
3615:           "method": "btree",
3616:           "with": {}
3617:         },
3618:         "reviews_location_idx": {
3619:           "name": "reviews_location_idx",
3620:           "columns": [
3621:             {
3622:               "expression": "location_id",
3623:               "isExpression": false,
3624:               "asc": true,
3625:               "nulls": "last"
3626:             }
3627:           ],
3628:           "isUnique": false,
3629:           "concurrently": false,
3630:           "method": "btree",
3631:           "with": {}
3632:         },
3633:         "reviews_updated_at_idx": {
3634:           "name": "reviews_updated_at_idx",
3635:           "columns": [
3636:             {
3637:               "expression": "updated_at",
3638:               "isExpression": false,
3639:               "asc": true,
3640:               "nulls": "last"
3641:             }
3642:           ],
3643:           "isUnique": false,
3644:           "concurrently": false,
3645:           "method": "btree",
3646:           "with": {}
3647:         },
3648:         "reviews_created_at_idx": {
3649:           "name": "reviews_created_at_idx",
3650:           "columns": [
3651:             {
3652:               "expression": "created_at",
3653:               "isExpression": false,
3654:               "asc": true,
3655:               "nulls": "last"
3656:             }
3657:           ],
3658:           "isUnique": false,
3659:           "concurrently": false,
3660:           "method": "btree",
3661:           "with": {}
3662:         }
3663:       },
3664:       "foreignKeys": {
3665:         "reviews_user_id_users_id_fk": {
3666:           "name": "reviews_user_id_users_id_fk",
3667:           "tableFrom": "reviews",
3668:           "tableTo": "users",
3669:           "columnsFrom": [
3670:             "user_id"
3671:           ],
3672:           "columnsTo": [
3673:             "id"
3674:           ],
3675:           "onDelete": "set null",
3676:           "onUpdate": "no action"
3677:         },
3678:         "reviews_location_id_locations_id_fk": {
3679:           "name": "reviews_location_id_locations_id_fk",
3680:           "tableFrom": "reviews",
3681:           "tableTo": "locations",
3682:           "columnsFrom": [
3683:             "location_id"
3684:           ],
3685:           "columnsTo": [
3686:             "id"
3687:           ],
3688:           "onDelete": "set null",
3689:           "onUpdate": "no action"
3690:         }
3691:       },
3692:       "compositePrimaryKeys": {},
3693:       "uniqueConstraints": {},
3694:       "policies": {},
3695:       "checkConstraints": {},
3696:       "isRLSEnabled": false
3697:     },
3698:     "public.reviews_rels": {
3699:       "name": "reviews_rels",
3700:       "schema": "",
3701:       "columns": {
3702:         "id": {
3703:           "name": "id",
3704:           "type": "serial",
3705:           "primaryKey": true,
3706:           "notNull": true
3707:         },
3708:         "order": {
3709:           "name": "order",
3710:           "type": "integer",
3711:           "primaryKey": false,
3712:           "notNull": false
3713:         },
3714:         "parent_id": {
3715:           "name": "parent_id",
3716:           "type": "integer",
3717:           "primaryKey": false,
3718:           "notNull": true
3719:         },
3720:         "path": {
3721:           "name": "path",
3722:           "type": "varchar",
3723:           "primaryKey": false,
3724:           "notNull": true
3725:         },
3726:         "review_keywords_id": {
3727:           "name": "review_keywords_id",
3728:           "type": "integer",
3729:           "primaryKey": false,
3730:           "notNull": false
3731:         }
3732:       },
3733:       "indexes": {
3734:         "reviews_rels_order_idx": {
3735:           "name": "reviews_rels_order_idx",
3736:           "columns": [
3737:             {
3738:               "expression": "order",
3739:               "isExpression": false,
3740:               "asc": true,
3741:               "nulls": "last"
3742:             }
3743:           ],
3744:           "isUnique": false,
3745:           "concurrently": false,
3746:           "method": "btree",
3747:           "with": {}
3748:         },
3749:         "reviews_rels_parent_idx": {
3750:           "name": "reviews_rels_parent_idx",
3751:           "columns": [
3752:             {
3753:               "expression": "parent_id",
3754:               "isExpression": false,
3755:               "asc": true,
3756:               "nulls": "last"
3757:             }
3758:           ],
3759:           "isUnique": false,
3760:           "concurrently": false,
3761:           "method": "btree",
3762:           "with": {}
3763:         },
3764:         "reviews_rels_path_idx": {
3765:           "name": "reviews_rels_path_idx",
3766:           "columns": [
3767:             {
3768:               "expression": "path",
3769:               "isExpression": false,
3770:               "asc": true,
3771:               "nulls": "last"
3772:             }
3773:           ],
3774:           "isUnique": false,
3775:           "concurrently": false,
3776:           "method": "btree",
3777:           "with": {}
3778:         },
3779:         "reviews_rels_review_keywords_id_idx": {
3780:           "name": "reviews_rels_review_keywords_id_idx",
3781:           "columns": [
3782:             {
3783:               "expression": "review_keywords_id",
3784:               "isExpression": false,
3785:               "asc": true,
3786:               "nulls": "last"
3787:             }
3788:           ],
3789:           "isUnique": false,
3790:           "concurrently": false,
3791:           "method": "btree",
3792:           "with": {}
3793:         }
3794:       },
3795:       "foreignKeys": {
3796:         "reviews_rels_parent_fk": {
3797:           "name": "reviews_rels_parent_fk",
3798:           "tableFrom": "reviews_rels",
3799:           "tableTo": "reviews",
3800:           "columnsFrom": [
3801:             "parent_id"
3802:           ],
3803:           "columnsTo": [
3804:             "id"
3805:           ],
3806:           "onDelete": "cascade",
3807:           "onUpdate": "no action"
3808:         },
3809:         "reviews_rels_review_keywords_fk": {
3810:           "name": "reviews_rels_review_keywords_fk",
3811:           "tableFrom": "reviews_rels",
3812:           "tableTo": "review_keywords",
3813:           "columnsFrom": [
3814:             "review_keywords_id"
3815:           ],
3816:           "columnsTo": [
3817:             "id"
3818:           ],
3819:           "onDelete": "cascade",
3820:           "onUpdate": "no action"
3821:         }
3822:       },
3823:       "compositePrimaryKeys": {},
3824:       "uniqueConstraints": {},
3825:       "policies": {},
3826:       "checkConstraints": {},
3827:       "isRLSEnabled": false
3828:     },
3829:     "public.server_reports": {
3830:       "name": "server_reports",
3831:       "schema": "",
3832:       "columns": {
3833:         "id": {
3834:           "name": "id",
3835:           "type": "serial",
3836:           "primaryKey": true,
3837:           "notNull": true
3838:         },
3839:         "title": {
3840:           "name": "title",
3841:           "type": "varchar",
3842:           "primaryKey": false,
3843:           "notNull": true
3844:         },
3845:         "date": {
3846:           "name": "date",
3847:           "type": "timestamp(3) with time zone",
3848:           "primaryKey": false,
3849:           "notNull": true
3850:         },
3851:         "server_id": {
3852:           "name": "server_id",
3853:           "type": "integer",
3854:           "primaryKey": false,
3855:           "notNull": true
3856:         },
3857:         "location_id": {
3858:           "name": "location_id",
3859:           "type": "integer",
3860:           "primaryKey": false,
3861:           "notNull": true
3862:         },
3863:         "notes": {
3864:           "name": "notes",
3865:           "type": "varchar",
3866:           "primaryKey": false,
3867:           "notNull": false
3868:         },
3869:         "updated_at": {
3870:           "name": "updated_at",
3871:           "type": "timestamp(3) with time zone",
3872:           "primaryKey": false,
3873:           "notNull": true,
3874:           "default": "now()"
3875:         },
3876:         "created_at": {
3877:           "name": "created_at",
3878:           "type": "timestamp(3) with time zone",
3879:           "primaryKey": false,
3880:           "notNull": true,
3881:           "default": "now()"
3882:         }
3883:       },
3884:       "indexes": {
3885:         "server_reports_server_idx": {
3886:           "name": "server_reports_server_idx",
3887:           "columns": [
3888:             {
3889:               "expression": "server_id",
3890:               "isExpression": false,
3891:               "asc": true,
3892:               "nulls": "last"
3893:             }
3894:           ],
3895:           "isUnique": false,
3896:           "concurrently": false,
3897:           "method": "btree",
3898:           "with": {}
3899:         },
3900:         "server_reports_location_idx": {
3901:           "name": "server_reports_location_idx",
3902:           "columns": [
3903:             {
3904:               "expression": "location_id",
3905:               "isExpression": false,
3906:               "asc": true,
3907:               "nulls": "last"
3908:             }
3909:           ],
3910:           "isUnique": false,
3911:           "concurrently": false,
3912:           "method": "btree",
3913:           "with": {}
3914:         },
3915:         "server_reports_updated_at_idx": {
3916:           "name": "server_reports_updated_at_idx",
3917:           "columns": [
3918:             {
3919:               "expression": "updated_at",
3920:               "isExpression": false,
3921:               "asc": true,
3922:               "nulls": "last"
3923:             }
3924:           ],
3925:           "isUnique": false,
3926:           "concurrently": false,
3927:           "method": "btree",
3928:           "with": {}
3929:         },
3930:         "server_reports_created_at_idx": {
3931:           "name": "server_reports_created_at_idx",
3932:           "columns": [
3933:             {
3934:               "expression": "created_at",
3935:               "isExpression": false,
3936:               "asc": true,
3937:               "nulls": "last"
3938:             }
3939:           ],
3940:           "isUnique": false,
3941:           "concurrently": false,
3942:           "method": "btree",
3943:           "with": {}
3944:         }
3945:       },
3946:       "foreignKeys": {
3947:         "server_reports_server_id_users_id_fk": {
3948:           "name": "server_reports_server_id_users_id_fk",
3949:           "tableFrom": "server_reports",
3950:           "tableTo": "users",
3951:           "columnsFrom": [
3952:             "server_id"
3953:           ],
3954:           "columnsTo": [
3955:             "id"
3956:           ],
3957:           "onDelete": "set null",
3958:           "onUpdate": "no action"
3959:         },
3960:         "server_reports_location_id_locations_id_fk": {
3961:           "name": "server_reports_location_id_locations_id_fk",
3962:           "tableFrom": "server_reports",
3963:           "tableTo": "locations",
3964:           "columnsFrom": [
3965:             "location_id"
3966:           ],
3967:           "columnsTo": [
3968:             "id"
3969:           ],
3970:           "onDelete": "set null",
3971:           "onUpdate": "no action"
3972:         }
3973:       },
3974:       "compositePrimaryKeys": {},
3975:       "uniqueConstraints": {},
3976:       "policies": {},
3977:       "checkConstraints": {},
3978:       "isRLSEnabled": false
3979:     },
3980:     "public.shift_types": {
3981:       "name": "shift_types",
3982:       "schema": "",
3983:       "columns": {
3984:         "id": {
3985:           "name": "id",
3986:           "type": "serial",
3987:           "primaryKey": true,
3988:           "notNull": true
3989:         },
3990:         "name": {
3991:           "name": "name",
3992:           "type": "varchar",
3993:           "primaryKey": false,
3994:           "notNull": true
3995:         },
3996:         "updated_at": {
3997:           "name": "updated_at",
3998:           "type": "timestamp(3) with time zone",
3999:           "primaryKey": false,
4000:           "notNull": true,
4001:           "default": "now()"
4002:         },
4003:         "created_at": {
4004:           "name": "created_at",
4005:           "type": "timestamp(3) with time zone",
4006:           "primaryKey": false,
4007:           "notNull": true,
4008:           "default": "now()"
4009:         }
4010:       },
4011:       "indexes": {
4012:         "shift_types_name_idx": {
4013:           "name": "shift_types_name_idx",
4014:           "columns": [
4015:             {
4016:               "expression": "name",
4017:               "isExpression": false,
4018:               "asc": true,
4019:               "nulls": "last"
4020:             }
4021:           ],
4022:           "isUnique": true,
4023:           "concurrently": false,
4024:           "method": "btree",
4025:           "with": {}
4026:         },
4027:         "shift_types_updated_at_idx": {
4028:           "name": "shift_types_updated_at_idx",
4029:           "columns": [
4030:             {
4031:               "expression": "updated_at",
4032:               "isExpression": false,
4033:               "asc": true,
4034:               "nulls": "last"
4035:             }
4036:           ],
4037:           "isUnique": false,
4038:           "concurrently": false,
4039:           "method": "btree",
4040:           "with": {}
4041:         },
4042:         "shift_types_created_at_idx": {
4043:           "name": "shift_types_created_at_idx",
4044:           "columns": [
4045:             {
4046:               "expression": "created_at",
4047:               "isExpression": false,
4048:               "asc": true,
4049:               "nulls": "last"
4050:             }
4051:           ],
4052:           "isUnique": false,
4053:           "concurrently": false,
4054:           "method": "btree",
4055:           "with": {}
4056:         }
4057:       },
4058:       "foreignKeys": {},
4059:       "compositePrimaryKeys": {},
4060:       "uniqueConstraints": {},
4061:       "policies": {},
4062:       "checkConstraints": {},
4063:       "isRLSEnabled": false
4064:     },
4065:     "public.upgrades": {
4066:       "name": "upgrades",
4067:       "schema": "",
4068:       "columns": {
4069:         "id": {
4070:           "name": "id",
4071:           "type": "serial",
4072:           "primaryKey": true,
4073:           "notNull": true
4074:         },
4075:         "name": {
4076:           "name": "name",
4077:           "type": "varchar",
4078:           "primaryKey": false,
4079:           "notNull": true
4080:         },
4081:         "location_id": {
4082:           "name": "location_id",
4083:           "type": "integer",
4084:           "primaryKey": false,
4085:           "notNull": false
4086:         },
4087:         "upgrade_type_id": {
4088:           "name": "upgrade_type_id",
4089:           "type": "integer",
4090:           "primaryKey": false,
4091:           "notNull": true
4092:         },
4093:         "status": {
4094:           "name": "status",
4095:           "type": "enum_upgrades_status",
4096:           "typeSchema": "public",
4097:           "primaryKey": false,
4098:           "notNull": false,
4099:           "default": "'planned'"
4100:         },
4101:         "description": {
4102:           "name": "description",
4103:           "type": "jsonb",
4104:           "primaryKey": false,
4105:           "notNull": false
4106:         },
4107:         "cost": {
4108:           "name": "cost",
4109:           "type": "numeric",
4110:           "primaryKey": false,
4111:           "notNull": false
4112:         },
4113:         "vendor_id": {
4114:           "name": "vendor_id",
4115:           "type": "integer",
4116:           "primaryKey": false,
4117:           "notNull": false
4118:         },
4119:         "scheduled_date": {
4120:           "name": "scheduled_date",
4121:           "type": "timestamp(3) with time zone",
4122:           "primaryKey": false,
4123:           "notNull": false
4124:         },
4125:         "completion_date": {
4126:           "name": "completion_date",
4127:           "type": "timestamp(3) with time zone",
4128:           "primaryKey": false,
4129:           "notNull": false
4130:         },
4131:         "notes": {
4132:           "name": "notes",
4133:           "type": "jsonb",
4134:           "primaryKey": false,
4135:           "notNull": false
4136:         },
4137:         "updated_at": {
4138:           "name": "updated_at",
4139:           "type": "timestamp(3) with time zone",
4140:           "primaryKey": false,
4141:           "notNull": true,
4142:           "default": "now()"
4143:         },
4144:         "created_at": {
4145:           "name": "created_at",
4146:           "type": "timestamp(3) with time zone",
4147:           "primaryKey": false,
4148:           "notNull": true,
4149:           "default": "now()"
4150:         }
4151:       },
4152:       "indexes": {
4153:         "upgrades_location_idx": {
4154:           "name": "upgrades_location_idx",
4155:           "columns": [
4156:             {
4157:               "expression": "location_id",
4158:               "isExpression": false,
4159:               "asc": true,
4160:               "nulls": "last"
4161:             }
4162:           ],
4163:           "isUnique": false,
4164:           "concurrently": false,
4165:           "method": "btree",
4166:           "with": {}
4167:         },
4168:         "upgrades_upgrade_type_idx": {
4169:           "name": "upgrades_upgrade_type_idx",
4170:           "columns": [
4171:             {
4172:               "expression": "upgrade_type_id",
4173:               "isExpression": false,
4174:               "asc": true,
4175:               "nulls": "last"
4176:             }
4177:           ],
4178:           "isUnique": false,
4179:           "concurrently": false,
4180:           "method": "btree",
4181:           "with": {}
4182:         },
4183:         "upgrades_vendor_idx": {
4184:           "name": "upgrades_vendor_idx",
4185:           "columns": [
4186:             {
4187:               "expression": "vendor_id",
4188:               "isExpression": false,
4189:               "asc": true,
4190:               "nulls": "last"
4191:             }
4192:           ],
4193:           "isUnique": false,
4194:           "concurrently": false,
4195:           "method": "btree",
4196:           "with": {}
4197:         },
4198:         "upgrades_updated_at_idx": {
4199:           "name": "upgrades_updated_at_idx",
4200:           "columns": [
4201:             {
4202:               "expression": "updated_at",
4203:               "isExpression": false,
4204:               "asc": true,
4205:               "nulls": "last"
4206:             }
4207:           ],
4208:           "isUnique": false,
4209:           "concurrently": false,
4210:           "method": "btree",
4211:           "with": {}
4212:         },
4213:         "upgrades_created_at_idx": {
4214:           "name": "upgrades_created_at_idx",
4215:           "columns": [
4216:             {
4217:               "expression": "created_at",
4218:               "isExpression": false,
4219:               "asc": true,
4220:               "nulls": "last"
4221:             }
4222:           ],
4223:           "isUnique": false,
4224:           "concurrently": false,
4225:           "method": "btree",
4226:           "with": {}
4227:         }
4228:       },
4229:       "foreignKeys": {
4230:         "upgrades_location_id_locations_id_fk": {
4231:           "name": "upgrades_location_id_locations_id_fk",
4232:           "tableFrom": "upgrades",
4233:           "tableTo": "locations",
4234:           "columnsFrom": [
4235:             "location_id"
4236:           ],
4237:           "columnsTo": [
4238:             "id"
4239:           ],
4240:           "onDelete": "set null",
4241:           "onUpdate": "no action"
4242:         },
4243:         "upgrades_upgrade_type_id_upgrade_types_id_fk": {
4244:           "name": "upgrades_upgrade_type_id_upgrade_types_id_fk",
4245:           "tableFrom": "upgrades",
4246:           "tableTo": "upgrade_types",
4247:           "columnsFrom": [
4248:             "upgrade_type_id"
4249:           ],
4250:           "columnsTo": [
4251:             "id"
4252:           ],
4253:           "onDelete": "set null",
4254:           "onUpdate": "no action"
4255:         },
4256:         "upgrades_vendor_id_contacts_id_fk": {
4257:           "name": "upgrades_vendor_id_contacts_id_fk",
4258:           "tableFrom": "upgrades",
4259:           "tableTo": "contacts",
4260:           "columnsFrom": [
4261:             "vendor_id"
4262:           ],
4263:           "columnsTo": [
4264:             "id"
4265:           ],
4266:           "onDelete": "set null",
4267:           "onUpdate": "no action"
4268:         }
4269:       },
4270:       "compositePrimaryKeys": {},
4271:       "uniqueConstraints": {},
4272:       "policies": {},
4273:       "checkConstraints": {},
4274:       "isRLSEnabled": false
4275:     },
4276:     "public.upgrades_rels": {
4277:       "name": "upgrades_rels",
4278:       "schema": "",
4279:       "columns": {
4280:         "id": {
4281:           "name": "id",
4282:           "type": "serial",
4283:           "primaryKey": true,
4284:           "notNull": true
4285:         },
4286:         "order": {
4287:           "name": "order",
4288:           "type": "integer",
4289:           "primaryKey": false,
4290:           "notNull": false
4291:         },
4292:         "parent_id": {
4293:           "name": "parent_id",
4294:           "type": "integer",
4295:           "primaryKey": false,
4296:           "notNull": true
4297:         },
4298:         "path": {
4299:           "name": "path",
4300:           "type": "varchar",
4301:           "primaryKey": false,
4302:           "notNull": true
4303:         },
4304:         "media_id": {
4305:           "name": "media_id",
4306:           "type": "integer",
4307:           "primaryKey": false,
4308:           "notNull": false
4309:         }
4310:       },
4311:       "indexes": {
4312:         "upgrades_rels_order_idx": {
4313:           "name": "upgrades_rels_order_idx",
4314:           "columns": [
4315:             {
4316:               "expression": "order",
4317:               "isExpression": false,
4318:               "asc": true,
4319:               "nulls": "last"
4320:             }
4321:           ],
4322:           "isUnique": false,
4323:           "concurrently": false,
4324:           "method": "btree",
4325:           "with": {}
4326:         },
4327:         "upgrades_rels_parent_idx": {
4328:           "name": "upgrades_rels_parent_idx",
4329:           "columns": [
4330:             {
4331:               "expression": "parent_id",
4332:               "isExpression": false,
4333:               "asc": true,
4334:               "nulls": "last"
4335:             }
4336:           ],
4337:           "isUnique": false,
4338:           "concurrently": false,
4339:           "method": "btree",
4340:           "with": {}
4341:         },
4342:         "upgrades_rels_path_idx": {
4343:           "name": "upgrades_rels_path_idx",
4344:           "columns": [
4345:             {
4346:               "expression": "path",
4347:               "isExpression": false,
4348:               "asc": true,
4349:               "nulls": "last"
4350:             }
4351:           ],
4352:           "isUnique": false,
4353:           "concurrently": false,
4354:           "method": "btree",
4355:           "with": {}
4356:         },
4357:         "upgrades_rels_media_id_idx": {
4358:           "name": "upgrades_rels_media_id_idx",
4359:           "columns": [
4360:             {
4361:               "expression": "media_id",
4362:               "isExpression": false,
4363:               "asc": true,
4364:               "nulls": "last"
4365:             }
4366:           ],
4367:           "isUnique": false,
4368:           "concurrently": false,
4369:           "method": "btree",
4370:           "with": {}
4371:         }
4372:       },
4373:       "foreignKeys": {
4374:         "upgrades_rels_parent_fk": {
4375:           "name": "upgrades_rels_parent_fk",
4376:           "tableFrom": "upgrades_rels",
4377:           "tableTo": "upgrades",
4378:           "columnsFrom": [
4379:             "parent_id"
4380:           ],
4381:           "columnsTo": [
4382:             "id"
4383:           ],
4384:           "onDelete": "cascade",
4385:           "onUpdate": "no action"
4386:         },
4387:         "upgrades_rels_media_fk": {
4388:           "name": "upgrades_rels_media_fk",
4389:           "tableFrom": "upgrades_rels",
4390:           "tableTo": "media",
4391:           "columnsFrom": [
4392:             "media_id"
4393:           ],
4394:           "columnsTo": [
4395:             "id"
4396:           ],
4397:           "onDelete": "cascade",
4398:           "onUpdate": "no action"
4399:         }
4400:       },
4401:       "compositePrimaryKeys": {},
4402:       "uniqueConstraints": {},
4403:       "policies": {},
4404:       "checkConstraints": {},
4405:       "isRLSEnabled": false
4406:     },
4407:     "public.upgrade_types": {
4408:       "name": "upgrade_types",
4409:       "schema": "",
4410:       "columns": {
4411:         "id": {
4412:           "name": "id",
4413:           "type": "serial",
4414:           "primaryKey": true,
4415:           "notNull": true
4416:         },
4417:         "name": {
4418:           "name": "name",
4419:           "type": "varchar",
4420:           "primaryKey": false,
4421:           "notNull": true
4422:         },
4423:         "updated_at": {
4424:           "name": "updated_at",
4425:           "type": "timestamp(3) with time zone",
4426:           "primaryKey": false,
4427:           "notNull": true,
4428:           "default": "now()"
4429:         },
4430:         "created_at": {
4431:           "name": "created_at",
4432:           "type": "timestamp(3) with time zone",
4433:           "primaryKey": false,
4434:           "notNull": true,
4435:           "default": "now()"
4436:         }
4437:       },
4438:       "indexes": {
4439:         "upgrade_types_name_idx": {
4440:           "name": "upgrade_types_name_idx",
4441:           "columns": [
4442:             {
4443:               "expression": "name",
4444:               "isExpression": false,
4445:               "asc": true,
4446:               "nulls": "last"
4447:             }
4448:           ],
4449:           "isUnique": true,
4450:           "concurrently": false,
4451:           "method": "btree",
4452:           "with": {}
4453:         },
4454:         "upgrade_types_updated_at_idx": {
4455:           "name": "upgrade_types_updated_at_idx",
4456:           "columns": [
4457:             {
4458:               "expression": "updated_at",
4459:               "isExpression": false,
4460:               "asc": true,
4461:               "nulls": "last"
4462:             }
4463:           ],
4464:           "isUnique": false,
4465:           "concurrently": false,
4466:           "method": "btree",
4467:           "with": {}
4468:         },
4469:         "upgrade_types_created_at_idx": {
4470:           "name": "upgrade_types_created_at_idx",
4471:           "columns": [
4472:             {
4473:               "expression": "created_at",
4474:               "isExpression": false,
4475:               "asc": true,
4476:               "nulls": "last"
4477:             }
4478:           ],
4479:           "isUnique": false,
4480:           "concurrently": false,
4481:           "method": "btree",
4482:           "with": {}
4483:         }
4484:       },
4485:       "foreignKeys": {},
4486:       "compositePrimaryKeys": {},
4487:       "uniqueConstraints": {},
4488:       "policies": {},
4489:       "checkConstraints": {},
4490:       "isRLSEnabled": false
4491:     },
4492:     "public.payload_locked_documents": {
4493:       "name": "payload_locked_documents",
4494:       "schema": "",
4495:       "columns": {
4496:         "id": {
4497:           "name": "id",
4498:           "type": "serial",
4499:           "primaryKey": true,
4500:           "notNull": true
4501:         },
4502:         "global_slug": {
4503:           "name": "global_slug",
4504:           "type": "varchar",
4505:           "primaryKey": false,
4506:           "notNull": false
4507:         },
4508:         "updated_at": {
4509:           "name": "updated_at",
4510:           "type": "timestamp(3) with time zone",
4511:           "primaryKey": false,
4512:           "notNull": true,
4513:           "default": "now()"
4514:         },
4515:         "created_at": {
4516:           "name": "created_at",
4517:           "type": "timestamp(3) with time zone",
4518:           "primaryKey": false,
4519:           "notNull": true,
4520:           "default": "now()"
4521:         }
4522:       },
4523:       "indexes": {
4524:         "payload_locked_documents_global_slug_idx": {
4525:           "name": "payload_locked_documents_global_slug_idx",
4526:           "columns": [
4527:             {
4528:               "expression": "global_slug",
4529:               "isExpression": false,
4530:               "asc": true,
4531:               "nulls": "last"
4532:             }
4533:           ],
4534:           "isUnique": false,
4535:           "concurrently": false,
4536:           "method": "btree",
4537:           "with": {}
4538:         },
4539:         "payload_locked_documents_updated_at_idx": {
4540:           "name": "payload_locked_documents_updated_at_idx",
4541:           "columns": [
4542:             {
4543:               "expression": "updated_at",
4544:               "isExpression": false,
4545:               "asc": true,
4546:               "nulls": "last"
4547:             }
4548:           ],
4549:           "isUnique": false,
4550:           "concurrently": false,
4551:           "method": "btree",
4552:           "with": {}
4553:         },
4554:         "payload_locked_documents_created_at_idx": {
4555:           "name": "payload_locked_documents_created_at_idx",
4556:           "columns": [
4557:             {
4558:               "expression": "created_at",
4559:               "isExpression": false,
4560:               "asc": true,
4561:               "nulls": "last"
4562:             }
4563:           ],
4564:           "isUnique": false,
4565:           "concurrently": false,
4566:           "method": "btree",
4567:           "with": {}
4568:         }
4569:       },
4570:       "foreignKeys": {},
4571:       "compositePrimaryKeys": {},
4572:       "uniqueConstraints": {},
4573:       "policies": {},
4574:       "checkConstraints": {},
4575:       "isRLSEnabled": false
4576:     },
4577:     "public.payload_locked_documents_rels": {
4578:       "name": "payload_locked_documents_rels",
4579:       "schema": "",
4580:       "columns": {
4581:         "id": {
4582:           "name": "id",
4583:           "type": "serial",
4584:           "primaryKey": true,
4585:           "notNull": true
4586:         },
4587:         "order": {
4588:           "name": "order",
4589:           "type": "integer",
4590:           "primaryKey": false,
4591:           "notNull": false
4592:         },
4593:         "parent_id": {
4594:           "name": "parent_id",
4595:           "type": "integer",
4596:           "primaryKey": false,
4597:           "notNull": true
4598:         },
4599:         "path": {
4600:           "name": "path",
4601:           "type": "varchar",
4602:           "primaryKey": false,
4603:           "notNull": true
4604:         },
4605:         "users_id": {
4606:           "name": "users_id",
4607:           "type": "integer",
4608:           "primaryKey": false,
4609:           "notNull": false
4610:         },
4611:         "media_id": {
4612:           "name": "media_id",
4613:           "type": "integer",
4614:           "primaryKey": false,
4615:           "notNull": false
4616:         },
4617:         "contacts_id": {
4618:           "name": "contacts_id",
4619:           "type": "integer",
4620:           "primaryKey": false,
4621:           "notNull": false
4622:         },
4623:         "dietary_restrictions_id": {
4624:           "name": "dietary_restrictions_id",
4625:           "type": "integer",
4626:           "primaryKey": false,
4627:           "notNull": false
4628:         },
4629:         "drink_menu_items_id": {
4630:           "name": "drink_menu_items_id",
4631:           "type": "integer",
4632:           "primaryKey": false,
4633:           "notNull": false
4634:         },
4635:         "drink_subcategories_id": {
4636:           "name": "drink_subcategories_id",
4637:           "type": "integer",
4638:           "primaryKey": false,
4639:           "notNull": false
4640:         },
4641:         "employee_ratings_id": {
4642:           "name": "employee_ratings_id",
4643:           "type": "integer",
4644:           "primaryKey": false,
4645:           "notNull": false
4646:         },
4647:         "features_id": {
4648:           "name": "features_id",
4649:           "type": "integer",
4650:           "primaryKey": false,
4651:           "notNull": false
4652:         },
4653:         "hotspot_logins_id": {
4654:           "name": "hotspot_logins_id",
4655:           "type": "integer",
4656:           "primaryKey": false,
4657:           "notNull": false
4658:         },
4659:         "incidents_id": {
4660:           "name": "incidents_id",
4661:           "type": "integer",
4662:           "primaryKey": false,
4663:           "notNull": false
4664:         },
4665:         "jobs_id": {
4666:           "name": "jobs_id",
4667:           "type": "integer",
4668:           "primaryKey": false,
4669:           "notNull": false
4670:         },
4671:         "locations_id": {
4672:           "name": "locations_id",
4673:           "type": "integer",
4674:           "primaryKey": false,
4675:           "notNull": false
4676:         },
4677:         "manager_reports_id": {
4678:           "name": "manager_reports_id",
4679:           "type": "integer",
4680:           "primaryKey": false,
4681:           "notNull": false
4682:         },
4683:         "messages_id": {
4684:           "name": "messages_id",
4685:           "type": "integer",
4686:           "primaryKey": false,
4687:           "notNull": false
4688:         },
4689:         "message_types_id": {
4690:           "name": "message_types_id",
4691:           "type": "integer",
4692:           "primaryKey": false,
4693:           "notNull": false
4694:         },
4695:         "qr_feedback_id": {
4696:           "name": "qr_feedback_id",
4697:           "type": "integer",
4698:           "primaryKey": false,
4699:           "notNull": false
4700:         },
4701:         "questions_id": {
4702:           "name": "questions_id",
4703:           "type": "integer",
4704:           "primaryKey": false,
4705:           "notNull": false
4706:         },
4707:         "review_keywords_id": {
4708:           "name": "review_keywords_id",
4709:           "type": "integer",
4710:           "primaryKey": false,
4711:           "notNull": false
4712:         },
4713:         "reviews_id": {
4714:           "name": "reviews_id",
4715:           "type": "integer",
4716:           "primaryKey": false,
4717:           "notNull": false
4718:         },
4719:         "server_reports_id": {
4720:           "name": "server_reports_id",
4721:           "type": "integer",
4722:           "primaryKey": false,
4723:           "notNull": false
4724:         },
4725:         "shift_types_id": {
4726:           "name": "shift_types_id",
4727:           "type": "integer",
4728:           "primaryKey": false,
4729:           "notNull": false
4730:         },
4731:         "upgrades_id": {
4732:           "name": "upgrades_id",
4733:           "type": "integer",
4734:           "primaryKey": false,
4735:           "notNull": false
4736:         },
4737:         "upgrade_types_id": {
4738:           "name": "upgrade_types_id",
4739:           "type": "integer",
4740:           "primaryKey": false,
4741:           "notNull": false
4742:         }
4743:       },
4744:       "indexes": {
4745:         "payload_locked_documents_rels_order_idx": {
4746:           "name": "payload_locked_documents_rels_order_idx",
4747:           "columns": [
4748:             {
4749:               "expression": "order",
4750:               "isExpression": false,
4751:               "asc": true,
4752:               "nulls": "last"
4753:             }
4754:           ],
4755:           "isUnique": false,
4756:           "concurrently": false,
4757:           "method": "btree",
4758:           "with": {}
4759:         },
4760:         "payload_locked_documents_rels_parent_idx": {
4761:           "name": "payload_locked_documents_rels_parent_idx",
4762:           "columns": [
4763:             {
4764:               "expression": "parent_id",
4765:               "isExpression": false,
4766:               "asc": true,
4767:               "nulls": "last"
4768:             }
4769:           ],
4770:           "isUnique": false,
4771:           "concurrently": false,
4772:           "method": "btree",
4773:           "with": {}
4774:         },
4775:         "payload_locked_documents_rels_path_idx": {
4776:           "name": "payload_locked_documents_rels_path_idx",
4777:           "columns": [
4778:             {
4779:               "expression": "path",
4780:               "isExpression": false,
4781:               "asc": true,
4782:               "nulls": "last"
4783:             }
4784:           ],
4785:           "isUnique": false,
4786:           "concurrently": false,
4787:           "method": "btree",
4788:           "with": {}
4789:         },
4790:         "payload_locked_documents_rels_users_id_idx": {
4791:           "name": "payload_locked_documents_rels_users_id_idx",
4792:           "columns": [
4793:             {
4794:               "expression": "users_id",
4795:               "isExpression": false,
4796:               "asc": true,
4797:               "nulls": "last"
4798:             }
4799:           ],
4800:           "isUnique": false,
4801:           "concurrently": false,
4802:           "method": "btree",
4803:           "with": {}
4804:         },
4805:         "payload_locked_documents_rels_media_id_idx": {
4806:           "name": "payload_locked_documents_rels_media_id_idx",
4807:           "columns": [
4808:             {
4809:               "expression": "media_id",
4810:               "isExpression": false,
4811:               "asc": true,
4812:               "nulls": "last"
4813:             }
4814:           ],
4815:           "isUnique": false,
4816:           "concurrently": false,
4817:           "method": "btree",
4818:           "with": {}
4819:         },
4820:         "payload_locked_documents_rels_contacts_id_idx": {
4821:           "name": "payload_locked_documents_rels_contacts_id_idx",
4822:           "columns": [
4823:             {
4824:               "expression": "contacts_id",
4825:               "isExpression": false,
4826:               "asc": true,
4827:               "nulls": "last"
4828:             }
4829:           ],
4830:           "isUnique": false,
4831:           "concurrently": false,
4832:           "method": "btree",
4833:           "with": {}
4834:         },
4835:         "payload_locked_documents_rels_dietary_restrictions_id_idx": {
4836:           "name": "payload_locked_documents_rels_dietary_restrictions_id_idx",
4837:           "columns": [
4838:             {
4839:               "expression": "dietary_restrictions_id",
4840:               "isExpression": false,
4841:               "asc": true,
4842:               "nulls": "last"
4843:             }
4844:           ],
4845:           "isUnique": false,
4846:           "concurrently": false,
4847:           "method": "btree",
4848:           "with": {}
4849:         },
4850:         "payload_locked_documents_rels_drink_menu_items_id_idx": {
4851:           "name": "payload_locked_documents_rels_drink_menu_items_id_idx",
4852:           "columns": [
4853:             {
4854:               "expression": "drink_menu_items_id",
4855:               "isExpression": false,
4856:               "asc": true,
4857:               "nulls": "last"
4858:             }
4859:           ],
4860:           "isUnique": false,
4861:           "concurrently": false,
4862:           "method": "btree",
4863:           "with": {}
4864:         },
4865:         "payload_locked_documents_rels_drink_subcategories_id_idx": {
4866:           "name": "payload_locked_documents_rels_drink_subcategories_id_idx",
4867:           "columns": [
4868:             {
4869:               "expression": "drink_subcategories_id",
4870:               "isExpression": false,
4871:               "asc": true,
4872:               "nulls": "last"
4873:             }
4874:           ],
4875:           "isUnique": false,
4876:           "concurrently": false,
4877:           "method": "btree",
4878:           "with": {}
4879:         },
4880:         "payload_locked_documents_rels_employee_ratings_id_idx": {
4881:           "name": "payload_locked_documents_rels_employee_ratings_id_idx",
4882:           "columns": [
4883:             {
4884:               "expression": "employee_ratings_id",
4885:               "isExpression": false,
4886:               "asc": true,
4887:               "nulls": "last"
4888:             }
4889:           ],
4890:           "isUnique": false,
4891:           "concurrently": false,
4892:           "method": "btree",
4893:           "with": {}
4894:         },
4895:         "payload_locked_documents_rels_features_id_idx": {
4896:           "name": "payload_locked_documents_rels_features_id_idx",
4897:           "columns": [
4898:             {
4899:               "expression": "features_id",
4900:               "isExpression": false,
4901:               "asc": true,
4902:               "nulls": "last"
4903:             }
4904:           ],
4905:           "isUnique": false,
4906:           "concurrently": false,
4907:           "method": "btree",
4908:           "with": {}
4909:         },
4910:         "payload_locked_documents_rels_hotspot_logins_id_idx": {
4911:           "name": "payload_locked_documents_rels_hotspot_logins_id_idx",
4912:           "columns": [
4913:             {
4914:               "expression": "hotspot_logins_id",
4915:               "isExpression": false,
4916:               "asc": true,
4917:               "nulls": "last"
4918:             }
4919:           ],
4920:           "isUnique": false,
4921:           "concurrently": false,
4922:           "method": "btree",
4923:           "with": {}
4924:         },
4925:         "payload_locked_documents_rels_incidents_id_idx": {
4926:           "name": "payload_locked_documents_rels_incidents_id_idx",
4927:           "columns": [
4928:             {
4929:               "expression": "incidents_id",
4930:               "isExpression": false,
4931:               "asc": true,
4932:               "nulls": "last"
4933:             }
4934:           ],
4935:           "isUnique": false,
4936:           "concurrently": false,
4937:           "method": "btree",
4938:           "with": {}
4939:         },
4940:         "payload_locked_documents_rels_jobs_id_idx": {
4941:           "name": "payload_locked_documents_rels_jobs_id_idx",
4942:           "columns": [
4943:             {
4944:               "expression": "jobs_id",
4945:               "isExpression": false,
4946:               "asc": true,
4947:               "nulls": "last"
4948:             }
4949:           ],
4950:           "isUnique": false,
4951:           "concurrently": false,
4952:           "method": "btree",
4953:           "with": {}
4954:         },
4955:         "payload_locked_documents_rels_locations_id_idx": {
4956:           "name": "payload_locked_documents_rels_locations_id_idx",
4957:           "columns": [
4958:             {
4959:               "expression": "locations_id",
4960:               "isExpression": false,
4961:               "asc": true,
4962:               "nulls": "last"
4963:             }
4964:           ],
4965:           "isUnique": false,
4966:           "concurrently": false,
4967:           "method": "btree",
4968:           "with": {}
4969:         },
4970:         "payload_locked_documents_rels_manager_reports_id_idx": {
4971:           "name": "payload_locked_documents_rels_manager_reports_id_idx",
4972:           "columns": [
4973:             {
4974:               "expression": "manager_reports_id",
4975:               "isExpression": false,
4976:               "asc": true,
4977:               "nulls": "last"
4978:             }
4979:           ],
4980:           "isUnique": false,
4981:           "concurrently": false,
4982:           "method": "btree",
4983:           "with": {}
4984:         },
4985:         "payload_locked_documents_rels_messages_id_idx": {
4986:           "name": "payload_locked_documents_rels_messages_id_idx",
4987:           "columns": [
4988:             {
4989:               "expression": "messages_id",
4990:               "isExpression": false,
4991:               "asc": true,
4992:               "nulls": "last"
4993:             }
4994:           ],
4995:           "isUnique": false,
4996:           "concurrently": false,
4997:           "method": "btree",
4998:           "with": {}
4999:         },
5000:         "payload_locked_documents_rels_message_types_id_idx": {
5001:           "name": "payload_locked_documents_rels_message_types_id_idx",
5002:           "columns": [
5003:             {
5004:               "expression": "message_types_id",
5005:               "isExpression": false,
5006:               "asc": true,
5007:               "nulls": "last"
5008:             }
5009:           ],
5010:           "isUnique": false,
5011:           "concurrently": false,
5012:           "method": "btree",
5013:           "with": {}
5014:         },
5015:         "payload_locked_documents_rels_qr_feedback_id_idx": {
5016:           "name": "payload_locked_documents_rels_qr_feedback_id_idx",
5017:           "columns": [
5018:             {
5019:               "expression": "qr_feedback_id",
5020:               "isExpression": false,
5021:               "asc": true,
5022:               "nulls": "last"
5023:             }
5024:           ],
5025:           "isUnique": false,
5026:           "concurrently": false,
5027:           "method": "btree",
5028:           "with": {}
5029:         },
5030:         "payload_locked_documents_rels_questions_id_idx": {
5031:           "name": "payload_locked_documents_rels_questions_id_idx",
5032:           "columns": [
5033:             {
5034:               "expression": "questions_id",
5035:               "isExpression": false,
5036:               "asc": true,
5037:               "nulls": "last"
5038:             }
5039:           ],
5040:           "isUnique": false,
5041:           "concurrently": false,
5042:           "method": "btree",
5043:           "with": {}
5044:         },
5045:         "payload_locked_documents_rels_review_keywords_id_idx": {
5046:           "name": "payload_locked_documents_rels_review_keywords_id_idx",
5047:           "columns": [
5048:             {
5049:               "expression": "review_keywords_id",
5050:               "isExpression": false,
5051:               "asc": true,
5052:               "nulls": "last"
5053:             }
5054:           ],
5055:           "isUnique": false,
5056:           "concurrently": false,
5057:           "method": "btree",
5058:           "with": {}
5059:         },
5060:         "payload_locked_documents_rels_reviews_id_idx": {
5061:           "name": "payload_locked_documents_rels_reviews_id_idx",
5062:           "columns": [
5063:             {
5064:               "expression": "reviews_id",
5065:               "isExpression": false,
5066:               "asc": true,
5067:               "nulls": "last"
5068:             }
5069:           ],
5070:           "isUnique": false,
5071:           "concurrently": false,
5072:           "method": "btree",
5073:           "with": {}
5074:         },
5075:         "payload_locked_documents_rels_server_reports_id_idx": {
5076:           "name": "payload_locked_documents_rels_server_reports_id_idx",
5077:           "columns": [
5078:             {
5079:               "expression": "server_reports_id",
5080:               "isExpression": false,
5081:               "asc": true,
5082:               "nulls": "last"
5083:             }
5084:           ],
5085:           "isUnique": false,
5086:           "concurrently": false,
5087:           "method": "btree",
5088:           "with": {}
5089:         },
5090:         "payload_locked_documents_rels_shift_types_id_idx": {
5091:           "name": "payload_locked_documents_rels_shift_types_id_idx",
5092:           "columns": [
5093:             {
5094:               "expression": "shift_types_id",
5095:               "isExpression": false,
5096:               "asc": true,
5097:               "nulls": "last"
5098:             }
5099:           ],
5100:           "isUnique": false,
5101:           "concurrently": false,
5102:           "method": "btree",
5103:           "with": {}
5104:         },
5105:         "payload_locked_documents_rels_upgrades_id_idx": {
5106:           "name": "payload_locked_documents_rels_upgrades_id_idx",
5107:           "columns": [
5108:             {
5109:               "expression": "upgrades_id",
5110:               "isExpression": false,
5111:               "asc": true,
5112:               "nulls": "last"
5113:             }
5114:           ],
5115:           "isUnique": false,
5116:           "concurrently": false,
5117:           "method": "btree",
5118:           "with": {}
5119:         },
5120:         "payload_locked_documents_rels_upgrade_types_id_idx": {
5121:           "name": "payload_locked_documents_rels_upgrade_types_id_idx",
5122:           "columns": [
5123:             {
5124:               "expression": "upgrade_types_id",
5125:               "isExpression": false,
5126:               "asc": true,
5127:               "nulls": "last"
5128:             }
5129:           ],
5130:           "isUnique": false,
5131:           "concurrently": false,
5132:           "method": "btree",
5133:           "with": {}
5134:         }
5135:       },
5136:       "foreignKeys": {
5137:         "payload_locked_documents_rels_parent_fk": {
5138:           "name": "payload_locked_documents_rels_parent_fk",
5139:           "tableFrom": "payload_locked_documents_rels",
5140:           "tableTo": "payload_locked_documents",
5141:           "columnsFrom": [
5142:             "parent_id"
5143:           ],
5144:           "columnsTo": [
5145:             "id"
5146:           ],
5147:           "onDelete": "cascade",
5148:           "onUpdate": "no action"
5149:         },
5150:         "payload_locked_documents_rels_users_fk": {
5151:           "name": "payload_locked_documents_rels_users_fk",
5152:           "tableFrom": "payload_locked_documents_rels",
5153:           "tableTo": "users",
5154:           "columnsFrom": [
5155:             "users_id"
5156:           ],
5157:           "columnsTo": [
5158:             "id"
5159:           ],
5160:           "onDelete": "cascade",
5161:           "onUpdate": "no action"
5162:         },
5163:         "payload_locked_documents_rels_media_fk": {
5164:           "name": "payload_locked_documents_rels_media_fk",
5165:           "tableFrom": "payload_locked_documents_rels",
5166:           "tableTo": "media",
5167:           "columnsFrom": [
5168:             "media_id"
5169:           ],
5170:           "columnsTo": [
5171:             "id"
5172:           ],
5173:           "onDelete": "cascade",
5174:           "onUpdate": "no action"
5175:         },
5176:         "payload_locked_documents_rels_contacts_fk": {
5177:           "name": "payload_locked_documents_rels_contacts_fk",
5178:           "tableFrom": "payload_locked_documents_rels",
5179:           "tableTo": "contacts",
5180:           "columnsFrom": [
5181:             "contacts_id"
5182:           ],
5183:           "columnsTo": [
5184:             "id"
5185:           ],
5186:           "onDelete": "cascade",
5187:           "onUpdate": "no action"
5188:         },
5189:         "payload_locked_documents_rels_dietary_restrictions_fk": {
5190:           "name": "payload_locked_documents_rels_dietary_restrictions_fk",
5191:           "tableFrom": "payload_locked_documents_rels",
5192:           "tableTo": "dietary_restrictions",
5193:           "columnsFrom": [
5194:             "dietary_restrictions_id"
5195:           ],
5196:           "columnsTo": [
5197:             "id"
5198:           ],
5199:           "onDelete": "cascade",
5200:           "onUpdate": "no action"
5201:         },
5202:         "payload_locked_documents_rels_drink_menu_items_fk": {
5203:           "name": "payload_locked_documents_rels_drink_menu_items_fk",
5204:           "tableFrom": "payload_locked_documents_rels",
5205:           "tableTo": "drink_menu_items",
5206:           "columnsFrom": [
5207:             "drink_menu_items_id"
5208:           ],
5209:           "columnsTo": [
5210:             "id"
5211:           ],
5212:           "onDelete": "cascade",
5213:           "onUpdate": "no action"
5214:         },
5215:         "payload_locked_documents_rels_drink_subcategories_fk": {
5216:           "name": "payload_locked_documents_rels_drink_subcategories_fk",
5217:           "tableFrom": "payload_locked_documents_rels",
5218:           "tableTo": "drink_subcategories",
5219:           "columnsFrom": [
5220:             "drink_subcategories_id"
5221:           ],
5222:           "columnsTo": [
5223:             "id"
5224:           ],
5225:           "onDelete": "cascade",
5226:           "onUpdate": "no action"
5227:         },
5228:         "payload_locked_documents_rels_employee_ratings_fk": {
5229:           "name": "payload_locked_documents_rels_employee_ratings_fk",
5230:           "tableFrom": "payload_locked_documents_rels",
5231:           "tableTo": "employee_ratings",
5232:           "columnsFrom": [
5233:             "employee_ratings_id"
5234:           ],
5235:           "columnsTo": [
5236:             "id"
5237:           ],
5238:           "onDelete": "cascade",
5239:           "onUpdate": "no action"
5240:         },
5241:         "payload_locked_documents_rels_features_fk": {
5242:           "name": "payload_locked_documents_rels_features_fk",
5243:           "tableFrom": "payload_locked_documents_rels",
5244:           "tableTo": "features",
5245:           "columnsFrom": [
5246:             "features_id"
5247:           ],
5248:           "columnsTo": [
5249:             "id"
5250:           ],
5251:           "onDelete": "cascade",
5252:           "onUpdate": "no action"
5253:         },
5254:         "payload_locked_documents_rels_hotspot_logins_fk": {
5255:           "name": "payload_locked_documents_rels_hotspot_logins_fk",
5256:           "tableFrom": "payload_locked_documents_rels",
5257:           "tableTo": "hotspot_logins",
5258:           "columnsFrom": [
5259:             "hotspot_logins_id"
5260:           ],
5261:           "columnsTo": [
5262:             "id"
5263:           ],
5264:           "onDelete": "cascade",
5265:           "onUpdate": "no action"
5266:         },
5267:         "payload_locked_documents_rels_incidents_fk": {
5268:           "name": "payload_locked_documents_rels_incidents_fk",
5269:           "tableFrom": "payload_locked_documents_rels",
5270:           "tableTo": "incidents",
5271:           "columnsFrom": [
5272:             "incidents_id"
5273:           ],
5274:           "columnsTo": [
5275:             "id"
5276:           ],
5277:           "onDelete": "cascade",
5278:           "onUpdate": "no action"
5279:         },
5280:         "payload_locked_documents_rels_jobs_fk": {
5281:           "name": "payload_locked_documents_rels_jobs_fk",
5282:           "tableFrom": "payload_locked_documents_rels",
5283:           "tableTo": "jobs",
5284:           "columnsFrom": [
5285:             "jobs_id"
5286:           ],
5287:           "columnsTo": [
5288:             "id"
5289:           ],
5290:           "onDelete": "cascade",
5291:           "onUpdate": "no action"
5292:         },
5293:         "payload_locked_documents_rels_locations_fk": {
5294:           "name": "payload_locked_documents_rels_locations_fk",
5295:           "tableFrom": "payload_locked_documents_rels",
5296:           "tableTo": "locations",
5297:           "columnsFrom": [
5298:             "locations_id"
5299:           ],
5300:           "columnsTo": [
5301:             "id"
5302:           ],
5303:           "onDelete": "cascade",
5304:           "onUpdate": "no action"
5305:         },
5306:         "payload_locked_documents_rels_manager_reports_fk": {
5307:           "name": "payload_locked_documents_rels_manager_reports_fk",
5308:           "tableFrom": "payload_locked_documents_rels",
5309:           "tableTo": "manager_reports",
5310:           "columnsFrom": [
5311:             "manager_reports_id"
5312:           ],
5313:           "columnsTo": [
5314:             "id"
5315:           ],
5316:           "onDelete": "cascade",
5317:           "onUpdate": "no action"
5318:         },
5319:         "payload_locked_documents_rels_messages_fk": {
5320:           "name": "payload_locked_documents_rels_messages_fk",
5321:           "tableFrom": "payload_locked_documents_rels",
5322:           "tableTo": "messages",
5323:           "columnsFrom": [
5324:             "messages_id"
5325:           ],
5326:           "columnsTo": [
5327:             "id"
5328:           ],
5329:           "onDelete": "cascade",
5330:           "onUpdate": "no action"
5331:         },
5332:         "payload_locked_documents_rels_message_types_fk": {
5333:           "name": "payload_locked_documents_rels_message_types_fk",
5334:           "tableFrom": "payload_locked_documents_rels",
5335:           "tableTo": "message_types",
5336:           "columnsFrom": [
5337:             "message_types_id"
5338:           ],
5339:           "columnsTo": [
5340:             "id"
5341:           ],
5342:           "onDelete": "cascade",
5343:           "onUpdate": "no action"
5344:         },
5345:         "payload_locked_documents_rels_qr_feedback_fk": {
5346:           "name": "payload_locked_documents_rels_qr_feedback_fk",
5347:           "tableFrom": "payload_locked_documents_rels",
5348:           "tableTo": "qr_feedback",
5349:           "columnsFrom": [
5350:             "qr_feedback_id"
5351:           ],
5352:           "columnsTo": [
5353:             "id"
5354:           ],
5355:           "onDelete": "cascade",
5356:           "onUpdate": "no action"
5357:         },
5358:         "payload_locked_documents_rels_questions_fk": {
5359:           "name": "payload_locked_documents_rels_questions_fk",
5360:           "tableFrom": "payload_locked_documents_rels",
5361:           "tableTo": "questions",
5362:           "columnsFrom": [
5363:             "questions_id"
5364:           ],
5365:           "columnsTo": [
5366:             "id"
5367:           ],
5368:           "onDelete": "cascade",
5369:           "onUpdate": "no action"
5370:         },
5371:         "payload_locked_documents_rels_review_keywords_fk": {
5372:           "name": "payload_locked_documents_rels_review_keywords_fk",
5373:           "tableFrom": "payload_locked_documents_rels",
5374:           "tableTo": "review_keywords",
5375:           "columnsFrom": [
5376:             "review_keywords_id"
5377:           ],
5378:           "columnsTo": [
5379:             "id"
5380:           ],
5381:           "onDelete": "cascade",
5382:           "onUpdate": "no action"
5383:         },
5384:         "payload_locked_documents_rels_reviews_fk": {
5385:           "name": "payload_locked_documents_rels_reviews_fk",
5386:           "tableFrom": "payload_locked_documents_rels",
5387:           "tableTo": "reviews",
5388:           "columnsFrom": [
5389:             "reviews_id"
5390:           ],
5391:           "columnsTo": [
5392:             "id"
5393:           ],
5394:           "onDelete": "cascade",
5395:           "onUpdate": "no action"
5396:         },
5397:         "payload_locked_documents_rels_server_reports_fk": {
5398:           "name": "payload_locked_documents_rels_server_reports_fk",
5399:           "tableFrom": "payload_locked_documents_rels",
5400:           "tableTo": "server_reports",
5401:           "columnsFrom": [
5402:             "server_reports_id"
5403:           ],
5404:           "columnsTo": [
5405:             "id"
5406:           ],
5407:           "onDelete": "cascade",
5408:           "onUpdate": "no action"
5409:         },
5410:         "payload_locked_documents_rels_shift_types_fk": {
5411:           "name": "payload_locked_documents_rels_shift_types_fk",
5412:           "tableFrom": "payload_locked_documents_rels",
5413:           "tableTo": "shift_types",
5414:           "columnsFrom": [
5415:             "shift_types_id"
5416:           ],
5417:           "columnsTo": [
5418:             "id"
5419:           ],
5420:           "onDelete": "cascade",
5421:           "onUpdate": "no action"
5422:         },
5423:         "payload_locked_documents_rels_upgrades_fk": {
5424:           "name": "payload_locked_documents_rels_upgrades_fk",
5425:           "tableFrom": "payload_locked_documents_rels",
5426:           "tableTo": "upgrades",
5427:           "columnsFrom": [
5428:             "upgrades_id"
5429:           ],
5430:           "columnsTo": [
5431:             "id"
5432:           ],
5433:           "onDelete": "cascade",
5434:           "onUpdate": "no action"
5435:         },
5436:         "payload_locked_documents_rels_upgrade_types_fk": {
5437:           "name": "payload_locked_documents_rels_upgrade_types_fk",
5438:           "tableFrom": "payload_locked_documents_rels",
5439:           "tableTo": "upgrade_types",
5440:           "columnsFrom": [
5441:             "upgrade_types_id"
5442:           ],
5443:           "columnsTo": [
5444:             "id"
5445:           ],
5446:           "onDelete": "cascade",
5447:           "onUpdate": "no action"
5448:         }
5449:       },
5450:       "compositePrimaryKeys": {},
5451:       "uniqueConstraints": {},
5452:       "policies": {},
5453:       "checkConstraints": {},
5454:       "isRLSEnabled": false
5455:     },
5456:     "public.payload_preferences": {
5457:       "name": "payload_preferences",
5458:       "schema": "",
5459:       "columns": {
5460:         "id": {
5461:           "name": "id",
5462:           "type": "serial",
5463:           "primaryKey": true,
5464:           "notNull": true
5465:         },
5466:         "key": {
5467:           "name": "key",
5468:           "type": "varchar",
5469:           "primaryKey": false,
5470:           "notNull": false
5471:         },
5472:         "value": {
5473:           "name": "value",
5474:           "type": "jsonb",
5475:           "primaryKey": false,
5476:           "notNull": false
5477:         },
5478:         "updated_at": {
5479:           "name": "updated_at",
5480:           "type": "timestamp(3) with time zone",
5481:           "primaryKey": false,
5482:           "notNull": true,
5483:           "default": "now()"
5484:         },
5485:         "created_at": {
5486:           "name": "created_at",
5487:           "type": "timestamp(3) with time zone",
5488:           "primaryKey": false,
5489:           "notNull": true,
5490:           "default": "now()"
5491:         }
5492:       },
5493:       "indexes": {
5494:         "payload_preferences_key_idx": {
5495:           "name": "payload_preferences_key_idx",
5496:           "columns": [
5497:             {
5498:               "expression": "key",
5499:               "isExpression": false,
5500:               "asc": true,
5501:               "nulls": "last"
5502:             }
5503:           ],
5504:           "isUnique": false,
5505:           "concurrently": false,
5506:           "method": "btree",
5507:           "with": {}
5508:         },
5509:         "payload_preferences_updated_at_idx": {
5510:           "name": "payload_preferences_updated_at_idx",
5511:           "columns": [
5512:             {
5513:               "expression": "updated_at",
5514:               "isExpression": false,
5515:               "asc": true,
5516:               "nulls": "last"
5517:             }
5518:           ],
5519:           "isUnique": false,
5520:           "concurrently": false,
5521:           "method": "btree",
5522:           "with": {}
5523:         },
5524:         "payload_preferences_created_at_idx": {
5525:           "name": "payload_preferences_created_at_idx",
5526:           "columns": [
5527:             {
5528:               "expression": "created_at",
5529:               "isExpression": false,
5530:               "asc": true,
5531:               "nulls": "last"
5532:             }
5533:           ],
5534:           "isUnique": false,
5535:           "concurrently": false,
5536:           "method": "btree",
5537:           "with": {}
5538:         }
5539:       },
5540:       "foreignKeys": {},
5541:       "compositePrimaryKeys": {},
5542:       "uniqueConstraints": {},
5543:       "policies": {},
5544:       "checkConstraints": {},
5545:       "isRLSEnabled": false
5546:     },
5547:     "public.payload_preferences_rels": {
5548:       "name": "payload_preferences_rels",
5549:       "schema": "",
5550:       "columns": {
5551:         "id": {
5552:           "name": "id",
5553:           "type": "serial",
5554:           "primaryKey": true,
5555:           "notNull": true
5556:         },
5557:         "order": {
5558:           "name": "order",
5559:           "type": "integer",
5560:           "primaryKey": false,
5561:           "notNull": false
5562:         },
5563:         "parent_id": {
5564:           "name": "parent_id",
5565:           "type": "integer",
5566:           "primaryKey": false,
5567:           "notNull": true
5568:         },
5569:         "path": {
5570:           "name": "path",
5571:           "type": "varchar",
5572:           "primaryKey": false,
5573:           "notNull": true
5574:         },
5575:         "users_id": {
5576:           "name": "users_id",
5577:           "type": "integer",
5578:           "primaryKey": false,
5579:           "notNull": false
5580:         }
5581:       },
5582:       "indexes": {
5583:         "payload_preferences_rels_order_idx": {
5584:           "name": "payload_preferences_rels_order_idx",
5585:           "columns": [
5586:             {
5587:               "expression": "order",
5588:               "isExpression": false,
5589:               "asc": true,
5590:               "nulls": "last"
5591:             }
5592:           ],
5593:           "isUnique": false,
5594:           "concurrently": false,
5595:           "method": "btree",
5596:           "with": {}
5597:         },
5598:         "payload_preferences_rels_parent_idx": {
5599:           "name": "payload_preferences_rels_parent_idx",
5600:           "columns": [
5601:             {
5602:               "expression": "parent_id",
5603:               "isExpression": false,
5604:               "asc": true,
5605:               "nulls": "last"
5606:             }
5607:           ],
5608:           "isUnique": false,
5609:           "concurrently": false,
5610:           "method": "btree",
5611:           "with": {}
5612:         },
5613:         "payload_preferences_rels_path_idx": {
5614:           "name": "payload_preferences_rels_path_idx",
5615:           "columns": [
5616:             {
5617:               "expression": "path",
5618:               "isExpression": false,
5619:               "asc": true,
5620:               "nulls": "last"
5621:             }
5622:           ],
5623:           "isUnique": false,
5624:           "concurrently": false,
5625:           "method": "btree",
5626:           "with": {}
5627:         },
5628:         "payload_preferences_rels_users_id_idx": {
5629:           "name": "payload_preferences_rels_users_id_idx",
5630:           "columns": [
5631:             {
5632:               "expression": "users_id",
5633:               "isExpression": false,
5634:               "asc": true,
5635:               "nulls": "last"
5636:             }
5637:           ],
5638:           "isUnique": false,
5639:           "concurrently": false,
5640:           "method": "btree",
5641:           "with": {}
5642:         }
5643:       },
5644:       "foreignKeys": {
5645:         "payload_preferences_rels_parent_fk": {
5646:           "name": "payload_preferences_rels_parent_fk",
5647:           "tableFrom": "payload_preferences_rels",
5648:           "tableTo": "payload_preferences",
5649:           "columnsFrom": [
5650:             "parent_id"
5651:           ],
5652:           "columnsTo": [
5653:             "id"
5654:           ],
5655:           "onDelete": "cascade",
5656:           "onUpdate": "no action"
5657:         },
5658:         "payload_preferences_rels_users_fk": {
5659:           "name": "payload_preferences_rels_users_fk",
5660:           "tableFrom": "payload_preferences_rels",
5661:           "tableTo": "users",
5662:           "columnsFrom": [
5663:             "users_id"
5664:           ],
5665:           "columnsTo": [
5666:             "id"
5667:           ],
5668:           "onDelete": "cascade",
5669:           "onUpdate": "no action"
5670:         }
5671:       },
5672:       "compositePrimaryKeys": {},
5673:       "uniqueConstraints": {},
5674:       "policies": {},
5675:       "checkConstraints": {},
5676:       "isRLSEnabled": false
5677:     },
5678:     "public.payload_migrations": {
5679:       "name": "payload_migrations",
5680:       "schema": "",
5681:       "columns": {
5682:         "id": {
5683:           "name": "id",
5684:           "type": "serial",
5685:           "primaryKey": true,
5686:           "notNull": true
5687:         },
5688:         "name": {
5689:           "name": "name",
5690:           "type": "varchar",
5691:           "primaryKey": false,
5692:           "notNull": false
5693:         },
5694:         "batch": {
5695:           "name": "batch",
5696:           "type": "numeric",
5697:           "primaryKey": false,
5698:           "notNull": false
5699:         },
5700:         "updated_at": {
5701:           "name": "updated_at",
5702:           "type": "timestamp(3) with time zone",
5703:           "primaryKey": false,
5704:           "notNull": true,
5705:           "default": "now()"
5706:         },
5707:         "created_at": {
5708:           "name": "created_at",
5709:           "type": "timestamp(3) with time zone",
5710:           "primaryKey": false,
5711:           "notNull": true,
5712:           "default": "now()"
5713:         }
5714:       },
5715:       "indexes": {
5716:         "payload_migrations_updated_at_idx": {
5717:           "name": "payload_migrations_updated_at_idx",
5718:           "columns": [
5719:             {
5720:               "expression": "updated_at",
5721:               "isExpression": false,
5722:               "asc": true,
5723:               "nulls": "last"
5724:             }
5725:           ],
5726:           "isUnique": false,
5727:           "concurrently": false,
5728:           "method": "btree",
5729:           "with": {}
5730:         },
5731:         "payload_migrations_created_at_idx": {
5732:           "name": "payload_migrations_created_at_idx",
5733:           "columns": [
5734:             {
5735:               "expression": "created_at",
5736:               "isExpression": false,
5737:               "asc": true,
5738:               "nulls": "last"
5739:             }
5740:           ],
5741:           "isUnique": false,
5742:           "concurrently": false,
5743:           "method": "btree",
5744:           "with": {}
5745:         }
5746:       },
5747:       "foreignKeys": {},
5748:       "compositePrimaryKeys": {},
5749:       "uniqueConstraints": {},
5750:       "policies": {},
5751:       "checkConstraints": {},
5752:       "isRLSEnabled": false
5753:     }
5754:   },
5755:   "enums": {
5756:     "public.enum_users_roles": {
5757:       "name": "enum_users_roles",
5758:       "schema": "public",
5759:       "values": [
5760:         "admin",
5761:         "store_manager",
5762:         "shift_manager",
5763:         "foh_employee",
5764:         "boh_employee",
5765:         "user"
5766:       ]
5767:     },
5768:     "public.enum_users_status": {
5769:       "name": "enum_users_status",
5770:       "schema": "public",
5771:       "values": [
5772:         "active",
5773:         "inactive",
5774:         "on_leave",
5775:         "terminated"
5776:       ]
5777:     },
5778:     "public.enum_users_employment_details_employment_type": {
5779:       "name": "enum_users_employment_details_employment_type",
5780:       "schema": "public",
5781:       "values": [
5782:         "full_time",
5783:         "part_time",
5784:         "seasonal",
5785:         "contract"
5786:       ]
5787:     },
5788:     "public.enum_contacts_contact_type": {
5789:       "name": "enum_contacts_contact_type",
5790:       "schema": "public",
5791:       "values": [
5792:         "customer",
5793:         "vendor",
5794:         "contractor",
5795:         "other"
5796:       ]
5797:     },
5798:     "public.enum_contacts_visit_frequency": {
5799:       "name": "enum_contacts_visit_frequency",
5800:       "schema": "public",
5801:       "values": [
5802:         "first_time",
5803:         "occasional",
5804:         "regular",
5805:         "vip"
5806:       ]
5807:     },
5808:     "public.enum_incidents_status": {
5809:       "name": "enum_incidents_status",
5810:       "schema": "public",
5811:       "values": [
5812:         "open",
5813:         "in_progress",
5814:         "closed"
5815:       ]
5816:     },
5817:     "public.enum_messages_status": {
5818:       "name": "enum_messages_status",
5819:       "schema": "public",
5820:       "values": [
5821:         "new",
5822:         "in_progress",
5823:         "resolved",
5824:         "archived"
5825:       ]
5826:     },
5827:     "public.enum_messages_priority": {
5828:       "name": "enum_messages_priority",
5829:       "schema": "public",
5830:       "values": [
5831:         "low",
5832:         "normal",
5833:         "high",
5834:         "urgent"
5835:       ]
5836:     },
5837:     "public.enum_questions_shift_selection": {
5838:       "name": "enum_questions_shift_selection",
5839:       "schema": "public",
5840:       "values": [
5841:         "bartender",
5842:         "server",
5843:         "foh_support",
5844:         "shift_manager",
5845:         "store_manager"
5846:       ]
5847:     },
5848:     "public.enum_questions_status": {
5849:       "name": "enum_questions_status",
5850:       "schema": "public",
5851:       "values": [
5852:         "active",
5853:         "inactive",
5854:         "archived"
5855:       ]
5856:     },
5857:     "public.enum_questions_shift_timing": {
5858:       "name": "enum_questions_shift_timing",
5859:       "schema": "public",
5860:       "values": [
5861:         "am",
5862:         "pm",
5863:         "any"
5864:       ]
5865:     },
5866:     "public.enum_upgrades_status": {
5867:       "name": "enum_upgrades_status",
5868:       "schema": "public",
5869:       "values": [
5870:         "planned",
5871:         "in_progress",
5872:         "completed",
5873:         "on_hold",
5874:         "cancelled"
5875:       ]
5876:     }
5877:   },
5878:   "schemas": {},
5879:   "sequences": {},
5880:   "roles": {},
5881:   "policies": {},
5882:   "views": {},
5883:   "_meta": {
5884:     "schemas": {},
5885:     "tables": {},
5886:     "columns": {}
5887:   }
5888: }
</file>

<file path="src/migrations/20250702_042115_initial_schema.ts">
  1: import { MigrateUpArgs, MigrateDownArgs, sql } from '@payloadcms/db-vercel-postgres'
  2: 
  3: /**
  4:  * @description Migrates the database schema up.
  5:  * @param {MigrateUpArgs} { db, payload, req }
  6:  * @returns {Promise<void>}
  7:  */
  8: export async function up({ db, payload, req }: MigrateUpArgs): Promise<void> {
  9:   await db.execute(sql`
 10:    CREATE TYPE "public"."enum_users_roles" AS ENUM('admin', 'store_manager', 'shift_manager', 'foh_employee', 'boh_employee', 'user');
 11:   CREATE TYPE "public"."enum_users_status" AS ENUM('active', 'inactive', 'on_leave', 'terminated');
 12:   CREATE TYPE "public"."enum_users_employment_details_employment_type" AS ENUM('full_time', 'part_time', 'seasonal', 'contract');
 13:   CREATE TYPE "public"."enum_contacts_contact_type" AS ENUM('customer', 'vendor', 'contractor', 'other');
 14:   CREATE TYPE "public"."enum_contacts_visit_frequency" AS ENUM('first_time', 'occasional', 'regular', 'vip');
 15:   CREATE TYPE "public"."enum_incidents_status" AS ENUM('open', 'in_progress', 'closed');
 16:   CREATE TYPE "public"."enum_messages_status" AS ENUM('new', 'in_progress', 'resolved', 'archived');
 17:   CREATE TYPE "public"."enum_messages_priority" AS ENUM('low', 'normal', 'high', 'urgent');
 18:   CREATE TYPE "public"."enum_questions_shift_selection" AS ENUM('bartender', 'server', 'foh_support', 'shift_manager', 'store_manager');
 19:   CREATE TYPE "public"."enum_questions_status" AS ENUM('active', 'inactive', 'archived');
 20:   CREATE TYPE "public"."enum_questions_shift_timing" AS ENUM('am', 'pm', 'any');
 21:   CREATE TYPE "public"."enum_upgrades_status" AS ENUM('planned', 'in_progress', 'completed', 'on_hold', 'cancelled');
 22:   CREATE TABLE "users_roles" (
 23:   	"order" integer NOT NULL,
 24:   	"parent_id" integer NOT NULL,
 25:   	"value" "enum_users_roles",
 26:   	"id" serial PRIMARY KEY NOT NULL
 27:   );
 28:   
 29:   CREATE TABLE "users_sessions" (
 30:   	"_order" integer NOT NULL,
 31:   	"_parent_id" integer NOT NULL,
 32:   	"id" varchar PRIMARY KEY NOT NULL,
 33:   	"created_at" timestamp(3) with time zone,
 34:   	"expires_at" timestamp(3) with time zone NOT NULL
 35:   );
 36:   
 37:   CREATE TABLE "users" (
 38:   	"id" serial PRIMARY KEY NOT NULL,
 39:   	"first_name" varchar NOT NULL,
 40:   	"last_name" varchar NOT NULL,
 41:   	"phone" varchar,
 42:   	"employee_id" varchar,
 43:   	"status" "enum_users_status" DEFAULT 'active',
 44:   	"primary_location_id" integer,
 45:   	"employment_details_hire_date" timestamp(3) with time zone,
 46:   	"employment_details_termination_date" timestamp(3) with time zone,
 47:   	"employment_details_employment_type" "enum_users_employment_details_employment_type",
 48:   	"employment_details_hourly_rate" numeric,
 49:   	"profile_photo_id" integer,
 50:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
 51:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
 52:   	"email" varchar NOT NULL,
 53:   	"reset_password_token" varchar,
 54:   	"reset_password_expiration" timestamp(3) with time zone,
 55:   	"salt" varchar,
 56:   	"hash" varchar,
 57:   	"login_attempts" numeric DEFAULT 0,
 58:   	"lock_until" timestamp(3) with time zone
 59:   );
 60:   
 61:   CREATE TABLE "users_rels" (
 62:   	"id" serial PRIMARY KEY NOT NULL,
 63:   	"order" integer,
 64:   	"parent_id" integer NOT NULL,
 65:   	"path" varchar NOT NULL,
 66:   	"locations_id" integer,
 67:   	"jobs_id" integer
 68:   );
 69:   
 70:   CREATE TABLE "media" (
 71:   	"id" serial PRIMARY KEY NOT NULL,
 72:   	"alt" varchar,
 73:   	"caption" varchar,
 74:   	"uploaded_by_id" integer NOT NULL,
 75:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
 76:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
 77:   	"url" varchar,
 78:   	"thumbnail_u_r_l" varchar,
 79:   	"filename" varchar,
 80:   	"mime_type" varchar,
 81:   	"filesize" numeric,
 82:   	"width" numeric,
 83:   	"height" numeric,
 84:   	"focal_x" numeric,
 85:   	"focal_y" numeric,
 86:   	"sizes_thumbnail_url" varchar,
 87:   	"sizes_thumbnail_width" numeric,
 88:   	"sizes_thumbnail_height" numeric,
 89:   	"sizes_thumbnail_mime_type" varchar,
 90:   	"sizes_thumbnail_filesize" numeric,
 91:   	"sizes_thumbnail_filename" varchar,
 92:   	"sizes_card_url" varchar,
 93:   	"sizes_card_width" numeric,
 94:   	"sizes_card_height" numeric,
 95:   	"sizes_card_mime_type" varchar,
 96:   	"sizes_card_filesize" numeric,
 97:   	"sizes_card_filename" varchar,
 98:   	"sizes_tablet_url" varchar,
 99:   	"sizes_tablet_width" numeric,
100:   	"sizes_tablet_height" numeric,
101:   	"sizes_tablet_mime_type" varchar,
102:   	"sizes_tablet_filesize" numeric,
103:   	"sizes_tablet_filename" varchar
104:   );
105:   
106:   CREATE TABLE "contacts" (
107:   	"id" serial PRIMARY KEY NOT NULL,
108:   	"first_name" varchar NOT NULL,
109:   	"last_name" varchar NOT NULL,
110:   	"email" varchar,
111:   	"phone" varchar,
112:   	"company" varchar,
113:   	"contact_type" "enum_contacts_contact_type" DEFAULT 'customer' NOT NULL,
114:   	"toast_id" varchar,
115:   	"brevo_id" varchar,
116:   	"vip_id" numeric,
117:   	"visit_frequency" "enum_contacts_visit_frequency",
118:   	"last_visit" timestamp(3) with time zone,
119:   	"total_visits" numeric DEFAULT 0,
120:   	"average_spend" numeric,
121:   	"preferred_location_id" integer,
122:   	"notes" varchar,
123:   	"marketing_consent" boolean DEFAULT false,
124:   	"birthday" timestamp(3) with time zone,
125:   	"anniversary" timestamp(3) with time zone,
126:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
127:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
128:   );
129:   
130:   CREATE TABLE "contacts_rels" (
131:   	"id" serial PRIMARY KEY NOT NULL,
132:   	"order" integer,
133:   	"parent_id" integer NOT NULL,
134:   	"path" varchar NOT NULL,
135:   	"locations_id" integer,
136:   	"messages_id" integer
137:   );
138:   
139:   CREATE TABLE "dietary_restrictions" (
140:   	"id" serial PRIMARY KEY NOT NULL,
141:   	"name" varchar NOT NULL,
142:   	"description" varchar,
143:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
144:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
145:   );
146:   
147:   CREATE TABLE "drink_menu_items" (
148:   	"id" serial PRIMARY KEY NOT NULL,
149:   	"name" varchar NOT NULL,
150:   	"description" varchar,
151:   	"price" numeric NOT NULL,
152:   	"category_id" integer NOT NULL,
153:   	"active" boolean DEFAULT true,
154:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
155:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
156:   );
157:   
158:   CREATE TABLE "drink_subcategories" (
159:   	"id" serial PRIMARY KEY NOT NULL,
160:   	"name" varchar NOT NULL,
161:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
162:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
163:   );
164:   
165:   CREATE TABLE "employee_ratings" (
166:   	"id" serial PRIMARY KEY NOT NULL,
167:   	"employee_id_id" integer NOT NULL,
168:   	"location_id_id" integer NOT NULL,
169:   	"data_date" timestamp(3) with time zone NOT NULL,
170:   	"rating" numeric NOT NULL,
171:   	"manager_report_id_id" integer,
172:   	"employee_notes" jsonb,
173:   	"internal_notes" varchar,
174:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
175:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
176:   );
177:   
178:   CREATE TABLE "features" (
179:   	"id" serial PRIMARY KEY NOT NULL,
180:   	"name" varchar NOT NULL,
181:   	"enabled" boolean DEFAULT false,
182:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
183:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
184:   );
185:   
186:   CREATE TABLE "hotspot_logins" (
187:   	"id" serial PRIMARY KEY NOT NULL,
188:   	"location_id" integer NOT NULL,
189:   	"customer_name" varchar,
190:   	"customer_email" varchar,
191:   	"marketing_consent" boolean DEFAULT false,
192:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
193:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
194:   );
195:   
196:   CREATE TABLE "incidents" (
197:   	"id" serial PRIMARY KEY NOT NULL,
198:   	"title" varchar NOT NULL,
199:   	"description" varchar,
200:   	"date" timestamp(3) with time zone NOT NULL,
201:   	"location_id" integer NOT NULL,
202:   	"reported_by_id" integer NOT NULL,
203:   	"status" "enum_incidents_status" DEFAULT 'open',
204:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
205:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
206:   );
207:   
208:   CREATE TABLE "jobs" (
209:   	"id" serial PRIMARY KEY NOT NULL,
210:   	"name" varchar NOT NULL,
211:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
212:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
213:   );
214:   
215:   CREATE TABLE "locations" (
216:   	"id" serial PRIMARY KEY NOT NULL,
217:   	"name" varchar NOT NULL,
218:   	"address" varchar NOT NULL,
219:   	"city" varchar NOT NULL,
220:   	"state" varchar NOT NULL,
221:   	"zip" varchar NOT NULL,
222:   	"phone" varchar,
223:   	"email" varchar,
224:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
225:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
226:   );
227:   
228:   CREATE TABLE "manager_reports" (
229:   	"id" serial PRIMARY KEY NOT NULL,
230:   	"title" varchar NOT NULL,
231:   	"date" timestamp(3) with time zone NOT NULL,
232:   	"manager_id" integer NOT NULL,
233:   	"location_id" integer NOT NULL,
234:   	"notes" varchar,
235:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
236:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
237:   );
238:   
239:   CREATE TABLE "messages" (
240:   	"id" serial PRIMARY KEY NOT NULL,
241:   	"status" "enum_messages_status" DEFAULT 'new',
242:   	"priority" "enum_messages_priority" DEFAULT 'normal',
243:   	"subject" varchar NOT NULL,
244:   	"from_name" varchar NOT NULL,
245:   	"from_email" varchar NOT NULL,
246:   	"from_phone" varchar,
247:   	"location_id" integer,
248:   	"message_type_id" integer NOT NULL,
249:   	"message" jsonb NOT NULL,
250:   	"internal_notes" jsonb,
251:   	"assigned_to_id" integer,
252:   	"response_sent" boolean DEFAULT false,
253:   	"response_date" timestamp(3) with time zone,
254:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
255:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
256:   );
257:   
258:   CREATE TABLE "messages_rels" (
259:   	"id" serial PRIMARY KEY NOT NULL,
260:   	"order" integer,
261:   	"parent_id" integer NOT NULL,
262:   	"path" varchar NOT NULL,
263:   	"media_id" integer
264:   );
265:   
266:   CREATE TABLE "message_types" (
267:   	"id" serial PRIMARY KEY NOT NULL,
268:   	"name" varchar NOT NULL,
269:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
270:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
271:   );
272:   
273:   CREATE TABLE "qr_feedback" (
274:   	"id" serial PRIMARY KEY NOT NULL,
275:   	"rating" numeric NOT NULL,
276:   	"comment" varchar,
277:   	"location_id" integer NOT NULL,
278:   	"user_id" integer,
279:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
280:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
281:   );
282:   
283:   CREATE TABLE "questions_shift_selection" (
284:   	"order" integer NOT NULL,
285:   	"parent_id" integer NOT NULL,
286:   	"value" "enum_questions_shift_selection",
287:   	"id" serial PRIMARY KEY NOT NULL
288:   );
289:   
290:   CREATE TABLE "questions" (
291:   	"id" serial PRIMARY KEY NOT NULL,
292:   	"status" "enum_questions_status" DEFAULT 'active',
293:   	"sort" numeric,
294:   	"question" varchar NOT NULL,
295:   	"shift_timing" "enum_questions_shift_timing" DEFAULT 'any',
296:   	"min_characters" numeric,
297:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
298:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
299:   );
300:   
301:   CREATE TABLE "questions_rels" (
302:   	"id" serial PRIMARY KEY NOT NULL,
303:   	"order" integer,
304:   	"parent_id" integer NOT NULL,
305:   	"path" varchar NOT NULL,
306:   	"locations_id" integer
307:   );
308:   
309:   CREATE TABLE "review_keywords" (
310:   	"id" serial PRIMARY KEY NOT NULL,
311:   	"keyword" varchar NOT NULL,
312:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
313:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
314:   );
315:   
316:   CREATE TABLE "reviews" (
317:   	"id" serial PRIMARY KEY NOT NULL,
318:   	"title" varchar NOT NULL,
319:   	"rating" numeric NOT NULL,
320:   	"comment" varchar,
321:   	"user_id" integer NOT NULL,
322:   	"location_id" integer NOT NULL,
323:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
324:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
325:   );
326:   
327:   CREATE TABLE "reviews_rels" (
328:   	"id" serial PRIMARY KEY NOT NULL,
329:   	"order" integer,
330:   	"parent_id" integer NOT NULL,
331:   	"path" varchar NOT NULL,
332:   	"review_keywords_id" integer
333:   );
334:   
335:   CREATE TABLE "server_reports" (
336:   	"id" serial PRIMARY KEY NOT NULL,
337:   	"title" varchar NOT NULL,
338:   	"date" timestamp(3) with time zone NOT NULL,
339:   	"server_id" integer NOT NULL,
340:   	"location_id" integer NOT NULL,
341:   	"notes" varchar,
342:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
343:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
344:   );
345:   
346:   CREATE TABLE "shift_types" (
347:   	"id" serial PRIMARY KEY NOT NULL,
348:   	"name" varchar NOT NULL,
349:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
350:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
351:   );
352:   
353:   CREATE TABLE "upgrades" (
354:   	"id" serial PRIMARY KEY NOT NULL,
355:   	"name" varchar NOT NULL,
356:   	"location_id" integer,
357:   	"upgrade_type_id" integer NOT NULL,
358:   	"status" "enum_upgrades_status" DEFAULT 'planned',
359:   	"description" jsonb,
360:   	"cost" numeric,
361:   	"vendor_id" integer,
362:   	"scheduled_date" timestamp(3) with time zone,
363:   	"completion_date" timestamp(3) with time zone,
364:   	"notes" jsonb,
365:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
366:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
367:   );
368:   
369:   CREATE TABLE "upgrades_rels" (
370:   	"id" serial PRIMARY KEY NOT NULL,
371:   	"order" integer,
372:   	"parent_id" integer NOT NULL,
373:   	"path" varchar NOT NULL,
374:   	"media_id" integer
375:   );
376:   
377:   CREATE TABLE "upgrade_types" (
378:   	"id" serial PRIMARY KEY NOT NULL,
379:   	"name" varchar NOT NULL,
380:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
381:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
382:   );
383:   
384:   CREATE TABLE "payload_locked_documents" (
385:   	"id" serial PRIMARY KEY NOT NULL,
386:   	"global_slug" varchar,
387:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
388:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
389:   );
390:   
391:   CREATE TABLE "payload_locked_documents_rels" (
392:   	"id" serial PRIMARY KEY NOT NULL,
393:   	"order" integer,
394:   	"parent_id" integer NOT NULL,
395:   	"path" varchar NOT NULL,
396:   	"users_id" integer,
397:   	"media_id" integer,
398:   	"contacts_id" integer,
399:   	"dietary_restrictions_id" integer,
400:   	"drink_menu_items_id" integer,
401:   	"drink_subcategories_id" integer,
402:   	"employee_ratings_id" integer,
403:   	"features_id" integer,
404:   	"hotspot_logins_id" integer,
405:   	"incidents_id" integer,
406:   	"jobs_id" integer,
407:   	"locations_id" integer,
408:   	"manager_reports_id" integer,
409:   	"messages_id" integer,
410:   	"message_types_id" integer,
411:   	"qr_feedback_id" integer,
412:   	"questions_id" integer,
413:   	"review_keywords_id" integer,
414:   	"reviews_id" integer,
415:   	"server_reports_id" integer,
416:   	"shift_types_id" integer,
417:   	"upgrades_id" integer,
418:   	"upgrade_types_id" integer
419:   );
420:   
421:   CREATE TABLE "payload_preferences" (
422:   	"id" serial PRIMARY KEY NOT NULL,
423:   	"key" varchar,
424:   	"value" jsonb,
425:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
426:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
427:   );
428:   
429:   CREATE TABLE "payload_preferences_rels" (
430:   	"id" serial PRIMARY KEY NOT NULL,
431:   	"order" integer,
432:   	"parent_id" integer NOT NULL,
433:   	"path" varchar NOT NULL,
434:   	"users_id" integer
435:   );
436:   
437:   CREATE TABLE "payload_migrations" (
438:   	"id" serial PRIMARY KEY NOT NULL,
439:   	"name" varchar,
440:   	"batch" numeric,
441:   	"updated_at" timestamp(3) with time zone DEFAULT now() NOT NULL,
442:   	"created_at" timestamp(3) with time zone DEFAULT now() NOT NULL
443:   );
444:   
445:   ALTER TABLE "users_roles" ADD CONSTRAINT "users_roles_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."users"("id") ON DELETE cascade ON UPDATE no action;
446:   ALTER TABLE "users_sessions" ADD CONSTRAINT "users_sessions_parent_id_fk" FOREIGN KEY ("_parent_id") REFERENCES "public"."users"("id") ON DELETE cascade ON UPDATE no action;
447:   ALTER TABLE "users" ADD CONSTRAINT "users_primary_location_id_locations_id_fk" FOREIGN KEY ("primary_location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
448:   ALTER TABLE "users" ADD CONSTRAINT "users_profile_photo_id_media_id_fk" FOREIGN KEY ("profile_photo_id") REFERENCES "public"."media"("id") ON DELETE set null ON UPDATE no action;
449:   ALTER TABLE "users_rels" ADD CONSTRAINT "users_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."users"("id") ON DELETE cascade ON UPDATE no action;
450:   ALTER TABLE "users_rels" ADD CONSTRAINT "users_rels_locations_fk" FOREIGN KEY ("locations_id") REFERENCES "public"."locations"("id") ON DELETE cascade ON UPDATE no action;
451:   ALTER TABLE "users_rels" ADD CONSTRAINT "users_rels_jobs_fk" FOREIGN KEY ("jobs_id") REFERENCES "public"."jobs"("id") ON DELETE cascade ON UPDATE no action;
452:   ALTER TABLE "media" ADD CONSTRAINT "media_uploaded_by_id_users_id_fk" FOREIGN KEY ("uploaded_by_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
453:   ALTER TABLE "contacts" ADD CONSTRAINT "contacts_preferred_location_id_locations_id_fk" FOREIGN KEY ("preferred_location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
454:   ALTER TABLE "contacts_rels" ADD CONSTRAINT "contacts_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."contacts"("id") ON DELETE cascade ON UPDATE no action;
455:   ALTER TABLE "contacts_rels" ADD CONSTRAINT "contacts_rels_locations_fk" FOREIGN KEY ("locations_id") REFERENCES "public"."locations"("id") ON DELETE cascade ON UPDATE no action;
456:   ALTER TABLE "contacts_rels" ADD CONSTRAINT "contacts_rels_messages_fk" FOREIGN KEY ("messages_id") REFERENCES "public"."messages"("id") ON DELETE cascade ON UPDATE no action;
457:   ALTER TABLE "drink_menu_items" ADD CONSTRAINT "drink_menu_items_category_id_drink_subcategories_id_fk" FOREIGN KEY ("category_id") REFERENCES "public"."drink_subcategories"("id") ON DELETE set null ON UPDATE no action;
458:   ALTER TABLE "employee_ratings" ADD CONSTRAINT "employee_ratings_employee_id_id_users_id_fk" FOREIGN KEY ("employee_id_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
459:   ALTER TABLE "employee_ratings" ADD CONSTRAINT "employee_ratings_location_id_id_locations_id_fk" FOREIGN KEY ("location_id_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
460:   ALTER TABLE "employee_ratings" ADD CONSTRAINT "employee_ratings_manager_report_id_id_manager_reports_id_fk" FOREIGN KEY ("manager_report_id_id") REFERENCES "public"."manager_reports"("id") ON DELETE set null ON UPDATE no action;
461:   ALTER TABLE "hotspot_logins" ADD CONSTRAINT "hotspot_logins_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
462:   ALTER TABLE "incidents" ADD CONSTRAINT "incidents_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
463:   ALTER TABLE "incidents" ADD CONSTRAINT "incidents_reported_by_id_users_id_fk" FOREIGN KEY ("reported_by_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
464:   ALTER TABLE "manager_reports" ADD CONSTRAINT "manager_reports_manager_id_users_id_fk" FOREIGN KEY ("manager_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
465:   ALTER TABLE "manager_reports" ADD CONSTRAINT "manager_reports_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
466:   ALTER TABLE "messages" ADD CONSTRAINT "messages_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
467:   ALTER TABLE "messages" ADD CONSTRAINT "messages_message_type_id_message_types_id_fk" FOREIGN KEY ("message_type_id") REFERENCES "public"."message_types"("id") ON DELETE set null ON UPDATE no action;
468:   ALTER TABLE "messages" ADD CONSTRAINT "messages_assigned_to_id_users_id_fk" FOREIGN KEY ("assigned_to_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
469:   ALTER TABLE "messages_rels" ADD CONSTRAINT "messages_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."messages"("id") ON DELETE cascade ON UPDATE no action;
470:   ALTER TABLE "messages_rels" ADD CONSTRAINT "messages_rels_media_fk" FOREIGN KEY ("media_id") REFERENCES "public"."media"("id") ON DELETE cascade ON UPDATE no action;
471:   ALTER TABLE "qr_feedback" ADD CONSTRAINT "qr_feedback_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
472:   ALTER TABLE "qr_feedback" ADD CONSTRAINT "qr_feedback_user_id_users_id_fk" FOREIGN KEY ("user_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
473:   ALTER TABLE "questions_shift_selection" ADD CONSTRAINT "questions_shift_selection_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."questions"("id") ON DELETE cascade ON UPDATE no action;
474:   ALTER TABLE "questions_rels" ADD CONSTRAINT "questions_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."questions"("id") ON DELETE cascade ON UPDATE no action;
475:   ALTER TABLE "questions_rels" ADD CONSTRAINT "questions_rels_locations_fk" FOREIGN KEY ("locations_id") REFERENCES "public"."locations"("id") ON DELETE cascade ON UPDATE no action;
476:   ALTER TABLE "reviews" ADD CONSTRAINT "reviews_user_id_users_id_fk" FOREIGN KEY ("user_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
477:   ALTER TABLE "reviews" ADD CONSTRAINT "reviews_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
478:   ALTER TABLE "reviews_rels" ADD CONSTRAINT "reviews_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."reviews"("id") ON DELETE cascade ON UPDATE no action;
479:   ALTER TABLE "reviews_rels" ADD CONSTRAINT "reviews_rels_review_keywords_fk" FOREIGN KEY ("review_keywords_id") REFERENCES "public"."review_keywords"("id") ON DELETE cascade ON UPDATE no action;
480:   ALTER TABLE "server_reports" ADD CONSTRAINT "server_reports_server_id_users_id_fk" FOREIGN KEY ("server_id") REFERENCES "public"."users"("id") ON DELETE set null ON UPDATE no action;
481:   ALTER TABLE "server_reports" ADD CONSTRAINT "server_reports_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
482:   ALTER TABLE "upgrades" ADD CONSTRAINT "upgrades_location_id_locations_id_fk" FOREIGN KEY ("location_id") REFERENCES "public"."locations"("id") ON DELETE set null ON UPDATE no action;
483:   ALTER TABLE "upgrades" ADD CONSTRAINT "upgrades_upgrade_type_id_upgrade_types_id_fk" FOREIGN KEY ("upgrade_type_id") REFERENCES "public"."upgrade_types"("id") ON DELETE set null ON UPDATE no action;
484:   ALTER TABLE "upgrades" ADD CONSTRAINT "upgrades_vendor_id_contacts_id_fk" FOREIGN KEY ("vendor_id") REFERENCES "public"."contacts"("id") ON DELETE set null ON UPDATE no action;
485:   ALTER TABLE "upgrades_rels" ADD CONSTRAINT "upgrades_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."upgrades"("id") ON DELETE cascade ON UPDATE no action;
486:   ALTER TABLE "upgrades_rels" ADD CONSTRAINT "upgrades_rels_media_fk" FOREIGN KEY ("media_id") REFERENCES "public"."media"("id") ON DELETE cascade ON UPDATE no action;
487:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."payload_locked_documents"("id") ON DELETE cascade ON UPDATE no action;
488:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_users_fk" FOREIGN KEY ("users_id") REFERENCES "public"."users"("id") ON DELETE cascade ON UPDATE no action;
489:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_media_fk" FOREIGN KEY ("media_id") REFERENCES "public"."media"("id") ON DELETE cascade ON UPDATE no action;
490:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_contacts_fk" FOREIGN KEY ("contacts_id") REFERENCES "public"."contacts"("id") ON DELETE cascade ON UPDATE no action;
491:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_dietary_restrictions_fk" FOREIGN KEY ("dietary_restrictions_id") REFERENCES "public"."dietary_restrictions"("id") ON DELETE cascade ON UPDATE no action;
492:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_drink_menu_items_fk" FOREIGN KEY ("drink_menu_items_id") REFERENCES "public"."drink_menu_items"("id") ON DELETE cascade ON UPDATE no action;
493:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_drink_subcategories_fk" FOREIGN KEY ("drink_subcategories_id") REFERENCES "public"."drink_subcategories"("id") ON DELETE cascade ON UPDATE no action;
494:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_employee_ratings_fk" FOREIGN KEY ("employee_ratings_id") REFERENCES "public"."employee_ratings"("id") ON DELETE cascade ON UPDATE no action;
495:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_features_fk" FOREIGN KEY ("features_id") REFERENCES "public"."features"("id") ON DELETE cascade ON UPDATE no action;
496:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_hotspot_logins_fk" FOREIGN KEY ("hotspot_logins_id") REFERENCES "public"."hotspot_logins"("id") ON DELETE cascade ON UPDATE no action;
497:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_incidents_fk" FOREIGN KEY ("incidents_id") REFERENCES "public"."incidents"("id") ON DELETE cascade ON UPDATE no action;
498:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_jobs_fk" FOREIGN KEY ("jobs_id") REFERENCES "public"."jobs"("id") ON DELETE cascade ON UPDATE no action;
499:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_locations_fk" FOREIGN KEY ("locations_id") REFERENCES "public"."locations"("id") ON DELETE cascade ON UPDATE no action;
500:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_manager_reports_fk" FOREIGN KEY ("manager_reports_id") REFERENCES "public"."manager_reports"("id") ON DELETE cascade ON UPDATE no action;
501:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_messages_fk" FOREIGN KEY ("messages_id") REFERENCES "public"."messages"("id") ON DELETE cascade ON UPDATE no action;
502:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_message_types_fk" FOREIGN KEY ("message_types_id") REFERENCES "public"."message_types"("id") ON DELETE cascade ON UPDATE no action;
503:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_qr_feedback_fk" FOREIGN KEY ("qr_feedback_id") REFERENCES "public"."qr_feedback"("id") ON DELETE cascade ON UPDATE no action;
504:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_questions_fk" FOREIGN KEY ("questions_id") REFERENCES "public"."questions"("id") ON DELETE cascade ON UPDATE no action;
505:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_review_keywords_fk" FOREIGN KEY ("review_keywords_id") REFERENCES "public"."review_keywords"("id") ON DELETE cascade ON UPDATE no action;
506:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_reviews_fk" FOREIGN KEY ("reviews_id") REFERENCES "public"."reviews"("id") ON DELETE cascade ON UPDATE no action;
507:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_server_reports_fk" FOREIGN KEY ("server_reports_id") REFERENCES "public"."server_reports"("id") ON DELETE cascade ON UPDATE no action;
508:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_shift_types_fk" FOREIGN KEY ("shift_types_id") REFERENCES "public"."shift_types"("id") ON DELETE cascade ON UPDATE no action;
509:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_upgrades_fk" FOREIGN KEY ("upgrades_id") REFERENCES "public"."upgrades"("id") ON DELETE cascade ON UPDATE no action;
510:   ALTER TABLE "payload_locked_documents_rels" ADD CONSTRAINT "payload_locked_documents_rels_upgrade_types_fk" FOREIGN KEY ("upgrade_types_id") REFERENCES "public"."upgrade_types"("id") ON DELETE cascade ON UPDATE no action;
511:   ALTER TABLE "payload_preferences_rels" ADD CONSTRAINT "payload_preferences_rels_parent_fk" FOREIGN KEY ("parent_id") REFERENCES "public"."payload_preferences"("id") ON DELETE cascade ON UPDATE no action;
512:   ALTER TABLE "payload_preferences_rels" ADD CONSTRAINT "payload_preferences_rels_users_fk" FOREIGN KEY ("users_id") REFERENCES "public"."users"("id") ON DELETE cascade ON UPDATE no action;
513:   CREATE INDEX "users_roles_order_idx" ON "users_roles" USING btree ("order");
514:   CREATE INDEX "users_roles_parent_idx" ON "users_roles" USING btree ("parent_id");
515:   CREATE INDEX "users_sessions_order_idx" ON "users_sessions" USING btree ("_order");
516:   CREATE INDEX "users_sessions_parent_id_idx" ON "users_sessions" USING btree ("_parent_id");
517:   CREATE UNIQUE INDEX "users_employee_id_idx" ON "users" USING btree ("employee_id");
518:   CREATE INDEX "users_primary_location_idx" ON "users" USING btree ("primary_location_id");
519:   CREATE INDEX "users_profile_photo_idx" ON "users" USING btree ("profile_photo_id");
520:   CREATE INDEX "users_updated_at_idx" ON "users" USING btree ("updated_at");
521:   CREATE INDEX "users_created_at_idx" ON "users" USING btree ("created_at");
522:   CREATE UNIQUE INDEX "users_email_idx" ON "users" USING btree ("email");
523:   CREATE INDEX "users_rels_order_idx" ON "users_rels" USING btree ("order");
524:   CREATE INDEX "users_rels_parent_idx" ON "users_rels" USING btree ("parent_id");
525:   CREATE INDEX "users_rels_path_idx" ON "users_rels" USING btree ("path");
526:   CREATE INDEX "users_rels_locations_id_idx" ON "users_rels" USING btree ("locations_id");
527:   CREATE INDEX "users_rels_jobs_id_idx" ON "users_rels" USING btree ("jobs_id");
528:   CREATE INDEX "media_uploaded_by_idx" ON "media" USING btree ("uploaded_by_id");
529:   CREATE INDEX "media_updated_at_idx" ON "media" USING btree ("updated_at");
530:   CREATE INDEX "media_created_at_idx" ON "media" USING btree ("created_at");
531:   CREATE UNIQUE INDEX "media_filename_idx" ON "media" USING btree ("filename");
532:   CREATE INDEX "media_sizes_thumbnail_sizes_thumbnail_filename_idx" ON "media" USING btree ("sizes_thumbnail_filename");
533:   CREATE INDEX "media_sizes_card_sizes_card_filename_idx" ON "media" USING btree ("sizes_card_filename");
534:   CREATE INDEX "media_sizes_tablet_sizes_tablet_filename_idx" ON "media" USING btree ("sizes_tablet_filename");
535:   CREATE UNIQUE INDEX "contacts_email_idx" ON "contacts" USING btree ("email");
536:   CREATE UNIQUE INDEX "contacts_vip_id_idx" ON "contacts" USING btree ("vip_id");
537:   CREATE INDEX "contacts_preferred_location_idx" ON "contacts" USING btree ("preferred_location_id");
538:   CREATE INDEX "contacts_updated_at_idx" ON "contacts" USING btree ("updated_at");
539:   CREATE INDEX "contacts_created_at_idx" ON "contacts" USING btree ("created_at");
540:   CREATE INDEX "contacts_rels_order_idx" ON "contacts_rels" USING btree ("order");
541:   CREATE INDEX "contacts_rels_parent_idx" ON "contacts_rels" USING btree ("parent_id");
542:   CREATE INDEX "contacts_rels_path_idx" ON "contacts_rels" USING btree ("path");
543:   CREATE INDEX "contacts_rels_locations_id_idx" ON "contacts_rels" USING btree ("locations_id");
544:   CREATE INDEX "contacts_rels_messages_id_idx" ON "contacts_rels" USING btree ("messages_id");
545:   CREATE UNIQUE INDEX "dietary_restrictions_name_idx" ON "dietary_restrictions" USING btree ("name");
546:   CREATE INDEX "dietary_restrictions_updated_at_idx" ON "dietary_restrictions" USING btree ("updated_at");
547:   CREATE INDEX "dietary_restrictions_created_at_idx" ON "dietary_restrictions" USING btree ("created_at");
548:   CREATE INDEX "drink_menu_items_category_idx" ON "drink_menu_items" USING btree ("category_id");
549:   CREATE INDEX "drink_menu_items_updated_at_idx" ON "drink_menu_items" USING btree ("updated_at");
550:   CREATE INDEX "drink_menu_items_created_at_idx" ON "drink_menu_items" USING btree ("created_at");
551:   CREATE UNIQUE INDEX "drink_subcategories_name_idx" ON "drink_subcategories" USING btree ("name");
552:   CREATE INDEX "drink_subcategories_updated_at_idx" ON "drink_subcategories" USING btree ("updated_at");
553:   CREATE INDEX "drink_subcategories_created_at_idx" ON "drink_subcategories" USING btree ("created_at");
554:   CREATE INDEX "employee_ratings_employee_id_idx" ON "employee_ratings" USING btree ("employee_id_id");
555:   CREATE INDEX "employee_ratings_location_id_idx" ON "employee_ratings" USING btree ("location_id_id");
556:   CREATE INDEX "employee_ratings_manager_report_id_idx" ON "employee_ratings" USING btree ("manager_report_id_id");
557:   CREATE INDEX "employee_ratings_updated_at_idx" ON "employee_ratings" USING btree ("updated_at");
558:   CREATE INDEX "employee_ratings_created_at_idx" ON "employee_ratings" USING btree ("created_at");
559:   CREATE UNIQUE INDEX "features_name_idx" ON "features" USING btree ("name");
560:   CREATE INDEX "features_updated_at_idx" ON "features" USING btree ("updated_at");
561:   CREATE INDEX "features_created_at_idx" ON "features" USING btree ("created_at");
562:   CREATE INDEX "hotspot_logins_location_idx" ON "hotspot_logins" USING btree ("location_id");
563:   CREATE INDEX "hotspot_logins_updated_at_idx" ON "hotspot_logins" USING btree ("updated_at");
564:   CREATE INDEX "hotspot_logins_created_at_idx" ON "hotspot_logins" USING btree ("created_at");
565:   CREATE INDEX "incidents_location_idx" ON "incidents" USING btree ("location_id");
566:   CREATE INDEX "incidents_reported_by_idx" ON "incidents" USING btree ("reported_by_id");
567:   CREATE INDEX "incidents_updated_at_idx" ON "incidents" USING btree ("updated_at");
568:   CREATE INDEX "incidents_created_at_idx" ON "incidents" USING btree ("created_at");
569:   CREATE UNIQUE INDEX "jobs_name_idx" ON "jobs" USING btree ("name");
570:   CREATE INDEX "jobs_updated_at_idx" ON "jobs" USING btree ("updated_at");
571:   CREATE INDEX "jobs_created_at_idx" ON "jobs" USING btree ("created_at");
572:   CREATE UNIQUE INDEX "locations_name_idx" ON "locations" USING btree ("name");
573:   CREATE INDEX "locations_updated_at_idx" ON "locations" USING btree ("updated_at");
574:   CREATE INDEX "locations_created_at_idx" ON "locations" USING btree ("created_at");
575:   CREATE INDEX "manager_reports_manager_idx" ON "manager_reports" USING btree ("manager_id");
576:   CREATE INDEX "manager_reports_location_idx" ON "manager_reports" USING btree ("location_id");
577:   CREATE INDEX "manager_reports_updated_at_idx" ON "manager_reports" USING btree ("updated_at");
578:   CREATE INDEX "manager_reports_created_at_idx" ON "manager_reports" USING btree ("created_at");
579:   CREATE INDEX "messages_location_idx" ON "messages" USING btree ("location_id");
580:   CREATE INDEX "messages_message_type_idx" ON "messages" USING btree ("message_type_id");
581:   CREATE INDEX "messages_assigned_to_idx" ON "messages" USING btree ("assigned_to_id");
582:   CREATE INDEX "messages_updated_at_idx" ON "messages" USING btree ("updated_at");
583:   CREATE INDEX "messages_created_at_idx" ON "messages" USING btree ("created_at");
584:   CREATE INDEX "messages_rels_order_idx" ON "messages_rels" USING btree ("order");
585:   CREATE INDEX "messages_rels_parent_idx" ON "messages_rels" USING btree ("parent_id");
586:   CREATE INDEX "messages_rels_path_idx" ON "messages_rels" USING btree ("path");
587:   CREATE INDEX "messages_rels_media_id_idx" ON "messages_rels" USING btree ("media_id");
588:   CREATE UNIQUE INDEX "message_types_name_idx" ON "message_types" USING btree ("name");
589:   CREATE INDEX "message_types_updated_at_idx" ON "message_types" USING btree ("updated_at");
590:   CREATE INDEX "message_types_created_at_idx" ON "message_types" USING btree ("created_at");
591:   CREATE INDEX "qr_feedback_location_idx" ON "qr_feedback" USING btree ("location_id");
592:   CREATE INDEX "qr_feedback_user_idx" ON "qr_feedback" USING btree ("user_id");
593:   CREATE INDEX "qr_feedback_updated_at_idx" ON "qr_feedback" USING btree ("updated_at");
594:   CREATE INDEX "qr_feedback_created_at_idx" ON "qr_feedback" USING btree ("created_at");
595:   CREATE INDEX "questions_shift_selection_order_idx" ON "questions_shift_selection" USING btree ("order");
596:   CREATE INDEX "questions_shift_selection_parent_idx" ON "questions_shift_selection" USING btree ("parent_id");
597:   CREATE INDEX "questions_updated_at_idx" ON "questions" USING btree ("updated_at");
598:   CREATE INDEX "questions_created_at_idx" ON "questions" USING btree ("created_at");
599:   CREATE INDEX "questions_rels_order_idx" ON "questions_rels" USING btree ("order");
600:   CREATE INDEX "questions_rels_parent_idx" ON "questions_rels" USING btree ("parent_id");
601:   CREATE INDEX "questions_rels_path_idx" ON "questions_rels" USING btree ("path");
602:   CREATE INDEX "questions_rels_locations_id_idx" ON "questions_rels" USING btree ("locations_id");
603:   CREATE UNIQUE INDEX "review_keywords_keyword_idx" ON "review_keywords" USING btree ("keyword");
604:   CREATE INDEX "review_keywords_updated_at_idx" ON "review_keywords" USING btree ("updated_at");
605:   CREATE INDEX "review_keywords_created_at_idx" ON "review_keywords" USING btree ("created_at");
606:   CREATE INDEX "reviews_user_idx" ON "reviews" USING btree ("user_id");
607:   CREATE INDEX "reviews_location_idx" ON "reviews" USING btree ("location_id");
608:   CREATE INDEX "reviews_updated_at_idx" ON "reviews" USING btree ("updated_at");
609:   CREATE INDEX "reviews_created_at_idx" ON "reviews" USING btree ("created_at");
610:   CREATE INDEX "reviews_rels_order_idx" ON "reviews_rels" USING btree ("order");
611:   CREATE INDEX "reviews_rels_parent_idx" ON "reviews_rels" USING btree ("parent_id");
612:   CREATE INDEX "reviews_rels_path_idx" ON "reviews_rels" USING btree ("path");
613:   CREATE INDEX "reviews_rels_review_keywords_id_idx" ON "reviews_rels" USING btree ("review_keywords_id");
614:   CREATE INDEX "server_reports_server_idx" ON "server_reports" USING btree ("server_id");
615:   CREATE INDEX "server_reports_location_idx" ON "server_reports" USING btree ("location_id");
616:   CREATE INDEX "server_reports_updated_at_idx" ON "server_reports" USING btree ("updated_at");
617:   CREATE INDEX "server_reports_created_at_idx" ON "server_reports" USING btree ("created_at");
618:   CREATE UNIQUE INDEX "shift_types_name_idx" ON "shift_types" USING btree ("name");
619:   CREATE INDEX "shift_types_updated_at_idx" ON "shift_types" USING btree ("updated_at");
620:   CREATE INDEX "shift_types_created_at_idx" ON "shift_types" USING btree ("created_at");
621:   CREATE INDEX "upgrades_location_idx" ON "upgrades" USING btree ("location_id");
622:   CREATE INDEX "upgrades_upgrade_type_idx" ON "upgrades" USING btree ("upgrade_type_id");
623:   CREATE INDEX "upgrades_vendor_idx" ON "upgrades" USING btree ("vendor_id");
624:   CREATE INDEX "upgrades_updated_at_idx" ON "upgrades" USING btree ("updated_at");
625:   CREATE INDEX "upgrades_created_at_idx" ON "upgrades" USING btree ("created_at");
626:   CREATE INDEX "upgrades_rels_order_idx" ON "upgrades_rels" USING btree ("order");
627:   CREATE INDEX "upgrades_rels_parent_idx" ON "upgrades_rels" USING btree ("parent_id");
628:   CREATE INDEX "upgrades_rels_path_idx" ON "upgrades_rels" USING btree ("path");
629:   CREATE INDEX "upgrades_rels_media_id_idx" ON "upgrades_rels" USING btree ("media_id");
630:   CREATE UNIQUE INDEX "upgrade_types_name_idx" ON "upgrade_types" USING btree ("name");
631:   CREATE INDEX "upgrade_types_updated_at_idx" ON "upgrade_types" USING btree ("updated_at");
632:   CREATE INDEX "upgrade_types_created_at_idx" ON "upgrade_types" USING btree ("created_at");
633:   CREATE INDEX "payload_locked_documents_global_slug_idx" ON "payload_locked_documents" USING btree ("global_slug");
634:   CREATE INDEX "payload_locked_documents_updated_at_idx" ON "payload_locked_documents" USING btree ("updated_at");
635:   CREATE INDEX "payload_locked_documents_created_at_idx" ON "payload_locked_documents" USING btree ("created_at");
636:   CREATE INDEX "payload_locked_documents_rels_order_idx" ON "payload_locked_documents_rels" USING btree ("order");
637:   CREATE INDEX "payload_locked_documents_rels_parent_idx" ON "payload_locked_documents_rels" USING btree ("parent_id");
638:   CREATE INDEX "payload_locked_documents_rels_path_idx" ON "payload_locked_documents_rels" USING btree ("path");
639:   CREATE INDEX "payload_locked_documents_rels_users_id_idx" ON "payload_locked_documents_rels" USING btree ("users_id");
640:   CREATE INDEX "payload_locked_documents_rels_media_id_idx" ON "payload_locked_documents_rels" USING btree ("media_id");
641:   CREATE INDEX "payload_locked_documents_rels_contacts_id_idx" ON "payload_locked_documents_rels" USING btree ("contacts_id");
642:   CREATE INDEX "payload_locked_documents_rels_dietary_restrictions_id_idx" ON "payload_locked_documents_rels" USING btree ("dietary_restrictions_id");
643:   CREATE INDEX "payload_locked_documents_rels_drink_menu_items_id_idx" ON "payload_locked_documents_rels" USING btree ("drink_menu_items_id");
644:   CREATE INDEX "payload_locked_documents_rels_drink_subcategories_id_idx" ON "payload_locked_documents_rels" USING btree ("drink_subcategories_id");
645:   CREATE INDEX "payload_locked_documents_rels_employee_ratings_id_idx" ON "payload_locked_documents_rels" USING btree ("employee_ratings_id");
646:   CREATE INDEX "payload_locked_documents_rels_features_id_idx" ON "payload_locked_documents_rels" USING btree ("features_id");
647:   CREATE INDEX "payload_locked_documents_rels_hotspot_logins_id_idx" ON "payload_locked_documents_rels" USING btree ("hotspot_logins_id");
648:   CREATE INDEX "payload_locked_documents_rels_incidents_id_idx" ON "payload_locked_documents_rels" USING btree ("incidents_id");
649:   CREATE INDEX "payload_locked_documents_rels_jobs_id_idx" ON "payload_locked_documents_rels" USING btree ("jobs_id");
650:   CREATE INDEX "payload_locked_documents_rels_locations_id_idx" ON "payload_locked_documents_rels" USING btree ("locations_id");
651:   CREATE INDEX "payload_locked_documents_rels_manager_reports_id_idx" ON "payload_locked_documents_rels" USING btree ("manager_reports_id");
652:   CREATE INDEX "payload_locked_documents_rels_messages_id_idx" ON "payload_locked_documents_rels" USING btree ("messages_id");
653:   CREATE INDEX "payload_locked_documents_rels_message_types_id_idx" ON "payload_locked_documents_rels" USING btree ("message_types_id");
654:   CREATE INDEX "payload_locked_documents_rels_qr_feedback_id_idx" ON "payload_locked_documents_rels" USING btree ("qr_feedback_id");
655:   CREATE INDEX "payload_locked_documents_rels_questions_id_idx" ON "payload_locked_documents_rels" USING btree ("questions_id");
656:   CREATE INDEX "payload_locked_documents_rels_review_keywords_id_idx" ON "payload_locked_documents_rels" USING btree ("review_keywords_id");
657:   CREATE INDEX "payload_locked_documents_rels_reviews_id_idx" ON "payload_locked_documents_rels" USING btree ("reviews_id");
658:   CREATE INDEX "payload_locked_documents_rels_server_reports_id_idx" ON "payload_locked_documents_rels" USING btree ("server_reports_id");
659:   CREATE INDEX "payload_locked_documents_rels_shift_types_id_idx" ON "payload_locked_documents_rels" USING btree ("shift_types_id");
660:   CREATE INDEX "payload_locked_documents_rels_upgrades_id_idx" ON "payload_locked_documents_rels" USING btree ("upgrades_id");
661:   CREATE INDEX "payload_locked_documents_rels_upgrade_types_id_idx" ON "payload_locked_documents_rels" USING btree ("upgrade_types_id");
662:   CREATE INDEX "payload_preferences_key_idx" ON "payload_preferences" USING btree ("key");
663:   CREATE INDEX "payload_preferences_updated_at_idx" ON "payload_preferences" USING btree ("updated_at");
664:   CREATE INDEX "payload_preferences_created_at_idx" ON "payload_preferences" USING btree ("created_at");
665:   CREATE INDEX "payload_preferences_rels_order_idx" ON "payload_preferences_rels" USING btree ("order");
666:   CREATE INDEX "payload_preferences_rels_parent_idx" ON "payload_preferences_rels" USING btree ("parent_id");
667:   CREATE INDEX "payload_preferences_rels_path_idx" ON "payload_preferences_rels" USING btree ("path");
668:   CREATE INDEX "payload_preferences_rels_users_id_idx" ON "payload_preferences_rels" USING btree ("users_id");
669:   CREATE INDEX "payload_migrations_updated_at_idx" ON "payload_migrations" USING btree ("updated_at");
670:   CREATE INDEX "payload_migrations_created_at_idx" ON "payload_migrations" USING btree ("created_at");`)
671: }
672: 
673: /**
674:  * @description Migrates the database schema down.
675:  * @param {MigrateDownArgs} { db, payload, req }
676:  * @returns {Promise<void>}
677:  */
678: /**
679:  * @description Migrates the database schema down.
680:  * @param {MigrateDownArgs} { db, payload, req }
681:  * @returns {Promise<void>}
682:  */
683: export async function down({ db, payload, req }: MigrateDownArgs): Promise<void> {
684:   await db.execute(sql`
685:    DROP TABLE "users_roles" CASCADE;
686:   DROP TABLE "users_sessions" CASCADE;
687:   DROP TABLE "users" CASCADE;
688:   DROP TABLE "users_rels" CASCADE;
689:   DROP TABLE "media" CASCADE;
690:   DROP TABLE "contacts" CASCADE;
691:   DROP TABLE "contacts_rels" CASCADE;
692:   DROP TABLE "dietary_restrictions" CASCADE;
693:   DROP TABLE "drink_menu_items" CASCADE;
694:   DROP TABLE "drink_subcategories" CASCADE;
695:   DROP TABLE "employee_ratings" CASCADE;
696:   DROP TABLE "features" CASCADE;
697:   DROP TABLE "hotspot_logins" CASCADE;
698:   DROP TABLE "incidents" CASCADE;
699:   DROP TABLE "jobs" CASCADE;
700:   DROP TABLE "locations" CASCADE;
701:   DROP TABLE "manager_reports" CASCADE;
702:   DROP TABLE "messages" CASCADE;
703:   DROP TABLE "messages_rels" CASCADE;
704:   DROP TABLE "message_types" CASCADE;
705:   DROP TABLE "qr_feedback" CASCADE;
706:   DROP TABLE "questions_shift_selection" CASCADE;
707:   DROP TABLE "questions" CASCADE;
708:   DROP TABLE "questions_rels" CASCADE;
709:   DROP TABLE "review_keywords" CASCADE;
710:   DROP TABLE "reviews" CASCADE;
711:   DROP TABLE "reviews_rels" CASCADE;
712:   DROP TABLE "server_reports" CASCADE;
713:   DROP TABLE "shift_types" CASCADE;
714:   DROP TABLE "upgrades" CASCADE;
715:   DROP TABLE "upgrades_rels" CASCADE;
716:   DROP TABLE "upgrade_types" CASCADE;
717:   DROP TABLE "payload_locked_documents" CASCADE;
718:   DROP TABLE "payload_locked_documents_rels" CASCADE;
719:   DROP TABLE "payload_preferences" CASCADE;
720:   DROP TABLE "payload_preferences_rels" CASCADE;
721:   DROP TABLE "payload_migrations" CASCADE;
722:   DROP TYPE "public"."enum_users_roles";
723:   DROP TYPE "public"."enum_users_status";
724:   DROP TYPE "public"."enum_users_employment_details_employment_type";
725:   DROP TYPE "public"."enum_contacts_contact_type";
726:   DROP TYPE "public"."enum_contacts_visit_frequency";
727:   DROP TYPE "public"."enum_incidents_status";
728:   DROP TYPE "public"."enum_messages_status";
729:   DROP TYPE "public"."enum_messages_priority";
730:   DROP TYPE "public"."enum_questions_shift_selection";
731:   DROP TYPE "public"."enum_questions_status";
732:   DROP TYPE "public"."enum_questions_shift_timing";
733:   DROP TYPE "public"."enum_upgrades_status";`)
734: }
</file>

<file path="src/migrations/index.ts">
1: import * as migration_20250702_042115_initial_schema from './20250702_042115_initial_schema';
2: 
3: export const migrations = [
4:   {
5:     up: migration_20250702_042115_initial_schema.up,
6:     down: migration_20250702_042115_initial_schema.down,
7:     name: '20250702_042115_initial_schema'
8:   },
9: ];
</file>

<file path="src/schemas/loginSchema.ts">
1: import { z } from 'zod';
2: 
3: export const loginSchema = z.object({
4:   email: z.string().email('Invalid email address'),
5:   password: z.string().min(1, 'Password is required'),
6: });
7: 
8: export type LoginSchema = z.infer<typeof loginSchema>;
</file>

<file path="src/schemas/registerSchema.ts">
 1: import { z } from 'zod';
 2: 
 3: export const registerSchema = z.object({
 4:   first_name: z.string().min(1, 'First name is required'),
 5:   last_name: z.string().min(1, 'Last name is required'),
 6:   email: z.string().email('Invalid email address'),
 7:   password: z.string().min(8, 'Password must be at least 8 characters'),
 8: });
 9: 
10: export type RegisterSchema = z.infer<typeof registerSchema>;
</file>

<file path="src/types/auth.ts">
 1: /**
 2:  * @description Represents a user in the restaurant management system.
 3:  */
 4: export interface RestaurantUser {
 5:   id: string
 6:   email: string
 7:   first_name?: string
 8:   last_name?: string
 9:   phone?: string
10:   employee_id?: string
11:   roles?: string[]
12:   status?: 'active' | 'inactive' | 'on_leave' | 'terminated'
13:   locations?: string[] | any[]
14:   primary_location?: string | any
15:   employment_details?: {
16:     hire_date?: string
17:     termination_date?: string
18:     employment_type?: 'full_time' | 'part_time' | 'seasonal' | 'contract'
19:     hourly_rate?: number
20:   }
21:   profile_photo?: string | any
22:   jobs?: string[] | any[]
23:   collection: 'users'
24:   createdAt: string
25:   updatedAt: string
26: }
27: 
28: /**
29:  * @description Defines the possible roles a user can have.
30:  */
31: export type UserRole = 'admin' | 'store_manager' | 'shift_manager' | 'foh_employee' | 'boh_employee' | 'user'
32: /**
33:  * @description Defines the possible statuses for a user.
34:  */
35: export type UserStatus = 'active' | 'inactive' | 'on_leave' | 'terminated'
36: /**
37:  * @description Defines the possible employment types for a user.
38:  */
39: export type EmploymentType = 'full_time' | 'part_time' | 'seasonal' | 'contract'
</file>

<file path="src/types/restaurant.ts">
  1: /**
  2:  * Restaurant Management System - Core Type Definitions
  3:  * Defines TypeScript interfaces for restaurant operations, employee management, and ratings
  4:  */
  5: 
  6: // Base types for all entities
  7: /**
  8:  * @description Base interface for all entities with common fields.
  9:  */
 10: export interface BaseEntity {
 11:   id: string
 12:   createdAt: string
 13:   updatedAt: string
 14: }
 15: 
 16: // User and Authentication Types
 17: /**
 18:  * @description Represents a user in the system.
 19:  */
 20: export interface User extends BaseEntity {
 21:   email: string
 22:   firstName: string
 23:   lastName: string
 24:   role: UserRole
 25:   isActive: boolean
 26:   lastLogin?: string
 27:   profileImage?: string
 28: }
 29: 
 30: /**
 31:  * @description Defines the possible roles a user can have.
 32:  */
 33: export type UserRole = 'admin' | 'manager' | 'employee'
 34: 
 35: /**
 36:  * @description Represents an authentication session.
 37:  */
 38: export interface AuthSession {
 39:   user: User
 40:   token: string
 41:   expiresAt: string
 42: }
 43: 
 44: // Employee Management Types
 45: /**
 46:  * @description Represents an employee in the system.
 47:  */
 48: export interface Employee extends BaseEntity {
 49:   userId: string
 50:   employeeId: string
 51:   position: string
 52:   department: string
 53:   hireDate: string
 54:   hourlyRate?: number
 55:   isActive: boolean
 56:   emergencyContact?: EmergencyContact
 57:   schedule?: WorkSchedule[]
 58: }
 59: 
 60: /**
 61:  * @description Represents an emergency contact for an employee.
 62:  */
 63: export interface EmergencyContact {
 64:   name: string
 65:   relationship: string
 66:   phone: string
 67:   email?: string
 68: }
 69: 
 70: /**
 71:  * @description Represents a work schedule for an employee.
 72:  */
 73: export interface WorkSchedule {
 74:   dayOfWeek: number // 0-6 (Sunday-Saturday)
 75:   startTime: string // HH:MM format
 76:   endTime: string // HH:MM format
 77:   isActive: boolean
 78: }
 79: 
 80: // Rating and Performance Types
 81: /**
 82:  * @description Represents an employee performance rating.
 83:  */
 84: export interface EmployeeRating extends BaseEntity {
 85:   employeeId: string
 86:   raterId: string // Manager or admin who gave the rating
 87:   ratingPeriod: RatingPeriod
 88:   overallScore: number // 1-10 scale
 89:   categories: RatingCategory[]
 90:   comments?: string
 91:   improvementAreas?: string[]
 92:   strengths?: string[]
 93:   goals?: string[]
 94: }
 95: 
 96: /**
 97:  * @description Defines the period for a rating.
 98:  */
 99: export interface RatingPeriod {
100:   startDate: string
101:   endDate: string
102:   type: 'weekly' | 'monthly' | 'quarterly' | 'annual'
103: }
104: 
105: /**
106:  * @description Represents a category within a rating.
107:  */
108: export interface RatingCategory {
109:   name: string
110:   score: number // 1-10 scale
111:   weight: number // Percentage weight in overall score
112:   comments?: string
113: }
114: 
115: /**
116:  * @description Standard rating categories for restaurant employees.
117:  */
118: export const RATING_CATEGORIES = {
119:   CUSTOMER_SERVICE: 'Customer Service',
120:   TEAMWORK: 'Teamwork & Collaboration',
121:   PUNCTUALITY: 'Punctuality & Attendance',
122:   FOOD_SAFETY: 'Food Safety & Hygiene',
123:   EFFICIENCY: 'Work Efficiency',
124:   COMMUNICATION: 'Communication Skills',
125:   LEADERSHIP: 'Leadership (if applicable)',
126:   PROBLEM_SOLVING: 'Problem Solving',
127:   ADAPTABILITY: 'Adaptability',
128:   INITIATIVE: 'Initiative & Proactivity'
129: } as const
130: 
131: // Report Types
132: /**
133:  * @description Represents a manager's report.
134:  */
135: export interface ManagerReport extends BaseEntity {
136:   managerId: string
137:   reportType: ReportType
138:   period: RatingPeriod
139:   summary: string
140:   metrics: ReportMetric[]
141:   recommendations?: string[]
142:   attachments?: string[]
143: }
144: 
145: /**
146:  * @description Defines the types of reports.
147:  */
148: export type ReportType = 
149:   | 'performance_summary'
150:   | 'team_analysis'
151:   | 'improvement_plan'
152:   | 'incident_report'
153:   | 'training_needs'
154: 
155: /**
156:  * @description Represents a metric within a report.
157:  */
158: export interface ReportMetric {
159:   name: string
160:   value: number
161:   unit: string
162:   trend?: 'up' | 'down' | 'stable'
163:   comparison?: {
164:     period: string
165:     value: number
166:   }
167: }
168: 
169: // Location and Restaurant Types
170: /**
171:  * @description Represents a physical location of the business.
172:  */
173: export interface Location extends BaseEntity {
174:   name: string
175:   address: string
176:   city: string
177:   state: string
178:   zipCode: string
179:   phone: string
180:   email?: string
181:   managerId?: string
182:   isActive: boolean
183:   operatingHours: OperatingHours[]
184: }
185: 
186: /**
187:  * @description Represents the operating hours for a location.
188:  */
189: export interface OperatingHours {
190:   dayOfWeek: number
191:   openTime: string
192:   closeTime: string
193:   isClosed: boolean
194: }
195: 
196: // API Response Types
197: /**
198:  * @description Represents a generic API response.
199:  * @template T
200:  */
201: export interface ApiResponse<T = any> {
202:   success: boolean
203:   data?: T
204:   error?: string
205:   message?: string
206:   pagination?: {
207:     page: number
208:     limit: number
209:     total: number
210:     totalPages: number
211:   }
212: }
213: 
214: /**
215:  * @description Defines parameters for pagination.
216:  */
217: export interface PaginationParams {
218:   page?: number
219:   limit?: number
220:   sortBy?: string
221:   sortOrder?: 'asc' | 'desc'
222:   search?: string
223: }
224: 
225: // Form and Validation Types
226: /**
227:  * @description Represents a validation error for a form field.
228:  */
229: export interface ValidationError {
230:   field: string
231:   message: string
232:   code?: string
233: }
234: 
235: /**
236:  * @description Represents the state of a form.
237:  * @template T
238:  */
239: export interface FormState<T = any> {
240:   data: T
241:   errors: ValidationError[]
242:   isSubmitting: boolean
243:   isValid: boolean
244: }
245: 
246: // Notification and Alert Types
247: /**
248:  * @description Represents a notification or alert.
249:  */
250: export interface Notification extends BaseEntity {
251:   userId: string
252:   title: string
253:   message: string
254:   type: NotificationType
255:   isRead: boolean
256:   actionUrl?: string
257:   metadata?: Record<string, any>
258: }
259: 
260: /**
261:  * @description Defines the types of notifications.
262:  */
263: export type NotificationType = 
264:   | 'rating_received'
265:   | 'schedule_change'
266:   | 'performance_alert'
267:   | 'system_update'
268:   | 'reminder'
269: 
270: // Dashboard and Analytics Types
271: /**
272:  * @description Represents dashboard metrics.
273:  */
274: export interface DashboardMetrics {
275:   totalEmployees: number
276:   activeEmployees: number
277:   averageRating: number
278:   ratingsTrendData: TrendDataPoint[]
279:   topPerformers: Employee[]
280:   improvementNeeded: Employee[]
281:   recentRatings: EmployeeRating[]
282: }
283: 
284: /**
285:  * @description Represents a data point for trend analysis.
286:  */
287: export interface TrendDataPoint {
288:   date: string
289:   value: number
290:   label?: string
291: }
292: 
293: // Export utility type for Payload CMS collections
294: /**
295:  * @description Utility type for Payload CMS collections.
296:  * @template T
297:  */
298: export type PayloadCollection<T> = T & {
299:   id: string
300:   createdAt: string
301:   updatedAt: string
302: }
</file>

<file path="src/utils/index.ts">
  1: /**
  2:  * Restaurant Management System - Utility Functions
  3:  * Common utilities for data formatting, validation, and calculations
  4:  */
  5: 
  6: import { type ClassValue, clsx } from 'clsx'
  7: import { twMerge } from 'tailwind-merge'
  8: import { EmployeeRating, RatingCategory, User, UserRole } from '@/types/restaurant'
  9: 
 10: // Tailwind CSS class merging utility
 11: /**
 12:  * @description Combines Tailwind CSS classes and other class values into a single string.
 13:  * @param {ClassValue[]} inputs
 14:  * @returns {string}
 15:  */
 16: export function cn(...inputs: ClassValue[]) {
 17:   return twMerge(clsx(inputs))
 18: }
 19: 
 20: // Date and Time Utilities
 21: export const dateUtils = {
 22:   /**
 23:    * @description Format date to readable string
 24:    * @param {string | Date} date
 25:    * @param {Intl.DateTimeFormatOptions} [options]
 26:    * @returns {string}
 27:    */
 28:   formatDate: (date: string | Date, options?: Intl.DateTimeFormatOptions): string => {
 29:     const dateObj = typeof date === 'string' ? new Date(date) : date
 30:     return dateObj.toLocaleDateString('en-US', {
 31:       year: 'numeric',
 32:       month: 'short',
 33:       day: 'numeric',
 34:       ...options
 35:     })
 36:   },
 37: 
 38:   /**
 39:    * @description Format time to readable string
 40:    * @param {string} time
 41:    * @returns {string}
 42:    */
 43:   formatTime: (time: string): string => {
 44:     const [hours, minutes] = time.split(':')
 45:     const hour = parseInt(hours)
 46:     const ampm = hour >= 12 ? 'PM' : 'AM'
 47:     const displayHour = hour % 12 || 12
 48:     return `${displayHour}:${minutes} ${ampm}`
 49:   },
 50: 
 51:   /**
 52:    * @description Get relative time (e.g., "2 hours ago")
 53:    * @param {string | Date} date
 54:    * @returns {string}
 55:    */
 56:   getRelativeTime: (date: string | Date): string => {
 57:     const now = new Date()
 58:     const dateObj = typeof date === 'string' ? new Date(date) : date
 59:     const diffMs = now.getTime() - dateObj.getTime()
 60:     const diffMins = Math.floor(diffMs / (1000 * 60))
 61:     const diffHours = Math.floor(diffMins / 60)
 62:     const diffDays = Math.floor(diffHours / 24)
 63: 
 64:     if (diffMins < 1) return 'Just now'
 65:     if (diffMins < 60) return `${diffMins} minute${diffMins > 1 ? 's' : ''} ago`
 66:     if (diffHours < 24) return `${diffHours} hour${diffHours > 1 ? 's' : ''} ago`
 67:     if (diffDays < 7) return `${diffDays} day${diffDays > 1 ? 's' : ''} ago`
 68:     
 69:     return dateUtils.formatDate(dateObj)
 70:   },
 71: 
 72:   /**
 73:    * @description Check if date is within the last N days
 74:    * @param {string | Date} date
 75:    * @param {number} days
 76:    * @returns {boolean}
 77:    */
 78:   isWithinDays: (date: string | Date, days: number): boolean => {
 79:     const dateObj = typeof date === 'string' ? new Date(date) : date
 80:     const now = new Date()
 81:     const diffMs = now.getTime() - dateObj.getTime()
 82:     const diffDays = diffMs / (1000 * 60 * 60 * 24)
 83:     return diffDays <= days
 84:   }
 85: }
 86: 
 87: // Rating and Performance Utilities
 88: export const ratingUtils = {
 89:   /**
 90:    * @description Calculate weighted overall score from rating categories
 91:    * @param {RatingCategory[]} categories
 92:    * @returns {number}
 93:    */
 94:   calculateOverallScore: (categories: RatingCategory[]): number => {
 95:     if (!categories.length) return 0
 96:     
 97:     const totalWeight = categories.reduce((sum, cat) => sum + cat.weight, 0)
 98:     if (totalWeight === 0) return 0
 99:     
100:     const weightedSum = categories.reduce((sum, cat) => {
101:       return sum + (cat.score * cat.weight)
102:     }, 0)
103:     
104:     return Math.round((weightedSum / totalWeight) * 100) / 100
105:   },
106: 
107:   /**
108:    * @description Get rating level description
109:    * @param {number} score
110:    * @returns {{ level: string; color: string; description: string }}
111:    */
112:   getRatingLevel: (score: number): { level: string; color: string; description: string } => {
113:     if (score >= 9) return { 
114:       level: 'Exceptional', 
115:       color: 'green', 
116:       description: 'Outstanding performance' 
117:     }
118:     if (score >= 8) return { 
119:       level: 'Excellent', 
120:       color: 'blue', 
121:       description: 'Exceeds expectations' 
122:     }
123:     if (score >= 7) return { 
124:       level: 'Good', 
125:       color: 'teal', 
126:       description: 'Meets expectations' 
127:     }
128:     if (score >= 6) return { 
129:       level: 'Satisfactory', 
130:       color: 'yellow', 
131:       description: 'Acceptable performance' 
132:     }
133:     if (score >= 4) return { 
134:       level: 'Needs Improvement', 
135:       color: 'orange', 
136:       description: 'Below expectations' 
137:     }
138:     return { 
139:       level: 'Unsatisfactory', 
140:       color: 'red', 
141:       description: 'Significant improvement needed' 
142:     }
143:   },
144: 
145:   /**
146:    * @description Calculate average rating for an employee
147:    * @param {EmployeeRating[]} ratings
148:    * @returns {number}
149:    */
150:   calculateAverageRating: (ratings: EmployeeRating[]): number => {
151:     if (!ratings.length) return 0
152:     const sum = ratings.reduce((total, rating) => total + rating.overallScore, 0)
153:     return Math.round((sum / ratings.length) * 100) / 100
154:   },
155: 
156:   /**
157:    * @description Get rating trend (improving, declining, stable)
158:    * @param {EmployeeRating[]} ratings
159:    * @returns {'improving' | 'declining' | 'stable'}
160:    */
161:   getRatingTrend: (ratings: EmployeeRating[]): 'improving' | 'declining' | 'stable' => {
162:     if (ratings.length < 2) return 'stable'
163:     
164:     const sortedRatings = [...ratings].sort((a, b) => 
165:       new Date(a.createdAt).getTime() - new Date(b.createdAt).getTime()
166:     )
167:     
168:     const recent = sortedRatings.slice(-3)
169:     const older = sortedRatings.slice(-6, -3)
170:     
171:     if (recent.length < 2) return 'stable'
172:     
173:     const recentAvg = recent.reduce((sum, r) => sum + r.overallScore, 0) / recent.length
174:     const olderAvg = older.length > 0 
175:       ? older.reduce((sum, r) => sum + r.overallScore, 0) / older.length 
176:       : recentAvg
177:     
178:     const difference = recentAvg - olderAvg
179:     
180:     if (difference > 0.5) return 'improving'
181:     if (difference < -0.5) return 'declining'
182:     return 'stable'
183:   }
184: }
185: 
186: // User and Permission Utilities
187: export const userUtils = {
188:   /**
189:    * @description Get user's full name
190:    * @param {User} user
191:    * @returns {string}
192:    */
193:   getFullName: (user: User): string => {
194:     return `${user.firstName} ${user.lastName}`.trim()
195:   },
196: 
197:   /**
198:    * @description Get user's initials
199:    * @param {User} user
200:    * @returns {string}
201:    */
202:   getInitials: (user: User): string => {
203:     const first = user.firstName?.charAt(0) || ''
204:     const last = user.lastName?.charAt(0) || ''
205:     return (first + last).toUpperCase()
206:   },
207: 
208:   /**
209:    * @description Check if user has permission for action
210:    * @param {UserRole} userRole
211:    * @param {UserRole} requiredRole
212:    * @returns {boolean}
213:    */
214:   hasPermission: (userRole: UserRole, requiredRole: UserRole): boolean => {
215:     const roleHierarchy: Record<UserRole, number> = {
216:       employee: 1,
217:       manager: 2,
218:       admin: 3
219:     }
220:     
221:     return roleHierarchy[userRole] >= roleHierarchy[requiredRole]
222:   },
223: 
224:   /**
225:    * @description Check if user can rate another user
226:    * @param {UserRole} raterRole
227:    * @param {UserRole} targetRole
228:    * @returns {boolean}
229:    */
230:   canRateEmployee: (raterRole: UserRole, targetRole: UserRole): boolean => {
231:     // Admins can rate anyone, managers can rate employees, employees cannot rate
232:     if (raterRole === 'admin') return true
233:     if (raterRole === 'manager' && targetRole === 'employee') return true
234:     return false
235:   }
236: }
237: 
238: // Data Formatting Utilities
239: export const formatUtils = {
240:   /**
241:    * @description Format currency
242:    * @param {number} amount
243:    * @returns {string}
244:    */
245:   currency: (amount: number): string => {
246:     return new Intl.NumberFormat('en-US', {
247:       style: 'currency',
248:       currency: 'USD'
249:     }).format(amount)
250:   },
251: 
252:   /**
253:    * @description Format percentage
254:    * @param {number} value
255:    * @param {number} [decimals=1]
256:    * @returns {string}
257:    */
258:   percentage: (value: number, decimals: number = 1): string => {
259:     return `${value.toFixed(decimals)}%`
260:   },
261: 
262:   /**
263:    * @description Format phone number
264:    * @param {string} phone
265:    * @returns {string}
266:    */
267:   phone: (phone: string): string => {
268:     const cleaned = phone.replace(/\D/g, '')
269:     if (cleaned.length === 10) {
270:       return `(${cleaned.slice(0, 3)}) ${cleaned.slice(3, 6)}-${cleaned.slice(6)}`
271:     }
272:     return phone
273:   },
274: 
275:   /**
276:    * @description Truncate text with ellipsis
277:    * @param {string} text
278:    * @param {number} maxLength
279:    * @returns {string}
280:    */
281:   truncate: (text: string, maxLength: number): string => {
282:     if (text.length <= maxLength) return text
283:     return text.slice(0, maxLength - 3) + '...'
284:   },
285: 
286:   /**
287:    * @description Capitalize first letter of each word
288:    * @param {string} text
289:    * @returns {string}
290:    */
291:   titleCase: (text: string): string => {
292:     return text.replace(/\w\S*/g, (txt) => 
293:       txt.charAt(0).toUpperCase() + txt.substr(1).toLowerCase()
294:     )
295:   }
296: }
297: 
298: // Validation Utilities
299: export const validationUtils = {
300:   /**
301:    * @description Validate email format
302:    * @param {string} email
303:    * @returns {boolean}
304:    */
305:   isValidEmail: (email: string): boolean => {
306:     const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/
307:     return emailRegex.test(email)
308:   },
309: 
310:   /**
311:    * @description Validate phone number
312:    * @param {string} phone
313:    * @returns {boolean}
314:    */
315:   isValidPhone: (phone: string): boolean => {
316:     const phoneRegex = /^\(?([0-9]{3})\)?[-. ]?([0-9]{3})[-. ]?([0-9]{4})$/
317:     return phoneRegex.test(phone)
318:   },
319: 
320:   /**
321:    * @description Validate rating score (1-10)
322:    * @param {number} score
323:    * @returns {boolean}
324:    */
325:   isValidRating: (score: number): boolean => {
326:     return score >= 1 && score <= 10 && Number.isInteger(score * 10)
327:   },
328: 
329:   /**
330:    * @description Check if string is not empty
331:    * @param {string} value
332:    * @returns {boolean}
333:    */
334:   isNotEmpty: (value: string): boolean => {
335:     return value.trim().length > 0
336:   }
337: }
338: 
339: // Array and Object Utilities
340: export const arrayUtils = {
341:   /**
342:    * @description Group array by key
343:    * @template T
344:    * @param {T[]} array
345:    * @param {keyof T} key
346:    * @returns {Record<string, T[]>}
347:    */
348:   groupBy: <T>(array: T[], key: keyof T): Record<string, T[]> => {
349:     return array.reduce((groups, item) => {
350:       const groupKey = String(item[key])
351:       if (!groups[groupKey]) {
352:         groups[groupKey] = []
353:       }
354:       groups[groupKey].push(item)
355:       return groups
356:     }, {} as Record<string, T[]>)
357:   },
358: 
359:   /**
360:    * @description Sort array by multiple criteria
361:    * @template T
362:    * @param {T[]} array
363:    * @param {(keyof T | ((item: T) => any))[]} criteria
364:    * @returns {T[]}
365:    */
366:   sortBy: <T>(array: T[], ...criteria: Array<keyof T | ((item: T) => any)>): T[] => {
367:     return [...array].sort((a, b) => {
368:       for (const criterion of criteria) {
369:         let aVal, bVal
370:         
371:         if (typeof criterion === 'function') {
372:           aVal = criterion(a)
373:           bVal = criterion(b)
374:         } else {
375:           aVal = a[criterion]
376:           bVal = b[criterion]
377:         }
378:         
379:         if (aVal < bVal) return -1
380:         if (aVal > bVal) return 1
381:       }
382:       return 0
383:     })
384:   },
385: 
386:   /**
387:    * @description Remove duplicates from array
388:    * @template T
389:    * @param {T[]} array
390:    * @param {keyof T} [key]
391:    * @returns {T[]}
392:    */
393:   unique: <T>(array: T[], key?: keyof T): T[] => {
394:     if (!key) {
395:       return [...new Set(array)]
396:     }
397:     
398:     const seen = new Set()
399:     return array.filter(item => {
400:       const value = item[key]
401:       if (seen.has(value)) {
402:         return false
403:       }
404:       seen.add(value)
405:       return true
406:     })
407:   }
408: }
409: 
410: // Error Handling Utilities
411: export const errorUtils = {
412:   /**
413:    * @description Extract error message from various error types
414:    * @param {unknown} error
415:    * @returns {string}
416:    */
417:   getErrorMessage: (error: unknown): string => {
418:     if (error instanceof Error) {
419:       return error.message
420:     }
421:     if (typeof error === 'string') {
422:       return error
423:     }
424:     if (error && typeof error === 'object' && 'message' in error) {
425:       return String(error.message)
426:     }
427:     return 'An unexpected error occurred'
428:   },
429: 
430:   /**
431:    * @description Check if error is a network error
432:    * @param {unknown} error
433:    * @returns {boolean}
434:    */
435:   isNetworkError: (error: unknown): boolean => {
436:     const message = errorUtils.getErrorMessage(error).toLowerCase()
437:     return message.includes('network') || 
438:            message.includes('fetch') || 
439:            message.includes('connection')
440:   }
441: }
442: 
443: // All utilities are already exported above
</file>

<file path="tests/e2e/frontend.e2e.spec.ts">
 1: import { test, expect, Page } from '@playwright/test'
 2: 
 3: test.describe('Frontend', () => {
 4:   let page: Page
 5: 
 6:   test.beforeAll(async ({ browser }, testInfo) => {
 7:     const context = await browser.newContext()
 8:     page = await context.newPage()
 9:   })
10: 
11:   test('can go on homepage', async ({ page }) => {
12:     await page.goto('http://localhost:3000')
13: 
14:     await expect(page).toHaveTitle(/Payload Blank Template/)
15: 
16:     const headging = page.locator('h1').first()
17: 
18:     await expect(headging).toHaveText('Welcome to your new project.')
19:   })
20: })
</file>

<file path="tests/int/DynamicFormBuilder.int.spec.tsx">
 1: import React from 'react';
 2: import { render, screen, fireEvent } from '@testing-library/react';
 3: import { describe, it, expect } from 'vitest';
 4: import { useForm, FormProvider } from 'react-hook-form';
 5: import { z } from 'zod';
 6: import { zodResolver } from '@hookform/resolvers/zod';
 7: 
 8: // Mock a simple dynamic field component for testing
 9: const TextField = ({ name, label }: { name: string; label: string }) => {
10:   const { register, formState: { errors } } = useForm();
11:   return (
12:     <div>
13:       <label htmlFor={name}>{label}</label>
14:       <input id={name} {...register(name)} />
15:       {errors[name] && <span role="alert">{errors[name]?.message as string}</span>}
16:     </div>
17:   );
18: };
19: 
20: // Mock a simple DynamicFormBuilder component
21: const DynamicFormBuilder = ({ schema, fieldsConfig }: { schema: z.ZodObject<any>; fieldsConfig: Array<{ name: string; label: string; type: string }> }) => {
22:   const methods = useForm({
23:     resolver: zodResolver(schema),
24:   });
25: 
26:   return (
27:     <FormProvider {...methods}>
28:       <form>
29:         {fieldsConfig.map((field) => {
30:           if (field.type === 'text') {
31:             return <TextField key={field.name} name={field.name} label={field.label} />;
32:           }
33:           return null;
34:         })}
35:         <button type="submit">Submit</button>
36:       </form>
37:     </FormProvider>
38:   );
39: };
40: 
41: describe('DynamicFormBuilder', () => {
42:   it('renders fields based on configuration', () => {
43:     const testSchema = z.object({
44:       firstName: z.string().min(1, 'First name is required'),
45:     });
46:     const fields = [{ name: 'firstName', label: 'First Name', type: 'text' }];
47: 
48:     render(<DynamicFormBuilder schema={testSchema} fieldsConfig={fields} />);
49: 
50:     expect(screen.getByLabelText(/first name/i)).toBeInTheDocument();
51:   });
52: 
53:   it('displays validation errors on submit', async () => {
54:     const testSchema = z.object({
55:       email: z.string().email('Invalid email format'),
56:     });
57:     const fields = [{ name: 'email', label: 'Email', type: 'text' }];
58: 
59:     render(<DynamicFormBuilder schema={testSchema} fieldsConfig={fields} />);
60: 
61:     fireEvent.click(screen.getByRole('button', { name: /submit/i }));
62: 
63:     expect(await screen.findByRole('alert')).toHaveTextContent('Invalid email format');
64:   });
65: 
66:   it('renders multiple fields and validates them', async () => {
67:     const testSchema = z.object({
68:       username: z.string().min(3, 'Username must be at least 3 characters'),
69:       password: z.string().min(6, 'Password must be at least 6 characters'),
70:     });
71:     const fields = [
72:       { name: 'username', label: 'Username', type: 'text' },
73:       { name: 'password', label: 'Password', type: 'text' },
74:     ];
75: 
76:     render(<DynamicFormBuilder schema={testSchema} fieldsConfig={fields} />);
77: 
78:     const usernameInput = screen.getByLabelText(/username/i);
79:     const passwordInput = screen.getByLabelText(/password/i);
80:     const submitButton = screen.getByRole('button', { name: /submit/i });
81: 
82:     fireEvent.click(submitButton);
83: 
84:     expect(await screen.findByText('Username must be at least 3 characters')).toBeInTheDocument();
85:     expect(screen.getByText('Password must be at least 6 characters')).toBeInTheDocument();
86: 
87:     fireEvent.change(usernameInput, { target: { value: 'abc' } });
88:     fireEvent.change(passwordInput, { target: { value: '123456' } });
89: 
90:     fireEvent.click(submitButton);
91: 
92:     // Expect no validation errors after valid input
93:     expect(screen.queryByText('Username must be at least 3 characters')).not.toBeInTheDocument();
94:     expect(screen.queryByText('Password must be at least 6 characters')).not.toBeInTheDocument();
95:   });
96: });
</file>

<file path=".prettierrc.json">
1: {
2:   "singleQuote": true,
3:   "trailingComma": "all",
4:   "printWidth": 100,
5:   "semi": false
6: }
</file>

<file path="AGENTS.md">
  1: # Task Master AI - Claude Code Integration Guide
  2: 
  3: ## Essential Commands
  4: 
  5: ### Core Workflow Commands
  6: 
  7: ```bash
  8: # Project Setup
  9: task-master init                                    # Initialize Task Master in current project
 10: task-master parse-prd .taskmaster/docs/prd.txt      # Generate tasks from PRD document
 11: task-master models --setup                        # Configure AI models interactively
 12: 
 13: # Daily Development Workflow
 14: task-master list                                   # Show all tasks with status
 15: task-master next                                   # Get next available task to work on
 16: task-master show <id>                             # View detailed task information (e.g., task-master show 1.2)
 17: task-master set-status --id=<id> --status=done    # Mark task complete
 18: 
 19: # Task Management
 20: task-master add-task --prompt="description" --research        # Add new task with AI assistance
 21: task-master expand --id=<id> --research --force              # Break task into subtasks
 22: task-master update-task --id=<id> --prompt="changes"         # Update specific task
 23: task-master update --from=<id> --prompt="changes"            # Update multiple tasks from ID onwards
 24: task-master update-subtask --id=<id> --prompt="notes"        # Add implementation notes to subtask
 25: 
 26: # Analysis & Planning
 27: task-master analyze-complexity --research          # Analyze task complexity
 28: task-master complexity-report                      # View complexity analysis
 29: task-master expand --all --research               # Expand all eligible tasks
 30: 
 31: # Dependencies & Organization
 32: task-master add-dependency --id=<id> --depends-on=<id>       # Add task dependency
 33: task-master move --from=<id> --to=<id>                       # Reorganize task hierarchy
 34: task-master validate-dependencies                            # Check for dependency issues
 35: task-master generate                                         # Update task markdown files (usually auto-called)
 36: ```
 37: 
 38: ## Key Files & Project Structure
 39: 
 40: ### Core Files
 41: 
 42: - `.taskmaster/tasks/tasks.json` - Main task data file (auto-managed)
 43: - `.taskmaster/config.json` - AI model configuration (use `task-master models` to modify)
 44: - `.taskmaster/docs/prd.txt` - Product Requirements Document for parsing
 45: - `.taskmaster/tasks/*.txt` - Individual task files (auto-generated from tasks.json)
 46: - `.env` - API keys for CLI usage
 47: 
 48: ### Claude Code Integration Files
 49: 
 50: - `CLAUDE.md` - Auto-loaded context for Claude Code (this file)
 51: - `.claude/settings.json` - Claude Code tool allowlist and preferences
 52: - `.claude/commands/` - Custom slash commands for repeated workflows
 53: - `.mcp.json` - MCP server configuration (project-specific)
 54: 
 55: ### Directory Structure
 56: 
 57: ```
 58: project/
 59: ├── .taskmaster/
 60: │   ├── tasks/              # Task files directory
 61: │   │   ├── tasks.json      # Main task database
 62: │   │   ├── task-1.md      # Individual task files
 63: │   │   └── task-2.md
 64: │   ├── docs/              # Documentation directory
 65: │   │   ├── prd.txt        # Product requirements
 66: │   ├── reports/           # Analysis reports directory
 67: │   │   └── task-complexity-report.json
 68: │   ├── templates/         # Template files
 69: │   │   └── example_prd.txt  # Example PRD template
 70: │   └── config.json        # AI models & settings
 71: ├── .claude/
 72: │   ├── settings.json      # Claude Code configuration
 73: │   └── commands/         # Custom slash commands
 74: ├── .env                  # API keys
 75: ├── .mcp.json            # MCP configuration
 76: └── CLAUDE.md            # This file - auto-loaded by Claude Code
 77: ```
 78: 
 79: ## MCP Integration
 80: 
 81: Task Master provides an MCP server that Claude Code can connect to. Configure in `.mcp.json`:
 82: 
 83: ```json
 84: {
 85:   "mcpServers": {
 86:     "task-master-ai": {
 87:       "command": "npx",
 88:       "args": ["-y", "--package=task-master-ai", "task-master-ai"],
 89:       "env": {
 90:         "ANTHROPIC_API_KEY": "your_key_here",
 91:         "PERPLEXITY_API_KEY": "your_key_here",
 92:         "OPENAI_API_KEY": "OPENAI_API_KEY_HERE",
 93:         "GOOGLE_API_KEY": "GOOGLE_API_KEY_HERE",
 94:         "XAI_API_KEY": "XAI_API_KEY_HERE",
 95:         "OPENROUTER_API_KEY": "OPENROUTER_API_KEY_HERE",
 96:         "MISTRAL_API_KEY": "MISTRAL_API_KEY_HERE",
 97:         "AZURE_OPENAI_API_KEY": "AZURE_OPENAI_API_KEY_HERE",
 98:         "OLLAMA_API_KEY": "OLLAMA_API_KEY_HERE"
 99:       }
100:     }
101:   }
102: }
103: ```
104: 
105: ### Essential MCP Tools
106: 
107: ```javascript
108: help; // = shows available taskmaster commands
109: // Project setup
110: initialize_project; // = task-master init
111: parse_prd; // = task-master parse-prd
112: 
113: // Daily workflow
114: get_tasks; // = task-master list
115: next_task; // = task-master next
116: get_task; // = task-master show <id>
117: set_task_status; // = task-master set-status
118: 
119: // Task management
120: add_task; // = task-master add-task
121: expand_task; // = task-master expand
122: update_task; // = task-master update-task
123: update_subtask; // = task-master update-subtask
124: update; // = task-master update
125: 
126: // Analysis
127: analyze_project_complexity; // = task-master analyze-complexity
128: complexity_report; // = task-master complexity-report
129: ```
130: 
131: ## Claude Code Workflow Integration
132: 
133: ### Standard Development Workflow
134: 
135: #### 1. Project Initialization
136: 
137: ```bash
138: # Initialize Task Master
139: task-master init
140: 
141: # Create or obtain PRD, then parse it
142: task-master parse-prd .taskmaster/docs/prd.txt
143: 
144: # Analyze complexity and expand tasks
145: task-master analyze-complexity --research
146: task-master expand --all --research
147: ```
148: 
149: If tasks already exist, another PRD can be parsed (with new information only!) using parse-prd with --append flag. This will add the generated tasks to the existing list of tasks..
150: 
151: #### 2. Daily Development Loop
152: 
153: ```bash
154: # Start each session
155: task-master next                           # Find next available task
156: task-master show <id>                     # Review task details
157: 
158: # During implementation, check in code context into the tasks and subtasks
159: task-master update-subtask --id=<id> --prompt="implementation notes..."
160: 
161: # Complete tasks
162: task-master set-status --id=<id> --status=done
163: ```
164: 
165: #### 3. Multi-Claude Workflows
166: 
167: For complex projects, use multiple Claude Code sessions:
168: 
169: ```bash
170: # Terminal 1: Main implementation
171: cd project && claude
172: 
173: # Terminal 2: Testing and validation
174: cd project-test-worktree && claude
175: 
176: # Terminal 3: Documentation updates
177: cd project-docs-worktree && claude
178: ```
179: 
180: ### Custom Slash Commands
181: 
182: Create `.claude/commands/taskmaster-next.md`:
183: 
184: ```markdown
185: Find the next available Task Master task and show its details.
186: 
187: Steps:
188: 
189: 1. Run `task-master next` to get the next task
190: 2. If a task is available, run `task-master show <id>` for full details
191: 3. Provide a summary of what needs to be implemented
192: 4. Suggest the first implementation step
193: ```
194: 
195: Create `.claude/commands/taskmaster-complete.md`:
196: 
197: ```markdown
198: Complete a Task Master task: $ARGUMENTS
199: 
200: Steps:
201: 
202: 1. Review the current task with `task-master show $ARGUMENTS`
203: 2. Verify all implementation is complete
204: 3. Run any tests related to this task
205: 4. Mark as complete: `task-master set-status --id=$ARGUMENTS --status=done`
206: 5. Show the next available task with `task-master next`
207: ```
208: 
209: ## Tool Allowlist Recommendations
210: 
211: Add to `.claude/settings.json`:
212: 
213: ```json
214: {
215:   "allowedTools": [
216:     "Edit",
217:     "Bash(task-master *)",
218:     "Bash(git commit:*)",
219:     "Bash(git add:*)",
220:     "Bash(npm run *)",
221:     "mcp__task_master_ai__*"
222:   ]
223: }
224: ```
225: 
226: ## Configuration & Setup
227: 
228: ### API Keys Required
229: 
230: At least **one** of these API keys must be configured:
231: 
232: - `ANTHROPIC_API_KEY` (Claude models) - **Recommended**
233: - `PERPLEXITY_API_KEY` (Research features) - **Highly recommended**
234: - `OPENAI_API_KEY` (GPT models)
235: - `GOOGLE_API_KEY` (Gemini models)
236: - `MISTRAL_API_KEY` (Mistral models)
237: - `OPENROUTER_API_KEY` (Multiple models)
238: - `XAI_API_KEY` (Grok models)
239: 
240: An API key is required for any provider used across any of the 3 roles defined in the `models` command.
241: 
242: ### Model Configuration
243: 
244: ```bash
245: # Interactive setup (recommended)
246: task-master models --setup
247: 
248: # Set specific models
249: task-master models --set-main claude-3-5-sonnet-20241022
250: task-master models --set-research perplexity-llama-3.1-sonar-large-128k-online
251: task-master models --set-fallback gpt-4o-mini
252: ```
253: 
254: ## Task Structure & IDs
255: 
256: ### Task ID Format
257: 
258: - Main tasks: `1`, `2`, `3`, etc.
259: - Subtasks: `1.1`, `1.2`, `2.1`, etc.
260: - Sub-subtasks: `1.1.1`, `1.1.2`, etc.
261: 
262: ### Task Status Values
263: 
264: - `pending` - Ready to work on
265: - `in-progress` - Currently being worked on
266: - `done` - Completed and verified
267: - `deferred` - Postponed
268: - `cancelled` - No longer needed
269: - `blocked` - Waiting on external factors
270: 
271: ### Task Fields
272: 
273: ```json
274: {
275:   "id": "1.2",
276:   "title": "Implement user authentication",
277:   "description": "Set up JWT-based auth system",
278:   "status": "pending",
279:   "priority": "high",
280:   "dependencies": ["1.1"],
281:   "details": "Use bcrypt for hashing, JWT for tokens...",
282:   "testStrategy": "Unit tests for auth functions, integration tests for login flow",
283:   "subtasks": []
284: }
285: ```
286: 
287: ## Claude Code Best Practices with Task Master
288: 
289: ### Context Management
290: 
291: - Use `/clear` between different tasks to maintain focus
292: - This CLAUDE.md file is automatically loaded for context
293: - Use `task-master show <id>` to pull specific task context when needed
294: 
295: ### Iterative Implementation
296: 
297: 1. `task-master show <subtask-id>` - Understand requirements
298: 2. Explore codebase and plan implementation
299: 3. `task-master update-subtask --id=<id> --prompt="detailed plan"` - Log plan
300: 4. `task-master set-status --id=<id> --status=in-progress` - Start work
301: 5. Implement code following logged plan
302: 6. `task-master update-subtask --id=<id> --prompt="what worked/didn't work"` - Log progress
303: 7. `task-master set-status --id=<id> --status=done` - Complete task
304: 
305: ### Complex Workflows with Checklists
306: 
307: For large migrations or multi-step processes:
308: 
309: 1. Create a markdown PRD file describing the new changes: `touch task-migration-checklist.md` (prds can be .txt or .md)
310: 2. Use Taskmaster to parse the new prd with `task-master parse-prd --append` (also available in MCP)
311: 3. Use Taskmaster to expand the newly generated tasks into subtasks. Consdier using `analyze-complexity` with the correct --to and --from IDs (the new ids) to identify the ideal subtask amounts for each task. Then expand them.
312: 4. Work through items systematically, checking them off as completed
313: 5. Use `task-master update-subtask` to log progress on each task/subtask and/or updating/researching them before/during implementation if getting stuck
314: 
315: ### Git Integration
316: 
317: Task Master works well with `gh` CLI:
318: 
319: ```bash
320: # Create PR for completed task
321: gh pr create --title "Complete task 1.2: User authentication" --body "Implements JWT auth system as specified in task 1.2"
322: 
323: # Reference task in commits
324: git commit -m "feat: implement JWT auth (task 1.2)"
325: ```
326: 
327: ### Parallel Development with Git Worktrees
328: 
329: ```bash
330: # Create worktrees for parallel task development
331: git worktree add ../project-auth feature/auth-system
332: git worktree add ../project-api feature/api-refactor
333: 
334: # Run Claude Code in each worktree
335: cd ../project-auth && claude    # Terminal 1: Auth work
336: cd ../project-api && claude     # Terminal 2: API work
337: ```
338: 
339: ## Troubleshooting
340: 
341: ### AI Commands Failing
342: 
343: ```bash
344: # Check API keys are configured
345: cat .env                           # For CLI usage
346: 
347: # Verify model configuration
348: task-master models
349: 
350: # Test with different model
351: task-master models --set-fallback gpt-4o-mini
352: ```
353: 
354: ### MCP Connection Issues
355: 
356: - Check `.mcp.json` configuration
357: - Verify Node.js installation
358: - Use `--mcp-debug` flag when starting Claude Code
359: - Use CLI as fallback if MCP unavailable
360: 
361: ### Task File Sync Issues
362: 
363: ```bash
364: # Regenerate task files from tasks.json
365: task-master generate
366: 
367: # Fix dependency issues
368: task-master fix-dependencies
369: ```
370: 
371: DO NOT RE-INITIALIZE. That will not do anything beyond re-adding the same Taskmaster core files.
372: 
373: ## Important Notes
374: 
375: ### AI-Powered Operations
376: 
377: These commands make AI calls and may take up to a minute:
378: 
379: - `parse_prd` / `task-master parse-prd`
380: - `analyze_project_complexity` / `task-master analyze-complexity`
381: - `expand_task` / `task-master expand`
382: - `expand_all` / `task-master expand --all`
383: - `add_task` / `task-master add-task`
384: - `update` / `task-master update`
385: - `update_task` / `task-master update-task`
386: - `update_subtask` / `task-master update-subtask`
387: 
388: ### File Management
389: 
390: - Never manually edit `tasks.json` - use commands instead
391: - Never manually edit `.taskmaster/config.json` - use `task-master models`
392: - Task markdown files in `tasks/` are auto-generated
393: - Run `task-master generate` after manual changes to tasks.json
394: 
395: ### Claude Code Session Management
396: 
397: - Use `/clear` frequently to maintain focused context
398: - Create custom slash commands for repeated Task Master workflows
399: - Configure tool allowlist to streamline permissions
400: - Use headless mode for automation: `claude -p "task-master next"`
401: 
402: ### Multi-Task Updates
403: 
404: - Use `update --from=<id>` to update multiple future tasks
405: - Use `update-task --id=<id>` for single task updates
406: - Use `update-subtask --id=<id>` for implementation logging
407: 
408: ### Research Mode
409: 
410: - Add `--research` flag for research-based AI enhancement
411: - Requires a research model API key like Perplexity (`PERPLEXITY_API_KEY`) in environment
412: - Provides more informed task creation and updates
413: - Recommended for complex technical tasks
414: 
415: ---
416: 
417: _This guide ensures Claude Code has immediate access to Task Master's essential functionality for agentic development workflows._
</file>

<file path="CLAUDE.md">
  1: # Task Master AI - Claude Code Integration Guide
  2: 
  3: ## Essential Commands
  4: 
  5: ### Core Workflow Commands
  6: 
  7: ```bash
  8: # Project Setup
  9: task-master init                                    # Initialize Task Master in current project
 10: task-master parse-prd .taskmaster/docs/prd.txt      # Generate tasks from PRD document
 11: task-master models --setup                        # Configure AI models interactively
 12: 
 13: # Daily Development Workflow
 14: task-master list                                   # Show all tasks with status
 15: task-master next                                   # Get next available task to work on
 16: task-master show <id>                             # View detailed task information (e.g., task-master show 1.2)
 17: task-master set-status --id=<id> --status=done    # Mark task complete
 18: 
 19: # Task Management
 20: task-master add-task --prompt="description" --research        # Add new task with AI assistance
 21: task-master expand --id=<id> --research --force              # Break task into subtasks
 22: task-master update-task --id=<id> --prompt="changes"         # Update specific task
 23: task-master update --from=<id> --prompt="changes"            # Update multiple tasks from ID onwards
 24: task-master update-subtask --id=<id> --prompt="notes"        # Add implementation notes to subtask
 25: 
 26: # Analysis & Planning
 27: task-master analyze-complexity --research          # Analyze task complexity
 28: task-master complexity-report                      # View complexity analysis
 29: task-master expand --all --research               # Expand all eligible tasks
 30: 
 31: # Dependencies & Organization
 32: task-master add-dependency --id=<id> --depends-on=<id>       # Add task dependency
 33: task-master move --from=<id> --to=<id>                       # Reorganize task hierarchy
 34: task-master validate-dependencies                            # Check for dependency issues
 35: task-master generate                                         # Update task markdown files (usually auto-called)
 36: ```
 37: 
 38: ## Key Files & Project Structure
 39: 
 40: ### Core Files
 41: 
 42: - `.taskmaster/tasks/tasks.json` - Main task data file (auto-managed)
 43: - `.taskmaster/config.json` - AI model configuration (use `task-master models` to modify)
 44: - `.taskmaster/docs/prd.txt` - Product Requirements Document for parsing
 45: - `.taskmaster/tasks/*.txt` - Individual task files (auto-generated from tasks.json)
 46: - `.env` - API keys for CLI usage
 47: 
 48: ### Claude Code Integration Files
 49: 
 50: - `CLAUDE.md` - Auto-loaded context for Claude Code (this file)
 51: - `.claude/settings.json` - Claude Code tool allowlist and preferences
 52: - `.claude/commands/` - Custom slash commands for repeated workflows
 53: - `.mcp.json` - MCP server configuration (project-specific)
 54: 
 55: ### Directory Structure
 56: 
 57: ```
 58: project/
 59: ├── .taskmaster/
 60: │   ├── tasks/              # Task files directory
 61: │   │   ├── tasks.json      # Main task database
 62: │   │   ├── task-1.md      # Individual task files
 63: │   │   └── task-2.md
 64: │   ├── docs/              # Documentation directory
 65: │   │   ├── prd.txt        # Product requirements
 66: │   ├── reports/           # Analysis reports directory
 67: │   │   └── task-complexity-report.json
 68: │   ├── templates/         # Template files
 69: │   │   └── example_prd.txt  # Example PRD template
 70: │   └── config.json        # AI models & settings
 71: ├── .claude/
 72: │   ├── settings.json      # Claude Code configuration
 73: │   └── commands/         # Custom slash commands
 74: ├── .env                  # API keys
 75: ├── .mcp.json            # MCP configuration
 76: └── CLAUDE.md            # This file - auto-loaded by Claude Code
 77: ```
 78: 
 79: ## MCP Integration
 80: 
 81: Task Master provides an MCP server that Claude Code can connect to. Configure in `.mcp.json`:
 82: 
 83: ```json
 84: {
 85:   "mcpServers": {
 86:     "task-master-ai": {
 87:       "command": "npx",
 88:       "args": ["-y", "--package=task-master-ai", "task-master-ai"],
 89:       "env": {
 90:         "ANTHROPIC_API_KEY": "your_key_here",
 91:         "PERPLEXITY_API_KEY": "your_key_here",
 92:         "OPENAI_API_KEY": "OPENAI_API_KEY_HERE",
 93:         "GOOGLE_API_KEY": "GOOGLE_API_KEY_HERE",
 94:         "XAI_API_KEY": "XAI_API_KEY_HERE",
 95:         "OPENROUTER_API_KEY": "OPENROUTER_API_KEY_HERE",
 96:         "MISTRAL_API_KEY": "MISTRAL_API_KEY_HERE",
 97:         "AZURE_OPENAI_API_KEY": "AZURE_OPENAI_API_KEY_HERE",
 98:         "OLLAMA_API_KEY": "OLLAMA_API_KEY_HERE"
 99:       }
100:     }
101:   }
102: }
103: ```
104: 
105: ### Essential MCP Tools
106: 
107: ```javascript
108: help; // = shows available taskmaster commands
109: // Project setup
110: initialize_project; // = task-master init
111: parse_prd; // = task-master parse-prd
112: 
113: // Daily workflow
114: get_tasks; // = task-master list
115: next_task; // = task-master next
116: get_task; // = task-master show <id>
117: set_task_status; // = task-master set-status
118: 
119: // Task management
120: add_task; // = task-master add-task
121: expand_task; // = task-master expand
122: update_task; // = task-master update-task
123: update_subtask; // = task-master update-subtask
124: update; // = task-master update
125: 
126: // Analysis
127: analyze_project_complexity; // = task-master analyze-complexity
128: complexity_report; // = task-master complexity-report
129: ```
130: 
131: ## Claude Code Workflow Integration
132: 
133: ### Standard Development Workflow
134: 
135: #### 1. Project Initialization
136: 
137: ```bash
138: # Initialize Task Master
139: task-master init
140: 
141: # Create or obtain PRD, then parse it
142: task-master parse-prd .taskmaster/docs/prd.txt
143: 
144: # Analyze complexity and expand tasks
145: task-master analyze-complexity --research
146: task-master expand --all --research
147: ```
148: 
149: If tasks already exist, another PRD can be parsed (with new information only!) using parse-prd with --append flag. This will add the generated tasks to the existing list of tasks..
150: 
151: #### 2. Daily Development Loop
152: 
153: ```bash
154: # Start each session
155: task-master next                           # Find next available task
156: task-master show <id>                     # Review task details
157: 
158: # During implementation, check in code context into the tasks and subtasks
159: task-master update-subtask --id=<id> --prompt="implementation notes..."
160: 
161: # Complete tasks
162: task-master set-status --id=<id> --status=done
163: ```
164: 
165: #### 3. Multi-Claude Workflows
166: 
167: For complex projects, use multiple Claude Code sessions:
168: 
169: ```bash
170: # Terminal 1: Main implementation
171: cd project && claude
172: 
173: # Terminal 2: Testing and validation
174: cd project-test-worktree && claude
175: 
176: # Terminal 3: Documentation updates
177: cd project-docs-worktree && claude
178: ```
179: 
180: ### Custom Slash Commands
181: 
182: Create `.claude/commands/taskmaster-next.md`:
183: 
184: ```markdown
185: Find the next available Task Master task and show its details.
186: 
187: Steps:
188: 
189: 1. Run `task-master next` to get the next task
190: 2. If a task is available, run `task-master show <id>` for full details
191: 3. Provide a summary of what needs to be implemented
192: 4. Suggest the first implementation step
193: ```
194: 
195: Create `.claude/commands/taskmaster-complete.md`:
196: 
197: ```markdown
198: Complete a Task Master task: $ARGUMENTS
199: 
200: Steps:
201: 
202: 1. Review the current task with `task-master show $ARGUMENTS`
203: 2. Verify all implementation is complete
204: 3. Run any tests related to this task
205: 4. Mark as complete: `task-master set-status --id=$ARGUMENTS --status=done`
206: 5. Show the next available task with `task-master next`
207: ```
208: 
209: ## Tool Allowlist Recommendations
210: 
211: Add to `.claude/settings.json`:
212: 
213: ```json
214: {
215:   "allowedTools": [
216:     "Edit",
217:     "Bash(task-master *)",
218:     "Bash(git commit:*)",
219:     "Bash(git add:*)",
220:     "Bash(npm run *)",
221:     "mcp__task_master_ai__*"
222:   ]
223: }
224: ```
225: 
226: ## Configuration & Setup
227: 
228: ### API Keys Required
229: 
230: At least **one** of these API keys must be configured:
231: 
232: - `ANTHROPIC_API_KEY` (Claude models) - **Recommended**
233: - `PERPLEXITY_API_KEY` (Research features) - **Highly recommended**
234: - `OPENAI_API_KEY` (GPT models)
235: - `GOOGLE_API_KEY` (Gemini models)
236: - `MISTRAL_API_KEY` (Mistral models)
237: - `OPENROUTER_API_KEY` (Multiple models)
238: - `XAI_API_KEY` (Grok models)
239: 
240: An API key is required for any provider used across any of the 3 roles defined in the `models` command.
241: 
242: ### Model Configuration
243: 
244: ```bash
245: # Interactive setup (recommended)
246: task-master models --setup
247: 
248: # Set specific models
249: task-master models --set-main claude-3-5-sonnet-20241022
250: task-master models --set-research perplexity-llama-3.1-sonar-large-128k-online
251: task-master models --set-fallback gpt-4o-mini
252: ```
253: 
254: ## Task Structure & IDs
255: 
256: ### Task ID Format
257: 
258: - Main tasks: `1`, `2`, `3`, etc.
259: - Subtasks: `1.1`, `1.2`, `2.1`, etc.
260: - Sub-subtasks: `1.1.1`, `1.1.2`, etc.
261: 
262: ### Task Status Values
263: 
264: - `pending` - Ready to work on
265: - `in-progress` - Currently being worked on
266: - `done` - Completed and verified
267: - `deferred` - Postponed
268: - `cancelled` - No longer needed
269: - `blocked` - Waiting on external factors
270: 
271: ### Task Fields
272: 
273: ```json
274: {
275:   "id": "1.2",
276:   "title": "Implement user authentication",
277:   "description": "Set up JWT-based auth system",
278:   "status": "pending",
279:   "priority": "high",
280:   "dependencies": ["1.1"],
281:   "details": "Use bcrypt for hashing, JWT for tokens...",
282:   "testStrategy": "Unit tests for auth functions, integration tests for login flow",
283:   "subtasks": []
284: }
285: ```
286: 
287: ## Claude Code Best Practices with Task Master
288: 
289: ### Context Management
290: 
291: - Use `/clear` between different tasks to maintain focus
292: - This CLAUDE.md file is automatically loaded for context
293: - Use `task-master show <id>` to pull specific task context when needed
294: 
295: ### Iterative Implementation
296: 
297: 1. `task-master show <subtask-id>` - Understand requirements
298: 2. Explore codebase and plan implementation
299: 3. `task-master update-subtask --id=<id> --prompt="detailed plan"` - Log plan
300: 4. `task-master set-status --id=<id> --status=in-progress` - Start work
301: 5. Implement code following logged plan
302: 6. `task-master update-subtask --id=<id> --prompt="what worked/didn't work"` - Log progress
303: 7. `task-master set-status --id=<id> --status=done` - Complete task
304: 
305: ### Complex Workflows with Checklists
306: 
307: For large migrations or multi-step processes:
308: 
309: 1. Create a markdown PRD file describing the new changes: `touch task-migration-checklist.md` (prds can be .txt or .md)
310: 2. Use Taskmaster to parse the new prd with `task-master parse-prd --append` (also available in MCP)
311: 3. Use Taskmaster to expand the newly generated tasks into subtasks. Consdier using `analyze-complexity` with the correct --to and --from IDs (the new ids) to identify the ideal subtask amounts for each task. Then expand them.
312: 4. Work through items systematically, checking them off as completed
313: 5. Use `task-master update-subtask` to log progress on each task/subtask and/or updating/researching them before/during implementation if getting stuck
314: 
315: ### Git Integration
316: 
317: Task Master works well with `gh` CLI:
318: 
319: ```bash
320: # Create PR for completed task
321: gh pr create --title "Complete task 1.2: User authentication" --body "Implements JWT auth system as specified in task 1.2"
322: 
323: # Reference task in commits
324: git commit -m "feat: implement JWT auth (task 1.2)"
325: ```
326: 
327: ### Parallel Development with Git Worktrees
328: 
329: ```bash
330: # Create worktrees for parallel task development
331: git worktree add ../project-auth feature/auth-system
332: git worktree add ../project-api feature/api-refactor
333: 
334: # Run Claude Code in each worktree
335: cd ../project-auth && claude    # Terminal 1: Auth work
336: cd ../project-api && claude     # Terminal 2: API work
337: ```
338: 
339: ## Troubleshooting
340: 
341: ### AI Commands Failing
342: 
343: ```bash
344: # Check API keys are configured
345: cat .env                           # For CLI usage
346: 
347: # Verify model configuration
348: task-master models
349: 
350: # Test with different model
351: task-master models --set-fallback gpt-4o-mini
352: ```
353: 
354: ### MCP Connection Issues
355: 
356: - Check `.mcp.json` configuration
357: - Verify Node.js installation
358: - Use `--mcp-debug` flag when starting Claude Code
359: - Use CLI as fallback if MCP unavailable
360: 
361: ### Task File Sync Issues
362: 
363: ```bash
364: # Regenerate task files from tasks.json
365: task-master generate
366: 
367: # Fix dependency issues
368: task-master fix-dependencies
369: ```
370: 
371: DO NOT RE-INITIALIZE. That will not do anything beyond re-adding the same Taskmaster core files.
372: 
373: ## Important Notes
374: 
375: ### AI-Powered Operations
376: 
377: These commands make AI calls and may take up to a minute:
378: 
379: - `parse_prd` / `task-master parse-prd`
380: - `analyze_project_complexity` / `task-master analyze-complexity`
381: - `expand_task` / `task-master expand`
382: - `expand_all` / `task-master expand --all`
383: - `add_task` / `task-master add-task`
384: - `update` / `task-master update`
385: - `update_task` / `task-master update-task`
386: - `update_subtask` / `task-master update-subtask`
387: 
388: ### File Management
389: 
390: - Never manually edit `tasks.json` - use commands instead
391: - Never manually edit `.taskmaster/config.json` - use `task-master models`
392: - Task markdown files in `tasks/` are auto-generated
393: - Run `task-master generate` after manual changes to tasks.json
394: 
395: ### Claude Code Session Management
396: 
397: - Use `/clear` frequently to maintain focused context
398: - Create custom slash commands for repeated Task Master workflows
399: - Configure tool allowlist to streamline permissions
400: - Use headless mode for automation: `claude -p "task-master next"`
401: 
402: ### Multi-Task Updates
403: 
404: - Use `update --from=<id>` to update multiple future tasks
405: - Use `update-task --id=<id>` for single task updates
406: - Use `update-subtask --id=<id>` for implementation logging
407: 
408: ### Research Mode
409: 
410: - Add `--research` flag for research-based AI enhancement
411: - Requires a research model API key like Perplexity (`PERPLEXITY_API_KEY`) in environment
412: - Provides more informed task creation and updates
413: - Recommended for complex technical tasks
414: 
415: ---
416: 
417: _This guide ensures Claude Code has immediate access to Task Master's essential functionality for agentic development workflows._
</file>

<file path="docker-compose.yml">
 1: version: '3'
 2: 
 3: services:
 4:   payload:
 5:     image: node:18-alpine
 6:     ports:
 7:       - '4000:3000'
 8:     volumes:
 9:       - .:/home/node/app
10:       - node_modules:/home/node/app/node_modules
11:     working_dir: /home/node/app/
12:     command: sh -c "corepack enable && corepack prepare pnpm@latest --activate && pnpm install && pnpm dev"
13:     depends_on:
14:       - postgres
15:     env_file:
16:       - .env
17: 
18:   postgres:
19:     restart: always
20:     image: postgres:latest
21:     volumes:
22:       - pgdata:/var/lib/postgresql/data
23:     ports:
24:       - "5432:5432"
25: 
26: volumes:
27:   pgdata:
28:   node_modules:
</file>

<file path="eslint.config.mjs">
 1: import { dirname } from 'path'
 2: import { fileURLToPath } from 'url'
 3: import { FlatCompat } from "@eslint/eslintrc";
 4: 
 5: const __filename = fileURLToPath(import.meta.url)
 6: const __dirname = dirname(__filename)
 7: 
 8: const compat = new FlatCompat({
 9:   baseDirectory: __dirname,
10: })
11: 
12: import jsdoc from 'eslint-plugin-jsdoc'
13: 
14: const eslintConfig = [
15:   ...compat.extends('next/core-web-vitals', 'next/typescript'),
16:   {
17:     plugins: {
18:       jsdoc,
19:     },
20:     rules: {
21:       '@typescript-eslint/ban-ts-comment': 'warn',
22:       '@typescript-eslint/no-empty-object-type': 'warn',
23:       '@typescript-eslint/no-explicit-any': 'warn',
24:       '@typescript-eslint/no-unused-vars': [
25:         'warn',
26:         {
27:           vars: 'all',
28:           args: 'after-used',
29:           ignoreRestSiblings: false,
30:           argsIgnorePattern: '^_',
31:           varsIgnorePattern: '^_',
32:           destructuredArrayIgnorePattern: '^_',
33:           caughtErrorsIgnorePattern: '^(_|ignore)',
34:         },
35:       ],
36:       'jsdoc/require-jsdoc': [
37:         'warn',
38:         {
39:           require: {
40:             FunctionDeclaration: true,
41:             MethodDefinition: true,
42:             ClassDeclaration: true,
43:             ArrowFunctionExpression: true,
44:             FunctionExpression: true,
45:           },
46:         },
47:       ],
48:     },
49:   },
50:   {
51:     ignores: ['.next/'],
52:   },
53: ]
54: 
55: export default eslintConfig
</file>

<file path="next.config.mjs">
 1: import { withPayload } from '@payloadcms/next/withPayload'
 2: 
 3: /** @type {import('next').NextConfig} */
 4: const nextConfig = {
 5:   // Restaurant Management System Configuration
 6:   experimental: {
 7:     reactCompiler: false,
 8:   },
 9:   serverExternalPackages: ['sharp'],
10: 
11:   // Image optimization for restaurant photos and media
12:   images: {
13:     domains: ['localhost', 'your-domain.com'],
14:     formats: ['image/webp', 'image/avif'],
15:     deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],
16:     imageSizes: [16, 32, 48, 64, 96, 128, 256, 384],
17:   },
18: 
19:   // Security headers for restaurant data protection
20:   async headers() {
21:     return [
22:       {
23:         source: '/(.*)',
24:         headers: [
25:           {
26:             key: 'X-Frame-Options',
27:             value: 'DENY',
28:           },
29:           {
30:             key: 'X-Content-Type-Options',
31:             value: 'nosniff',
32:           },
33:           {
34:             key: 'Referrer-Policy',
35:             value: 'origin-when-cross-origin',
36:           },
37:         ],
38:       },
39:     ]
40:   },
41: 
42:   // Webpack configuration for restaurant management modules
43:   webpack: (webpackConfig) => {
44:     webpackConfig.resolve.extensionAlias = {
45:       '.cjs': ['.cts', '.cjs'],
46:       '.js': ['.ts', '.tsx', '.js', '.jsx'],
47:       '.mjs': ['.mts', '.mjs'],
48:     }
49: 
50:     return webpackConfig
51:   },
52: 
53:   // Environment variables for restaurant configuration
54:   env: {
55:     RESTAURANT_NAME: process.env.RESTAURANT_NAME,
56:     RESTAURANT_TIMEZONE: process.env.RESTAURANT_TIMEZONE,
57:     RATING_SCALE_MAX: process.env.RATING_SCALE_MAX,
58:   },
59: }
60: 
61: export default withPayload(nextConfig, { devBundleServerPackages: false })
</file>

<file path="playwright.config.ts">
 1: import { defineConfig, devices } from '@playwright/test'
 2: 
 3: /**
 4:  * Read environment variables from file.
 5:  * https://github.com/motdotla/dotenv
 6:  */
 7: import 'dotenv/config'
 8: 
 9: /**
10:  * See https://playwright.dev/docs/test-configuration.
11:  */
12: export default defineConfig({
13:   testDir: './tests/e2e',
14:   /* Fail the build on CI if you accidentally left test.only in the source code. */
15:   forbidOnly: !!process.env.CI,
16:   /* Retry on CI only */
17:   retries: process.env.CI ? 2 : 0,
18:   /* Opt out of parallel tests on CI. */
19:   workers: process.env.CI ? 1 : undefined,
20:   /* Reporter to use. See https://playwright.dev/docs/test-reporters */
21:   reporter: 'html',
22:   /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
23:   use: {
24:     /* Base URL to use in actions like `await page.goto('/')`. */
25:     // baseURL: 'http://localhost:3000',
26: 
27:     /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
28:     trace: 'on-first-retry',
29:   },
30:   projects: [
31:     {
32:       name: 'chromium',
33:       use: { ...devices['Desktop Chrome'] },
34:     },
35:   ],
36:   webServer: {
37:     command: 'pnpm dev',
38:     reuseExistingServer: true,
39:     url: 'http://localhost:3000',
40:   },
41: })
</file>

<file path="repomix.config.json">
 1: {
 2:   "include": [
 3:     "**/*.ts",
 4:     "**/*.tsx",
 5:     "**/*.js",
 6:     "**/*.jsx",
 7:     "**/*.json",
 8:     "**/*.md",
 9:     "**/*.yml",
10:     "**/*.yaml",
11:     "**/*.env.example",
12:     "**/*.config.*",
13:     "**/*.mjs",
14:     "**/*.mts"
15:   ],
16:   "ignore": {
17:     "useGitignore": true,
18:     "useDefaultPatterns": true,
19:     "customPatterns": [
20:       "node_modules/**",
21:       ".git/**",
22:       "dist/**",
23:       "build/**",
24:       ".next/**",
25:       "coverage/**",
26:       "*.log",
27:       "*.lock",
28:       "pnpm-lock.yaml",
29:       "yarn.lock",
30:       "package-lock.json",
31:       ".env",
32:       ".env.local",
33:       ".env.production",
34:       "**/.DS_Store",
35:       "**/Thumbs.db",
36:       "**/*.min.js",
37:       "**/*.min.css",
38:       "**/payload-types.ts",
39:       "**/*.d.ts",
40:       "repomix-output.*"
41:     ]
42:   },
43:   "output": {
44:     "filePath": "repomix-output.xml",
45:     "style": "xml",
46:     "headerText": "Canvas Payload v3 Restaurant Management System - Complete Codebase",
47:     "removeComments": false,
48:     "removeEmptyLines": false,
49:     "topFilesLength": 12,
50:     "showLineNumbers": true
51:   },
52:   "security": {
53:     "enableSecurityCheck": true
54:   }
55: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "baseUrl": ".",
 4:     "lib": ["DOM", "DOM.Iterable", "ES2022"],
 5:     "allowJs": true,
 6:     "skipLibCheck": true,
 7:     "strict": true,
 8:     "noEmit": true,
 9:     "esModuleInterop": true,
10:     "module": "esnext",
11:     "moduleResolution": "bundler",
12:     "resolveJsonModule": true,
13:     "isolatedModules": true,
14:     "jsx": "preserve",
15:     "incremental": true,
16:     "plugins": [
17:       {
18:         "name": "next"
19:       }
20:     ],
21:     "paths": {
22:       "@/*": ["./src/*"],
23:       "@payload-config": ["./src/payload.config.ts"],
24:       "@/collections/*": ["./src/collections/*"],
25:       "@/components/*": ["./src/components/*"],
26:       "@/lib/*": ["./src/lib/*"],
27:       "@/types/*": ["./src/types/*"],
28:       "@/hooks/*": ["./src/hooks/*"],
29:       "@/utils/*": ["./src/utils/*"]
30:     },
31:     "target": "ES2022"
32:   },
33:   "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
34:   "exclude": ["node_modules"]
35: }
</file>

<file path=".clinerules/cline_rules.md">
 1: ---
 2: description: Guidelines for creating and maintaining Cline rules to ensure consistency and effectiveness.
 3: globs: .cline/rules/*.md
 4: alwaysApply: true
 5: ---
 6: 
 7: - **Required Rule Structure:**
 8:   ```markdown
 9:   ---
10:   description: Clear, one-line description of what the rule enforces
11:   globs: path/to/files/*.ext, other/path/**/*
12:   alwaysApply: boolean
13:   ---
14: 
15:   - **Main Points in Bold**
16:     - Sub-points with details
17:     - Examples and explanations
18:   ```
19: 
20: - **File References:**
21:   - Use `[filename](mdc:filename)` to reference files
22:   - Example: [prisma.md](mdc:prisma.md) for rule references
23:   - Example: [schema.prisma](mdc:prisma/schema.prisma) for code references
24: 
25: - **Code Examples:**
26:   - Use language-specific code blocks
27:   ```typescript
28:   // ✅ DO: Show good examples
29:   const goodExample = true;
30:   
31:   // ❌ DON'T: Show anti-patterns
32:   const badExample = false;
33:   ```
34: 
35: - **Rule Content Guidelines:**
36:   - Start with high-level overview
37:   - Include specific, actionable requirements
38:   - Show examples of correct implementation
39:   - Reference existing code when possible
40:   - Keep rules DRY by referencing other rules
41: 
42: - **Rule Maintenance:**
43:   - Update rules when new patterns emerge
44:   - Add examples from actual codebase
45:   - Remove outdated patterns
46:   - Cross-reference related rules
47: 
48: - **Best Practices:**
49:   - Use bullet points for clarity
50:   - Keep descriptions concise
51:   - Include both DO and DON'T examples
52:   - Reference actual code over theoretical examples
53:   - Use consistent formatting across rules
</file>

<file path=".gemini/settings.json">
 1: {
 2:   "mcpServers": {
 3:     "context7": {
 4:       "command": "npx",
 5:       "args": ["-y", "@upstash/context7-mcp"]
 6:     },
 7:     "taskmaster": {
 8:       "command": "npx",
 9:       "args": ["-y", "--package=task-master-ai", "task-master-ai"]
10:     }
11:   }
12: }
</file>

<file path=".taskmaster/config.json">
 1: {
 2:   "models": {
 3:     "main": {
 4:       "provider": "openrouter",
 5:       "modelId": "openai/gpt-4.1",
 6:       "maxTokens": 32000,
 7:       "temperature": 0.2
 8:     },
 9:     "research": {
10:       "provider": "openrouter",
11:       "modelId": "perplexity/sonar-reasoning-pro",
12:       "maxTokens": 2700,
13:       "temperature": 0.1
14:     },
15:     "fallback": {
16:       "provider": "openrouter",
17:       "modelId": "openai/gpt-4.1-mini",
18:       "maxTokens": 10000,
19:       "temperature": 0.1
20:     }
21:   },
22:   "global": {
23:     "logLevel": "info",
24:     "debug": false,
25:     "defaultSubtasks": 5,
26:     "defaultPriority": "medium",
27:     "projectName": "Taskmaster",
28:     "ollamaBaseURL": "http://localhost:11434/api",
29:     "bedrockBaseURL": "https://bedrock.us-east-1.amazonaws.com",
30:     "defaultTag": "master",
31:     "azureOpenaiBaseURL": "https://your-endpoint.openai.azure.com/",
32:     "userId": "1234567890"
33:   }
34: }
</file>

<file path=".taskmaster/state.json">
1: {
2:   "currentTag": "master",
3:   "lastSwitched": "2025-07-01T23:01:27.048Z",
4:   "branchTagMapping": {},
5:   "migrationNoticeShown": true
6: }
</file>

<file path="llm_context/forms/complex_forms.md">
  1: # Complex Forms: Advanced Composition Patterns
  2: 
  3: This guide covers patterns for building multi-step, dynamic, and state-driven forms using React Hook Form, Zod, and Zustand.
  4: 
  5: ## 1. Multi-Step (Wizard) Forms
  6: 
  7: - **Step Schema Isolation**
  8:   - Define a separate Zod schema per step.
  9:   - Merge schemas at submission:  
 10: 
 11:     ```ts
 12:     const step1Schema = z.object({ name: z.string().min(1) });
 13:     const step2Schema = z.object({ address: z.string().min(1) });
 14:     const fullSchema = step1Schema.merge(step2Schema);
 15:     ```
 16: 
 17: - **FormProvider & useFormContext**
 18:   - Wrap steps in `<FormProvider {...methods}>`.
 19:   - Inside each step component, use `useFormContext()` to register fields.
 20: - **Navigation & Validation**
 21:   - On “Next”, call `trigger(stepFields)` to validate only current step.
 22:   - Store `currentStep` in local component state or Zustand.
 23: 
 24: ## 2. Dynamic Field Arrays
 25: 
 26: - **useFieldArray**
 27:   - Use React Hook Form’s `useFieldArray` for repeating sections.
 28:   - Example:
 29: 
 30:     ```tsx
 31:     const { fields, append, remove } = useFieldArray({ name: "items" });
 32:     ```
 33: 
 34: - **Nested Arrays**
 35:   - Combine with step forms: manage separate arrays per step.
 36:   - Ensure unique keys: use `id` from `fields`.
 37: 
 38: ## 3. Conditional & Dependent Fields
 39: 
 40: - **watch & conditional render**
 41:   - Use `watch("type")` to conditionally render and register fields.
 42:   - Unregister fields when hidden:  
 43: 
 44:     ```ts
 45:     useEffect(() => {
 46:       if (type !== "other") unregister("otherText");
 47:     }, [type]);
 48:     ```
 49: 
 50: - **Zod refinements**
 51:   - Enforce cross-field conditions:  
 52: 
 53:     ```ts
 54:     z.object({ a: z.string(), b: z.string() })
 55:       .refine(data => data.a !== data.b, { message: "A and B must differ" });
 56:     ```
 57: 
 58: ## 4. Persisted Form State (Zustand)
 59: 
 60: - **Create store slice**
 61: 
 62:   ```ts
 63:   const useFormStore = create(persist((set) => ({
 64:     data: {},
 65:     setData: (partial) => set(state => ({ data: { ...state.data, ...partial } })),
 66:   })));
 67:   ```
 68: 
 69: - **Sync with RHF**
 70:   - On step submit: `useFormStore.getState().setData(getValues())`.
 71:   - On mount: `reset(useFormStore.getState().data)` to restore values.
 72: 
 73: ## 5. Async Field-Level Validation
 74: 
 75: - **Debounced checks**
 76:   - Use `watch` + `useDebounce` hook.
 77:   - In `useEffect`, call server validation and `setError` or `clearErrors`.
 78: - **Resolver with Zod + async**
 79:   - Zod supports async refinements for unique-value checks.
 80: 
 81: ## 6. File Uploads & Previews
 82: 
 83: - **react-dropzone + RHF**
 84:   - Wrap `<input type="file" {...register("files")} />`.
 85:   - Show previews: read `watch("files")`.
 86: - **Upload Hooks**
 87:   - Use Payload upload hooks or direct S3 upload in `onSubmit`.
 88:   - Show progress with `onUploadProgress`.
 89: 
 90: ## 7. Accessibility & UX
 91: 
 92: - **ARIA Roles**
 93:   - Use `aria-invalid={!!errors.field}` and `<span role="alert">` for error messages.
 94: - **Keyboard Navigation**
 95:   - Ensure step controls (`Next`, `Back`) are focusable.
 96: - **Progress Indicators**
 97:   - Render a progress bar/update on each step.
 98: 
 99: ## 8. Testing Complex Forms
100: 
101: - **Vitest + React Testing Library**
102:   - Use `renderHook` for store slice.
103:   - Simulate user flows: `userEvent.type`, `userEvent.click`.
104: - **Playwright E2E**
105:   - Cover multi-step navigation, validation errors, and final submission.
106: 
107: ---
108: 
109: **Centralize** these patterns in your feature code by importing from this guide and reusing across form modules.
</file>

<file path="llm_context/forms/README.md">
 1: # Form Submission Patterns
 2: 
 3: ## Form Libraries
 4: 
 5: - [x] React Hook Form integration patterns - Integrates well with Zod for schema validation
 6: - [x] Zod schema validation - Provides type safety and validation logic
 7: - [x] Form state management with Zustand - Use Zustand for complex form state across components
 8: - [x] File upload handling with Payload Media - Implement using Form Builder plugin with custom overrides[1][2]
 9: - [x] Password reset flow - Backend endpoints and frontend forms with validation and email verification
10: - [x] Login flow - Backend API and frontend form with JWT authentication and secure cookie handling
11: 
12: ## Submission Strategies
13: 
14: - [x] Optimistic UI updates - Implement with Tanstack Query's `onMutate`[4]
15: - [x] Error handling and user feedback - Use Form Builder's confirmation messages[1][4]
16: - [x] Multi-step form patterns - Implement with Zustand state management
17: - [x] Auto-save functionality - Use debounced submissions with Zustand
18: - [x] Form validation timing - Real-time validation with Zod schemas
19: 
20: ## Payload Integration
21: 
22: - [x] Collection field mapping - Map form fields directly to Payload collections[3]
23: - [x] Relationship field handling - Use Form Builder's relationship fields[3]
24: - [x] Rich text editor integration - Implement Lexical editor in forms[3]
25: - [x] Media upload workflows - Custom file upload handling with Form Builder[1][2]
26: 
27: ```typescript
28: // File upload example with Form Builder
29: import { FormBuilder } from 'payload-plugin-form-builder';
30: 
31: const formConfig = {
32:   fields: {
33:     fileUpload: {
34:       type: 'upload',
35:       relationTo: 'media',
36:       required: true
37:     }
38:   },
39:   hooks: {
40:     beforeSubmit: async ({ data }) => {
41:       // Custom file processing
42:       return processFileUpload(data.fileUpload);
43:     }
44:   }
45: };
46: ```
47: 
48: - [x] Bulk operations - Implement with Payload's bulk operation endpoints
49: 
50: ## UI Patterns
51: 
52: - [x] Loading states and spinners - Show during form submission
53: - [x] Success/error notifications - Use Form Builder's confirmation system[1][4]
54: - [x] Form reset strategies - Reset form after successful submission
55: - [x] Conditional field rendering - Implement with React state and useEffect
56: - [x] Accessibility considerations - Use semantic HTML and ARIA attributes
57: 
58: ## Form Builder Best Practices
59: 
60: 1. Use `redirectRelationships` for confirmation page redirection[4]
61: 2. Implement `beforeEmail` hook for custom email templates[4]
62: 3. Set `defaultToEmail` for fallback submission addresses[4]
63: 4. Use `formOverrides` to customize form collection behavior[4]
64: 5. Add reCAPTCHA for spam protection[3]
65: 
66: ## Files to Create
67: 
68: - `best_practices.md` - Form handling best practices
69: - `common_patterns.md` - Reusable form components
70: - `troubleshooting.md` - Common form issues
71: - `integration_guides.md` - Integration with Payload and Tanstack
</file>

<file path="llm_context/payload3/best_practices.md">
 1: # Payload 3 Best Practices
 2: 
 3: ## Collection Design
 4: - [x] Field type selection strategies - Define collections in separate files and import into main config
 5: - [x] Relationship modeling patterns - Use bi-directional relationships with join fields
 6: - [x] Access control implementation - Granular access rules in collection configs
 7: - [x] Validation rule patterns - Zod schema validation with custom errors
 8: - [x] Index optimization - Indexes for frequently queried fields
 9: 
10: ## API Usage
11: - [x] REST vs GraphQL decision criteria - REST for simplicity, GraphQL for complex data
12: - [x] Query optimization techniques - Depth parameters and selective fields
13: - [x] Pagination strategies - Cursor-based pagination for large datasets
14: - [x] Error handling patterns - Standardized error responses
15: - [x] Authentication integration - JWT with refresh tokens
16: 
17: ## Lexical Editor
18: - [x] Custom block creation - Implement through plugin development
19: - [x] Plugin development patterns - Extend core functionality with custom plugins
20: - [x] Content serialization - Server-side serialization for storage
21: - [x] Editor state management - Debounced updates for performance
22: - [x] Performance optimization - Virtualized rendering for large documents
23: 
24: ## Performance
25: - [x] Database query optimization - Indexing and query profiling
26: - [x] Caching strategies - Implement caching for frequent queries
27: - [x] Image optimization - Built-in transformations and CDN delivery
28: - [x] Bundle size management - Code splitting and dynamic imports
29: - [x] Server-side rendering - Next.js SSR for faster initial loads
30: 
31: ## Security
32: - [x] Access control patterns - Role-based access with inheritance
33: - [x] Input validation - Schema-based validation for all inputs
34: - [x] File upload security - Type validation and virus scanning
35: - [x] API rate limiting - Token bucket algorithm
36: - [x] Authentication best practices - Multi-factor authentication
37: - [x] Login security - Implement `maxLoginAttempts` and `lockTime` to prevent brute force attacks[1]
38: - [x] CSRF prevention - Enable CSRF protection for all API endpoints[1][5]
39: - [x] Session management - Use HttpOnly cookies for authentication tokens[5]
40: - [x] Environment security - Store sensitive data in environment variables[3]
41: - [x] Data encryption - Always use HTTPS for data transmission[3]
42: - [x] Audit logging - Implement detailed audit logs for all admin actions using plugins like `payload-auditor`[1][4]
43:   - Configure specific operations to log (create/update/delete)[1]
44:   - Set automated log cleanup with retention policies[1]
45:   - Include user information and payload details in logs[4]
46:   - Restrict access to audit logs using access control[1]
</file>

<file path="llm_context/README.md">
 1: # LLM Context Library
 2: 
 3: This comprehensive context library serves as a central knowledge base for LLM agents working on this Payload 3 + Next.js project. It provides structured documentation, best practices, and actionable guidance across all major technologies and tools used in the project.
 4: 
 5: ## 📁 Library Structure
 6: 
 7: ### Core Technologies
 8: - **[payload3/](./payload3/)** - Payload 3 CMS, Lexical Editor, and data modeling
 9: - **[tanstack/](./tanstack/)** - Query and Tables for data management
10: - **[forms/](./forms/)** - Form submission patterns and validation
11: - **[ui_patterns/](./ui_patterns/)** - Shadcn UI consistency and patterns
12: - **[state_management/](./state_management/)** - Zustand global state patterns
13: 
14: ### Development Tools & Workflows
15: - **[mcp_tools/](./mcp_tools/)** - MCP server tools and integration guides
16: - **[llm_agent_insights/](./llm_agent_insights/)** - Agent-specific considerations and patterns
17: 
18: ## 🎯 Usage Guidelines
19: 
20: Each directory contains:
21: - **README.md** - Overview and quick reference
22: - **best_practices.md** - Proven patterns and approaches
23: - **common_patterns.md** - Frequently used code patterns
24: - **troubleshooting.md** - Common issues and solutions
25: - **integration_guides.md** - How to integrate with other technologies
26: 
27: ## 🔄 Maintenance
28: 
29: This library should be updated as:
30: - New patterns emerge in the codebase
31: - Dependencies are updated
32: - Best practices evolve
33: - New MCP tools are integrated
34: 
35: ## 📖 Quick Start
36: 
37: 1. Navigate to the relevant technology folder
38: 2. Start with the README.md for overview
39: 3. Check best_practices.md for proven approaches
40: 4. Reference common_patterns.md for code examples
41: 5. Use troubleshooting.md when issues arise
42: 
43: ## File Index
44: 
45: ### forms
46: - `complex_forms.md`: Patterns for building multi-step, dynamic, and state-driven forms.
47: - `README.md`: Overview of form submission patterns and libraries.
48: 
49: ### llm_agent_insights
50: - `code_documentation_standards.md`: Standards for JSDoc/TSDoc.
51: - `README.md`: Overview of LLM agent behavior patterns and best practices.
52: 
53: ### mcp_tools
54: - `context7_advanced.md`: Advanced usage of the Context7 MCP tool.
55: - `README.md`: Overview of MCP tool integrations.
56: - `repomix_automation.md`: Guide for automating code context generation with Repomix.
57: 
58: ### payload3
59: - `best_practices.md`: Best practices for Payload 3 collection design, API usage, and security.
60: - `data_models.md`: Overview of data models and relationships in the Payload CMS.
61: - `README.md`: Core concepts of Payload 3.
62: - `user_documentation.md`: User guide for managing data in the Payload CMS.
63: 
64: ### responses
65: - `prompt_template.md`: Template for scripting TypeScript error resolution.
66: - `setup_verification.md`: Checklist for verifying the project setup.
67: - `typescript_error_resolution_v2.md`: Guide for resolving advanced TypeScript errors.
68: - `typescript_errors.md`: Guide for resolving common TypeScript errors.
69: 
70: ### state_management
71: - `README.md`: Overview of Zustand state management patterns.
72: 
73: ### tanstack
74: - `README.md`: Overview of Tanstack Query and Tables implementation.
75: 
76: ### ui_patterns
77: - `README.md`: Overview of Shadcn UI patterns and best practices.
</file>

<file path="prompts/git_update.md">
  1: # Gemini CLI: Git Operations & Taskmaster Integration Workflow
  2: 
  3: You are a Gemini CLI agent responsible for managing Git operations in this repository. Your primary goal is to preserve code integrity, enforce branch discipline, and integrate seamlessly with our Taskmaster-AI MCP workflow for comprehensive project management.
  4: 
  5: ## 1. Repository State Inspection
  6: 
  7: **Initial Assessment:**
  8: 
  9: ```bash
 10: git status
 11: ```
 12: 
 13: **Comprehensive Analysis & Reporting:**
 14: 
 15: - **Uncommitted Changes:** List modified, added, deleted files with counts and file paths
 16: - **Untracked Files:** Identify new files not under version control with full paths
 17: - **Merge Conflicts:** Detect and list conflicting files requiring resolution
 18: - **Branch Status:** Report current branch and any divergence from remote
 19: - **Stash Status:** Check for any stashed changes that might be relevant
 20: 
 21: **Output Format:** Provide clear, structured summary:
 22: 
 23: ```
 24: Repository Status Summary:
 25: - Current Branch: feature/user-auth
 26: - 3 modified files: src/auth.ts, src/types/user.ts, package.json
 27: - 2 untracked files: src/utils/validation.ts, tests/auth.spec.ts
 28: - 1 conflict in: src/auth.ts (lines 45-52)
 29: - Remote status: 2 commits ahead, 0 behind
 30: ```
 31: 
 32: ## 2. Git Issue Resolution
 33: 
 34: ### Uncommitted Changes
 35: 
 36: - **Strategy Assessment:** Analyze changes to determine staging approach
 37: - **Auto-staging Command:**
 38: 
 39:   ```bash
 40:   git add -A
 41:   ```
 42: 
 43: - **Selective Staging:** For complex scenarios, suggest file-specific staging
 44: - **Verification:** Confirm all intended changes are staged
 45: 
 46: ### Merge Conflicts
 47: 
 48: - **Conflict Detection:** List all files with conflict markers (`<<<<<<<`, `=======`, `>>>>>>>`)
 49: - **Resolution Guidance:**
 50:   - Simple conflicts: Recommend manual editing with clear instructions
 51:   - Complex conflicts: Suggest `git mergetool` for GUI resolution
 52:   - Provide file-specific conflict context when possible
 53: - **Validation:** Ensure all conflicts resolved before proceeding
 54: - **Halt Condition:** Stop entire workflow until conflicts are completely resolved
 55: 
 56: ### Unpushed Commits
 57: 
 58: - **Detection Command:**
 59: 
 60:   ```bash
 61:   git log origin/$(git rev-parse --abbrev-ref HEAD)..HEAD --oneline
 62:   ```
 63: 
 64: - **Analysis:** Count unpushed commits and summarize their scope
 65: - **Integration Planning:** Prepare for coordinated push with new commits
 66: 
 67: ## 3. Branch Discipline Enforcement
 68: 
 69: ### Current Branch Analysis
 70: 
 71: ```bash
 72: git rev-parse --abbrev-ref HEAD
 73: ```
 74: 
 75: ### Branch Validation & Enforcement
 76: 
 77: - **Protected Branch Detection:** Flag direct work on `main`, `master`, `develop`
 78: - **Work Classification:**
 79:   - **Feature Work:** Require feature branches (`feature/<task-id>-<description>`)
 80:   - **Bug Fixes:** Require bugfix branches (`bugfix/<issue-id>-<description>`)
 81:   - **Hotfixes:** Allow direct main/master work only for critical production fixes
 82:   - **Chores:** Use chore branches (`chore/<description>`)
 83: 
 84: ### Branch Creation Guidance
 85: 
 86: ```bash
 87: # Suggested branch creation
 88: git checkout -b feature/<task-id>-<short-description>
 89: ```
 90: 
 91: ### Branch Overview
 92: 
 93: ```bash
 94: git branch -a
 95: ```
 96: 
 97: - List all local and remote branches for context
 98: - Identify stale branches that might need cleanup
 99: - Show branch relationships and tracking status
100: 
101: ## 4. Commit Message Generation & Execution
102: 
103: ### Staging Verification
104: 
105: ```bash
106: git add -A
107: ```
108: 
109: ### Conventional Commits Message Generation
110: 
111: **Format:**
112: 
113: ```
114: <type>(<scope>): <short description>
115: 
116: [Optional body with detailed explanation]
117: 
118: [TASK-<ID>] (if related to Taskmaster-AI task)
119: [Closes #<issue>] (if applicable)
120: ```
121: 
122: **Commit Types:**
123: 
124: - `feat`: New features
125: - `fix`: Bug fixes
126: - `docs`: Documentation changes
127: - `style`: Code style changes (formatting, missing semicolons, etc.)
128: - `refactor`: Code refactoring without feature changes
129: - `test`: Adding or updating tests
130: - `chore`: Maintenance tasks, dependency updates
131: - `build`: Build system or external dependency changes
132: - `ci`: CI/CD configuration changes
133: - `perf`: Performance improvements
134: - `revert`: Reverting previous commits
135: 
136: **Scope Examples:** `auth`, `ui`, `api`, `database`, `config`, `utils`
137: 
138: ### Taskmaster-AI Integration
139: 
140: - **Task Reference:** Include `[TASK-<ID>]` when work relates to specific Taskmaster tasks
141: - **Status Correlation:** Align commit with task progression (implementation → review → completion)
142: - **Context Preservation:** Reference task details in commit body when relevant
143: 
144: ### Commit Execution
145: 
146: ```bash
147: git commit -m "<generated-message>"
148: ```
149: 
150: ### Push Strategy
151: 
152: ```bash
153: # For new branches
154: git push --set-upstream origin <branch-name>
155: 
156: # For existing branches
157: git push
158: ```
159: 
160: ## 5. Taskmaster-AI MCP Integration
161: 
162: ### Post-Commit Workflow
163: 
164: After successful commit and push:
165: 
166: 1. **Task Status Assessment:**
167:    - Determine if Taskmaster task status should be updated
168:    - Common progressions: `pending` → `in-progress` → `review` → `done`
169: 
170: 2. **Status Update Recommendations:**
171:    - **Implementation Complete:** Suggest `review` status
172:    - **Feature Complete & Tested:** Suggest `done` status
173:    - **Partial Progress:** Suggest `in-progress` status
174:    - **Blocked by Dependencies:** Suggest `blocked` status
175: 
176: 3. **Integration Prompts:**
177: 
178:    ```
179:    Commit successful! Taskmaster-AI Integration:
180:    - Task TASK-123 appears to be implementation-complete
181:    - Suggested status update: 'review'
182:    - Recommended next action: Create pull request for code review
183:    ```
184: 
185: ### Taskmaster Context Awareness
186: 
187: - **Branch-Task Correlation:** Link git branches to Taskmaster task contexts
188: - **Progress Tracking:** Suggest task updates based on commit content and scope
189: - **Dependency Management:** Alert about task dependencies that might be affected
190: 
191: ## 6. Advanced Git Operations & Best Practices
192: 
193: ### Repository Hygiene
194: 
195: - **Atomic Commits:** Encourage focused, single-purpose commits
196: - **Commit Frequency:** Suggest regular commits for complex features
197: - **Branch Cleanup:** Recommend deletion of merged feature branches
198: 
199: ### History Management
200: 
201: - **Interactive Rebase Suggestions:**
202: 
203:   ```bash
204:   git rebase -i HEAD~<N>
205:   ```
206: 
207:   - Suggest only when history is messy and branch is not shared
208:   - Require explicit user confirmation before executing
209:   - Provide clear warnings about rebase risks
210: 
211: ### Collaboration Considerations
212: 
213: - **Remote Synchronization:** Check for remote changes before pushing
214: - **Conflict Prevention:** Suggest regular pulls from main branch
215: - **Team Coordination:** Alert about potential conflicts with shared branches
216: 
217: ## 7. Error Handling & Recovery
218: 
219: ### Common Git Issues
220: 
221: - **Detached HEAD:** Provide recovery instructions
222: - **Failed Pushes:** Analyze rejection reasons and suggest solutions
223: - **Corrupted Repository:** Offer diagnostic and repair commands
224: - **Lost Commits:** Guide through reflog recovery
225: 
226: ### Rollback Strategies
227: 
228: - **Soft Reset:** For uncommitted changes
229: - **Hard Reset:** For complete rollback (with warnings)
230: - **Revert:** For published commits that need undoing
231: 
232: ## 8. Output Format & Communication
233: 
234: ### Command Execution Plan
235: 
236: Before executing any commands, provide:
237: 
238: ```
239: Git Operations Plan:
240: 1. Check repository status
241: 2. Resolve 1 merge conflict in src/auth.ts
242: 3. Stage all changes (3 files)
243: 4. Generate conventional commit message
244: 5. Commit with message: "feat(auth): implement JWT token validation [TASK-123]"
245: 6. Push to origin/feature/auth-validation
246: 7. Suggest Taskmaster status update: pending → review
247: ```
248: 
249: ### Progress Reporting
250: 
251: - **Step-by-step execution** with clear status indicators
252: - **Command output summaries** rather than raw git output
253: - **Next action recommendations** for both Git and Taskmaster workflows
254: - **Error explanations** with suggested remediation steps
255: 
256: ### Integration Recommendations
257: 
258: ```
259: Post-Commit Recommendations:
260: ✅ Code committed successfully
261: 🔄 Suggested Taskmaster update: Set TASK-123 to 'review'
262: 📋 Next steps: 
263:    - Create pull request for code review
264:    - Update task documentation if needed
265:    - Notify team members if collaboration required
266: ```
267: 
268: ## 9. Workflow Customization
269: 
270: ### Project-Specific Adaptations
271: 
272: - **Branch Naming Conventions:** Adapt to project standards
273: - **Commit Message Templates:** Customize for team preferences
274: - **Integration Depth:** Adjust Taskmaster integration based on project setup
275: - **Automation Level:** Scale from manual guidance to automated execution
276: 
277: ### Context Awareness
278: 
279: - **Repository Type:** Adjust workflow for different project types (library, application, documentation)
280: - **Team Size:** Modify collaboration recommendations based on team structure
281: - **Development Stage:** Adapt rigor based on project maturity (prototype vs. production)
282: 
283: ---
284: 
285: **Usage Instructions:**
286: This prompt is designed for direct use with Gemini CLI. The agent will execute this workflow step-by-step, providing clear command plans, executing Git operations, and offering Taskmaster-AI integration recommendations. Each step includes verification and user confirmation before proceeding to ensure safe and effective Git management.
</file>

<file path="src/app/(frontend)/components/forms/DynamicForm.tsx">
  1: 'use client'
  2: 
  3: import React, { useEffect, useMemo, useState } from 'react'
  4: import { FieldValues } from 'react-hook-form'
  5: import debounce from 'lodash.debounce'
  6: import FieldRegistry from '@/app/(frontend)/components/forms/FieldRegistry'
  7: import { useCollectionSchema } from '@/app/(frontend)/hooks/useCollectionSchema'
  8: import { z } from 'zod'
  9: import { zodResolver } from '@hookform/resolvers/zod'
 10: import { FormProvider, useForm } from 'react-hook-form'
 11: 
 12: interface DynamicFormProps {
 13:   collectionSlug: string
 14:   onSubmit: (data: FieldValues) => void
 15:   className?: string
 16: }
 17: 
 18: /**
 19:  * @description A dynamic form component that generates form fields based on a Payload collection schema.
 20:  * @param {DynamicFormProps} { collectionSlug, onSubmit, className }
 21:  * @returns {React.ReactElement}
 22:  */
 23: const DynamicForm: React.FC<DynamicFormProps> = ({ collectionSlug, onSubmit, className }) => {
 24:   const { data: schema, isLoading, isError, error } = useCollectionSchema(collectionSlug)
 25: 
 26:   const [isMounted, setIsMounted] = useState(false)
 27: 
 28:   const dynamicZodSchema = useMemo(() => {
 29:     if (!schema) return z.object({})
 30: 
 31:     const schemaFields = schema.fields.reduce((acc, field) => {
 32:       let fieldSchema: z.ZodTypeAny
 33:       switch (field.type) {
 34:         case 'text':
 35:         case 'email':
 36:         case 'password':
 37:           fieldSchema = z.string()
 38:           break
 39:         case 'number':
 40:           fieldSchema = z.number()
 41:           break
 42:         case 'checkbox':
 43:           fieldSchema = z.boolean()
 44:           break
 45:         case 'select':
 46:           fieldSchema = z.string()
 47:           if (field.hasMany) {
 48:             fieldSchema = z.array(z.string())
 49:           }
 50:           break
 51:         default:
 52:           fieldSchema = z.any()
 53:           break
 54:       }
 55: 
 56:       if (field.required) {
 57:         if ('min' in fieldSchema) {
 58:           fieldSchema = (fieldSchema as z.ZodString | z.ZodArray<any>).min(
 59:             1,
 60:             `${field.label || field.name} is required`,
 61:           )
 62:         }
 63:       }
 64: 
 65:       if (field.type === 'number') {
 66:         if (field.min !== undefined) {
 67:           fieldSchema = (fieldSchema as z.ZodNumber).min(field.min, `Must be at least ${field.min}`)
 68:         }
 69:         if (field.max !== undefined) {
 70:           fieldSchema = (fieldSchema as z.ZodNumber).max(field.max, `Must be at most ${field.max}`)
 71:         }
 72:       }
 73: 
 74:       if (field.type === 'text' || field.type === 'email' || field.type === 'password') {
 75:         if (field.maxLength !== undefined) {
 76:           fieldSchema = (fieldSchema as z.ZodString).max(
 77:             field.maxLength,
 78:             `Must be at most ${field.maxLength} characters`,
 79:           )
 80:         }
 81:       }
 82: 
 83:       return { ...acc, [field.name]: fieldSchema }
 84:     }, {})
 85: 
 86:     return z.object(schemaFields)
 87:   }, [schema])
 88: 
 89:   useEffect(() => {
 90:     setIsMounted(true)
 91:   }, [])
 92: 
 93:   const formMethods = useForm({
 94:     resolver: zodResolver(dynamicZodSchema),
 95:     mode: 'onChange',
 96:     reValidateMode: 'onChange',
 97:   })
 98: 
 99:   const debouncedSubmit = useMemo(
100:     () => debounce(formMethods.handleSubmit(onSubmit), 500),
101:     [formMethods, onSubmit],
102:   )
103: 
104:   if (isLoading || !isMounted) {
105:     return <div>Loading form schema...</div>
106:   }
107: 
108:   if (isError) {
109:     return <div>Error loading form schema: {error?.message}</div>
110:   }
111: 
112:   if (!schema || schema.fields.length === 0) {
113:     return <div>No schema found for {collectionSlug} or no fields defined.</div>
114:   }
115: 
116:   return (
117:     <FormProvider {...formMethods}>
118:       <form onSubmit={debouncedSubmit} className={className}>
119:         {schema.fields.map((field, index) => (
120:           <FieldRegistry key={`${field.name}-${index}`} field={field} formMethods={formMethods} />
121:         ))}
122:         <button type="submit">Submit</button>
123:       </form>
124:     </FormProvider>
125:   )
126: }
127: 
128: export default DynamicForm
</file>

<file path="src/app/(frontend)/components/forms/FieldRegistry.tsx">
 1: import React from 'react'
 2: import { FieldValues, UseFormReturn } from 'react-hook-form'
 3: import { InputField } from './InputField'
 4: import { SelectField } from './SelectField'
 5: import { ArrayField } from './ArrayField' // Placeholder
 6: import { TabbedField } from './TabbedField' // Placeholder
 7: import { PayloadField } from '@/app/(frontend)/hooks/useCollectionSchema'
 8: 
 9: interface FieldRegistryProps<TFormValues extends FieldValues> {
10:   field: PayloadField
11:   formMethods: UseFormReturn<TFormValues>
12: }
13: 
14: /**
15:  * @description A registry component that renders different form fields based on their type.
16:  * @template TFormValues
17:  * @param {FieldRegistryProps<TFormValues>} { field, formMethods }
18:  * @returns {React.ReactElement}
19:  */
20: const FieldRegistry = <TFormValues extends FieldValues>({
21:   field,
22:   formMethods,
23: }: FieldRegistryProps<TFormValues>) => {
24:   const {
25:     formState: { errors },
26:   } = formMethods
27:   const error = errors[field.name]
28: 
29:   switch (field.type) {
30:     case 'text':
31:     case 'email':
32:     case 'password':
33:     case 'number':
34:       return (
35:         <div>
36:           <InputField
37:             name={field.name}
38:             label={field.label}
39:             type={field.type}
40:             placeholder={field.admin?.placeholder || field.label}
41:             aria-invalid={!!error}
42:             {...formMethods.register(field.name)}
43:           />
44:           {error && (
45:             <span role="alert" style={{ color: 'red' }}>
46:               {error.message?.toString()}
47:             </span>
48:           )}
49:         </div>
50:       )
51:     case 'select':
52:       return (
53:         <div>
54:           <SelectField
55:             name={field.name}
56:             label={field.label}
57:             options={field.options || []}
58:             placeholder={field.admin?.placeholder || field.label}
59:             aria-invalid={!!error}
60:           />
61:           {error && (
62:             <span role="alert" style={{ color: 'red' }}>
63:               {error.message?.toString()}
64:             </span>
65:           )}
66:         </div>
67:       )
68:     case 'array':
69:       return <ArrayField field={field} formMethods={formMethods} />
70:     case 'tabs':
71:       return <TabbedField field={field} formMethods={formMethods} />
72:     // TODO: Add more cases for other field types (checkbox, relationship, richText, etc.)
73:     default:
74:       return <p>Unknown or unsupported field type: {field.type}</p>
75:   }
76: }
77: 
78: export default FieldRegistry
</file>

<file path="src/app/(frontend)/components/forms/FormWrapper.tsx">
 1: 'use client'
 2: 
 3: import React from 'react'
 4: import { useForm, FormProvider, UseFormProps, UseFormReturn } from 'react-hook-form'
 5: import { ZodSchema, z } from 'zod'
 6: import { zodResolver } from '@hookform/resolvers/zod'
 7: import { FieldValues } from 'react-hook-form'
 8: 
 9: interface FormWrapperProps<TFormValues extends FieldValues> {
10:   children: (methods: UseFormReturn<TFormValues>) => React.ReactNode
11:   onSubmit: (data: TFormValues) => void
12:   schema: ZodSchema<TFormValues>
13:   options?: UseFormProps<TFormValues>
14:   className?: string
15: }
16: 
17: /**
18:  * @description A wrapper component for react-hook-form that provides a FormProvider and handles form submission.
19:  * @template TFormValues
20:  * @param {FormWrapperProps<TFormValues>} props
21:  * @returns {React.ReactElement}
22:  */
23: export const FormWrapper = <TFormValues extends FieldValues>({
24:   children,
25:   onSubmit,
26:   schema,
27:   options,
28:   className,
29: }: FormWrapperProps<TFormValues>) => {
30:   const methods = useForm<TFormValues>({
31:     ...options,
32:     resolver: zodResolver(schema),
33:   })
34: 
35:   return (
36:     <FormProvider {...methods}>
37:       <form onSubmit={methods.handleSubmit(onSubmit)} className={className}>
38:         {children(methods)}
39:       </form>
40:     </FormProvider>
41:   )
42: }
43: 
44: // Re-exporting for convenience
45: export { useForm, zodResolver, z }
46: export type { UseFormReturn }
</file>

<file path="src/app/(frontend)/lib/QueryClientProviderWrapper.tsx">
 1: 'use client'
 2: 
 3: import React, { useState } from 'react'
 4: import { QueryClient, QueryClientProvider } from '@tanstack/react-query'
 5: import { persistQueryClient } from '@tanstack/react-query-persist-client'
 6: import { createSyncStoragePersister } from '@tanstack/query-sync-storage-persister'
 7: import { ReactQueryDevtools } from '@tanstack/react-query-devtools'
 8: 
 9: interface QueryClientProviderWrapperProps {
10:   children: React.ReactNode
11: }
12: 
13: /**
14:  * @description Provides a QueryClient to the application and persists its state.
15:  * @param {QueryClientProviderWrapperProps} { children }
16:  * @returns {React.ReactElement}
17:  */
18: /**
19:  * @description Provides a QueryClient to the application and persists its state.
20:  * @param {QueryClientProviderWrapperProps} { children }
21:  * @returns {React.ReactElement}
22:  */
23: export const QueryClientProviderWrapper: React.FC<QueryClientProviderWrapperProps> = ({
24:   children,
25: }) => {
26:   const [queryClient] = useState(
27:     () =>
28:       new QueryClient({
29:         defaultOptions: {
30:           queries: {
31:             gcTime: 1000 * 60 * 60 * 24, // 24 hours
32:           },
33:         },
34:       }),
35:   )
36: 
37:   const persister = createSyncStoragePersister({
38:     storage: typeof window !== 'undefined' ? window.localStorage : undefined,
39:   })
40: 
41:   React.useEffect(() => {
42:     if (typeof window !== 'undefined') {
43:       const setupPersistence = async () => {
44:         await persistQueryClient({
45:           queryClient,
46:           persister,
47:           maxAge: 1000 * 60 * 60 * 24 * 7, // 1 week
48:         })
49:         queryClient.resumePausedMutations()
50:       }
51: 
52:       setupPersistence()
53:     }
54:   }, [queryClient, persister])
55: 
56:   return (
57:     <QueryClientProvider client={queryClient}>
58:       {children}
59:       <ReactQueryDevtools initialIsOpen={false} />
60:     </QueryClientProvider>
61:   )
62: }
</file>

<file path="src/app/(frontend)/page.tsx">
 1: 'use client'
 2: 
 3: import Image from 'next/image'
 4: import React from 'react'
 5: import './styles.css'
 6: import { useAuthQuery } from './hooks/useAuthQuery'
 7: 
 8: /**
 9:  * @description The home page for the frontend application.
10:  * @returns {React.ReactElement}
11:  */
12: export default function HomePage() {
13:   const {
14:     data: user,
15:     isLoading,
16:     isError,
17:   } = useAuthQuery(
18:     ['currentUser'],
19:     async ({ signal }) => {
20:       const response = await fetch('/api/users/me', { signal })
21:       if (!response.ok) {
22:         throw new Error('Failed to fetch user data')
23:       }
24:       return response.json()
25:     },
26:     { requireAuth: false }, // This page can be viewed by unauthenticated users
27:   )
28: 
29:   // Create VSCode link using client-side only approach to prevent hydration mismatch
30:   const [fileURL, setFileURL] = React.useState('')
31: 
32:   React.useEffect(() => {
33:     // Only set the URL on the client side to ensure consistent rendering
34:     setFileURL(`vscode://file${process.cwd()}/src/app/(frontend)/page.tsx`)
35:   }, [])
36: 
37:   return (
38:     <div className="home">
39:       <div className="content">
40:         <picture>
41:           <source srcSet="https://raw.githubusercontent.com/payloadcms/payload/main/packages/ui/src/assets/payload-favicon.svg" />
42:           <Image
43:             alt="Payload Logo"
44:             height={65}
45:             src="https://raw.githubusercontent.com/payloadcms/payload/main/packages/ui/src/assets/payload-favicon.svg"
46:             width={65}
47:           />
48:         </picture>
49:         {isLoading && <h1>Loading user data...</h1>}
50:         {isError && <h1>Error loading user data.</h1>}
51:         {!isLoading && !isError && !user && <h1>Welcome to your new project.</h1>}
52:         {!isLoading && !isError && user && <h1>Welcome back, {user.email}</h1>}
53:         <div className="links">
54:           <a className="admin" href="/admin" rel="noopener noreferrer" target="_blank">
55:             Go to admin panel
56:           </a>
57:           <a
58:             className="docs"
59:             href="https://payloadcms.com/docs"
60:             rel="noopener noreferrer"
61:             target="_blank"
62:           >
63:             Documentation
64:           </a>
65:         </div>
66:       </div>
67:       <div className="footer">
68:         <p>Update this page by editing</p>
69:         <a className="codeLink" href={fileURL}>
70:           <code>app/(frontend)/page.tsx</code>
71:         </a>
72:       </div>
73:     </div>
74:   )
75: }
</file>

<file path="src/collections/DietaryRestrictions.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: export const DietaryRestrictions: CollectionConfig = {
 5:   slug: 'dietary-restrictions',
 6:   admin: {
 7:     useAsTitle: 'name',
 8:     defaultColumns: ['name', 'description'],
 9:     description: 'Manage common dietary restrictions and allergies.',
10:   },
11:   access: {
12:     create: isAdminOrManager,
13:     read: isAuthenticated, // Authenticated read access for menu display, etc.
14:     update: isAdminOrManager,
15:     delete: isAdmin,
16:   },
17:   fields: [
18:     {
19:       name: 'name',
20:       label: 'Restriction Name',
21:       type: 'text',
22:       required: true,
23:       unique: true,
24:       index: true,
25:       maxLength: 100,
26:       admin: {
27:         description: 'e.g., Gluten-Free, Vegan, Nut Allergy, Dairy-Free',
28:       },
29:     },
30:     {
31:       name: 'description',
32:       label: 'Description',
33:       type: 'textarea',
34:       maxLength: 500,
35:       admin: {
36:         description: 'Optional: Provide more details about this restriction.',
37:       },
38:     },
39:   ],
40: };
</file>

<file path="src/collections/DrinkMenuItems.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: export const DrinkMenuItems: CollectionConfig = {
 5:   slug: 'drinkMenuItems',
 6:   admin: {
 7:     useAsTitle: 'name',
 8:   },
 9:   access: {
10:     create: isAdminOrManager,
11:     read: isAuthenticated,
12:     update: isAdminOrManager,
13:     delete: isAdmin,
14:   },
15:   fields: [
16:     {
17:       name: 'name',
18:       type: 'text',
19:       required: true,
20:     },
21:     {
22:       name: 'description',
23:       type: 'textarea',
24:     },
25:     {
26:       name: 'price',
27:       type: 'number',
28:       min: 0,
29:       required: true,
30:     },
31:     {
32:       name: 'category',
33:       type: 'relationship',
34:       relationTo: 'drinkSubcategories',
35:       required: true,
36:     },
37:     {
38:       name: 'active',
39:       type: 'checkbox',
40:       defaultValue: true,
41:     },
42:   ],
43: };
</file>

<file path="src/collections/DrinkSubcategories.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: /**
 5:  * @description Drink Subcategories collection configuration.
 6:  */
 7: export const DrinkSubcategories: CollectionConfig = {
 8:   slug: 'drinkSubcategories',
 9:   admin: {
10:     useAsTitle: 'name',
11:   },
12:   access: {
13:     read: isAuthenticated,
14:   },
15:   fields: [
16:     {
17:       name: 'name',
18:       type: 'text',
19:       required: true,
20:       unique: true,
21:     },
22:   ],
23: };
</file>

<file path="src/collections/Features.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAuthenticated } from '../access';
 3: 
 4: export const Features: CollectionConfig = {
 5:   slug: 'features',
 6:   admin: {
 7:     useAsTitle: 'name',
 8:   },
 9:   access: {
10:     read: isAuthenticated,
11:     update: isAdmin,
12:   },
13:   fields: [
14:     {
15:       name: 'name',
16:       type: 'text',
17:       required: true,
18:       unique: true,
19:     },
20:     {
21:       name: 'enabled',
22:       type: 'checkbox',
23:       defaultValue: false,
24:     },
25:   ],
26: };
</file>

<file path="src/collections/Jobs.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: /**
 5:  * @description Jobs collection configuration.
 6:  */
 7: export const Jobs: CollectionConfig = {
 8:   slug: 'jobs',
 9:   admin: {
10:     useAsTitle: 'name',
11:   },
12:   access: {
13:     read: isAuthenticated,
14:   },
15:   fields: [
16:     {
17:       name: 'name',
18:       type: 'text',
19:       required: true,
20:       unique: true,
21:     },
22:   ],
23: };
</file>

<file path="src/collections/Locations.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: export const Locations: CollectionConfig = {
 5:   slug: 'locations',
 6:   admin: {
 7:     useAsTitle: 'name',
 8:     defaultColumns: ['name', 'city', 'state', 'phone'],
 9:   },
10:   access: {
11:     create: isAdminOrManager,
12:     read: isAuthenticated, // All authenticated users can read locations
13:     update: isAdminOrManager,
14:     delete: isAdmin,
15:   },
16:   fields: [
17:     {
18:       name: 'name',
19:       type: 'text',
20:       required: true,
21:       unique: true,
22:     },
23:     {
24:       name: 'address',
25:       type: 'text',
26:       required: true,
27:     },
28:     {
29:       name: 'city',
30:       type: 'text',
31:       required: true,
32:     },
33:     {
34:       name: 'state',
35:       type: 'text',
36:       required: true,
37:     },
38:     {
39:       name: 'zip',
40:       type: 'text',
41:       required: true,
42:     },
43:     {
44:       name: 'phone',
45:       type: 'text',
46:     },
47:     {
48:       name: 'email',
49:       type: 'email',
50:     },
51:   ],
52: };
</file>

<file path="src/collections/Media.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAuthenticated, isOwnerOrAdmin } from '../access';
 3: 
 4: 
 5: export const Media: CollectionConfig = {
 6:   slug: 'media',
 7:   upload: {
 8:     imageSizes: [
 9:       {
10:         name: 'thumbnail',
11:         width: 400,
12:         height: 300,
13:         position: 'centre',
14:       },
15:       {
16:         name: 'card',
17:         width: 768,
18:         height: 1024,
19:         position: 'centre',
20:       },
21:       {
22:         name: 'tablet',
23:         width: 1024,
24:         height: undefined,
25:         position: 'centre',
26:       },
27:     ],
28:     adminThumbnail: 'thumbnail',
29:     mimeTypes: ['image/*', 'application/pdf', 'video/*'],
30:   },
31:   access: {
32:     create: isAuthenticated,
33:     read: isAuthenticated, // Public read access for media
34:     update: isOwnerOrAdmin('uploadedBy'),
35:     delete: isOwnerOrAdmin('uploadedBy'),
36:   },
37:   fields: [
38:     {
39:       name: 'alt',
40:       type: 'text',
41:       label: 'Alt Text',
42:       required: false,
43:     },
44:     {
45:       name: 'caption',
46:       type: 'textarea',
47:       label: 'Caption',
48:       required: false,
49:     },
50:     {
51:       name: 'uploadedBy',
52:       type: 'relationship',
53:       relationTo: 'users',
54:       required: true,
55:       admin: {
56:         position: 'sidebar',
57:       },
58:     },
59:   ],
60:   hooks: {
61:     beforeChange: [
62:       ({ data, req }) => {
63:         // Automatically set uploadedBy to current user
64:         if (req.user && !data.uploadedBy) {
65:           data.uploadedBy = req.user.id;
66:         }
67:         return data;
68:       },
69:     ],
70:   },
71: };
</file>

<file path="src/collections/Messages.ts">
  1: import { CollectionConfig } from 'payload';
  2: import { isAdmin, isAdminOrManager } from '../access';
  3: 
  4: /**
  5:  * @description Messages collection configuration.
  6:  */
  7: export const Messages: CollectionConfig = {
  8:   slug: 'messages',
  9:   admin: {
 10:     useAsTitle: 'subject',
 11:     defaultColumns: ['subject', 'from_name', 'from_email', 'status', 'date_created'],
 12:     group: 'Communications',
 13:     description: 'Customer messages and inquiries'
 14:   },
 15:   access: {
 16:     read: isAdminOrManager,
 17:     create: () => true, // Public can create (contact form submissions)
 18:     update: isAdminOrManager,
 19:     delete: isAdmin,
 20:   },
 21:   fields: [
 22:     {
 23:       name: 'status',
 24:       type: 'select',
 25:       options: [
 26:         { label: 'New', value: 'new' },
 27:         { label: 'In Progress', value: 'in_progress' },
 28:         { label: 'Resolved', value: 'resolved' },
 29:         { label: 'Archived', value: 'archived' }
 30:       ],
 31:       defaultValue: 'new',
 32:       admin: {
 33:         position: 'sidebar' as const
 34:       }
 35:     },
 36:     {
 37:       name: 'priority',
 38:       type: 'select',
 39:       options: [
 40:         { label: 'Low', value: 'low' },
 41:         { label: 'Normal', value: 'normal' },
 42:         { label: 'High', value: 'high' },
 43:         { label: 'Urgent', value: 'urgent' }
 44:       ],
 45:       defaultValue: 'normal',
 46:       admin: {
 47:         position: 'sidebar'
 48:       }
 49:     },
 50:     {
 51:       name: 'subject',
 52:       type: 'text',
 53:       required: true,
 54:       admin: {
 55:         description: 'Message subject line'
 56:       }
 57:     },
 58:     {
 59:       type: 'row',
 60:       fields: [
 61:         {
 62:           name: 'from_name',
 63:           type: 'text',
 64:           required: true,
 65:           admin: {
 66:             width: '50%'
 67:           }
 68:         },
 69:         {
 70:           name: 'from_email',
 71:           type: 'email',
 72:           required: true,
 73:           admin: {
 74:             width: '50%'
 75:           }
 76:         }
 77:       ]
 78:     },
 79:     {
 80:       type: 'row',
 81:       fields: [
 82:         {
 83:           name: 'from_phone',
 84:           type: 'text',
 85:           admin: {
 86:             width: '50%'
 87:           }
 88:         },
 89:         {
 90:           name: 'location',
 91:           type: 'relationship',
 92:           relationTo: 'locations',
 93:           admin: {
 94:             width: '50%',
 95:             description: 'Related location (if applicable)'
 96:           }
 97:         }
 98:       ]
 99:     },
100:     {
101:       name: 'message_type',
102:       type: 'relationship',
103:       relationTo: 'message-types',
104:       required: true,
105:       admin: {
106:         description: 'Type of message (e.g., General Inquiry, Complaint).',
107:       },
108:     },
109:     {
110:       name: 'message',
111:       type: 'richText',
112:       required: true,
113:       admin: {
114:         description: 'Customer message content'
115:       }
116:     },
117:     {
118:       name: 'internal_notes',
119:       type: 'richText',
120:       admin: {
121:         description: 'Internal staff notes (not visible to customer)'
122:       }
123:     },
124:     {
125:       name: 'assigned_to',
126:       type: 'relationship',
127:       relationTo: 'users',
128:       admin: {
129:         description: 'Staff member assigned to handle this message'
130:       }
131:     },
132:     {
133:       name: 'response_sent',
134:       type: 'checkbox',
135:       defaultValue: false,
136:       admin: {
137:         position: 'sidebar'
138:       }
139:     },
140:     {
141:       name: 'response_date',
142:       type: 'date',
143:       admin: {
144:         position: 'sidebar',
145:         date: {
146:           pickerAppearance: 'dayAndTime'
147:         }
148:       }
149:     },
150:     {
151:       name: 'attachments',
152:       type: 'relationship',
153:       relationTo: 'media',
154:       hasMany: true,
155:       admin: {
156:         description: 'Files attached to the message'
157:       }
158:     }
159:   ],
160:   timestamps: true,
161:   hooks: {
162:     beforeChange: [
163:       /**
164:        * @description Hook to set response_date and validate email format before changing a message.
165:        * @param {object} args
166:        * @param {object} args.data - The data being saved.
167:        * @param {string} args.operation - The operation being performed (e.g., 'create', 'update').
168:        * @returns {object} The modified data.
169:        */
170:       ({ data, operation: _operation }: { data: any; operation: string }) => {
171:         // Auto-set response_date when response_sent is marked true
172:         if (data.response_sent && !data.response_date) {
173:           data.response_date = new Date().toISOString()
174:         }
175:         
176:         // Validate email format
177:         if (data.from_email && !data.from_email.includes('@')) {
178:           throw new Error('Invalid email format')
179:         }
180:         
181:         return data
182:       }
183:     ],
184:     afterChange: [
185:       /**
186:        * @description Hook to send notification to assigned staff member after a message changes.
187:        * @param {object} args
188:        * @param {object} args.doc - The document after the change.
189:        * @param {string} args.operation - The operation being performed (e.g., 'create', 'update').
190:        * @returns {void}
191:        */
192:       ({ doc, operation: _operation }: { doc: any; operation: string }) => {
193:         // Send notification to assigned staff member
194:         if (_operation === 'create' && doc.assigned_to) {
195:           // TODO: Implement email notification system
196:           console.log(`New message assigned to user ${doc.assigned_to}`)
197:         }
198:       }
199:     ]
200:   }
201: }
</file>

<file path="src/collections/MessageTypes.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: export const MessageTypes: CollectionConfig = {
 5:   slug: 'message-types',
 6:   admin: {
 7:     useAsTitle: 'name',
 8:     defaultColumns: ['name'],
 9:     description: 'Manage different types of customer messages (e.g., General Inquiry, Complaint).',
10:   },
11:   access: {
12:     create: isAdminOrManager,
13:     read: isAuthenticated, // Public read access
14:     update: isAdminOrManager,
15:     delete: isAdmin,
16:   },
17:   fields: [
18:     {
19:       name: 'name',
20:       label: 'Message Type Name',
21:       type: 'text',
22:       required: true,
23:       unique: true,
24:       index: true,
25:       maxLength: 100,
26:     },
27:   ],
28: };
</file>

<file path="src/collections/ReviewKeywords.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: export const ReviewKeywords: CollectionConfig = {
 5:   slug: 'reviewKeywords',
 6:   admin: {
 7:     useAsTitle: 'keyword',
 8:   },
 9:   access: {
10:     create: isAdminOrManager,
11:     read: isAuthenticated,
12:     update: isAdminOrManager,
13:     delete: isAdmin,
14:   },
15:   fields: [
16:     {
17:       name: 'keyword',
18:       type: 'text',
19:       required: true,
20:       unique: true,
21:     },
22:   ],
23: };
</file>

<file path="src/collections/Reviews.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAdminOrManager, isAuthenticated } from '../access';
 3: 
 4: export const Reviews: CollectionConfig = {
 5:   slug: 'reviews',
 6:   admin: {
 7:     useAsTitle: 'title',
 8:   },
 9:   access: {
10:     create: isAuthenticated,
11:     read: isAuthenticated,
12:     update: isAdminOrManager,
13:     delete: isAdmin,
14:   },
15:   fields: [
16:     {
17:       name: 'title',
18:       type: 'text',
19:       required: true,
20:     },
21:     {
22:       name: 'rating',
23:       type: 'number',
24:       min: 1,
25:       max: 5,
26:       required: true,
27:     },
28:     {
29:       name: 'comment',
30:       type: 'textarea',
31:     },
32:     {
33:       name: 'user',
34:       type: 'relationship',
35:       relationTo: 'users',
36:       required: true,
37:     },
38:     {
39:       name: 'location',
40:       type: 'relationship',
41:       relationTo: 'locations',
42:       required: true,
43:     },
44:     {
45:       name: 'keywords',
46:       type: 'relationship',
47:       relationTo: 'reviewKeywords',
48:       hasMany: true,
49:     },
50:   ],
51: };
</file>

<file path="src/collections/Upgrades.ts">
  1: import type { CollectionConfig } from 'payload'
  2: import { isAdmin, isAdminOrManager, isAdminOrHasLocationAccess, isAuthenticated } from '../access';
  3: 
  4: /**
  5:  * @description Upgrades collection configuration.
  6:  */
  7: export const Upgrades: CollectionConfig = {
  8:   slug: 'upgrades',
  9:   admin: {
 10:     useAsTitle: 'name',
 11:     defaultColumns: ['name', 'location', 'upgrade_type', 'status', 'date_created'],
 12:     group: 'Data',
 13:     description: 'System and facility upgrades tracking'
 14:   },
 15:   access: {
 16:     read: isAuthenticated,
 17:     create: isAdmin,
 18:     update: isAdmin,
 19:     delete: isAdmin,
 20:   },
 21:   fields: [
 22:     {
 23:       name: 'name',
 24:       type: 'text',
 25:       required: true,
 26:       admin: {
 27:         description: 'Name or title of the upgrade'
 28:       }
 29:     },
 30:     {
 31:       name: 'location',
 32:       type: 'relationship',
 33:       relationTo: 'locations',
 34:       admin: {
 35:         position: 'sidebar',
 36:         description: 'Location where upgrade is being implemented'
 37:       }
 38:     },
 39:     {
 40:       name: 'upgrade_type',
 41:       type: 'relationship',
 42:       relationTo: 'upgrade-types',
 43:       required: true,
 44:       admin: {
 45:         description: 'Type of upgrade being performed'
 46:       }
 47:     },
 48:     {
 49:       name: 'status',
 50:       type: 'select',
 51:       options: [
 52:         { label: 'Planned', value: 'planned' },
 53:         { label: 'In Progress', value: 'in_progress' },
 54:         { label: 'Completed', value: 'completed' },
 55:         { label: 'On Hold', value: 'on_hold' },
 56:         { label: 'Cancelled', value: 'cancelled' }
 57:       ],
 58:       defaultValue: 'planned',
 59:       admin: {
 60:         position: 'sidebar'
 61:       }
 62:     },
 63:     {
 64:       name: 'description',
 65:       type: 'richText',
 66:       admin: {
 67:         description: 'Detailed description of the upgrade'
 68:       }
 69:     },
 70:     {
 71:       name: 'cost',
 72:       type: 'number',
 73:       min: 0,
 74:       admin: {
 75:         description: 'Estimated or actual cost of the upgrade'
 76:       }
 77:     },
 78:     {
 79:       name: 'vendor',
 80:       type: 'relationship',
 81:       relationTo: 'contacts',
 82:       admin: {
 83:         description: 'Vendor or contractor performing the upgrade',
 84:       },
 85:     },
 86:     {
 87:       name: 'scheduled_date',
 88:       type: 'date',
 89:       admin: {
 90:         description: 'Scheduled start date for the upgrade',
 91:         date: {
 92:           pickerAppearance: 'dayOnly'
 93:         }
 94:       }
 95:     },
 96:     {
 97:       name: 'completion_date',
 98:       type: 'date',
 99:       admin: {
100:         description: 'Actual completion date',
101:         date: {
102:           pickerAppearance: 'dayOnly'
103:         },
104:         condition: (data) => data.status === 'completed'
105:       }
106:     },
107:     {
108:       name: 'notes',
109:       type: 'richText',
110:       admin: {
111:         description: 'Additional notes and updates about the upgrade'
112:       }
113:     },
114:     {
115:       name: 'attachments',
116:       type: 'relationship',
117:       relationTo: 'media',
118:       hasMany: true,
119:       admin: {
120:         description: 'Related documents, photos, or files'
121:       }
122:     }
123:   ],
124:   timestamps: true,
125:   hooks: {
126:     beforeChange: [
127:       ({ data }: { data: any }) => {
128:         // Auto-set completion date when status changes to completed
129:         if (data.status === 'completed' && !data.completion_date) {
130:           data.completion_date = new Date().toISOString().split('T')[0]
131:         }
132:         
133:         // Validate cost
134:         if (data.cost && data.cost < 0) {
135:           throw new Error('Cost cannot be negative')
136:         }
137:         
138:         return data
139:       }
140:     ]
141:   }
142: }
</file>

<file path="src/collections/UpgradeTypes.ts">
 1: import { CollectionConfig } from 'payload';
 2: import { isAdmin, isAuthenticated } from '../access';
 3: 
 4: export const UpgradeTypes: CollectionConfig = {
 5:   slug: 'upgrade-types',
 6:   admin: {
 7:     useAsTitle: 'name',
 8:     defaultColumns: ['name'],
 9:     description: 'Manage different types of upgrades (e.g., POS System, Kitchen Equipment).',
10:   },
11:   access: {
12:     create: isAdmin,
13:     read: isAuthenticated,
14:     update: isAdmin,
15:     delete: isAdmin,
16:   },
17:   fields: [
18:     {
19:       name: 'name',
20:       label: 'Upgrade Type Name',
21:       type: 'text',
22:       required: true,
23:       unique: true,
24:       index: true,
25:       maxLength: 100,
26:     },
27:   ],
28: };
</file>

<file path="src/middleware/authentication.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import { getPayloadClient } from '@/lib/payloadClient'
 3: import { AUTH_COOKIE_NAME } from '@/lib/constants'
 4: import { cookies } from 'next/headers'
 5: 
 6: export async function middleware(request: NextRequest) {
 7:   const { pathname } = request.nextUrl
 8: 
 9:   // Protect /admin and other protected routes
10:   if (pathname.startsWith('/admin')) {
11:     const token = request.cookies.get('token')?.value
12: 
13:     if (!token) {
14:       // Redirect to login if no token
15:       const loginUrl = new URL('/login', request.url)
16:       return NextResponse.redirect(loginUrl)
17:     }
18: 
19:     try {
20:       // Verify session by calling Payload API /api/users/me
21:       const response = await fetch(`${process.env.PAYLOAD_PUBLIC_SERVER_URL}/api/users/me`, {
22:         headers: {
23:           cookie: `token=${token}`,
24:         },
25:       })
26: 
27:       if (!response.ok) {
28:         // Invalid session, redirect to login
29:         const loginUrl = new URL('/login', request.url)
30:         return NextResponse.redirect(loginUrl)
31:       }
32: 
33:       // Session valid, allow request
34:       return NextResponse.next()
35:     } catch (error) {
36:       console.error('Middleware auth error:', error)
37:       const loginUrl = new URL('/login', request.url)
38:       return NextResponse.redirect(loginUrl)
39:     }
40:   }
41: 
42:   // Allow other requests
43:   return NextResponse.next()
44: }
45: 
46: export const config = {
47:   matcher: ['/admin/:path*'],
48: }
</file>

<file path="src/middleware/rateLimiting.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: 
 3: const RATE_LIMIT = 100 // max requests
 4: const WINDOW_SIZE_IN_SECONDS = 60 // per minute
 5: 
 6: // Simple in-memory store for demonstration (replace with Redis in production)
 7: const ipRequestCounts = new Map<string, { count: number; firstRequestTimestamp: number }>()
 8: 
 9: export function applyRateLimiting(request: NextRequest) {
10:   const { pathname } = request.nextUrl
11: 
12:   if (pathname.startsWith('/api/')) {
13:     const ip =
14:       request.headers.get('x-forwarded-for') || request.headers.get('x-real-ip') || 'unknown'
15: 
16:     const currentTime = Date.now()
17:     const record = ipRequestCounts.get(ip)
18: 
19:     if (record) {
20:       const elapsedTime = (currentTime - record.firstRequestTimestamp) / 1000
21:       if (elapsedTime < WINDOW_SIZE_IN_SECONDS) {
22:         if (record.count >= RATE_LIMIT) {
23:           return new NextResponse('Too Many Requests', { status: 429 })
24:         } else {
25:           record.count++
26:           ipRequestCounts.set(ip, record)
27:         }
28:       } else {
29:         // Reset count and timestamp
30:         ipRequestCounts.set(ip, { count: 1, firstRequestTimestamp: currentTime })
31:       }
32:     } else {
33:       ipRequestCounts.set(ip, { count: 1, firstRequestTimestamp: currentTime })
34:     }
35:   }
36: 
37:   return NextResponse.next()
38: }
</file>

<file path="src/middleware.ts">
 1: import { NextRequest, NextResponse } from 'next/server'
 2: import { setSecurityHeaders } from './middleware/securityHeaders'
 3: import { setCorsHeaders } from './middleware/cors'
 4: import { middleware as authenticationMiddleware } from './middleware/authentication'
 5: import { applyRateLimiting } from './middleware/rateLimiting'
 6: 
 7: // Restaurant management system middleware
 8: /**
 9:  * @description Main middleware function for the application.
10:  * Applies security headers, CORS, authentication, and rate limiting.
11:  * @param {NextRequest} request
12:  * @returns {NextResponse}
13:  */
14: export function middleware(request: NextRequest) {
15:   let response = NextResponse.next()
16: 
17:   // Apply security headers
18:   setSecurityHeaders(response)
19: 
20:   // Apply CORS headers and handle preflight requests
21:   response = setCorsHeaders(request, response)
22:   if (response instanceof Response) return response // If it's a preflight response, return it immediately
23: 
24:   // Apply authentication checks
25:   const authResponse = authenticationMiddleware(request)
26:   if (authResponse instanceof NextResponse && authResponse.status !== 200) return authResponse // If authentication failed, return redirect
27: 
28:   // Apply rate limiting
29:   applyRateLimiting(request)
30: 
31:   return response
32: }
33: 
34: export const config = {
35:   matcher: [
36:     /*
37:      * Match all request paths except for the ones starting with:
38:      * - _next/static (static files)
39:      * - _next/image (image optimization files)
40:      * - favicon.ico (favicon file)
41:      * - public folder
42:      */
43:     '/((?!_next/static|_next/image|favicon.ico|public/).*)',
44:   ],
45: }
</file>

<file path="src/payload.config.ts">
  1: //
  2: import { vercelPostgresAdapter } from '@payloadcms/db-vercel-postgres'
  3: import { payloadCloudPlugin } from '@payloadcms/payload-cloud'
  4: import { lexicalEditor } from '@payloadcms/richtext-lexical'
  5: import path from 'path'
  6: import { buildConfig } from 'payload'
  7: import { fileURLToPath } from 'url'
  8: import sharp from 'sharp'
  9: import { s3Storage } from '@payloadcms/storage-s3'
 10: 
 11: import Users from './collections/Users'
 12: import { Media } from './collections/Media'
 13: import { Contacts } from './collections/Contacts'
 14: import { DietaryRestrictions } from './collections/DietaryRestrictions'
 15: import { DrinkMenuItems } from './collections/DrinkMenuItems'
 16: import { DrinkSubcategories } from './collections/DrinkSubcategories'
 17: import { EmployeeRatings } from './collections/EmployeeRatings'
 18: import { Features } from './collections/Features'
 19: import { HotspotLogins } from './collections/HotspotLogins'
 20: import { Incidents } from './collections/Incidents'
 21: import { Jobs } from './collections/Jobs'
 22: import { Locations } from './collections/Locations'
 23: import { ManagerReports } from './collections/ManagerReports'
 24: import { Messages } from './collections/Messages'
 25: import { MessageTypes } from './collections/MessageTypes'
 26: import { QrFeedback } from './collections/QrFeedback'
 27: import { Questions } from './collections/Questions'
 28: import { ReviewKeywords } from './collections/ReviewKeywords'
 29: import { Reviews } from './collections/Reviews'
 30: import { ServerReports } from './collections/ServerReports'
 31: import { ShiftTypes } from './collections/ShiftTypes'
 32: import { Upgrades } from './collections/Upgrades'
 33: import { UpgradeTypes } from './collections/UpgradeTypes'
 34: 
 35: const filename = fileURLToPath(import.meta.url)
 36: const dirname = path.dirname(filename)
 37: 
 38: /**
 39:  * @description Builds the Payload CMS configuration.
 40:  */
 41: export default buildConfig({
 42:   admin: {
 43:     user: Users.slug,
 44:     importMap: {
 45:       baseDir: path.resolve(dirname),
 46:     },
 47:   },
 48:   auth: {
 49:     jwtOrder: ['cookie', 'Bearer', 'JWT'],
 50:   },
 51:   collections: [
 52:     Users,
 53:     Media,
 54:     Contacts,
 55:     DietaryRestrictions,
 56:     DrinkMenuItems,
 57:     DrinkSubcategories,
 58:     EmployeeRatings,
 59:     Features,
 60:     HotspotLogins,
 61:     Incidents,
 62:     Jobs,
 63:     Locations,
 64:     ManagerReports,
 65:     Messages,
 66:     MessageTypes,
 67:     QrFeedback,
 68:     Questions,
 69:     ReviewKeywords,
 70:     Reviews,
 71:     ServerReports,
 72:     ShiftTypes,
 73:     Upgrades,
 74:     UpgradeTypes,
 75:   ],
 76:   editor: lexicalEditor(),
 77:   secret: process.env.PAYLOAD_SECRET || '',
 78:   typescript: {
 79:     outputFile: path.resolve(dirname, 'payload-types.ts'),
 80:   },
 81:   db: vercelPostgresAdapter({
 82:     pool: {
 83:       connectionString: process.env.POSTGRES_URL || '',
 84:     },
 85:   }),
 86: 
 87:   sharp,
 88:   plugins: [
 89:     payloadCloudPlugin(),
 90:     s3Storage({
 91:       collections: {
 92:         media: true,
 93:       },
 94:       bucket: process.env.SUPABASE_S3_BUCKET || '',
 95:       region: process.env.SUPABASE_S3_REGION || '',
 96:       endpoint: process.env.SUPABASE_S3_ENDPOINT || '',
 97:       accessKeyId: process.env.SUPABASE_S3_KEY || '',
 98:       secretAccessKey: process.env.SUPABASE_S3_SECRET || '',
 99:       forcePathStyle: true,
100:     }),
101:   ],
102: })
</file>

<file path="tests/int/api.int.spec.ts">
 1: import { getPayload, Payload } from 'payload'
 2: import config from '@/payload.config'
 3: 
 4: import { describe, it, beforeAll, expect } from 'vitest'
 5: 
 6: let payload: Payload
 7: 
 8: describe('API', () => {
 9:   beforeAll(async () => {
10:     const payloadConfig = await config
11:     payload = await getPayload({ config: payloadConfig })
12:   }, 30000)
13: 
14:   it('fetches users', async () => {
15:     const users = await payload.find({
16:       collection: 'users',
17:     })
18:     expect(users).toBeDefined()
19:   })
20: })
</file>

<file path="tests/int/DynamicForm.int.spec.tsx">
  1: import React from 'react'
  2: import { render, screen, waitFor } from '@testing-library/react'
  3: import userEvent from '@testing-library/user-event'
  4: import { QueryClient, QueryClientProvider } from '@tanstack/react-query'
  5: import { FormProvider, useForm } from 'react-hook-form'
  6: import { vi } from 'vitest'
  7: import DynamicForm from '@/app/(frontend)/components/forms/DynamicForm'
  8: import { useCollectionSchema } from '@/app/(frontend)/hooks/useCollectionSchema'
  9: 
 10: // Mock the useCollectionSchema hook
 11: vi.mock('@/app/(frontend)/hooks/useCollectionSchema')
 12: 
 13: const mockUseCollectionSchema = useCollectionSchema as vi.Mock
 14: 
 15: const queryClient = new QueryClient({
 16:   defaultOptions: {
 17:     queries: {
 18:       retry: false,
 19:     },
 20:   },
 21: })
 22: 
 23: const Wrapper: React.FC<{ children: React.ReactNode }> = ({ children }) => {
 24:   return <QueryClientProvider client={queryClient}>{children}</QueryClientProvider>
 25: }
 26: 
 27: describe('DynamicForm Integration Tests', () => {
 28:   beforeEach(() => {
 29:     mockUseCollectionSchema.mockClear()
 30:   })
 31: 
 32:   it('handles multi-step forms', async () => {
 33:     const mockSchema = {
 34:       fields: [
 35:         {
 36:           type: 'tabs',
 37:           tabs: [
 38:             {
 39:               label: 'Step 1',
 40:               fields: [{ name: 'step1Field', label: 'Step 1 Field', type: 'text', required: true }],
 41:             },
 42:             {
 43:               label: 'Step 2',
 44:               fields: [{ name: 'step2Field', label: 'Step 2 Field', type: 'text', required: true }],
 45:             },
 46:           ],
 47:         },
 48:       ],
 49:     }
 50: 
 51:     mockUseCollectionSchema.mockReturnValue({
 52:       data: mockSchema,
 53:       isLoading: false,
 54:       isError: false,
 55:       error: null,
 56:     })
 57: 
 58:     const handleSubmit = vi.fn()
 59: 
 60:     render(
 61:       <Wrapper>
 62:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
 63:       </Wrapper>,
 64:     )
 65: 
 66:     await waitFor(() => {
 67:       expect(screen.getByText('Step 1')).toBeInTheDocument()
 68:       expect(screen.getByText('Step 2')).toBeInTheDocument()
 69:     })
 70: 
 71:     // Initially, Step 1 is active
 72:     expect(screen.getByLabelText(/Step 1 Field/i)).toBeInTheDocument()
 73:     expect(screen.queryByLabelText(/Step 2 Field/i)).not.toBeInTheDocument()
 74: 
 75:     userEvent.type(screen.getByLabelText(/Step 1 Field/i), 'Step 1 Value')
 76: 
 77:     // Navigate to Step 2
 78:     userEvent.click(screen.getByText('Step 2'))
 79: 
 80:     await waitFor(() => {
 81:       expect(screen.getByLabelText(/Step 2 Field/i)).toBeInTheDocument()
 82:     })
 83:     expect(screen.queryByLabelText(/Step 1 Field/i)).not.toBeInTheDocument()
 84: 
 85:     userEvent.type(screen.getByLabelText(/Step 2 Field/i), 'Step 2 Value')
 86: 
 87:     userEvent.click(screen.getByRole('button', { name: /submit/i }))
 88: 
 89:     await waitFor(() => {
 90:       expect(handleSubmit).toHaveBeenCalledWith({
 91:         step1Field: 'Step 1 Value',
 92:         step2Field: 'Step 2 Value',
 93:       })
 94:     })
 95:   })
 96: 
 97:   it('handles conditional fields based on other field values', async () => {
 98:     const mockSchema = {
 99:       fields: [
100:         {
101:           name: 'ticketType',
102:           label: 'Ticket Type',
103:           type: 'select',
104:           options: [
105:             { label: 'Standard', value: 'standard' },
106:             { label: 'VIP', value: 'vip' },
107:           ],
108:           required: true,
109:         },
110:         {
111:           name: 'vipDetails',
112:           label: 'VIP Details',
113:           type: 'text',
114:           required: true,
115:           admin: {
116:             condition: ({ ticketType }) => ticketType === 'vip',
117:           },
118:         },
119:       ],
120:     }
121: 
122:     mockUseCollectionSchema.mockReturnValue({
123:       data: mockSchema,
124:       isLoading: false,
125:       isError: false,
126:       error: null,
127:     })
128: 
129:     const handleSubmit = vi.fn()
130: 
131:     render(
132:       <Wrapper>
133:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
134:       </Wrapper>,
135:     )
136: 
137:     await waitFor(() => {
138:       expect(screen.getByLabelText(/Ticket Type/i)).toBeInTheDocument()
139:     })
140: 
141:     // Initially, VIP details should not be visible
142:     expect(screen.queryByLabelText(/VIP Details/i)).not.toBeInTheDocument()
143: 
144:     // Select VIP option
145:     userEvent.click(screen.getByRole('combobox', { name: /Ticket Type/i }))
146:     await screen.findByText('VIP')
147:     userEvent.click(screen.getByText('VIP'))
148: 
149:     // VIP details should now be visible
150:     await waitFor(() => {
151:       expect(screen.getByLabelText(/VIP Details/i)).toBeInTheDocument()
152:     })
153: 
154:     userEvent.type(screen.getByLabelText(/VIP Details/i), 'Special access')
155:     userEvent.click(screen.getByRole('button', { name: /submit/i }))
156: 
157:     await waitFor(() => {
158:       expect(handleSubmit).toHaveBeenCalledWith({
159:         ticketType: 'vip',
160:         vipDetails: 'Special access',
161:       })
162:     })
163: 
164:     // Switch back to Standard
165:     userEvent.click(screen.getByRole('combobox', { name: /Ticket Type/i }))
166:     await screen.findByText('Standard')
167:     userEvent.click(screen.getByText('Standard'))
168: 
169:     // VIP details should be hidden again
170:     await waitFor(() => {
171:       expect(screen.queryByLabelText(/VIP Details/i)).not.toBeInTheDocument()
172:     })
173: 
174:     userEvent.click(screen.getByRole('button', { name: /submit/i }))
175: 
176:     await waitFor(() => {
177:       expect(handleSubmit).toHaveBeenCalledWith({
178:         ticketType: 'standard',
179:         // vipDetails should not be part of the submission
180:       })
181:     })
182:   })
183: 
184:   it('handles dynamic field arrays', async () => {
185:     const mockSchema = {
186:       fields: [
187:         {
188:           name: 'attendees',
189:           label: 'Attendees',
190:           type: 'array',
191:           fields: [
192:             { name: 'name', label: 'Attendee Name', type: 'text', required: true },
193:             { name: 'email', label: 'Attendee Email', type: 'email', required: true },
194:           ],
195:         },
196:       ],
197:     }
198: 
199:     mockUseCollectionSchema.mockReturnValue({
200:       data: mockSchema,
201:       isLoading: false,
202:       isError: false,
203:       error: null,
204:     })
205: 
206:     const handleSubmit = vi.fn()
207: 
208:     render(
209:       <Wrapper>
210:         <DynamicForm collectionSlug="testCollection" onSubmit={handleSubmit} />
211:       </Wrapper>,
212:     )
213: 
214:     await waitFor(() => {
215:       expect(screen.getByText('Attendees')).toBeInTheDocument()
216:     })
217: 
218:     // Add an attendee
219:     userEvent.click(screen.getByRole('button', { name: /Add Attendee/i }))
220: 
221:     await waitFor(() => {
222:       expect(screen.getByLabelText(/Attendee Name/i)).toBeInTheDocument()
223:       expect(screen.getByLabelText(/Attendee Email/i)).toBeInTheDocument()
224:     })
225: 
226:     userEvent.type(screen.getByLabelText(/Attendee Name/i), 'Jane Doe')
227:     userEvent.type(screen.getByLabelText(/Attendee Email/i), 'jane.doe@example.com')
228: 
229:     // Add another attendee
230:     userEvent.click(screen.getByRole('button', { name: /Add Attendee/i }))
231: 
232:     await waitFor(() => {
233:       const nameInputs = screen.getAllByLabelText(/Attendee Name/i)
234:       const emailInputs = screen.getAllByLabelText(/Attendee Email/i)
235:       expect(nameInputs.length).toBe(2)
236:       expect(emailInputs.length).toBe(2)
237:     })
238: 
239:     const nameInputs = screen.getAllByLabelText(/Attendee Name/i)
240:     const emailInputs = screen.getAllByLabelText(/Attendee Email/i)
241: 
242:     userEvent.type(nameInputs[1], 'John Smith')
243:     userEvent.type(emailInputs[1], 'john.smith@example.com')
244: 
245:     userEvent.click(screen.getByRole('button', { name: /submit/i }))
246: 
247:     await waitFor(() => {
248:       expect(handleSubmit).toHaveBeenCalledWith({
249:         attendees: [
250:           { name: 'Jane Doe', email: 'jane.doe@example.com' },
251:           { name: 'John Smith', email: 'john.smith@example.com' },
252:         ],
253:       })
254:     })
255: 
256:     // Remove the first attendee
257:     const removeButtons = screen.getAllByRole('button', { name: /Remove/i })
258:     userEvent.click(removeButtons[0])
259: 
260:     await waitFor(() => {
261:       const nameInputs = screen.getAllByLabelText(/Attendee Name/i)
262:       expect(nameInputs.length).toBe(1)
263:       expect(nameInputs[0]).toHaveValue('John Smith')
264:     })
265: 
266:     userEvent.click(screen.getByRole('button', { name: /submit/i }))
267: 
268:     await waitFor(() => {
269:       expect(handleSubmit).toHaveBeenCalledWith({
270:         attendees: [{ name: 'John Smith', email: 'john.smith@example.com' }],
271:       })
272:     })
273:   })
274: })
</file>

<file path=".env.example">
1: DATABASE_URI=postgresql://user:password@localhost:5432/your-database-name
2: PAYLOAD_SECRET=YOUR_SECRET_HERE
</file>

<file path="tasks-updated.json">
  1: {
  2:   "master": {
  3:     "tasks": [
  4:       {
  5:         "id": 1,
  6:         "title": "Environment Setup",
  7:         "description": "Initial project scaffold, dependencies, configuration, and schema synchronization. Refer to `llm_context/payload3/README.md` for core concepts and `llm_context/payload3/best_practices.md` for general setup guidelines.",
  8:         "status": "done",
  9:         "dependencies": [],
 10:         "subtasks": [
 11:           {
 12:             "id": 1,
 13:             "title": "Initialize Next.js Project with TypeScript and Tailwind",
 14:             "status": "done",
 15:             "dependencies": []
 16:           },
 17:           {
 18:             "id": 2,
 19:             "title": "Install Core Dependencies and Configure Tailwind, ESLint, Prettier",
 20:             "status": "done",
 21:             "dependencies": [1]
 22:           },
 23:           {
 24:             "id": 3,
 25:             "title": "Set Up Payload CMS and Supabase Branch",
 26:             "status": "done",
 27:             "dependencies": [2]
 28:           },
 29:           {
 30:             "id": 4,
 31:             "title": "Export and Sync Database Schemas (Payload vs Supabase)",
 32:             "status": "done",
 33:             "dependencies": [3]
 34:           }
 35:         ]
 36:       },
 37:       {
 38:         "id": 2,
 39:         "title": "CMS & Database Integration",
 40:         "description": "Configure Payload 3.0 with Supabase, define collections, generate types, and verify setup. Refer to `llm_context/payload3/data_models.md` for detailed data models and relationships, `llm_context/payload3/README.md` for core concepts, and `llm_context/payload3/best_practices.md` for best practices in collection design and API usage. Pay attention to the Lexical WYSIWYG editor integration for rich text fields as described in `llm_context/payload3/data_models.md`.",
 41:         "status": "done",
 42:         "dependencies": [1],
 43:         "subtasks": [
 44:           {
 45:             "id": 1,
 46:             "title": "Initialize Payload CMS Project Structure",
 47:             "status": "done"
 48:           },
 49:           {
 50:             "id": 2,
 51:             "title": "Configure Environment Variables for Payload and Supabase",
 52:             "status": "done"
 53:           },
 54:           {
 55:             "id": 3,
 56:             "title": "Define Initial Collection Schemas and Relationships",
 57:             "status": "done"
 58:           },
 59:           {
 60:             "id": 4,
 61:             "title": "Generate TypeScript Types via Payload",
 62:             "status": "done"
 63:           },
 64:           {
 65:             "id": 5,
 66:             "title": "Set Up Postgres Database Configuration",
 67:             "status": "done"
 68:           }
 69:         ]
 70:       },
 71:       {
 72:         "id": 3,
 73:         "title": "Authentication & Authorization",
 74:         "description": "Implement secure authentication flows, RBAC, and middleware protections. Refer to `llm_context/payload3/best_practices.md` for security best practices (JWT revocation, secure password hashing, secure cookies, rate limiting, CSRF prevention, session management). Consult `llm_context/forms/README.md` for login/password reset flow patterns. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
 75:         "status": "done",
 76:         "dependencies": [2],
 77:         "subtasks": [
 78:           {
 79:             "id": 1,
 80:             "title": "Set Up Authentication Configuration",
 81:             "status": "done"
 82:           },
 83:           {
 84:             "id": 2,
 85:             "title": "Implement User Registration Flow",
 86:             "status": "done",
 87:             "dependencies": [1]
 88:           },
 89:           {
 90:             "id": 3,
 91:             "title": "Implement User Login Flow",
 92:             "status": "done",
 93:             "dependencies": [2]
 94:           },
 95:           {
 96:             "id": 4,
 97:             "title": "Configure JWT Generation and Validation",
 98:             "status": "done",
 99:             "dependencies": [3]
100:           },
101:           {
102:             "id": 5,
103:             "title": "Implement Secure Cookie Management",
104:             "status": "done",
105:             "dependencies": [4]
106:           },
107:           {
108:             "id": 6,
109:             "title": "Design and Implement RBAC",
110:             "status": "done",
111:             "dependencies": [5]
112:           },
113:           {
114:             "id": 7,
115:             "title": "Implement Session Management",
116:             "status": "done",
117:             "dependencies": [5]
118:           },
119:           {
120:             "id": 8,
121:             "title": "Develop Password Reset Flow",
122:             "status": "done",
123:             "dependencies": [2]
124:           },
125:           {
126:             "id": 9,
127:             "title": "Apply Rate Limiting for Auth Endpoints",
128:             "status": "done",
129:             "dependencies": [3]
130:           },
131:           {
132:             "id": 10,
133:             "title": "Apply CSRF Protection",
134:             "status": "done",
135:             "dependencies": [5]
136:           },
137:           {
138:             "id": 11,
139:             "title": "Integrate Next.js Middleware for Auth",
140:             "status": "done",
141:             "dependencies": [6, 7, 10]
142:           },
143:           {
144:             "id": 12,
145:             "title": "Configure CORS for Auth Endpoints",
146:             "status": "done",
147:             "dependencies": [1]
148:           },
149:           {
150:             "id": 13,
151:             "title": "Implement JWT Fallback Mechanism",
152:             "status": "done",
153:             "dependencies": [4, 7]
154:           },
155:           {
156:             "id": 14,
157:             "title": "Develop Custom Authentication Strategies",
158:             "status": "done",
159:             "dependencies": [1, 3]
160:           },
161:           {
162:             "id": 15,
163:             "title": "Implement Comprehensive Auth Testing",
164:             "status": "done",
165:             "dependencies": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
166:           }
167:         ]
168:       },
169:       {
170:         "id": 4,
171:         "title": "Form Infrastructure",
172:         "description": "Implement core form handling, validation, dynamic forms, performance, and analytics. Refer to `llm_context/forms/README.md` for form submission patterns and `llm_context/forms/complex_forms.md` for advanced composition patterns. Utilize `llm_context/state_management/README.md` for Zustand integration in form state management.",
173:         "status": "done",
174:         "dependencies": [1],
175:         "subtasks": [
176:           { "id": 1, "title": "Set up Form Component Base Structure", "status": "done" },
177:           { "id": 2, "title": "Implement Zod Validation Schema", "status": "done" },
178:           { "id": 3, "title": "Develop Form Field Components", "status": "done" },
179:           { "id": 5, "title": "Setup TanStack Query Integration", "status": "done" },
180:           { "id": 6, "title": "Add Form Submission Logic", "status": "done" },
181:           { "id": 7, "title": "Implement Form State Management", "status": "done" },
182:           { "id": 8, "title": "Integrate Next.js 15 Server Actions", "status": "done" },
183:           { "id": 9, "title": "Create Dynamic Form Builder with Field Registry", "status": "done" },
184:           { "id": 10, "title": "Add Performance Optimizations", "status": "done" },
185:           { "id": 12, "title": "Create Reusable Form Components and Hooks", "status": "done" },
186:           { "id": 13, "title": "Integrate Auth for Secure Form Submissions", "status": "done" },
187:           { "id": 14, "title": "Add Form Analytics and Validation Tracking", "status": "done" }
188:         ]
189:       },
190:       {
191:         "id": 5,
192:         "title": "Data-Fetching Layer",
193:         "description": "Set up advanced TanStack Query patterns for SSR, caching, optimistic updates, auth-aware queries, offline, sync, and error handling. Refer to `llm_context/tanstack/README.md` for best practices in table implementation and integration points. Also, consult `llm_context/payload3/data_models.md` for Payload 3.0 data loading patterns.",
194:         "status": "done",
195:         "dependencies": [2, 3],
196:         "subtasks": [
197:           { "id": 1, "title": "Query Client Setup", "status": "done" },
198:           { "id": 2, "title": "Hydration Boundaries", "status": "done" },
199:           { "id": 3, "title": "Caching Strategy", "status": "done" },
200:           { "id": 4, "title": "Mutation Handlers", "status": "done" },
201:           { "id": 6, "title": "Optimistic Updates", "status": "done" },
202:           { "id": 7, "title": "Authentication-Aware Querying", "status": "done" },
203:           { "id": 8, "title": "Factory Patterns", "status": "done" },
204:           { "id": 9, "title": "Offline Support and Background Sync", "status": "done" },
205:           { "id": 10, "title": "Loading States and Suspense Boundaries", "status": "done" }
206:         ]
207:       },
208:       {
209:         "id": 6,
210:         "title": "Dynamic Forms & Complex Forms Review",
211:         "description": "Audit, research, prototype, and plan migration for complex form scenarios. Refer to `llm_context/forms/complex_forms.md` for advanced composition patterns for multi-step, dynamic, and state-driven forms. This includes guidance on multi-step forms, dynamic field arrays, conditional fields, persisted form state with Zustand, async field-level validation, file uploads, accessibility, and testing strategies.",
212:         "status": "done",
213:         "dependencies": [4, 5],
214:         "subtasks": [
215:           { "id": 1, "title": "Audit Existing Forms", "status": "done" },
216:           { "id": 2, "title": "Identify Issues in Current Forms", "status": "done" },
217:           { "id": 3, "title": "Research Form Design Best Practices", "status": "done" },
218:           { "id": 4, "title": "Analyze Complexity and Architectural Needs", "status": "done" },
219:           { "id": 5, "title": "Develop Proof-of-Concept Implementation", "status": "done" },
220:           { "id": 6, "title": "Document Findings and Recommendations", "status": "done" },
221:           { "id": 7, "title": "Plan Migration and Implementation", "status": "done" }
222:         ]
223:       },
224:       {
225:         "id": 7,
226:         "title": "File Upload System",
227:         "description": "Implement drag-and-drop uploads, media collection integration, progress tracking, and media management. Refer to `llm_context/forms/README.md` for file upload handling patterns and `llm_context/payload3/best_practices.md` for file upload security best practices.",
228:         "status": "done",
229:         "dependencies": [2, 4],
230:         "subtasks": [
231:           { "id": 1, "title": "Dropzone UI Component Implementation", "status": "done" },
232:           { "id": 2, "title": "File State Management", "status": "done" },
233:           { "id": 3, "title": "Payload CMS Media Collection Integration", "status": "done" },
234:           { "id": 4, "title": "File Upload Handler", "status": "done" },
235:           { "id": 5, "title": "TanStack Query Mutation Setup", "status": "done" },
236:           { "id": 6, "title": "Progress Tracking UI", "status": "done" },
237:           { "id": 8, "title": "Media Management Integration", "status": "done" }
238:         ]
239:       },
240:       {
241:         "id": 8,
242:         "title": "Collection & UI Components",
243:         "description": "Implement CRUD hooks, relationship handling, and role-based UI/dashboard layout. Refer to `llm_context/payload3/data_models.md` for detailed data models and relationships, `llm_context/payload3/README.md` for core concepts, and `llm_context/ui_patterns/README.md` for Shadcn UI patterns and custom component development.",
244:         "status": "done",
245:         "dependencies": [5],
246:         "subtasks": [
247:           { "id": 1, "title": "Design Data Models and Relationships", "status": "done" },
248:           { "id": 2, "title": "Implement Create Operations", "status": "done" },
249:           { "id": 3, "title": "Implement Read Operations with Filtering", "status": "done" },
250:           { "id": 4, "title": "Implement Update Operations", "status": "done" },
251:           { "id": 5, "title": "Implement Delete Operations", "status": "done" },
252:           { "id": 6, "title": "Develop Advanced Filtering System", "status": "done" },
253:           { "id": 7, "title": "Test and Optimize CRUD and Filtering", "status": "done" }
254:         ]
255:       },
256:       {
257:         "id": 9,
258:         "title": "Role-Based UI & Dashboards",
259:         "description": "Build permission-aware UI components and responsive dashboard layout. Refer to `llm_context/ui_patterns/README.md` for Shadcn UI patterns and custom component development. Consult `llm_context/payload3/best_practices.md` for access control implementation.",
260:         "status": "done",
261:         "dependencies": [3],
262:         "subtasks": [
263:           { "id": 1, "title": "Permission Components", "status": "done" },
264:           { "id": 5, "title": "Dashboard Layout System", "status": "done" }
265:         ]
266:       },
267:       {
268:         "id": 10,
269:         "title": "Testing Infrastructure",
270:         "description": "Configure Vitest, Playwright, Supertest, and integrate into CI. Refer to `llm_context/llm_agent_insights/README.md` for agent behavior patterns related to testing integration workflows and code review/validation strategies.",
271:         "status": "done",
272:         "dependencies": [1],
273:         "subtasks": [
274:           { "id": 1, "title": "Vitest Configuration for Unit Testing", "status": "done" },
275:           { "id": 2, "title": "Playwright Integration Testing Setup", "status": "done" },
276:           { "id": 3, "title": "Supertest API Testing Implementation", "status": "done" },
277:           { "id": 4, "title": "React Component Testing Patterns", "status": "done" },
278:           { "id": 5, "title": "Payload CMS Collection Testing", "status": "done" },
279:           { "id": 6, "title": "CI Pipeline Integration", "status": "done" }
280:         ]
281:       },
282:       {
283:         "id": 11,
284:         "title": "Error Handling & Monitoring",
285:         "description": "Global error boundaries, Sentry integration, CSRF protection, and notifications. Refer to `llm_context/payload3/best_practices.md` for error handling patterns and `llm_context/llm_agent_insights/README.0.md` for error recovery strategies.",
286:         "status": "done",
287:         "dependencies": [1, 3, 5],
288:         "subtasks": [
289:           { "id": 1, "title": "Define Error Boundaries", "status": "done" },
290:           { "id": 2, "title": "Implement Boundary Setup", "status": "done" },
291:           { "id": 3, "title": "Integrate Monitoring Tools", "status": "done" },
292:           { "id": 4, "title": "Develop Notification System", "status": "done" },
293:           { "id": 5, "title": "Test Error Handling Workflow", "status": "done" },
294:           { "id": 6, "title": "Document Error Handling Implementation", "status": "done" }
295:         ]
296:       },
297:       {
298:         "id": 12,
299:         "title": "Audit Logging",
300:         "description": "Integrate Payload Auditor plugin and Supabase centralized logs with retention and dashboards. Refer to `llm_context/payload3/best_practices.md` for audit logging best practices, including configuring specific operations to log, setting automated log cleanup, including user information, and restricting access to audit logs.",
301:         "status": "done",
302:         "dependencies": [2, 8],
303:         "subtasks": [
304:           { "id": 1, "title": "Integrate Audit Logging with Plugins", "status": "done" },
305:           { "id": 2, "title": "Configure Audit Logging Hooks", "status": "done" },
306:           { "id": 3, "title": "Design Audit Log Schema", "status": "done" },
307:           { "id": 4, "title": "Implement Log Retention Policy", "status": "done" },
308:           { "id": 5, "title": "Conduct Security Review of Audit Logging", "status": "done" },
309:           { "id": 6, "title": "Test Audit Logging Functionality", "status": "done" },
310:           { "id": 7, "title": "Document Audit Logging Implementation", "status": "done" }
311:         ]
312:       },
313:       {
314:         "id": 13,
315:         "title": "Middleware & Security",
316:         "description": "Modular middleware, JWT revocation, bcrypt hashing, secure cookies, rate limiting, input validation, centralized access control. Refer to `llm_context/payload3/best_practices.md` for security best practices (JWT revocation, secure password hashing, secure cookies, rate limiting, CSRF prevention, session management, environment security, data encryption). For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
317:         "status": "done",
318:         "dependencies": [3, 4, 5, 9, 25],
319:         "subtasks": [
320:           {
321:             "id": 1,
322:             "title": "Implement JWT Revocation, Secure Password Hashing, and Secure Cookie Settings",
323:             "status": "done"
324:           },
325:           {
326:             "id": 2,
327:             "title": "Integrate Rate Limiting and Comprehensive Input Validation Middleware",
328:             "status": "done"
329:           },
330:           {
331:             "id": 3,
332:             "title": "Refactor Middleware into Modular Components and Add Security Headers",
333:             "status": "done"
334:           },
335:           {
336:             "id": 4,
337:             "title": "Centralize Access Control and Integrate Audit Logging with Retention Policies",
338:             "status": "done"
339:           },
340:           {
341:             "id": 5,
342:             "title": "Ensure Form Accessibility, Comprehensive Testing, and Docker Security Hardening",
343:             "status": "done"
344:           }
345:         ]
346:       },
347:       {
348:         "id": 14,
349:         "title": "CI/CD & Deployment",
350:         "description": "GitHub Actions, Vercel deployment, Docker security, environment-specific configuration. Refer to `llm_context/mcp_tools/repomix_automation.md` for CI/CD integration patterns and automated context generation. Also, consult `llm_context/llm_agent_insights/README.md` for performance optimization related to response time and caching mechanisms.",
351:         "status": "done",
352:         "dependencies": [10, 11],
353:         "subtasks": [
354:           { "id": 1, "title": "Define Deployment Workflow Requirements", "status": "done" },
355:           { "id": 2, "title": "Configure Environment Settings", "status": "done" },
356:           { "id": 3, "title": "Implement Deployment Workflow Automation", "status": "done" },
357:           { "id": 4, "title": "Integrate Testing into Deployment Pipeline", "status": "done" },
358:           { "id": 5, "title": "Validate Deployment and Testing Setup", "status": "done" },
359:           { "id": 6, "title": "Document Deployment and Testing Procedures", "status": "done" }
360:         ]
361:       },
362:       {
363:         "id": 15,
364:         "title": "Documentation & Developer Guidelines",
365:         "description": "TypeScript typing standards, ESLint enforcement, code documentation standards, onboarding, and migration support. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage, including tags like `@description`, `@param`, `@returns`, `@example`, `@typedef`, `@property`, `@deprecated`, `@see`, and `@ignore`. Also, consult `llm_context/llm_agent_insights/README.md` for documentation generation patterns.",
366:         "status": "done",
367:         "dependencies": [10, 12],
368:         "subtasks": [
369:           { "id": 1, "title": "Define Code Documentation Standards", "status": "done" },
370:           { "id": 2, "title": "Document the Standards", "status": "done" },
371:           { "id": 3, "title": "Set Up Linting and Pre-commit Hooks", "status": "done" },
372:           { "id": 4, "title": "Update Onboarding Materials", "status": "done" },
373:           { "id": 5, "title": "Establish Enforcement Process", "status": "done" },
374:           { "id": 6, "title": "Integrate Standards into Code Review", "status": "done" },
375:           {
376:             "id": 7,
377:             "title": "Consolidate Documentation Enforcement Workflows",
378:             "status": "done"
379:           }
380:         ]
381:       },
382:       {
383:         "id": 16,
384:         "title": "Schema Sync",
385:         "description": "Validate and synchronize database schema between Payload CMS and Supabase. Refer to `llm_context/payload3/data_models.md` for detailed Payload 3.0 data models and relationships, which are crucial for schema synchronization. This includes understanding collections like `Users`, `Media`, `Contacts`, `Locations`, and others, along with their key fields and relationships.",
386:         "status": "done",
387:         "dependencies": [27],
388:         "subtasks": [
389:           { "id": 1, "title": "Export Current Payload CMS and Supabase Schemas", "status": "done" },
390:           { "id": 2, "title": "Analyze and Document Schema Differences", "status": "done" },
391:           { "id": 3, "title": "Plan and Generate Required Schema Migrations", "status": "done" },
392:           { "id": 4, "title": "Apply Migrations and Update Payload CMS State", "status": "done" },
393:           { "id": 5, "title": "Document and Version Control Schema Changes", "status": "done" }
394:         ]
395:       },
396:       {
397:         "id": 17,
398:         "title": "Authenticated User Endpoint",
399:         "description": "Implement /api/users/me API route for current authenticated user info. Refer to `llm_context/payload3/best_practices.md` for authentication best practices, including JWT and session management. For TypeScript typing issues related to `PayloadRequest` and custom user types, consult `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
400:         "status": "done",
401:         "dependencies": [3, 23],
402:         "subtasks": []
403:       },
404:       {
405:         "id": 18,
406:         "title": "Implement Automated Enforcement of TypeScript Typing Guidelines in Payload",
407:         "description": "Set up and configured automated linting and documentation. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md`.",
408:         "status": "done",
409:         "dependencies": [],
410:         "subtasks": []
411:       },
412:       {
413:         "id": 19,
414:         "title": "Enforce Code Documentation Standards (Inline Comments & JSDoc/TSDoc)",
415:         "description": "Established and enforced code documentation standards using JSDoc/TSDoc. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage.",
416:         "status": "done",
417:         "dependencies": [],
418:         "subtasks": []
419:       },
420:       {
421:         "id": 20,
422:         "title": "Review and Refine Form Composition for Complex Forms",
423:         "description": "Analyzed and improved the architecture of complex forms. Refer to `llm_context/forms/complex_forms.md` for advanced composition patterns for multi-step, dynamic, and state-driven forms.",
424:         "status": "done",
425:         "dependencies": [],
426:         "subtasks": []
427:       },
428:       {
429:         "id": 21,
430:         "title": "Refactor and Centralize Access Control & Role Management",
431:         "description": "Centralized all access control logic into a dedicated module. Refer to `llm_context/payload3/best_practices.md` for access control implementation and `llm_context/responses/typescript_error_resolution_v2.md` for typing.",
432:         "status": "done",
433:         "dependencies": [],
434:         "subtasks": []
435:       },
436:       {
437:         "id": 22,
438:         "title": "Modularize Middleware for Security, CORS, Authentication, and Rate Limiting",
439:         "description": "Refactored the monolithic `middleware.ts` file into focused modules. Refer to `llm_context/payload3/best_practices.md` for API rate limiting and CSRF prevention. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md`.",
440:         "status": "done",
441:         "dependencies": [],
442:         "subtasks": []
443:       },
444:       {
445:         "id": 23,
446:         "title": "Implement API Versioning with URL Path Prefixes",
447:         "description": "Introduced URL path versioning (e.g., `/api/v1/`) for all API routes. Refer to `llm_context/payload3/best_practices.md` for API usage best practices.",
448:         "status": "done",
449:         "dependencies": [],
450:         "subtasks": []
451:       },
452:       {
453:         "id": 24,
454:         "title": "Integrate Supabase S3-Compatible Storage with Payload CMS Media Collection",
455:         "description": "Installed and configured `@payloadcms/storage-s3` for media uploads. Refer to `llm_context/payload3/best_practices.md` for file upload security best practices.",
456:         "status": "done",
457:         "dependencies": [],
458:         "subtasks": []
459:       },
460:       {
461:         "id": 25,
462:         "title": "Implement Centralized Logging with Supabase",
463:         "description": "Researched, designed, and implemented a centralized logging solution using Supabase. Refer to `llm_context/payload3/best_practices.md` for audit logging best practices.",
464:         "status": "done",
465:         "dependencies": [],
466:         "subtasks": []
467:       },
468:       {
469:         "id": 26,
470:         "title": "Implement Security Best Practices",
471:         "description": "Added explicit subtasks and implemented security best practices across the application. Refer to `llm_context/payload3/best_practices.md` for comprehensive security guidelines.",
472:         "status": "done",
473:         "dependencies": [],
474:         "subtasks": []
475:       },
476:       {
477:         "id": 27,
478:         "title": "Review and Update High-Complexity Tasks",
479:         "description": "Reviewed all high-complexity tasks and updated their subtasks to incorporate best practices. Refer to `llm_context/llm_agent_insights/README.md` for task decomposition approaches.",
480:         "status": "done",
481:         "dependencies": [],
482:         "subtasks": []
483:       },
484:       {
485:         "id": 28,
486:         "title": "Comprehensive Review and Enhancement of Form-Related Tasks and Subtasks",
487:         "description": "Performed an in-depth review of all form-related tasks to ensure advanced patterns are correctly implemented. Refer to `llm_context/forms/complex_forms.md` for advanced form composition patterns.",
488:         "status": "done",
489:         "dependencies": [],
490:         "subtasks": []
491:       },
492:       {
493:         "id": 29,
494:         "title": "Review and Update Data Fetching and API Integration",
495:         "description": "Reviewed and enhanced all data fetching and API integration tasks with advanced TanStack Query features. Refer to `llm_context/tanstack/README.md` for best practices in table implementation and integration points.",
496:         "status": "done",
497:         "dependencies": [],
498:         "subtasks": []
499:       },
500:       {
501:         "id": 30,
502:         "title": "Review and Update Middleware, Access Control, and Logging",
503:         "description": "Consolidated access control logic, modularized middleware, and implemented comprehensive logging. Refer to `llm_context/payload3/best_practices.md` for relevant security and logging best practices.",
504:         "status": "done",
505:         "dependencies": [],
506:         "subtasks": []
507:       },
508:       {
509:         "id": 31,
510:         "title": "Review and Enhance Deployment, Docker, and CI/CD Tasks",
511:         "description": "Reviewed and updated all deployment, Docker, and CI/CD related tasks for best practices. Refer to `llm_context/mcp_tools/repomix_automation.md` for CI/CD integration patterns and automated context generation.",
512:         "status": "done",
513:         "dependencies": [],
514:         "subtasks": []
515:       },
516:       {
517:         "id": 32,
518:         "title": "Validate and Sync Database Schema Between Payload CMS and Supabase",
519:         "description": "Researched and compared the current state of the database schema between Payload CMS and Supabase. Refer to `llm_context/payload3/data_models.md` for detailed Payload 3.0 data models and relationships.",
520:         "status": "done",
521:         "dependencies": [],
522:         "subtasks": []
523:       },
524:       {
525:         "id": 33,
526:         "title": "Implement /api/users/me API Route for Authenticated User Info",
527:         "description": "Created a secure API route at `/api/users/me` that returns the current authenticated user's information. Refer to `llm_context/payload3/best_practices.md` for authentication best practices, including JWT and session management. For TypeScript typing issues related to `PayloadRequest` and custom user types, consult `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
528:         "status": "done",
529:         "dependencies": [3, 23],
530:         "subtasks": []
531:       }
532:     ],
533:     "metadata": {
534:       "created": "2025-07-02T13:20:00.000Z",
535:       "description": "Updated master task list organized by phase/milestone"
536:     }
537:   }
538: }
</file>

<file path="vitest.config.mts">
 1: import { defineConfig } from 'vitest/config'
 2: import react from '@vitejs/plugin-react'
 3: import tsconfigPaths from 'vite-tsconfig-paths'
 4: 
 5: export default defineConfig({
 6:   plugins: [tsconfigPaths(), react()],
 7:   test: {
 8:     globals: true,
 9:     environment: 'jsdom',
10:     setupFiles: ['./vitest.setup.ts'],
11:     include: ['tests/int/**/*.int.spec.ts', 'tests/int/**/*.int.spec.tsx'],
12:   },
13: })
</file>

<file path="vitest.setup.ts">
1: import '@testing-library/jest-dom'
</file>

<file path="package.json">
 1: {
 2:   "name": "payload-backend",
 3:   "version": "1.0.0",
 4:   "description": "A blank template to get started with Payload 3.0",
 5:   "license": "MIT",
 6:   "type": "module",
 7:   "scripts": {
 8:     "build": "cross-env NODE_OPTIONS=\"--no-deprecation --max-old-space-size=8000\" next build",
 9:     "dev": "cross-env NODE_OPTIONS=--no-deprecation next dev -p 4000",
10:     "devsafe": "rm -rf .next && cross-env NODE_OPTIONS=--no-deprecation next dev -p 4001",
11:     "generate:importmap": "cross-env NODE_OPTIONS=--no-deprecation payload generate:importmap",
12:     "generate:types": "cross-env NODE_OPTIONS=--no-deprecation payload generate:types",
13:     "lint": "cross-env NODE_OPTIONS=--no-deprecation next lint",
14:     "payload": "cross-env NODE_OPTIONS=--no-deprecation payload",
15:     "start": "cross-env NODE_OPTIONS=--no-deprecation next start",
16:     "test": "pnpm run test:int && pnpm run test:e2e",
17:     "test:e2e": "cross-env NODE_OPTIONS=\"--no-deprecation --no-experimental-strip-types\" pnpm exec playwright test",
18:     "test:int": "cross-env NODE_OPTIONS=--no-deprecation vitest run --config ./vitest.config.mts"
19:   },
20:   "dependencies": {
21:     "@hookform/resolvers": "^5.1.1",
22:     "@payloadcms/db-vercel-postgres": "3.44.0",
23:     "@payloadcms/next": "3.44.0",
24:     "@payloadcms/payload-cloud": "3.44.0",
25:     "@payloadcms/richtext-lexical": "3.44.0",
26:     "@payloadcms/storage-s3": "^3.44.0",
27:     "@payloadcms/ui": "3.44.0",
28:     "@radix-ui/react-label": "^2.1.7",
29:     "@radix-ui/react-slot": "^1.2.3",
30:     "@tanstack/query-sync-storage-persister": "^5.81.5",
31:     "@tanstack/react-query": "^5.81.5",
32:     "@tanstack/react-query-devtools": "^5.81.5",
33:     "@tanstack/react-query-persist-client": "^5.81.5",
34:     "class-variance-authority": "^0.7.1",
35:     "clsx": "^2.1.1",
36:     "dotenv": "16.4.7",
37:     "graphql": "^16.8.1",
38:     "js-cookie": "^3.0.5",
39:     "lucide-react": "^0.525.0",
40:     "next": "15.3.2",
41:     "payload": "3.44.0",
42:     "react": "19.1.0",
43:     "react-dom": "^19.1.0",
44:     "react-hook-form": "^7.59.0",
45:     "sharp": "0.32.6",
46:     "tailwind-merge": "^3.3.1",
47:     "zod": "^3.25.67",
48:     "zustand": "^5.0.6"
49:   },
50:   "devDependencies": {
51:     "@playwright/test": "1.50.0",
52:     "@radix-ui/react-select": "^2.2.5",
53:     "@testing-library/jest-dom": "^6.6.3",
54:     "@testing-library/react": "16.3.0",
55:     "@testing-library/user-event": "^14.6.1",
56:     "@types/node": "^22.5.4",
57:     "@types/react": "19.1.0",
58:     "@types/react-dom": "19.1.2",
59:     "@vitejs/plugin-react": "4.5.2",
60:     "autoprefixer": "^10.4.21",
61:     "cross-env": "^7.0.3",
62:     "eslint": "^9.16.0",
63:     "eslint-config-next": "15.3.0",
64:     "eslint-plugin-jsdoc": "^51.3.2",
65:     "jsdom": "26.1.0",
66:     "playwright": "1.50.0",
67:     "playwright-core": "1.50.0",
68:     "postcss": "^8.5.6",
69:     "prettier": "^3.4.2",
70:     "tailwindcss": "^4.1.11",
71:     "typescript": "5.7.3",
72:     "vite-tsconfig-paths": "5.1.4",
73:     "vitest": "3.2.3"
74:   },
75:   "engines": {
76:     "node": "^18.20.2 || >=20.9.0",
77:     "pnpm": "^9 || ^10"
78:   },
79:   "pnpm": {
80:     "onlyBuiltDependencies": [
81:       "sharp",
82:       "esbuild",
83:       "unrs-resolver"
84:     ]
85:   }
86: }
</file>

<file path=".taskmaster/reports/task-complexity-report.json">
  1: {
  2: 	"meta": {
  3: 		"generatedAt": "2025-07-02T19:42:58.820Z",
  4: 		"tasksAnalyzed": 0,
  5: 		"thresholdScore": 5,
  6: 		"projectName": "Task Master",
  7: 		"usedResearch": true
  8: 	},
  9: 	"complexityAnalysis": [
 10: 		{
 11: 			"taskId": 1,
 12: 			"taskTitle": "Initialize Project Structure and Dependencies",
 13: 			"complexityScore": 5,
 14: 			"recommendedSubtasks": 6,
 15: 			"expansionPrompt": "Break down the setup into: Next.js project initialization, dependency installation, configuration files setup, folder structure creation, environment variable management, and verification/testing of the setup.",
 16: 			"reasoning": "This task is foundational but follows well-documented patterns. It involves several discrete steps (project creation, dependency management, config, structure, and verification), each with moderate complexity. Existing subtasks cover most areas, but explicit environment management and more granular verification could be added."
 17: 		},
 18: 		{
 19: 			"taskId": 8,
 20: 			"taskTitle": "Develop Collection Management",
 21: 			"complexityScore": 7,
 22: 			"recommendedSubtasks": 7,
 23: 			"expansionPrompt": "Expand into: data model/relationship design, create/read/update/delete operations, advanced filtering, batch operations, authentication/access control, and comprehensive testing/optimization.",
 24: 			"reasoning": "CRUD with relationship handling, advanced filtering, and modern authentication/access control is moderately complex, especially with Payload CMS and Next.js integration. Requires careful schema and permission design."
 25: 		},
 26: 		{
 27: 			"taskId": 4,
 28: 			"taskTitle": "Set Up Form Infrastructure",
 29: 			"complexityScore": 8,
 30: 			"recommendedSubtasks": 12,
 31: 			"expansionPrompt": "Decompose form infrastructure into subtasks for schema design, validation, field components, state management, TanStack Query integration, error handling, performance, analytics, authentication, and reusable patterns.",
 32: 			"reasoning": "This task spans frontend architecture, validation, state management, API integration, performance, and analytics. It requires reusable, scalable patterns and secure integration with authentication."
 33: 		},
 34: 		{
 35: 			"taskId": 5,
 36: 			"taskTitle": "Implement Data Fetching Layer",
 37: 			"complexityScore": 8,
 38: 			"recommendedSubtasks": 12,
 39: 			"expansionPrompt": "Break down the data fetching layer into subtasks for QueryClient setup, hydration, caching, mutations, optimistic updates, auth-aware queries, offline support, API integration, error/suspense boundaries, and performance.",
 40: 			"reasoning": "The data fetching layer is foundational, requiring SSR/CSR support, caching, optimistic updates, authentication, offline support, and integration with multiple APIs. It is both broad and deep in scope."
 41: 		},
 42: 		{
 43: 			"taskId": 19,
 44: 			"taskTitle": "Enforce Code Documentation Standards (Inline Comments & JSDoc/TSDoc)",
 45: 			"complexityScore": 5,
 46: 			"recommendedSubtasks": 6,
 47: 			"expansionPrompt": "Expand documentation enforcement into subtasks for standards definition, documentation, linting/pre-commit setup, code review, onboarding, and compliance validation.",
 48: 			"reasoning": "This is a process and tooling task, important for maintainability but not technically complex."
 49: 		},
 50: 		{
 51: 			"taskId": 20,
 52: 			"taskTitle": "Review and Refine Form Composition for Complex Forms",
 53: 			"complexityScore": 7,
 54: 			"recommendedSubtasks": 7,
 55: 			"expansionPrompt": "Decompose this review into subtasks for auditing current forms, identifying pain points, researching best practices, implementing a refactored proof-of-concept, documentation, and developer feedback.",
 56: 			"reasoning": "This task involves analysis, architectural improvement, and documentation, requiring both technical and design expertise."
 57: 		},
 58: 		{
 59: 			"taskId": 21,
 60: 			"taskTitle": "Refactor and Centralize Access Control & Role Management",
 61: 			"complexityScore": 7,
 62: 			"recommendedSubtasks": 8,
 63: 			"expansionPrompt": "Expand access control centralization into subtasks for module design, migration of logic, updating collections, type safety, documentation, test refactoring, and code review.",
 64: 			"reasoning": "Centralizing access control requires careful refactoring, strong typing, and coordination across multiple files, making it moderately complex."
 65: 		},
 66: 		{
 67: 			"taskId": 22,
 68: 			"taskTitle": "Modularize Middleware for Security, CORS, Authentication, and Rate Limiting",
 69: 			"complexityScore": 7,
 70: 			"recommendedSubtasks": 8,
 71: 			"expansionPrompt": "Break down middleware modularization into subtasks for analyzing current logic, creating modules for each concern, refactoring main middleware, testing, and documentation.",
 72: 			"reasoning": "Splitting monolithic middleware into modules requires careful separation of concerns, refactoring, and ensuring correct execution order."
 73: 		},
 74: 		{
 75: 			"taskId": 23,
 76: 			"taskTitle": "Implement API Versioning with URL Path Prefixes",
 77: 			"complexityScore": 7,
 78: 			"recommendedSubtasks": 8,
 79: 			"expansionPrompt": "Expand API versioning into subtasks for auditing routes, renaming/reorganizing files, updating references, refactoring middleware, updating documentation, and testing backward compatibility.",
 80: 			"reasoning": "API versioning impacts routing, references, and documentation across the codebase, requiring careful coordination and testing."
 81: 		},
 82: 		{
 83: 			"taskId": 2,
 84: 			"taskTitle": "Configure Payload CMS and Database Integration",
 85: 			"complexityScore": 9,
 86: 			"recommendedSubtasks": 10,
 87: 			"expansionPrompt": "Break down the integration into subtasks for Payload CMS installation, Supabase PostgreSQL connection, environment variable management, initial collection schema design, type generation, authentication setup, uploads/media configuration, real-time updates, Next.js 15 integration, and comprehensive testing.",
 88: 			"reasoning": "This task involves multi-system integration (Payload CMS, Supabase, Next.js), secure environment configuration, type safety, authentication, file uploads, real-time features, and adherence to best practices. Each area is non-trivial and requires careful setup and validation, justifying a high complexity and need for granular subtasks."
 89: 		},
 90: 		{
 91: 			"taskId": 3,
 92: 			"taskTitle": "Implement Authentication System",
 93: 			"complexityScore": 10,
 94: 			"recommendedSubtasks": 15,
 95: 			"expansionPrompt": "Expand into subtasks for authentication configuration, registration and login flows, JWT and cookie management, RBAC, session management, password reset, security hardening (rate limiting, CSRF), Next.js middleware, CORS, JWT fallback, custom auth strategies, and comprehensive testing.",
 96: 			"reasoning": "This is a full-stack, security-critical authentication system with multiple flows (cookie, JWT, RBAC, password reset, session, custom strategies), integration with Next.js, and strict security requirements. Each aspect is complex and must be robustly tested, warranting a maximum complexity score and detailed subtask breakdown."
 97: 		},
 98: 		{
 99: 			"taskId": 6,
100: 			"taskTitle": "Create Dynamic Form Builder",
101: 			"complexityScore": 8,
102: 			"recommendedSubtasks": 8,
103: 			"expansionPrompt": "Decompose into subtasks for requirements analysis, data structure design, dynamic field rendering, validation mapping, validation logic, form generation, performance optimization, and comprehensive testing.",
104: 			"reasoning": "Dynamic form builders require advanced TypeScript, validation, performance optimization, and integration with Payload schemas. The need for dynamic rendering, validation, and testing across many scenarios increases complexity, though it is slightly less than full authentication."
105: 		},
106: 		{
107: 			"taskId": 7,
108: 			"taskTitle": "Implement File Upload System",
109: 			"complexityScore": 8,
110: 			"recommendedSubtasks": 7,
111: 			"expansionPrompt": "Expand into subtasks for UI component development, state management, Payload CMS media integration, API upload handler, progress tracking, media management integration, and security/access control.",
112: 			"reasoning": "File upload systems involve UI/UX, backend integration, state management, chunked uploads, progress tracking, error handling, and security. Each area is moderately complex and requires careful coordination and testing."
113: 		},
114: 		{
115: 			"taskId": 9,
116: 			"taskTitle": "Implement Role-Based UI Components",
117: 			"complexityScore": 6,
118: 			"recommendedSubtasks": 4,
119: 			"expansionPrompt": "Break down into subtasks for permission-aware component creation, role-based navigation, conditional rendering utilities, and protected layout implementation.",
120: 			"reasoning": "While role-based UI is important, the patterns are well-established and the technical depth is moderate. Complexity arises from ensuring consistency and integration with backend RBAC, but the scope is more contained."
121: 		},
122: 		{
123: 			"taskId": 10,
124: 			"taskTitle": "Set Up Testing Infrastructure",
125: 			"complexityScore": 7,
126: 			"recommendedSubtasks": 6,
127: 			"expansionPrompt": "Expand into subtasks for unit test setup (Vitest), E2E test setup (Playwright), API testing (Supertest), React component testing patterns, Payload CMS collection testing, and CI pipeline integration.",
128: 			"reasoning": "Testing infrastructure spans multiple tools and test types (unit, integration, E2E, API), and must be integrated with CI. Each area is moderately complex and critical for project quality."
129: 		},
130: 		{
131: 			"taskId": 11,
132: 			"taskTitle": "Implement Error Handling and Monitoring",
133: 			"complexityScore": 7,
134: 			"recommendedSubtasks": 6,
135: 			"expansionPrompt": "Decompose into subtasks for defining error boundaries, implementing error boundary setup, integrating monitoring tools, developing notification systems, testing error handling workflows, and documentation.",
136: 			"reasoning": "Global error handling and monitoring require architectural planning, tool integration, and robust testing. The complexity is moderate due to the need for reliability and coverage across the stack."
137: 		},
138: 		{
139: 			"taskId": 12,
140: 			"taskTitle": "Configure CI/CD Pipeline",
141: 			"complexityScore": 7,
142: 			"recommendedSubtasks": 6,
143: 			"expansionPrompt": "Expand into subtasks for defining workflow requirements, configuring environment settings, automating deployment workflow, integrating testing, validating setup, and documentation.",
144: 			"reasoning": "CI/CD setup involves workflow design, environment management, automation, and documentation. Complexity is moderate, with emphasis on reliability and security."
145: 		},
146: 		{
147: 			"taskId": 13,
148: 			"taskTitle": "Implement and Configure Payload Auditor for Comprehensive Audit Logging",
149: 			"complexityScore": 8,
150: 			"recommendedSubtasks": 7,
151: 			"expansionPrompt": "Break down into subtasks for plugin integration, audit hook configuration, log schema design, retention policy implementation, security review, testing, and documentation.",
152: 			"reasoning": "Comprehensive audit logging requires plugin integration, schema design, security, retention, and compliance considerations. Each aspect is critical for traceability and compliance, increasing complexity."
153: 		},
154: 		{
155: 			"taskId": 14,
156: 			"taskTitle": "Establish and Enforce Strict TypeScript Typing Guidelines for Payload",
157: 			"complexityScore": 7,
158: 			"recommendedSubtasks": 6,
159: 			"expansionPrompt": "Expand into subtasks for drafting guidelines, documentation, ESLint rule configuration, CI integration, team communication, and migration support.",
160: 			"reasoning": "Strict typing guidelines require research, documentation, linting/tooling, CI integration, and team onboarding. Complexity is moderate due to the need for consistency and enforcement across the codebase."
161: 		},
162: 		{
163: 			"taskId": 15,
164: 			"taskTitle": "Enforce Code Documentation Standards (Inline Comments & JSDoc/TSDoc)",
165: 			"complexityScore": 6,
166: 			"recommendedSubtasks": 6,
167: 			"expansionPrompt": "Decompose into subtasks for defining documentation standards, documenting standards, linting/pre-commit hook setup, updating onboarding, enforcement process, and code review integration.",
168: 			"reasoning": "Documentation standards are important for maintainability but are more process/tooling focused. Complexity is moderate, with most effort in initial setup and enforcement."
169: 		},
170: 		{
171: 			"taskId": 16,
172: 			"taskTitle": "Review and Refine Form Composition for Complex Forms",
173: 			"complexityScore": 7,
174: 			"recommendedSubtasks": 7,
175: 			"expansionPrompt": "Expand into subtasks for auditing forms, identifying issues, researching best practices, analyzing complexity, proof-of-concept implementation, documentation, and migration planning.",
176: 			"reasoning": "Complex form composition involves architectural review, advanced state management, validation, and migration planning. Each step requires careful analysis and testing, resulting in moderate-high complexity."
177: 		},
178: 		{
179: 			"taskId": 17,
180: 			"taskTitle": "Verify and Test Payload Auditor Audit Logging and Retention Policies",
181: 			"complexityScore": 7,
182: 			"recommendedSubtasks": 6,
183: 			"expansionPrompt": "Break down into subtasks for designing test cases, integration testing, retention policy validation, cross-database checks, documentation review, and compliance validation.",
184: 			"reasoning": "Verification and testing of audit logging and retention policies require comprehensive test design, cross-database validation, and compliance checks, making it moderately complex."
185: 		},
186: 		{
187: 			"taskId": 18,
188: 			"taskTitle": "Implement Automated Enforcement of TypeScript Typing Guidelines in Payload",
189: 			"complexityScore": 7,
190: 			"recommendedSubtasks": 6,
191: 			"expansionPrompt": "Expand into subtasks for ESLint rule configuration, CI integration, documentation updates, codebase linting, developer onboarding, and feedback collection.",
192: 			"reasoning": "Automated enforcement of typing guidelines involves tooling, CI integration, documentation, and team adoption. Complexity is moderate due to the need for automation and team-wide compliance."
193: 		},
194: 		{
195: 			"taskId": 24,
196: 			"taskTitle": "Integrate Supabase S3-Compatible Storage with Payload CMS Media Collection",
197: 			"complexityScore": 7,
198: 			"recommendedSubtasks": 6,
199: 			"expansionPrompt": "Decompose into subtasks for package installation, environment variable setup, Payload config update, media collection configuration, integration testing, and documentation.",
200: 			"reasoning": "S3-compatible storage integration involves secure configuration, environment management, Payload customization, and thorough testing. Each step is moderately complex and must be robust."
201: 		},
202: 		{
203: 			"taskId": 25,
204: 			"taskTitle": "Implement Centralized Logging with Supabase",
205: 			"complexityScore": 8,
206: 			"recommendedSubtasks": 5,
207: 			"expansionPrompt": "Expand into subtasks for researching Supabase logging options, defining logging schema, implementing application logging, log retention policy, and monitoring/alerting configuration.",
208: 			"reasoning": "Centralized logging requires research, schema design, application integration, retention, and monitoring. Each area is non-trivial and critical for observability and compliance."
209: 		},
210: 		{
211: 			"taskId": 26,
212: 			"taskTitle": "Implement Security Best Practices Across Authentication, Forms, Data Fetching, Middleware, Access Control, and Logging",
213: 			"complexityScore": 10,
214: 			"recommendedSubtasks": 5,
215: 			"expansionPrompt": "Break down into subtasks for JWT revocation and secure password/cookie handling, rate limiting and input validation, modular middleware refactoring, centralized access control and audit logging, and accessibility/testing/Docker security.",
216: 			"reasoning": "This task spans multiple critical security domains across the stack, requiring deep integration, refactoring, and testing. Each area is complex and must be coordinated with existing systems, justifying the highest complexity."
217: 		},
218: 		{
219: 			"taskId": 27,
220: 			"taskTitle": "Review and Update High-Complexity Tasks with Explicit Security and Best Practice Patterns",
221: 			"complexityScore": 9,
222: 			"recommendedSubtasks": 5,
223: 			"expansionPrompt": "Expand into subtasks for auditing high-complexity tasks, updating subtasks for security and validation, integrating modular middleware and access control, enhancing audit logging/accessibility/testing, and updating deployment/Docker security.",
224: 			"reasoning": "This meta-task requires a comprehensive review and update of all high-complexity tasks to ensure best practices, security, and maintainability, involving coordination across many areas."
225: 		},
226: 		{
227: 			"taskId": 28,
228: 			"taskTitle": "Comprehensive Review and Enhancement of Form-Related Tasks and Subtasks",
229: 			"complexityScore": 9,
230: 			"recommendedSubtasks": 5,
231: 			"expansionPrompt": "Break down into subtasks for auditing/cataloging form tasks, validating form composition/state/validation, assessing dynamic fields and file uploads, reviewing accessibility/UX, and updating subtasks/testing/documentation.",
232: 			"reasoning": "This task requires a deep review and enhancement of all form-related logic, including advanced validation, state management, accessibility, and testing, across the codebase."
233: 		},
234: 		{
235: 			"taskId": 29,
236: 			"taskTitle": "Review and Update Data Fetching and API Integration with Advanced TanStack Query Patterns",
237: 			"complexityScore": 9,
238: 			"recommendedSubtasks": 8,
239: 			"expansionPrompt": "Expand into subtasks for auditing data fetching code, implementing SSR hydration, optimistic updates, advanced caching, authentication-aware queries, factory patterns, error handling, and loading/suspense states.",
240: 			"reasoning": "Advanced data fetching and API integration with TanStack Query involves SSR, caching, optimistic updates, authentication, error handling, and UI state management, each requiring careful design and testing."
241: 		},
242: 		{
243: 			"taskId": 30,
244: 			"taskTitle": "Review and Update Middleware, Access Control, and Logging for Centralization and Best Practices",
245: 			"complexityScore": 9,
246: 			"recommendedSubtasks": 8,
247: 			"expansionPrompt": "Break down into subtasks for centralizing access control, modularizing middleware, implementing security headers, integrating audit logging, implementing centralized logging, ensuring sensitive operation coverage, testing/validation, and documentation.",
248: 			"reasoning": "This task involves architectural refactoring for security and maintainability, requiring changes across access control, middleware, logging, and documentation, each with significant complexity."
249: 		},
250: 		{
251: 			"taskId": 31,
252: 			"taskTitle": "Review and Enhance Deployment, Docker, and CI/CD Tasks for Best Practices and Security",
253: 			"complexityScore": 8,
254: 			"recommendedSubtasks": 6,
255: 			"expansionPrompt": "Expand into subtasks for auditing deployment/Docker/CI tasks, updating Dockerfiles, implementing secure secret management, enhancing CI/CD pipelines, managing environment-specific configs, and documenting/validating workflows.",
256: 			"reasoning": "Deployment and CI/CD best practices require secure Docker builds, secret management, robust pipelines, and documentation. Each area is moderately complex and critical for secure, reliable operations."
257: 		},
258: 		{
259: 			"taskId": 32,
260: 			"taskTitle": "Validate and Sync Database Schema Between Payload CMS and Supabase",
261: 			"complexityScore": 8,
262: 			"recommendedSubtasks": 5,
263: 			"expansionPrompt": "Decompose into subtasks for exporting schemas, analyzing/documenting differences, generating migrations, applying migrations/updating Payload, and documenting/version-controlling changes.",
264: 			"reasoning": "Schema synchronization involves analysis, migration planning, execution, and documentation, with risk of data loss or inconsistency if not handled carefully."
265: 		},
266: 		{
267: 			"taskId": 33,
268: 			"taskTitle": "Implement /api/users/me API Route for Authenticated User Info",
269: 			"complexityScore": 6,
270: 			"recommendedSubtasks": 6,
271: 			"expansionPrompt": "Expand into subtasks for API route implementation, token extraction/validation, user data fetching, error handling, TypeScript typing, and endpoint documentation/testing.",
272: 			"reasoning": "While the endpoint is focused, it requires secure token handling, error management, strong typing, and documentation, making it moderately complex."
273: 		}
274: 	]
275: }
</file>

<file path=".taskmaster/tasks/tasks.json">
   1: {
   2:   "master": {
   3:     "tasks": [
   4:       {
   5:         "id": 1,
   6:         "title": "Environment Setup",
   7:         "description": "Initial project scaffold, dependencies, configuration, and schema synchronization. Refer to `llm_context/payload3/README.md` for core concepts and `llm_context/payload3/best_practices.md` for general setup guidelines.",
   8:         "status": "done",
   9:         "dependencies": [],
  10:         "subtasks": [
  11:           {
  12:             "id": 1,
  13:             "title": "Initialize Next.js Project with TypeScript and Tailwind",
  14:             "status": "done",
  15:             "dependencies": []
  16:           },
  17:           {
  18:             "id": 2,
  19:             "title": "Install Core Dependencies and Configure Tailwind, ESLint, Prettier",
  20:             "status": "done",
  21:             "dependencies": [
  22:               1
  23:             ]
  24:           },
  25:           {
  26:             "id": 3,
  27:             "title": "Set Up Payload CMS and Supabase Branch",
  28:             "status": "done",
  29:             "dependencies": [
  30:               2
  31:             ]
  32:           },
  33:           {
  34:             "id": 4,
  35:             "title": "Export and Sync Database Schemas (Payload vs Supabase)",
  36:             "status": "done",
  37:             "dependencies": [
  38:               3
  39:             ]
  40:           }
  41:         ]
  42:       },
  43:       {
  44:         "id": 2,
  45:         "title": "CMS & Database Integration",
  46:         "description": "Configure Payload 3.0 with Supabase, define collections, generate types, and verify setup. Refer to `llm_context/payload3/data_models.md` for detailed data models and relationships, `llm_context/payload3/README.md` for core concepts, and `llm_context/payload3/best_practices.md` for best practices in collection design and API usage. Pay attention to the Lexical WYSIWYG editor integration for rich text fields as described in `llm_context/payload3/data_models.md`.",
  47:         "status": "done",
  48:         "dependencies": [
  49:           1
  50:         ],
  51:         "subtasks": [
  52:           {
  53:             "id": 1,
  54:             "title": "Initialize Payload CMS Project Structure",
  55:             "status": "done"
  56:           },
  57:           {
  58:             "id": 2,
  59:             "title": "Configure Environment Variables for Payload and Supabase",
  60:             "status": "done"
  61:           },
  62:           {
  63:             "id": 3,
  64:             "title": "Define Initial Collection Schemas and Relationships",
  65:             "status": "done"
  66:           },
  67:           {
  68:             "id": 4,
  69:             "title": "Generate TypeScript Types via Payload",
  70:             "status": "done"
  71:           },
  72:           {
  73:             "id": 5,
  74:             "title": "Set Up Postgres Database Configuration",
  75:             "status": "done"
  76:           }
  77:         ]
  78:       },
  79:       {
  80:         "id": 3,
  81:         "title": "Authentication & Authorization",
  82:         "description": "Implement secure authentication flows, RBAC, and middleware protections. Refer to `llm_context/payload3/best_practices.md` for security best practices (JWT revocation, secure password hashing, secure cookies, rate limiting, CSRF prevention, session management). Consult `llm_context/forms/README.md` for login/password reset flow patterns. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
  83:         "status": "done",
  84:         "dependencies": [
  85:           2
  86:         ],
  87:         "subtasks": [
  88:           {
  89:             "id": 1,
  90:             "title": "Set Up Authentication Configuration",
  91:             "status": "done"
  92:           },
  93:           {
  94:             "id": 2,
  95:             "title": "Implement User Registration Flow",
  96:             "status": "done",
  97:             "dependencies": [
  98:               1
  99:             ]
 100:           },
 101:           {
 102:             "id": 3,
 103:             "title": "Implement User Login Flow",
 104:             "status": "done",
 105:             "dependencies": [
 106:               2
 107:             ]
 108:           },
 109:           {
 110:             "id": 4,
 111:             "title": "Configure JWT Generation and Validation",
 112:             "status": "done",
 113:             "dependencies": [
 114:               3
 115:             ]
 116:           },
 117:           {
 118:             "id": 5,
 119:             "title": "Implement Secure Cookie Management",
 120:             "status": "done",
 121:             "dependencies": [
 122:               4
 123:             ]
 124:           },
 125:           {
 126:             "id": 6,
 127:             "title": "Design and Implement RBAC",
 128:             "status": "done",
 129:             "dependencies": [
 130:               5
 131:             ]
 132:           },
 133:           {
 134:             "id": 7,
 135:             "title": "Implement Session Management",
 136:             "status": "done",
 137:             "dependencies": [
 138:               5
 139:             ]
 140:           },
 141:           {
 142:             "id": 8,
 143:             "title": "Develop Password Reset Flow",
 144:             "status": "done",
 145:             "dependencies": [
 146:               2
 147:             ]
 148:           },
 149:           {
 150:             "id": 9,
 151:             "title": "Apply Rate Limiting for Auth Endpoints",
 152:             "status": "done",
 153:             "dependencies": [
 154:               3
 155:             ]
 156:           },
 157:           {
 158:             "id": 10,
 159:             "title": "Apply CSRF Protection",
 160:             "status": "done",
 161:             "dependencies": [
 162:               5
 163:             ]
 164:           },
 165:           {
 166:             "id": 11,
 167:             "title": "Integrate Next.js Middleware for Auth",
 168:             "status": "done",
 169:             "dependencies": [
 170:               6,
 171:               7,
 172:               10
 173:             ]
 174:           },
 175:           {
 176:             "id": 12,
 177:             "title": "Configure CORS for Auth Endpoints",
 178:             "status": "done",
 179:             "dependencies": [
 180:               1
 181:             ]
 182:           },
 183:           {
 184:             "id": 13,
 185:             "title": "Implement JWT Fallback Mechanism",
 186:             "status": "done",
 187:             "dependencies": [
 188:               4,
 189:               7
 190:             ]
 191:           },
 192:           {
 193:             "id": 14,
 194:             "title": "Develop Custom Authentication Strategies",
 195:             "status": "done",
 196:             "dependencies": [
 197:               1,
 198:               3
 199:             ]
 200:           },
 201:           {
 202:             "id": 15,
 203:             "title": "Implement Comprehensive Auth Testing",
 204:             "status": "done",
 205:             "dependencies": [
 206:               2,
 207:               3,
 208:               4,
 209:               5,
 210:               6,
 211:               7,
 212:               8,
 213:               9,
 214:               10,
 215:               11,
 216:               12,
 217:               13,
 218:               14
 219:             ]
 220:           }
 221:         ]
 222:       },
 223:       {
 224:         "id": 4,
 225:         "title": "Form Infrastructure",
 226:         "description": "Implement core form handling, validation, dynamic forms, performance, and analytics. Refer to `llm_context/forms/README.md` for form submission patterns and `llm_context/forms/complex_forms.md` for advanced composition patterns. Utilize `llm_context/state_management/README.md` for Zustand integration in form state management.",
 227:         "status": "done",
 228:         "dependencies": [
 229:           1
 230:         ],
 231:         "subtasks": [
 232:           {
 233:             "id": 1,
 234:             "title": "Set up Form Component Base Structure",
 235:             "status": "done"
 236:           },
 237:           {
 238:             "id": 2,
 239:             "title": "Implement Zod Validation Schema",
 240:             "status": "done"
 241:           },
 242:           {
 243:             "id": 3,
 244:             "title": "Develop Form Field Components",
 245:             "status": "done"
 246:           },
 247:           {
 248:             "id": 5,
 249:             "title": "Setup TanStack Query Integration",
 250:             "status": "done"
 251:           },
 252:           {
 253:             "id": 6,
 254:             "title": "Add Form Submission Logic",
 255:             "status": "done"
 256:           },
 257:           {
 258:             "id": 7,
 259:             "title": "Implement Form State Management",
 260:             "status": "done"
 261:           },
 262:           {
 263:             "id": 8,
 264:             "title": "Integrate Next.js 15 Server Actions",
 265:             "status": "done"
 266:           },
 267:           {
 268:             "id": 9,
 269:             "title": "Create Dynamic Form Builder with Field Registry",
 270:             "status": "done"
 271:           },
 272:           {
 273:             "id": 10,
 274:             "title": "Add Performance Optimizations",
 275:             "status": "done"
 276:           },
 277:           {
 278:             "id": 12,
 279:             "title": "Create Reusable Form Components and Hooks",
 280:             "status": "done"
 281:           },
 282:           {
 283:             "id": 13,
 284:             "title": "Integrate Auth for Secure Form Submissions",
 285:             "status": "done"
 286:           },
 287:           {
 288:             "id": 14,
 289:             "title": "Add Form Analytics and Validation Tracking",
 290:             "status": "done"
 291:           }
 292:         ]
 293:       },
 294:       {
 295:         "id": 5,
 296:         "title": "Data-Fetching Layer",
 297:         "description": "Set up advanced TanStack Query patterns for SSR, caching, optimistic updates, auth-aware queries, offline, sync, and error handling. Refer to `llm_context/tanstack/README.md` for best practices in table implementation and integration points. Also, consult `llm_context/payload3/data_models.md` for Payload 3.0 data loading patterns.",
 298:         "status": "done",
 299:         "dependencies": [
 300:           2,
 301:           3
 302:         ],
 303:         "subtasks": [
 304:           {
 305:             "id": 1,
 306:             "title": "Query Client Setup",
 307:             "status": "done"
 308:           },
 309:           {
 310:             "id": 2,
 311:             "title": "Hydration Boundaries",
 312:             "status": "done"
 313:           },
 314:           {
 315:             "id": 3,
 316:             "title": "Caching Strategy",
 317:             "status": "done"
 318:           },
 319:           {
 320:             "id": 4,
 321:             "title": "Mutation Handlers",
 322:             "status": "done"
 323:           },
 324:           {
 325:             "id": 6,
 326:             "title": "Optimistic Updates",
 327:             "status": "done"
 328:           },
 329:           {
 330:             "id": 7,
 331:             "title": "Authentication-Aware Querying",
 332:             "status": "done"
 333:           },
 334:           {
 335:             "id": 8,
 336:             "title": "Factory Patterns",
 337:             "status": "done"
 338:           },
 339:           {
 340:             "id": 9,
 341:             "title": "Offline Support and Background Sync",
 342:             "status": "done"
 343:           },
 344:           {
 345:             "id": 10,
 346:             "title": "Loading States and Suspense Boundaries",
 347:             "status": "done"
 348:           }
 349:         ]
 350:       },
 351:       {
 352:         "id": 6,
 353:         "title": "Dynamic Forms & Complex Forms Review",
 354:         "description": "Audit, research, prototype, and plan migration for complex form scenarios. Refer to `llm_context/forms/complex_forms.md` for advanced composition patterns for multi-step, dynamic, and state-driven forms. This includes guidance on multi-step forms, dynamic field arrays, conditional fields, persisted form state with Zustand, async field-level validation, file uploads, accessibility, and testing strategies.",
 355:         "status": "done",
 356:         "dependencies": [
 357:           4,
 358:           5
 359:         ],
 360:         "subtasks": [
 361:           {
 362:             "id": 1,
 363:             "title": "Audit Existing Forms",
 364:             "status": "done"
 365:           },
 366:           {
 367:             "id": 2,
 368:             "title": "Identify Issues in Current Forms",
 369:             "status": "done"
 370:           },
 371:           {
 372:             "id": 3,
 373:             "title": "Research Form Design Best Practices",
 374:             "status": "done"
 375:           },
 376:           {
 377:             "id": 4,
 378:             "title": "Analyze Complexity and Architectural Needs",
 379:             "status": "done"
 380:           },
 381:           {
 382:             "id": 5,
 383:             "title": "Develop Proof-of-Concept Implementation",
 384:             "status": "done"
 385:           },
 386:           {
 387:             "id": 6,
 388:             "title": "Document Findings and Recommendations",
 389:             "status": "done"
 390:           },
 391:           {
 392:             "id": 7,
 393:             "title": "Plan Migration and Implementation",
 394:             "status": "done"
 395:           }
 396:         ]
 397:       },
 398:       {
 399:         "id": 7,
 400:         "title": "File Upload System",
 401:         "description": "Implement drag-and-drop uploads, media collection integration, progress tracking, and media management. Refer to `llm_context/forms/README.md` for file upload handling patterns and `llm_context/payload3/best_practices.md` for file upload security best practices.",
 402:         "status": "done",
 403:         "dependencies": [
 404:           2,
 405:           4
 406:         ],
 407:         "subtasks": [
 408:           {
 409:             "id": 1,
 410:             "title": "Dropzone UI Component Implementation",
 411:             "status": "done"
 412:           },
 413:           {
 414:             "id": 2,
 415:             "title": "File State Management",
 416:             "status": "done"
 417:           },
 418:           {
 419:             "id": 3,
 420:             "title": "Payload CMS Media Collection Integration",
 421:             "status": "done"
 422:           },
 423:           {
 424:             "id": 4,
 425:             "title": "File Upload Handler",
 426:             "status": "done"
 427:           },
 428:           {
 429:             "id": 5,
 430:             "title": "TanStack Query Mutation Setup",
 431:             "status": "done"
 432:           },
 433:           {
 434:             "id": 6,
 435:             "title": "Progress Tracking UI",
 436:             "status": "done"
 437:           },
 438:           {
 439:             "id": 8,
 440:             "title": "Media Management Integration",
 441:             "status": "done"
 442:           }
 443:         ]
 444:       },
 445:       {
 446:         "id": 8,
 447:         "title": "Collection & UI Components",
 448:         "description": "Implement CRUD hooks, relationship handling, and role-based UI/dashboard layout. Refer to `llm_context/payload3/data_models.md` for detailed data models and relationships, `llm_context/payload3/README.md` for core concepts, and `llm_context/ui_patterns/README.md` for Shadcn UI patterns and custom component development.",
 449:         "status": "done",
 450:         "dependencies": [
 451:           5
 452:         ],
 453:         "subtasks": [
 454:           {
 455:             "id": 1,
 456:             "title": "Design Data Models and Relationships",
 457:             "status": "done"
 458:           },
 459:           {
 460:             "id": 2,
 461:             "title": "Implement Create Operations",
 462:             "status": "done"
 463:           },
 464:           {
 465:             "id": 3,
 466:             "title": "Implement Read Operations with Filtering",
 467:             "status": "done"
 468:           },
 469:           {
 470:             "id": 4,
 471:             "title": "Implement Update Operations",
 472:             "status": "done"
 473:           },
 474:           {
 475:             "id": 5,
 476:             "title": "Implement Delete Operations",
 477:             "status": "done"
 478:           },
 479:           {
 480:             "id": 6,
 481:             "title": "Develop Advanced Filtering System",
 482:             "status": "done"
 483:           },
 484:           {
 485:             "id": 7,
 486:             "title": "Test and Optimize CRUD and Filtering",
 487:             "status": "done"
 488:           }
 489:         ]
 490:       },
 491:       {
 492:         "id": 9,
 493:         "title": "Role-Based UI & Dashboards",
 494:         "description": "Build permission-aware UI components and responsive dashboard layout. Refer to `llm_context/ui_patterns/README.md` for Shadcn UI patterns and custom component development. Consult `llm_context/payload3/best_practices.md` for access control implementation.",
 495:         "status": "done",
 496:         "dependencies": [
 497:           3
 498:         ],
 499:         "subtasks": [
 500:           {
 501:             "id": 1,
 502:             "title": "Permission Components",
 503:             "status": "done"
 504:           },
 505:           {
 506:             "id": 5,
 507:             "title": "Dashboard Layout System",
 508:             "status": "done"
 509:           }
 510:         ]
 511:       },
 512:       {
 513:         "id": 10,
 514:         "title": "Testing Infrastructure",
 515:         "description": "Configure Vitest, Playwright, Supertest, and integrate into CI. Refer to `llm_context/llm_agent_insights/README.md` for agent behavior patterns related to testing integration workflows and code review/validation strategies.",
 516:         "status": "done",
 517:         "dependencies": [
 518:           1
 519:         ],
 520:         "subtasks": [
 521:           {
 522:             "id": 1,
 523:             "title": "Vitest Configuration for Unit Testing",
 524:             "status": "done"
 525:           },
 526:           {
 527:             "id": 2,
 528:             "title": "Playwright Integration Testing Setup",
 529:             "status": "done"
 530:           },
 531:           {
 532:             "id": 3,
 533:             "title": "Supertest API Testing Implementation",
 534:             "status": "done"
 535:           },
 536:           {
 537:             "id": 4,
 538:             "title": "React Component Testing Patterns",
 539:             "status": "done"
 540:           },
 541:           {
 542:             "id": 5,
 543:             "title": "Payload CMS Collection Testing",
 544:             "status": "done"
 545:           },
 546:           {
 547:             "id": 6,
 548:             "title": "CI Pipeline Integration",
 549:             "status": "done"
 550:           }
 551:         ]
 552:       },
 553:       {
 554:         "id": 11,
 555:         "title": "Error Handling & Monitoring",
 556:         "description": "Global error boundaries, Sentry integration, CSRF protection, and notifications. Refer to `llm_context/payload3/best_practices.md` for error handling patterns and `llm_context/llm_agent_insights/README.0.md` for error recovery strategies.",
 557:         "status": "done",
 558:         "dependencies": [
 559:           1,
 560:           3,
 561:           5
 562:         ],
 563:         "subtasks": [
 564:           {
 565:             "id": 1,
 566:             "title": "Define Error Boundaries",
 567:             "status": "done"
 568:           },
 569:           {
 570:             "id": 2,
 571:             "title": "Implement Boundary Setup",
 572:             "status": "done"
 573:           },
 574:           {
 575:             "id": 3,
 576:             "title": "Integrate Monitoring Tools",
 577:             "status": "done"
 578:           },
 579:           {
 580:             "id": 4,
 581:             "title": "Develop Notification System",
 582:             "status": "done"
 583:           },
 584:           {
 585:             "id": 5,
 586:             "title": "Test Error Handling Workflow",
 587:             "status": "done"
 588:           },
 589:           {
 590:             "id": 6,
 591:             "title": "Document Error Handling Implementation",
 592:             "status": "done"
 593:           }
 594:         ]
 595:       },
 596:       {
 597:         "id": 12,
 598:         "title": "Audit Logging",
 599:         "description": "Integrate Payload Auditor plugin and Supabase centralized logs with retention and dashboards. Refer to `llm_context/payload3/best_practices.md` for audit logging best practices, including configuring specific operations to log, setting automated log cleanup, including user information, and restricting access to audit logs.",
 600:         "status": "done",
 601:         "dependencies": [
 602:           2,
 603:           8
 604:         ],
 605:         "subtasks": [
 606:           {
 607:             "id": 1,
 608:             "title": "Integrate Audit Logging with Plugins",
 609:             "status": "done"
 610:           },
 611:           {
 612:             "id": 2,
 613:             "title": "Configure Audit Logging Hooks",
 614:             "status": "done"
 615:           },
 616:           {
 617:             "id": 3,
 618:             "title": "Design Audit Log Schema",
 619:             "status": "done"
 620:           },
 621:           {
 622:             "id": 4,
 623:             "title": "Implement Log Retention Policy",
 624:             "status": "done"
 625:           },
 626:           {
 627:             "id": 5,
 628:             "title": "Conduct Security Review of Audit Logging",
 629:             "status": "done"
 630:           },
 631:           {
 632:             "id": 6,
 633:             "title": "Test Audit Logging Functionality",
 634:             "status": "done"
 635:           },
 636:           {
 637:             "id": 7,
 638:             "title": "Document Audit Logging Implementation",
 639:             "status": "done"
 640:           }
 641:         ]
 642:       },
 643:       {
 644:         "id": 13,
 645:         "title": "Middleware & Security",
 646:         "description": "Modular middleware, JWT revocation, bcrypt hashing, secure cookies, rate limiting, input validation, centralized access control. Refer to `llm_context/payload3/best_practices.md` for security best practices (JWT revocation, secure password hashing, secure cookies, rate limiting, CSRF prevention, session management, environment security, data encryption). For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
 647:         "status": "done",
 648:         "dependencies": [
 649:           3,
 650:           4,
 651:           5,
 652:           9,
 653:           25
 654:         ],
 655:         "subtasks": [
 656:           {
 657:             "id": 1,
 658:             "title": "Implement JWT Revocation, Secure Password Hashing, and Secure Cookie Settings",
 659:             "status": "done"
 660:           },
 661:           {
 662:             "id": 2,
 663:             "title": "Integrate Rate Limiting and Comprehensive Input Validation Middleware",
 664:             "status": "done"
 665:           },
 666:           {
 667:             "id": 3,
 668:             "title": "Refactor Middleware into Modular Components and Add Security Headers",
 669:             "status": "done"
 670:           },
 671:           {
 672:             "id": 4,
 673:             "title": "Centralize Access Control and Integrate Audit Logging with Retention Policies",
 674:             "status": "done"
 675:           },
 676:           {
 677:             "id": 5,
 678:             "title": "Ensure Form Accessibility, Comprehensive Testing, and Docker Security Hardening",
 679:             "status": "done"
 680:           }
 681:         ]
 682:       },
 683:       {
 684:         "id": 14,
 685:         "title": "CI/CD & Deployment",
 686:         "description": "GitHub Actions, Vercel deployment, Docker security, environment-specific configuration. Refer to `llm_context/mcp_tools/repomix_automation.md` for CI/CD integration patterns and automated context generation. Also, consult `llm_context/llm_agent_insights/README.md` for performance optimization related to response time and caching mechanisms.",
 687:         "status": "done",
 688:         "dependencies": [
 689:           10,
 690:           11
 691:         ],
 692:         "subtasks": [
 693:           {
 694:             "id": 1,
 695:             "title": "Define Deployment Workflow Requirements",
 696:             "status": "done"
 697:           },
 698:           {
 699:             "id": 2,
 700:             "title": "Configure Environment Settings",
 701:             "status": "done"
 702:           },
 703:           {
 704:             "id": 3,
 705:             "title": "Implement Deployment Workflow Automation",
 706:             "status": "done"
 707:           },
 708:           {
 709:             "id": 4,
 710:             "title": "Integrate Testing into Deployment Pipeline",
 711:             "status": "done"
 712:           },
 713:           {
 714:             "id": 5,
 715:             "title": "Validate Deployment and Testing Setup",
 716:             "status": "done"
 717:           },
 718:           {
 719:             "id": 6,
 720:             "title": "Document Deployment and Testing Procedures",
 721:             "status": "done"
 722:           }
 723:         ]
 724:       },
 725:       {
 726:         "id": 15,
 727:         "title": "Documentation & Developer Guidelines",
 728:         "description": "TypeScript typing standards, ESLint enforcement, code documentation standards, onboarding, and migration support. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage, including tags like `@description`, `@param`, `@returns`, `@example`, `@typedef`, `@property`, `@deprecated`, `@see`, and `@ignore`. Also, consult `llm_context/llm_agent_insights/README.md` for documentation generation patterns.",
 729:         "status": "done",
 730:         "dependencies": [
 731:           10,
 732:           12
 733:         ],
 734:         "subtasks": [
 735:           {
 736:             "id": 1,
 737:             "title": "Define Code Documentation Standards",
 738:             "status": "done"
 739:           },
 740:           {
 741:             "id": 2,
 742:             "title": "Document the Standards",
 743:             "status": "done"
 744:           },
 745:           {
 746:             "id": 3,
 747:             "title": "Set Up Linting and Pre-commit Hooks",
 748:             "status": "done"
 749:           },
 750:           {
 751:             "id": 4,
 752:             "title": "Update Onboarding Materials",
 753:             "status": "done"
 754:           },
 755:           {
 756:             "id": 5,
 757:             "title": "Establish Enforcement Process",
 758:             "status": "done"
 759:           },
 760:           {
 761:             "id": 6,
 762:             "title": "Integrate Standards into Code Review",
 763:             "status": "done"
 764:           },
 765:           {
 766:             "id": 7,
 767:             "title": "Consolidate Documentation Enforcement Workflows",
 768:             "status": "done"
 769:           }
 770:         ]
 771:       },
 772:       {
 773:         "id": 16,
 774:         "title": "Schema Sync",
 775:         "description": "Validate and synchronize database schema between Payload CMS and Supabase. Refer to `llm_context/payload3/data_models.md` for detailed Payload 3.0 data models and relationships, which are crucial for schema synchronization. This includes understanding collections like `Users`, `Media`, `Contacts`, `Locations`, and others, along with their key fields and relationships.",
 776:         "status": "done",
 777:         "dependencies": [
 778:           27
 779:         ],
 780:         "subtasks": [
 781:           {
 782:             "id": 1,
 783:             "title": "Export Current Payload CMS and Supabase Schemas",
 784:             "status": "done"
 785:           },
 786:           {
 787:             "id": 2,
 788:             "title": "Analyze and Document Schema Differences",
 789:             "status": "done"
 790:           },
 791:           {
 792:             "id": 3,
 793:             "title": "Plan and Generate Required Schema Migrations",
 794:             "status": "done"
 795:           },
 796:           {
 797:             "id": 4,
 798:             "title": "Apply Migrations and Update Payload CMS State",
 799:             "status": "done"
 800:           },
 801:           {
 802:             "id": 5,
 803:             "title": "Document and Version Control Schema Changes",
 804:             "status": "done"
 805:           }
 806:         ]
 807:       },
 808:       {
 809:         "id": 17,
 810:         "title": "Authenticated User Endpoint",
 811:         "description": "Implement /api/users/me API route for current authenticated user info. Refer to `llm_context/payload3/best_practices.md` for authentication best practices, including JWT and session management. For TypeScript typing issues related to `PayloadRequest` and custom user types, consult `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
 812:         "status": "in-progress",
 813:         "dependencies": [
 814:           3,
 815:           23
 816:         ],
 817:         "subtasks": [
 818:           {
 819:             "id": 1,
 820:             "title": "Design Test Cases",
 821:             "description": "Create comprehensive test scenarios for audit logging functionality and retention policy enforcement.",
 822:             "dependencies": [],
 823:             "details": "Cover log generation triggers, retention duration verification, access control checks, and edge cases like log rotation and storage limits. Include both positive and negative test scenarios.",
 824:             "status": "pending",
 825:             "testStrategy": ""
 826:           },
 827:           {
 828:             "id": 2,
 829:             "title": "Integration Testing",
 830:             "description": "Validate end-to-end log flow across systems including applications, databases, and archival storage.",
 831:             "dependencies": [
 832:               1
 833:             ],
 834:             "details": "Verify seamless data handoff between components, timestamp consistency, and metadata preservation during log ingestion and retrieval processes.",
 835:             "status": "pending",
 836:             "testStrategy": ""
 837:           },
 838:           {
 839:             "id": 3,
 840:             "title": "Retention Policy Validation",
 841:             "description": "Test automated enforcement of retention durations and deletion mechanisms.",
 842:             "dependencies": [
 843:               1
 844:             ],
 845:             "details": "Verify time-based purge triggers, legal hold exceptions, and tiered retention rules (e.g., 6 months for operational logs vs 10 years for compliance logs). Include recovery testing of archived logs.",
 846:             "status": "pending",
 847:             "testStrategy": ""
 848:           },
 849:           {
 850:             "id": 4,
 851:             "title": "Cross-Database Checks",
 852:             "description": "Ensure log consistency across distributed data stores and platforms.",
 853:             "dependencies": [
 854:               2,
 855:               3
 856:             ],
 857:             "details": "Audit schema alignment, ID correlation, and timestamp synchronization between SQL/NoSQL databases and cloud storage. Validate unified querying capabilities.",
 858:             "status": "pending",
 859:             "testStrategy": ""
 860:           },
 861:           {
 862:             "id": 5,
 863:             "title": "Documentation Review",
 864:             "description": "Verify accuracy of policy documentation against implemented controls.",
 865:             "dependencies": [
 866:               3
 867:             ],
 868:             "details": "Cross-check retention schedules, archival procedures, and destruction protocols against operational configurations. Ensure clarity on legal hold processes and audit trail requirements.",
 869:             "status": "pending",
 870:             "testStrategy": ""
 871:           },
 872:           {
 873:             "id": 6,
 874:             "title": "Compliance Validation",
 875:             "description": "Confirm adherence to regulatory frameworks (HIPAA, GDPR, etc.) and internal policies.",
 876:             "dependencies": [
 877:               3,
 878:               4,
 879:               5
 880:             ],
 881:             "details": "Map controls to specific regulations, verify evidence generation for audits, and test access revocation procedures. Include third-party certification checks if applicable.",
 882:             "status": "pending",
 883:             "testStrategy": ""
 884:           }
 885:         ],
 886:         "details": "<info added on 2025-07-02T19:57:25.611Z>\nSubtasks:\n- Implement the /api/users/me endpoint to return the authenticated user's information.\n- Ensure secure handling and validation of authentication tokens (e.g., JWT), following best practices outlined in llm_context/payload3/best_practices.md.\n- Implement comprehensive error handling for authentication failures and invalid tokens.\n- Apply strong TypeScript typing for request and response objects, referencing guidance in llm_context/responses/typescript_errors.md and llm_context/responses/typescript_error_resolution_v2.md to resolve any typing issues, especially with PayloadRequest and custom user types.\n- Write unit tests to verify correct behavior, security, and type safety of the endpoint.\n</info added on 2025-07-02T19:57:25.611Z>"
 887:       },
 888:       {
 889:         "id": 18,
 890:         "title": "Implement Automated Enforcement of TypeScript Typing Guidelines in Payload",
 891:         "description": "Set up and configured automated linting and documentation. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md`.",
 892:         "status": "in-progress",
 893:         "dependencies": [],
 894:         "subtasks": [],
 895:         "details": "<info added on 2025-07-02T19:57:43.835Z>\nDefine and configure ESLint rules specifically targeting TypeScript typing best practices, ensuring alignment with project standards. Integrate ESLint checks into the CI pipeline so that all pull requests are automatically validated for typing and documentation compliance. Enforce JSDoc/TSDoc standards as outlined in the referenced documentation, and ensure that any TypeScript typing issues are addressed according to the guidelines in `llm_context/responses/typescript_errors.md`. Document the linting and enforcement process so that contributors understand how to comply with the automated checks.\n</info added on 2025-07-02T19:57:43.835Z>"
 896:       },
 897:       {
 898:         "id": 19,
 899:         "title": "Enforce Code Documentation Standards (Inline Comments & JSDoc/TSDoc)",
 900:         "description": "Established and enforced code documentation standards using JSDoc/TSDoc. Refer to `llm_context/llm_agent_insights/code_documentation_standards.md` for detailed JSDoc/TSDoc standards and usage.",
 901:         "status": "in-progress",
 902:         "dependencies": [],
 903:         "subtasks": [
 904:           {
 905:             "id": 1,
 906:             "title": "Standards Definition",
 907:             "description": "Establish clear documentation standards and guidelines",
 908:             "dependencies": [],
 909:             "details": "Define required documentation elements (e.g., function descriptions, parameters, return values, examples) and format specifications. Create style guides and templates for consistency across the codebase.",
 910:             "status": "pending",
 911:             "testStrategy": ""
 912:           },
 913:           {
 914:             "id": 2,
 915:             "title": "Documentation Implementation",
 916:             "description": "Integrate documentation generation into development workflow",
 917:             "dependencies": [
 918:               1
 919:             ],
 920:             "details": "Set up automated documentation tools (e.g., Sphinx, JSDoc) and configure them to enforce standards. Ensure documentation is versioned with code updates and remains synchronized with implementation changes.",
 921:             "status": "pending",
 922:             "testStrategy": ""
 923:           },
 924:           {
 925:             "id": 3,
 926:             "title": "Linting/Pre-commit Setup",
 927:             "description": "Configure automated documentation checks",
 928:             "dependencies": [
 929:               1
 930:             ],
 931:             "details": "Implement linters (e.g., pydocstyle, ESLint) and pre-commit hooks to validate documentation quality before code submission. Enforce requirements like docstring presence, parameter descriptions, and example validity.",
 932:             "status": "pending",
 933:             "testStrategy": ""
 934:           },
 935:           {
 936:             "id": 4,
 937:             "title": "Code Review Integration",
 938:             "description": "Incorporate documentation verification in peer reviews",
 939:             "dependencies": [
 940:               1,
 941:               2,
 942:               3
 943:             ],
 944:             "details": "Update code review checklists to include documentation standards. Train reviewers to validate documentation completeness, accuracy, and adherence to style guides during pull request evaluations.",
 945:             "status": "pending",
 946:             "testStrategy": ""
 947:           },
 948:           {
 949:             "id": 5,
 950:             "title": "Onboarding & Training",
 951:             "description": "Educate team on documentation practices",
 952:             "dependencies": [
 953:               1
 954:             ],
 955:             "details": "Develop training materials and workshops for new and existing contributors. Cover documentation standards, tool usage, and review expectations. Include practical exercises for writing compliant documentation.",
 956:             "status": "pending",
 957:             "testStrategy": ""
 958:           },
 959:           {
 960:             "id": 6,
 961:             "title": "Compliance Validation",
 962:             "description": "Implement ongoing documentation audits",
 963:             "dependencies": [
 964:               1,
 965:               2,
 966:               3,
 967:               4,
 968:               5
 969:             ],
 970:             "details": "Establish regular audits using automated reports and manual sampling. Track metrics like documentation coverage percentage and linting pass rates. Generate compliance reports and address gaps through process improvements.",
 971:             "status": "pending",
 972:             "testStrategy": ""
 973:           }
 974:         ],
 975:         "details": "<info added on 2025-07-02T19:58:01.091Z>\nDefine and document comprehensive code documentation standards utilizing JSDoc/TSDoc, ensuring guidelines are clear and accessible to all contributors. Implement automated enforcement by configuring linting rules and pre-commit hooks to check for compliance with documentation standards. Integrate documentation verification as a mandatory step in the code review process. Update onboarding materials to include education on the established documentation standards and enforcement mechanisms. All standards and usage instructions should align with the specifications outlined in llm_context/llm_agent_insights/code_documentation_standards.md.\n</info added on 2025-07-02T19:58:01.091Z>"
 976:       },
 977:       {
 978:         "id": 20,
 979:         "title": "Review and Refine Form Composition for Complex Forms",
 980:         "description": "Analyzed and improved the architecture of complex forms. Refer to `llm_context/forms/complex_forms.md` for advanced composition patterns for multi-step, dynamic, and state-driven forms.",
 981:         "status": "pending",
 982:         "dependencies": [],
 983:         "subtasks": []
 984:       },
 985:       {
 986:         "id": 21,
 987:         "title": "Refactor and Centralize Access Control & Role Management",
 988:         "description": "Centralized all access control logic into a dedicated module. Refer to `llm_context/payload3/best_practices.md` for access control implementation and `llm_context/responses/typescript_error_resolution_v2.md` for typing.",
 989:         "status": "in-progress",
 990:         "dependencies": [],
 991:         "subtasks": []
 992:       },
 993:       {
 994:         "id": 22,
 995:         "title": "Modularize Middleware for Security, CORS, Authentication, and Rate Limiting",
 996:         "description": "Refactored the monolithic `middleware.ts` file into focused modules. Refer to `llm_context/payload3/best_practices.md` for API rate limiting and CSRF prevention. For TypeScript typing issues, refer to `llm_context/responses/typescript_errors.md`.",
 997:         "status": "in-progress",
 998:         "dependencies": [],
 999:         "subtasks": [],
1000:         "details": "<info added on 2025-07-02T19:58:57.882Z>\nAnalyze the current middleware.ts file to identify and separate logic related to security, CORS, authentication, and rate limiting. Create individual modules for each concern, ensuring clear separation of responsibilities and maintainability. Integrate these modules back into the application, replacing the monolithic middleware implementation. Conduct thorough testing to verify that all middleware functions operate correctly after refactoring. Address any TypeScript typing issues encountered during the process by consulting llm_context/responses/typescript_errors.md. Follow the guidelines in llm_context/payload3/best_practices.md for implementing API rate limiting and CSRF prevention within the appropriate modules.\n</info added on 2025-07-02T19:58:57.882Z>"
1001:       },
1002:       {
1003:         "id": 23,
1004:         "title": "Implement API Versioning with URL Path Prefixes",
1005:         "description": "Introduced URL path versioning (e.g., `/api/v1/`) for all API routes. Refer to `llm_context/payload3/best_practices.md` for API usage best practices.",
1006:         "status": "in-progress",
1007:         "dependencies": [],
1008:         "subtasks": [],
1009:         "details": "<info added on 2025-07-02T19:59:11.961Z>\nAudit all existing API routes to identify endpoints requiring versioning. Update route definitions to include a version prefix in the URL path (e.g., /api/v1/). Rename or reorganize route files and directories as needed to reflect the new versioned structure. Update all internal and external references to the affected routes, including frontend calls, service integrations, and tests. Refactor any middleware or shared logic that interacts with route paths to ensure compatibility with the new versioned URLs. Revise API documentation to reflect the updated endpoints and structure. Follow API usage best practices as outlined in llm_context/payload3/best_practices.md throughout the implementation.\n</info added on 2025-07-02T19:59:11.961Z>"
1010:       },
1011:       {
1012:         "id": 24,
1013:         "title": "Integrate Supabase S3-Compatible Storage with Payload CMS Media Collection",
1014:         "description": "Installed and configured `@payloadcms/storage-s3` for media uploads. Refer to `llm_context/payload3/best_practices.md` for file upload security best practices.",
1015:         "status": "in-progress",
1016:         "dependencies": [],
1017:         "subtasks": [
1018:           {
1019:             "id": 1,
1020:             "title": "Package Installation",
1021:             "description": "Install required packages for S3-compatible storage integration",
1022:             "dependencies": [],
1023:             "details": "Install SDKs and libraries for S3 storage access (e.g., AWS SDK, boto3). Verify compatibility with existing infrastructure and resolve dependency conflicts.",
1024:             "status": "pending",
1025:             "testStrategy": ""
1026:           },
1027:           {
1028:             "id": 2,
1029:             "title": "Environment Variable Setup",
1030:             "description": "Configure secure access credentials",
1031:             "dependencies": [
1032:               1
1033:             ],
1034:             "details": "Set AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and S3_ENDPOINT_URL in environment variables. Implement secret management using Kubernetes Secrets or cloud KMS with base64 encoding.",
1035:             "status": "pending",
1036:             "testStrategy": ""
1037:           },
1038:           {
1039:             "id": 3,
1040:             "title": "Payload Config Update",
1041:             "description": "Modify application configuration for S3 storage",
1042:             "dependencies": [
1043:               2
1044:             ],
1045:             "details": "Update configuration files to reference S3 bucket paths, set block size (4-8MB), and configure task limits (4-8 concurrent tasks). Implement immutability settings matching retention policies.",
1046:             "status": "pending",
1047:             "testStrategy": ""
1048:           },
1049:           {
1050:             "id": 4,
1051:             "title": "Media Collection Configuration",
1052:             "description": "Set up storage buckets and access policies",
1053:             "dependencies": [
1054:               3
1055:             ],
1056:             "details": "Create S3 buckets with proper IAM roles and bucket policies. Configure CORS settings and object lifecycle rules. Enable versioning and object lock for immutability.",
1057:             "status": "pending",
1058:             "testStrategy": ""
1059:           },
1060:           {
1061:             "id": 5,
1062:             "title": "Integration Testing",
1063:             "description": "Validate end-to-end functionality",
1064:             "dependencies": [
1065:               4
1066:             ],
1067:             "details": "Perform read/write tests with sample payloads. Verify encryption in transit/at rest, error handling for permission failures, and performance under load. Test backup/restore workflows.",
1068:             "status": "pending",
1069:             "testStrategy": ""
1070:           },
1071:           {
1072:             "id": 6,
1073:             "title": "Documentation",
1074:             "description": "Create operational guides and runbooks",
1075:             "dependencies": [
1076:               5
1077:             ],
1078:             "details": "Document IAM policies, troubleshooting steps, and cost optimization practices. Include configuration examples and monitoring setup for storage metrics.",
1079:             "status": "pending",
1080:             "testStrategy": ""
1081:           }
1082:         ],
1083:         "details": "<info added on 2025-07-02T19:59:24.859Z>\nInstall the `@payloadcms/storage-s3` package and its peer dependencies. Set up environment variables for S3 access credentials, region, and bucket name to ensure secure configuration. Update the Payload CMS configuration to use the S3 storage adapter for the media collection, specifying the correct bucket and any required access policies. Configure the media collection to utilize the S3 storage, ensuring proper permissions and lifecycle policies are in place. Perform comprehensive integration testing to verify successful uploads, downloads, and deletions of media files via S3. Follow the security guidelines outlined in `llm_context/payload3/best_practices.md` to safeguard file uploads.\n</info added on 2025-07-02T19:59:24.859Z>"
1084:       },
1085:       {
1086:         "id": 25,
1087:         "title": "Implement Centralized Logging with Supabase",
1088:         "description": "Researched, designed, and implemented a centralized logging solution using Supabase. Refer to `llm_context/payload3/best_practices.md` for audit logging best practices.",
1089:         "status": "in-progress",
1090:         "dependencies": [],
1091:         "subtasks": [
1092:           {
1093:             "id": 1,
1094:             "title": "Research Supabase Logging Options",
1095:             "description": "Investigate Supabase's native logging capabilities (Logs Explorer) for auth, database, storage, and realtime logs. Evaluate Log Drains for exporting logs to external systems such as Datadog, including compliance and integration with custom HTTP endpoints.",
1096:             "dependencies": [],
1097:             "details": "Review Supabase documentation on Logs Explorer and Log Drains. Identify which log types are available natively and what export/integration options exist for centralized log management and extended retention.",
1098:             "status": "pending",
1099:             "testStrategy": ""
1100:           },
1101:           {
1102:             "id": 2,
1103:             "title": "Define Logging Schema",
1104:             "description": "Design a standardized log entry schema to be used across all services, ensuring inclusion of user context, payload diffs for mutations, and compliance with audit requirements.",
1105:             "dependencies": [
1106:               1
1107:             ],
1108:             "details": "Create a TypeScript interface for log entries, specifying fields such as timestamp, service, event_type, user_id, payload, and severity. Ensure schema supports audit trails and captures necessary context for compliance and troubleshooting.",
1109:             "status": "pending",
1110:             "testStrategy": ""
1111:           },
1112:           {
1113:             "id": 3,
1114:             "title": "Implement Application Logging",
1115:             "description": "Instrument both client and server applications to emit logs according to the defined schema, integrating with Supabase's logging APIs and external drains as needed.",
1116:             "dependencies": [
1117:               2
1118:             ],
1119:             "details": "Configure Supabase client with appropriate log levels. Integrate payload-auditor for admin actions, implement middleware for API route logging, and add error boundaries to capture context. Ensure logs are structured and transmitted according to the schema.",
1120:             "status": "pending",
1121:             "testStrategy": ""
1122:           },
1123:           {
1124:             "id": 4,
1125:             "title": "Configure Log Retention Policies",
1126:             "description": "Establish and automate log retention and archival policies for different log types, ensuring compliance with audit and regulatory requirements.",
1127:             "dependencies": [
1128:               3
1129:             ],
1130:             "details": "Define retention periods for audit, error, and debug logs. Implement automated cleanup scripts (e.g., Postgres DELETE statements) and configure archival triggers for compliance events. Document retention strategy in project documentation.",
1131:             "status": "pending",
1132:             "testStrategy": ""
1133:           },
1134:           {
1135:             "id": 5,
1136:             "title": "Establish Monitoring and Alerting",
1137:             "description": "Set up dashboards and alerting rules for real-time monitoring of log data, including anomaly detection and security event notifications.",
1138:             "dependencies": [
1139:               4
1140:             ],
1141:             "details": "Build dashboards for failure rates and user activity. Configure alerting for failed login attempts, sensitive data access, and policy violations. Implement basic anomaly detection logic and integrate with team notification channels.",
1142:             "status": "pending",
1143:             "testStrategy": ""
1144:           }
1145:         ],
1146:         "details": "<info added on 2025-07-02T19:59:37.327Z>\nResearch Supabase's native logging capabilities and evaluate self-hosted alternatives for centralized logging. Define a standardized log schema to capture both application events and system metrics. Implement application logging by integrating appropriate logging libraries and configuring ingestion pipelines to Supabase or the selected solution. Establish a log retention policy, including archival rules and compliance controls, to ensure data governance and regulatory adherence. Configure monitoring and alerting by setting up dashboards and anomaly detection for proactive issue identification. Ensure all audit logging aligns with best practices outlined in llm_context/payload3/best_practices.md.\n</info added on 2025-07-02T19:59:37.327Z>"
1147:       },
1148:       {
1149:         "id": 26,
1150:         "title": "Implement Security Best Practices",
1151:         "description": "Added explicit subtasks and implemented security best practices across the application. Refer to `llm_context/payload3/best_practices.md` for comprehensive security guidelines.",
1152:         "status": "in-progress",
1153:         "dependencies": [],
1154:         "subtasks": [
1155:           {
1156:             "id": 1,
1157:             "title": "Implement JWT Revocation Mechanism",
1158:             "description": "Create a JWT token blacklist mechanism using Redis cache and update authentication middleware to check token status.",
1159:             "dependencies": [],
1160:             "details": "Develop a revocation function that stores revoked JWT IDs (jti) in Redis with a 24-hour TTL. Update authentication middleware to verify token status against Redis before granting access.",
1161:             "status": "pending",
1162:             "testStrategy": ""
1163:           },
1164:           {
1165:             "id": 2,
1166:             "title": "Enhance Password and Cookie Security",
1167:             "description": "Implement bcrypt password hashing with a cost factor of 12 and configure HTTP-only, SameSite strict cookies.",
1168:             "dependencies": [
1169:               1
1170:             ],
1171:             "details": "Use bcrypt for password hashing and add a password strength meter using zxcvbn. Set secure cookie options (httpOnly, sameSite: 'strict', secure in production). Pen-test cookie settings using OWASP ZAP.",
1172:             "status": "pending",
1173:             "testStrategy": ""
1174:           },
1175:           {
1176:             "id": 3,
1177:             "title": "Apply Rate Limiting and Input Validation",
1178:             "description": "Integrate a token bucket rate limiter for API routes and create input validation middleware using Zod schemas.",
1179:             "dependencies": [
1180:               2
1181:             ],
1182:             "details": "Implement Upstash-based rate limiting with a sliding window algorithm. Develop middleware to validate request bodies with Zod schemas and perform fuzz testing with Schemathesis.",
1183:             "status": "pending",
1184:             "testStrategy": ""
1185:           },
1186:           {
1187:             "id": 4,
1188:             "title": "Refactor Middleware and Centralize Access Control",
1189:             "description": "Refactor authentication, validation, and rate limiting into modular middleware. Implement centralized access control and audit logging.",
1190:             "dependencies": [
1191:               3
1192:             ],
1193:             "details": "Modularize middleware for maintainability. Integrate audit logging using payload-auditor with Supabase. Ensure access control logic is centralized and auditable.",
1194:             "status": "pending",
1195:             "testStrategy": ""
1196:           },
1197:           {
1198:             "id": 5,
1199:             "title": "Accessibility, Testing, and Docker Security Hardening",
1200:             "description": "Conduct accessibility testing, implement automated security tests, and harden Docker configuration.",
1201:             "dependencies": [
1202:               4
1203:             ],
1204:             "details": "Perform accessibility audits, automate security and integration tests, and review Dockerfiles for best security practices (e.g., non-root user, minimal base images, secret management).",
1205:             "status": "pending",
1206:             "testStrategy": ""
1207:           }
1208:         ],
1209:         "details": "<info added on 2025-07-02T20:00:04.309Z>\nImplement comprehensive security best practices across all application layers, including:\n\n- JWT revocation mechanisms to ensure compromised tokens can be invalidated.\n- Secure handling of passwords and cookies, following recommended encryption and storage protocols.\n- Rate limiting to prevent abuse and mitigate brute-force attacks.\n- Robust input validation and sanitization to protect against injection and other input-based vulnerabilities.\n- Refactoring middleware to be modular and maintainable, ensuring consistent application of security policies.\n- Centralized access control management for consistent permission enforcement.\n- Audit logging to track security-relevant events and support incident response.\n- Overall security hardening, including Docker container security, accessibility considerations, and thorough security testing.\n\nRefer to llm_context/payload3/best_practices.md for detailed implementation guidelines.\n</info added on 2025-07-02T20:00:04.309Z>"
1210:       },
1211:       {
1212:         "id": 27,
1213:         "title": "Review and Update High-Complexity Tasks",
1214:         "description": "Reviewed all high-complexity tasks and updated their subtasks to incorporate best practices. Refer to `llm_context/llm_agent_insights/README.md` for task decomposition approaches.",
1215:         "status": "in-progress",
1216:         "dependencies": [],
1217:         "subtasks": [
1218:           {
1219:             "id": 1,
1220:             "title": "Audit and Prioritize High-Complexity Tasks",
1221:             "description": "Audit all existing high-complexity tasks using project complexity metrics and categorize them by domain (e.g., forms, API, deployment) as referenced in llm_context documentation. Prioritize the review sequence based on dependencies (e.g., Task 16 depends on Task 27), implementation status (focus on in-progress tasks like Task 27/28/29), and security criticality (middleware and access control tasks first). Document the prioritized list and rationale for sequencing.",
1222:             "dependencies": [],
1223:             "details": "Reference llm_context/*.md for complexity metrics and domain categorization. Ensure prioritization rationale is documented for traceability.",
1224:             "status": "pending",
1225:             "testStrategy": ""
1226:           },
1227:           {
1228:             "id": 2,
1229:             "title": "Review and Update Subtasks for Security and Validation",
1230:             "description": "For each prioritized high-complexity task, review existing subtasks against security best practices and validation requirements. Use llm_context/payload3/best_practices.md#security for access control, and ensure all subtasks include atomic operations and validation protocols. Identify gaps and propose atomic subtasks to address missing security or validation steps.",
1231:             "dependencies": [
1232:               1
1233:             ],
1234:             "details": "Cross-reference each subtask with relevant context files. Document all identified gaps and proposed updates, ensuring each update is atomic and testable.",
1235:             "status": "pending",
1236:             "testStrategy": ""
1237:           },
1238:           {
1239:             "id": 3,
1240:             "title": "Integrate Modular Middleware and Access Control Enhancements",
1241:             "description": "Update middleware and access control components to align with modular design and security standards. Apply Payload3 best practices from llm_context/payload3/best_practices.md#security, and ensure middleware updates do not break dependencies (e.g., Task 30 logging). Refactor components into atomic steps as needed.",
1242:             "dependencies": [
1243:               2
1244:             ],
1245:             "details": "Reference all relevant middleware and access control files. Include explicit verification steps to test for regressions and compliance with project standards.",
1246:             "status": "pending",
1247:             "testStrategy": ""
1248:           },
1249:           {
1250:             "id": 4,
1251:             "title": "Enhance Audit Logging, Accessibility, and Testing Protocols",
1252:             "description": "Implement or update audit logging for all schema and access control changes (e.g., Task 16), and enhance accessibility and testing protocols. Validate form accessibility against WCAG 2.1 using llm_context/forms/complex_forms.md#a11y, and add test cases for new logic (e.g., optimistic updates in Task 29).",
1253:             "dependencies": [
1254:               3
1255:             ],
1256:             "details": "Ensure all updates include clear audit trails, accessibility compliance checks, and automated test coverage. Document verification methods for each enhancement.",
1257:             "status": "pending",
1258:             "testStrategy": ""
1259:           },
1260:           {
1261:             "id": 5,
1262:             "title": "Update Deployment and Docker Security Configurations",
1263:             "description": "Review and update deployment scripts and Dockerfiles for security and maintainability. Apply patterns from llm_context/mcp_tools/repomix_automation.md#L23 and ensure secret rotation procedures are included (e.g., Task 31). Validate that all changes align with project deployment standards and do not introduce vulnerabilities.",
1264:             "dependencies": [
1265:               4
1266:             ],
1267:             "details": "Reference all deployment and Docker-related context files. Include explicit compliance checks and document all security improvements.",
1268:             "status": "pending",
1269:             "testStrategy": ""
1270:           }
1271:         ],
1272:         "details": "<info added on 2025-07-02T20:00:31.142Z>\nConduct a thorough audit of all high-complexity tasks as identified in the complexity analysis report. Review each task's existing subtasks for alignment with current best practices, security patterns, and maintainability standards. Refine the scope of existing subtasks where necessary, and introduce new subtasks to address any gaps in detailed implementation. Ensure all updates are informed by the task decomposition strategies and recommendations outlined in llm_context/llm_agent_insights/README.md. Document all changes and rationale for traceability and future reference.\n</info added on 2025-07-02T20:00:31.142Z>"
1273:       },
1274:       {
1275:         "id": 28,
1276:         "title": "Comprehensive Review and Enhancement of Form-Related Tasks and Subtasks",
1277:         "description": "Performed an in-depth review of all form-related tasks to ensure advanced patterns are correctly implemented. Refer to `llm_context/forms/complex_forms.md` for advanced form composition patterns.",
1278:         "status": "in-progress",
1279:         "dependencies": [],
1280:         "subtasks": [
1281:           {
1282:             "id": 1,
1283:             "title": "Audit and Catalog All Form Implementations Against Project Patterns",
1284:             "description": "Catalog all form implementations in the codebase, referencing `complex_forms.md` for pattern compliance. Validate multi-step isolation using step schema merging (Section 1), dynamic field arrays with `useFieldArray` (Section 2), and conditional field handling via `watch`/`unregister` (Section 3). Output a gap analysis report with compliance status for each form.",
1285:             "dependencies": [],
1286:             "details": "Include code snippets from `complex_forms.md` in the audit. Ensure each form is mapped to its corresponding pattern and note any deviations or missing features.",
1287:             "status": "pending",
1288:             "testStrategy": ""
1289:           },
1290:           {
1291:             "id": 2,
1292:             "title": "Review and Validate Form Composition, State, and Validation Layers",
1293:             "description": "Assess all forms for proper validation and state management. Audit Zod schema refinements for cross-field logic (Section 3), test async validation debouncing (Section 5), and verify error handling matches `README.md` UX patterns. Produce a validation deficiency matrix with remediation priorities.",
1294:             "dependencies": [
1295:               1
1296:             ],
1297:             "details": "Reference relevant code from `complex_forms.md` and ensure all validation logic is both robust and consistent with project standards.",
1298:             "status": "pending",
1299:             "testStrategy": ""
1300:           },
1301:           {
1302:             "id": 3,
1303:             "title": "Assess Dynamic Fields and File Upload Workflows",
1304:             "description": "Evaluate dynamic field arrays and file upload implementations. Check `useFieldArray` usage (Section 2), conditional fields, and file uploads using `react-dropzone` (Section 6). Integrate Payload upload hooks from `README.md` and add upload progress indicators. Output a standardized upload component with test cases.",
1305:             "dependencies": [
1306:               2
1307:             ],
1308:             "details": "Ensure all dynamic fields and file uploads are robust, user-friendly, and follow the documented patterns. Include code references and propose enhancements where needed.",
1309:             "status": "pending",
1310:             "testStrategy": ""
1311:           },
1312:           {
1313:             "id": 4,
1314:             "title": "Review Accessibility and User Experience Across All Forms",
1315:             "description": "Perform a WCAG 2.1 AA accessibility audit. Test ARIA roles and alert mechanisms (Section 7), keyboard navigation in multi-step flows, and contrast ratios in error states. Output an accessibility audit report with component-level fixes.",
1316:             "dependencies": [
1317:               3
1318:             ],
1319:             "details": "Embed relevant code snippets and ensure all forms are accessible and provide a high-quality user experience. Document any issues and proposed solutions.",
1320:             "status": "pending",
1321:             "testStrategy": ""
1322:           },
1323:           {
1324:             "id": 5,
1325:             "title": "Update Subtasks, Expand Testing, and Synchronize Documentation",
1326:             "description": "Based on previous findings, update all subtasks, expand test coverage (Playwright for multi-step flows, Vitest for Zod schema, accessibility regression tests), and synchronize documentation. Map findings to `complex_forms.md`, add new examples to `README.md`, and create a troubleshooting guide.",
1327:             "dependencies": [
1328:               4
1329:             ],
1330:             "details": "Ensure the documentation and test suite reflect all enhancements and fixes. Achieve at least 95% pattern coverage in tests and provide clear documentation for future maintenance.",
1331:             "status": "pending",
1332:             "testStrategy": ""
1333:           }
1334:         ],
1335:         "details": "<info added on 2025-07-02T20:00:46.909Z>\nConduct a comprehensive audit and catalog of all existing form-related tasks and subtasks. Validate that advanced form composition patterns are correctly implemented, including state management, validation logic, and handling of dynamic fields and file uploads. Assess each form for accessibility compliance and optimal user experience. Update or create subtasks as needed to address gaps or improvements. Ensure all relevant tests are in place and update documentation to reflect any changes. Reference llm_context/forms/complex_forms.md throughout the review to align with advanced form composition standards.\n</info added on 2025-07-02T20:00:46.909Z>"
1336:       },
1337:       {
1338:         "id": 29,
1339:         "title": "Review and Update Data Fetching and API Integration",
1340:         "description": "Reviewed and enhanced all data fetching and API integration tasks with advanced TanStack Query features. Refer to `llm_context/tanstack/README.md` for best practices in table implementation and integration points.",
1341:         "status": "in-progress",
1342:         "dependencies": [],
1343:         "subtasks": [
1344:           {
1345:             "id": 1,
1346:             "title": "Audit Existing Data Fetching Patterns",
1347:             "description": "Identify and document all current data-fetching implementations across the codebase, mapping each useQuery/useMutation hook to its API endpoint. Flag instances lacking pagination, SSR support, or caching strategies, and verify authentication token handling in query functions.",
1348:             "dependencies": [],
1349:             "details": "Cross-reference with llm_context/tanstack/README.md for TanStack best practices. Validate data models against llm_context/payload3/data_models.md. List all files/components using TanStack Query, noting missing features. Complexity: medium. Validation: All data-fetching hooks are mapped and reviewed for SSR, pagination, caching, and auth.",
1350:             "status": "pending",
1351:             "testStrategy": ""
1352:           },
1353:           {
1354:             "id": 2,
1355:             "title": "Implement SSR Hydration",
1356:             "description": "Enable server-side rendering (SSR) support for public routes by creating a getQueryClient utility, wrapping pages with HydrationBoundary, and prefetching critical data in getServerSideProps.",
1357:             "dependencies": [
1358:               1
1359:             ],
1360:             "details": "Update utils/queryClient.ts with makeQueryClient as per provided snippet. Modify pages (e.g., menu pages) to use HydrationBoundary. Ensure SSR hydration for all public routes. Complexity: high. Validation: SSR pages hydrate correctly with prefetched data and no hydration mismatches.",
1361:             "status": "pending",
1362:             "testStrategy": ""
1363:           },
1364:           {
1365:             "id": 3,
1366:             "title": "Optimize Pagination Strategies",
1367:             "description": "Implement smooth paginated data loading using keepPreviousData, cursor-based pagination for large datasets, and UI skeletons during transitions for collections with more than 50 items.",
1368:             "dependencies": [
1369:               2
1370:             ],
1371:             "details": "Refactor components displaying Contacts and Messages to use keepPreviousData and cursor-based pagination. Add loading skeletons for transitions. Complexity: medium. Validation: Pagination is seamless, with no data flicker and proper loading states.",
1372:             "status": "pending",
1373:             "testStrategy": ""
1374:           },
1375:           {
1376:             "id": 4,
1377:             "title": "Enhance Caching Strategies",
1378:             "description": "Reduce network requests by defining granular query keys, setting cache lifetimes based on data volatility, and implementing automatic garbage collection.",
1379:             "dependencies": [
1380:               3
1381:             ],
1382:             "details": "Update query keys to include collection, list, and filter params. Set staleTime and cacheTime per data type as per provided table. Ensure cache is cleared appropriately. Complexity: medium. Validation: Network requests are minimized and cache behaves as expected.",
1383:             "status": "pending",
1384:             "testStrategy": ""
1385:           },
1386:           {
1387:             "id": 5,
1388:             "title": "Implement Optimistic Updates",
1389:             "description": "Improve user experience for mutations by adding onMutate handlers to rollback failed updates, focusing on high-frequency mutations such as order status updates and forms requiring immediate feedback.",
1390:             "dependencies": [
1391:               4
1392:             ],
1393:             "details": "Update mutation hooks in forms (see llm_context/forms/complex_forms.md) to use onMutate and onError as per provided code. Test rollback on mutation failure. Complexity: medium. Validation: UI updates optimistically and rolls back on error.",
1394:             "status": "pending",
1395:             "testStrategy": ""
1396:           },
1397:           {
1398:             "id": 6,
1399:             "title": "Secure Authentication-Aware Queries",
1400:             "description": "Integrate authentication with data fetching by creating an auth interceptor for automatic token refresh and implementing role-based query enabling using user roles from the Users collection.",
1401:             "dependencies": [
1402:               5
1403:             ],
1404:             "details": "Add axios interceptor in apiClient.ts as per provided snippet. Update queries to use enabled based on user.role. Reference llm_context/payload3/data_models.md for roles. Complexity: high. Validation: Queries respect authentication and roles, and tokens refresh automatically.",
1405:             "status": "pending",
1406:             "testStrategy": ""
1407:           },
1408:           {
1409:             "id": 7,
1410:             "title": "Refactor Table Data Fetching",
1411:             "description": "Optimize table components by implementing server-side sorting/filtering, adding virtualization for large datasets, integrating Zustand for state persistence, and developing CSV export using query cache data.",
1412:             "dependencies": [
1413:               6
1414:             ],
1415:             "details": "Update all Payload collection table views to use server-side sorting/filtering and virtualization. Integrate Zustand as per llm_context/tanstack/README.md. Add CSV export functionality. Complexity: high. Validation: Tables handle large datasets efficiently and support CSV export.",
1416:             "status": "pending",
1417:             "testStrategy": ""
1418:           },
1419:           {
1420:             "id": 8,
1421:             "title": "Establish Monitoring and Metrics",
1422:             "description": "Track data-fetching performance by implementing query logging in development, tracking cache hit/miss ratios, and setting up performance alerts for slow queries, connecting to the existing logging system.",
1423:             "dependencies": [
1424:               7
1425:             ],
1426:             "details": "Integrate query logging and cache metrics with the logging system from Task 30. Set up alerts for slow queries. Complexity: medium. Validation: Monitoring captures relevant metrics and alerts trigger as expected.",
1427:             "status": "pending",
1428:             "testStrategy": ""
1429:           }
1430:         ],
1431:         "details": "<info added on 2025-07-02T20:03:09.041Z>\nAudit all existing data fetching and API integration code to ensure alignment with advanced TanStack Query features. Implement SSR hydration to support server-side rendering scenarios. Add optimistic update logic where appropriate to improve user experience. Enhance caching strategies for efficient data management and reduced network requests. Ensure queries are authentication-aware, handling token refresh and access control as needed. Refactor data fetching logic to utilize factory patterns for scalability and maintainability. Strengthen error handling to gracefully manage API failures and edge cases. Integrate proper loading and suspense states for seamless UI feedback. Follow best practices outlined in llm_context/tanstack/README.md, especially regarding table implementation and integration points.\n</info added on 2025-07-02T20:03:09.041Z>"
1432:       },
1433:       {
1434:         "id": 30,
1435:         "title": "Review and Update Middleware, Access Control, and Logging",
1436:         "description": "Consolidated access control logic, modularized middleware, and implemented comprehensive logging. Refer to `llm_context/payload3/best_practices.md` for relevant security and logging best practices.",
1437:         "status": "in-progress",
1438:         "dependencies": [],
1439:         "subtasks": [
1440:           {
1441:             "id": 1,
1442:             "title": "Audit Existing Access Points",
1443:             "description": "Identify and document all current access control checks across routes, APIs, and UI components. Note locations of permission logic and any inconsistencies to inform centralization.",
1444:             "dependencies": [],
1445:             "details": "Review server routes, API endpoints, and UI permission checks. Create a comprehensive list of where access control is enforced, referencing Payload CMS best practices and RBAC patterns. Document findings for use in subsequent refactoring.",
1446:             "status": "pending",
1447:             "testStrategy": ""
1448:           },
1449:           {
1450:             "id": 2,
1451:             "title": "Design and Implement Centralized RBAC Module",
1452:             "description": "Develop a core access control module (accessControl.js) implementing role-based access control with role inheritance and resource-based permission matrix.",
1453:             "dependencies": [
1454:               1
1455:             ],
1456:             "details": "Define roles (Admin > Editor > Viewer), create a permission matrix for resources, and implement the evaluateAccess(userRole, resource, action) function. Ensure alignment with centralized access principles and project security standards.",
1457:             "status": "pending",
1458:             "testStrategy": ""
1459:           },
1460:           {
1461:             "id": 3,
1462:             "title": "Refactor Access Checks to Use Central Module",
1463:             "description": "Replace all scattered permission checks with calls to the new evaluateAccess() function, ensuring all security contexts are routed through the centralized RBAC module.",
1464:             "dependencies": [
1465:               2
1466:             ],
1467:             "details": "Update server, API, and UI code to remove legacy permission logic. Integrate evaluateAccess() at all access control points, referencing the audit from subtask 1. Test for consistency and correctness.",
1468:             "status": "pending",
1469:             "testStrategy": ""
1470:           },
1471:           {
1472:             "id": 4,
1473:             "title": "Modularize and Standardize Middleware",
1474:             "description": "Decompose existing middleware into discrete modules (authMiddleware.js, auditMiddleware.js, errorHandler.js) and configure a unified middleware pipeline in server.js.",
1475:             "dependencies": [
1476:               3
1477:             ],
1478:             "details": "Implement authenticate, logOperation, and errorHandler middleware. Set up execution order in server.js. Ensure errorHandler provides unified error formatting and HTTP status mapping. Reference Payload CMS hooks and project security docs.",
1479:             "status": "pending",
1480:             "testStrategy": ""
1481:           },
1482:           {
1483:             "id": 5,
1484:             "title": "Implement Security Headers and Middleware Hardening",
1485:             "description": "Configure helmet for strict CSP and security headers, add API-specific headers, and integrate additional security middleware (CSRF, input validation, session timeout).",
1486:             "dependencies": [
1487:               4
1488:             ],
1489:             "details": "Use helmet with custom CSP and HSTS. Add X-Content-Type-Options and X-Frame-Options to API responses. Integrate csurf for CSRF protection, Zod for input validation, and session timeout logic. Ensure compliance with project security standards.",
1490:             "status": "pending",
1491:             "testStrategy": ""
1492:           },
1493:           {
1494:             "id": 6,
1495:             "title": "Integrate Comprehensive Audit and Centralized Logging",
1496:             "description": "Define audit log schema, implement Payload CMS hooks for logging state transitions, and configure centralized log aggregation with Winston and Elasticsearch.",
1497:             "dependencies": [
1498:               5
1499:             ],
1500:             "details": "Create AuditLog interface with required fields. Use beforeChange and afterChange hooks to capture critical operations. Set up Winston logger with Elasticsearch transport, 90-day retention, and sensitive data redaction.",
1501:             "status": "pending",
1502:             "testStrategy": ""
1503:           },
1504:           {
1505:             "id": 7,
1506:             "title": "Validation, Automated Testing, and Security Scanning",
1507:             "description": "Develop Jest tests for permission matrix and log integrity, and integrate OWASP ZAP into CI for automated security scanning of headers and access control.",
1508:             "dependencies": [
1509:               6
1510:             ],
1511:             "details": "Write tests to verify RBAC enforcement and audit log completeness. Set up OWASP ZAP in CI pipeline for weekly scans. Ensure test coverage and log integrity meet project targets.",
1512:             "status": "pending",
1513:             "testStrategy": ""
1514:           },
1515:           {
1516:             "id": 8,
1517:             "title": "Documentation and CI/CD Pipeline Integration",
1518:             "description": "Document architecture, middleware usage, access control, and logging. Integrate checks in CI/CD for security headers, audit log coverage, and access control test coverage.",
1519:             "dependencies": [
1520:               7
1521:             ],
1522:             "details": "Update project docs to reflect new middleware, RBAC, and logging architecture. Add CI/CD steps to verify security headers, audit log coverage (>95%), and access control test coverage (>90%).",
1523:             "status": "pending",
1524:             "testStrategy": ""
1525:           }
1526:         ],
1527:         "details": "<info added on 2025-07-02T20:03:24.842Z>\nThis task involves centralizing access control logic to a single location for maintainability and consistency, refactoring existing middleware into modular and reusable components, and implementing security headers to enhance application security. Integrate audit logging to track sensitive operations and ensure all critical actions are logged. Establish a centralized logging system to aggregate logs from all components, ensuring comprehensive coverage of sensitive operations. Conduct thorough testing to verify the effectiveness of access control, middleware modularity, and logging mechanisms. Provide detailed documentation of the updated architecture, middleware modules, access control flows, and logging strategies. Follow the security and logging best practices outlined in llm_context/payload3/best_practices.md throughout the implementation.\n</info added on 2025-07-02T20:03:24.842Z>"
1528:       },
1529:       {
1530:         "id": 31,
1531:         "title": "Review and Enhance Deployment, Docker, and CI/CD Tasks",
1532:         "description": "Reviewed and updated all deployment, Docker, and CI/CD related tasks for best practices. Refer to `llm_context/mcp_tools/repomix_automation.md` for CI/CD integration patterns and automated context generation.",
1533:         "status": "in-progress",
1534:         "dependencies": [],
1535:         "subtasks": [
1536:           {
1537:             "id": 1,
1538:             "title": "Dockerfile Security Audit",
1539:             "description": "Review all Dockerfiles for security best practices, including non-root user execution, read-only filesystems, minimized image layers, resource limits, and up-to-date base images. Generate a vulnerability report with remediation steps.",
1540:             "dependencies": [],
1541:             "details": "Context: Review Dockerfiles in the project repository as per 2025 best practices. Reference `llm_context/mcp_tools/repomix_automation.md` for automation guidelines. Ensure no Dockerfile runs as root, all base images are scanned and updated, and filesystems are set to read-only where possible.",
1542:             "status": "pending",
1543:             "testStrategy": ""
1544:           },
1545:           {
1546:             "id": 2,
1547:             "title": "CI/CD Pipeline Analysis",
1548:             "description": "Map existing deployment workflows and identify missing LLM-specific checks, such as automated bias detection, performance benchmarking, and version control for prompts/datasets.",
1549:             "dependencies": [
1550:               1
1551:             ],
1552:             "details": "Context: Analyze current CI/CD pipelines as described in `llm_context/tanstack/README.md`. Document areas lacking LLM-specific deployment gates and recommend improvements for bias and performance validation.",
1553:             "status": "pending",
1554:             "testStrategy": ""
1555:           },
1556:           {
1557:             "id": 3,
1558:             "title": "Secret Management Implementation",
1559:             "description": "Audit current secret storage locations, design and implement integration with HashiCorp Vault, and ensure secrets are encrypted, rotated, and access is logged.",
1560:             "dependencies": [
1561:               1
1562:             ],
1563:             "details": "Context: Use `llm_context/payload3/best_practices.md` to guide secure secret management. Migrate secrets from environment files or hardcoded locations to Vault, set up dynamic secrets, and enforce access controls.",
1564:             "status": "pending",
1565:             "testStrategy": ""
1566:           },
1567:           {
1568:             "id": 4,
1569:             "title": "Environment Configuration Setup",
1570:             "description": "Define a matrix for environment-specific configurations (dev, staging, production), parameterize environment variables, and implement configuration validation tests.",
1571:             "dependencies": [
1572:               2,
1573:               3
1574:             ],
1575:             "details": "Context: Reference `llm_context/state_management/README.md` for environment management. Ensure secrets and configs are isolated per environment and validated before deployment.",
1576:             "status": "pending",
1577:             "testStrategy": ""
1578:           },
1579:           {
1580:             "id": 5,
1581:             "title": "Monitoring Integration",
1582:             "description": "Implement container activity logging and set up a vulnerability alerting system to monitor Docker and CI/CD pipeline security events.",
1583:             "dependencies": [
1584:               1,
1585:               3
1586:             ],
1587:             "details": "Context: Use guidance from `llm_context/payload3/best_practices.md`. Integrate tools for real-time monitoring of container activity and automated alerts for detected vulnerabilities.",
1588:             "status": "pending",
1589:             "testStrategy": ""
1590:           },
1591:           {
1592:             "id": 6,
1593:             "title": "Documentation and Workflow Validation",
1594:             "description": "Document all updated workflows, including Docker, CI/CD, secret management, and environment configuration. Validate that all enhancements are correctly implemented and reproducible.",
1595:             "dependencies": [
1596:               1,
1597:               2,
1598:               3,
1599:               4,
1600:               5
1601:             ],
1602:             "details": "Context: Consolidate documentation for all security and deployment enhancements. Include validation steps and checklists to ensure workflows are robust and compliant with best practices.",
1603:             "status": "pending",
1604:             "testStrategy": ""
1605:           }
1606:         ],
1607:         "details": "<info added on 2025-07-02T20:03:40.844Z>\nConduct a comprehensive audit of all existing deployment and CI/CD workflows to identify areas for improvement in best practices and security. Update Dockerfiles to incorporate security hardening measures, such as minimizing image layers, using non-root users, and regularly updating base images. Implement secure secret management solutions to prevent sensitive data exposure in both deployment and CI/CD processes. Enhance CI/CD pipelines to improve efficiency, reliability, and error handling, ensuring robust rollback and notification mechanisms. Establish and manage environment-specific configurations to support seamless deployments across different stages. Thoroughly document all workflows, configurations, and security measures, and validate each workflow through testing to ensure correctness and compliance. Utilize the CI/CD integration patterns and automated context generation guidelines provided in llm_context/mcp_tools/repomix_automation.md.\n</info added on 2025-07-02T20:03:40.844Z>"
1608:       },
1609:       {
1610:         "id": 32,
1611:         "title": "Validate and Sync Database Schema Between Payload CMS and Supabase",
1612:         "description": "Researched and compared the current state of the database schema between Payload CMS and Supabase. Refer to `llm_context/payload3/data_models.md` for detailed Payload 3.0 data models and relationships.",
1613:         "status": "in-progress",
1614:         "dependencies": [],
1615:         "subtasks": [
1616:           {
1617:             "id": 1,
1618:             "title": "Export Payload and Supabase Schemas",
1619:             "description": "Extract the current schema definitions from both Payload CMS and Supabase. For Payload, use the `dump` command to export the schema as JSON, referencing collections, fields, and relationships as defined in `llm_context/payload3/data_models.md`. For Supabase, use `pg_dump --schema-only` via the Supabase CLI, filtering to relevant schemas.",
1620:             "dependencies": [],
1621:             "details": "Ensure access to the Payload config at `src/payload.config.ts` and necessary authentication credentials. For Supabase, obtain the connection string and project ID. Store the exported Payload schema and Supabase `schema.sql` in a designated workspace directory for further analysis.",
1622:             "status": "pending",
1623:             "testStrategy": ""
1624:           },
1625:           {
1626:             "id": 2,
1627:             "title": "Analyze and Document Schema Differences",
1628:             "description": "Perform a structural and constraint-based comparison between the exported Payload and Supabase schemas. Generate a delta report identifying missing tables, field type mismatches (e.g., `richText` vs `TEXT`), relationship inconsistencies, and constraint differences.",
1629:             "dependencies": [
1630:               1
1631:             ],
1632:             "details": "Use `data_models.md` as the source of truth for Payload expectations and compare against the Supabase `schema.sql` dump. Pay special attention to relationship mappings (e.g., `Users.locations` ↔ `Locations`), field type conversions (such as `richText` to `JSONB`), and constraint validation (indexes, unique constraints, foreign keys). Document all findings in a structured report.",
1633:             "status": "pending",
1634:             "testStrategy": ""
1635:           },
1636:           {
1637:             "id": 3,
1638:             "title": "Generate Migration Scripts for Supabase",
1639:             "description": "Based on the documented differences, create SQL migration scripts to synchronize Supabase's schema with Payload's data model. Scripts should handle table/column creation, type conversions, and constraint synchronization.",
1640:             "dependencies": [
1641:               2
1642:             ],
1643:             "details": "Reference the delta report and Supabase compatibility matrix to ensure all migrations are valid. Include handling for JSONB fields for Lexical content, proper foreign key relationships, and ensure scripts are idempotent and compatible with Supabase's declarative migration system.",
1644:             "status": "pending",
1645:             "testStrategy": ""
1646:           },
1647:           {
1648:             "id": 4,
1649:             "title": "Apply and Validate Migrations on Supabase",
1650:             "description": "Run pre-execution checks on the migration scripts using `supabase migration lint`, then apply the migrations atomically with `supabase migration up`. Validate the resulting schema using Payload's `validate` command and test relationship queries.",
1651:             "dependencies": [
1652:               3
1653:             ],
1654:             "details": "Ensure Supabase project environment variables and service role credentials are available. After applying migrations, run Payload's validation, execute test queries for all relationships, confirm Lexical field integrity via the admin UI, and check RLS policies for relationship-based access.",
1655:             "status": "pending",
1656:             "testStrategy": ""
1657:           },
1658:           {
1659:             "id": 5,
1660:             "title": "Document and Version-Control Schema Changes",
1661:             "description": "Commit the updated `schema.sql`, Payload configs, and migration scripts to the project's Git repository. Include a clear commit message and store reverse migration scripts for rollback capability.",
1662:             "dependencies": [
1663:               4
1664:             ],
1665:             "details": "Follow repository path and branch naming conventions. Use a commit message such as `feat(schema): Sync Payload<->Supabase @v1.2`. Store rollback scripts in `migrations/down/20250702_sync_revert.sql` and tag the previous schema version for reference. Integrate with Task 23's API versioning path (`/api/v1/`).",
1666:             "status": "pending",
1667:             "testStrategy": ""
1668:           }
1669:         ],
1670:         "details": "<info added on 2025-07-02T20:03:53.563Z>\nExport the current database schemas from both Payload CMS and Supabase. Perform a detailed comparison to identify discrepancies, referencing the data models and relationships specified in llm_context/payload3/data_models.md. Document all differences found. Develop a plan for schema synchronization, including the generation of necessary migration scripts. Apply the migrations to align both schemas, ensuring that the Payload CMS state is updated accordingly. Document each step of the process and commit all changes to version control for traceability and future reference.\n</info added on 2025-07-02T20:03:53.563Z>"
1671:       },
1672:       {
1673:         "id": 33,
1674:         "title": "Implement /api/users/me API Route for Authenticated User Info",
1675:         "description": "Created a secure API route at `/api/users/me` that returns the current authenticated user's information. Refer to `llm_context/payload3/best_practices.2.md` for authentication best practices, including JWT and session management. For TypeScript typing issues related to `PayloadRequest` and custom user types, consult `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md`.",
1676:         "status": "in-progress",
1677:         "dependencies": [
1678:           3,
1679:           23
1680:         ],
1681:         "subtasks": [],
1682:         "details": "<info added on 2025-07-02T20:04:12.730Z>\nImplement the `/api/users/me` API route to securely return the current authenticated user's information. This includes:\n\n- Creating the API endpoint and ensuring it is protected by authentication middleware.\n- Securely extracting and validating authentication tokens (such as JWT) from the request, following best practices outlined in `llm_context/payload3/best_practices.md`.\n- Fetching the authenticated user's data from the database or user store.\n- Handling errors gracefully, including invalid or missing tokens and user not found scenarios.\n- Applying strong TypeScript typing for both the request (including custom user types and `PayloadRequest` issues) and response objects, referencing `llm_context/responses/typescript_errors.md` and `llm_context/responses/typescript_error_resolution_v2.md` for guidance on resolving typing issues.\n- Writing comprehensive tests to cover successful responses, authentication failures, and error cases for the endpoint.\n</info added on 2025-07-02T20:04:12.730Z>"
1683:       }
1684:     ],
1685:     "metadata": {
1686:       "created": "2025-07-02T13:20:00.000Z",
1687:       "description": "Updated master task list organized by phase/milestone",
1688:       "updated": "2025-07-02T20:06:14.536Z"
1689:     }
1690:   }
1691: }
</file>

</files>
